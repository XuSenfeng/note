# 音频

CODEC的本质是ADC和DAC，那么采样率和采样位数就是衡量一款音频CODEC 最重要的指标。比如常见音频采样率有 8K、44.1K、48K、192K甚至 384K 和 768K，采样位数常见的有 8 位、16 位、24 位、32 位。采样率和采样位数越高，那么音频 CODEC 越能真实的还原声音，也就是大家说的 HIFI。

实际的音频处理的流程

1.   读取音频文件
2.   软件界面
3.   使用I2S传输数据给音频芯片

使用整个框架称为`ALSA`分为三部分

1.   SOC: SOC使用的音频接口, 比如IMX6ULL使用的SAL接口, 半导体厂商提供
2.   Codec: 具体的音频芯片, WM8960, IIC驱动等, Codec厂商编写
3.   板载部分: Machine部分, 具体的SOC以及Codec需要结合的部分

## 硬件

### 音频解码

![image-20251118151740230](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/mac-picture/image-20251118151740230.png)

1.   输入接口，作为立体声音频输入源，一共提供了三路，分别为 LINPUT1/RINPUT1、LINPUT2/RINPUT2、LINPUT3/RINPUT3。麦克风或线路输入就连接到此接口上，这部分是需要硬件工程师重点关心的
2.   此部分是WM8960的输出接口，比如输出给耳机或喇叭，SPK_LP/SPKLN用于连接_左声道的喇叭，支持1W的8Ω喇叭。SPK\_RP/SPKRN用于连接右声道的喇叭，同样支持 1W\_的 8Ω喇叭，最后就是HP\_L/HP\_R，用于连接耳机
3.   此部分是数字音频接口，用于和主控制器连接，有5根线，用于主控制器和WM8960之间进行数据“沟通”。主控制器向WM8960的DAC发送的数据，WM8960的ADC向主控制传递的数据都是通过此音频接口来完成的。这个接口非常重要，是我们驱动开发人员重点关注的，此接口支持I2S格式

+   **ADCDAT**： ADC数据输出引脚，采集到的音频数据转换为数字信号以后通过此引脚传输给主控制器。
+   **ADCLRC**：ADC 数据对齐时钟，也就是帧时钟(LRCK)，用于切换左右声道数据，此信号的频率就是采样率。此引脚可以配置为 GPIO功能，配置为 GPIO以后 ADC就会使用 DACLRC引脚作为帧时钟。
+   **DACDAT**：DAC 数据输入引脚，主控器通过此引脚将数字信号输入给 WM8960 的 DAC。
+   **DACLRC**：DAC数据对齐时钟，功能和ADCLRC一样，都是帧时钟(LRCK)，用于切换左右声道数据，此信号的频率等于采样率。
+   **BCLK**：位时钟，用于同步。
+   **MCLK**：主时钟，WM8960工作的时候还需要一路主时钟，此时钟由 I.MX6ULL提供，MCLK 频率等于采样率的 256 或 384 倍，因此大家在 WM8960 的数据手册里面常看到 MCLK=256fs或 MCLK=384fs

4.   此部分为控制接口，是一个标准的 I2C 接口，WM8960 要想工作必须对其进行配置，这个I2C接口就是用于配置 WM8960的

### 音频编解码芯片

ES8388 是一款高性能、低功耗且低成本的音频 CODEC 芯片。它集成了 2 通道 ADC、2 通道 DAC、麦克风放大器、耳机放大器、数字音效处理功能以及模拟信号混合增益功能。

1.   ADC（模数转换）24位高精度，8kHz~96kHz采样率, 95dB动态范围和信噪比, 支持立体声/单声道麦克风，内置放大器, 自动增益（AGC）、噪声门、模拟混音
2.   DAC（数模转换）24位高精度，8kHz~96kHz采样率, 96dB动态范围和信噪比, 40mW耳机驱动，免耦电容输出, 支持音效增强、混音和增益调节
3.   低功耗 1.8V~3.3V供电，超低功耗, 播放仅7mW，录放同步仅 16mW
4.   系统接口 支持 I²C/SPI配置, 支持 I²S、DSP/PCM等音频格式, 可做主机或从机，兼容多种时钟和采样率

![image-20251118152615315](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/mac-picture/image-20251118152615315.png)

## IIS

飞利浦公司提出的一种用于数字音频设备之间进行音频数据传输的总线, I2S总线用于主控制器和音频 CODEC 芯片之间传输音频数据。因此，要想使用 I2S 协议，主控制器和音频 CODEC都得支持I2S协议

**SCK**：串行时钟信号，也叫做位时钟(BCLK)，音频数据的每一位数据都对应一个 SCK，立体声都是双声道的，因此SCK=2×采样率×采样位数。比如采样率为44.1KHz、16位的立体声音频，那么`SCK=2**×**44100**×**16=1411200Hz=1.4112MHz`。

**WS**：字段(声道)选择信号，也叫做LRCK，也叫做帧时钟，用于切换左右声道数据，WS为“1”表示正在传输左声道的数据，WS为“0”表示正在传输右声道的数据。WS的频率等于采样率，比如采样率为 44.1KHz的音频，WS=44.1KHz。

**SD**：串行数据信号，也就是我们实际的音频数据，如果要同时实现放音和录音，那么就需要 2根数据线，比如WM8960的ADCDAT和DACDAT，就是分别用于录音和放音。不管音频数据是多少位的，数据的最高位都是最先传输的。数据的最高位总是出现在一帧开始后(LRCK变化)的第2个SCK脉冲处。

>   有时候为了使音频 CODEC 芯片与主控制器之间能够更好的同步，会引入另外一个叫做MCLK的信号，也叫做主时钟或系统时钟，一般是采样率的 256倍或 384倍

![image-20251118153112142](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/mac-picture/image-20251118153112142.png)

如果数据时钟一个周期的位数比实际的数据的数量大, 在实际的使用的时候需要确定一下对齐方式

![image-20251118202024397](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/mac-picture/image-20251118202024397.png)

## SAI驱动

i.MX 6ull芯片上具有iic、sai和lcd fpc接口，其中iic和sai接口用来控制和播放音频， fpc接口用来播放视频。通过这些接口，用户可以把相关外设连接到芯片上，从而来实现音视频的播放。

SAI 接口（串行音频接口）适用于许多立体声或单声道应用。例如，它可配置为支持 I2S 标准、LSB 或 MSB 对齐、PCM/DSP、TDM 和 AC’97 等协议。将音频模块配置为发 送器时，SAI 接口可提供 SPDIF 输出。

### 设备树

#### I2C部分

由于实际的控制使用的接口是i2c的, 所以需要在i2c的节点下面添加设备, 这个设备是被内核支持的, 所以可以直接使用, 具体使用的驱动放在sound/soc/codecs文件夹下面

>   Documentation/devicetree/bindings/sound/wm8960.txt
>
>   Required properties:
>
>     - compatible : "wlf,wm8960"
>
>     - reg : the I2C address of the device.
>
>   Optional properties:
>     - wlf,shared-lrclk: This is a boolean property. If present, the LRCM bit of
>   	R24 (Additional control 2) gets set, indicating that ADCLRC and DACLRC pins
>   	will be disabled only when ADC (Left and Right) and DAC (Left and Right)
>   	are disabled.
>   	When wm8960 works on synchronize mode and DACLRC pin is used to supply
>   	frame clock, it will no frame clock for captrue unless enable DAC to enable
>   	DACLRC pin. If shared-lrclk is present, no need to enable DAC for captrue.
>
>   - 这是一个bool类型的属性，如果添加了此属性，WM8960的R24寄存器的 LRCM位(bit2)就会置 1。当 LRCM 为 1 的时候只有当 ADC 和 DAC全部关闭以后 ADCLRC和DACLRC时钟才会关闭
>     - wlf,capless: This is a boolean property. If present, OUT3 pin will be
>   	enabled and disabled together with HP_L and HP_R pins in response to jack
>   	detect events.
>   - bool 类型的属性，如果添加了此属性，OUT3 引脚将会使能，并且为了响应耳机插入响应事件，HP_L和HP_R这两个引脚都会关闭。

实际应用如下

```json
codec2: wm8960@1a {
  compatible = "wlf,wm8960";
  reg = <0x1a>;
  clocks = <&clks IMX6UL_CLK_SAI2>;
  clock-names = "mclk";
  wlf,shared-lrclk;
};
```

为了更好的同步，一般都会额外提供一条 MCLK时钟

#### SAI部分

Documentation/devicetree/bindings/sound/fsl-sai.txt

 imx6ull.dtsi文件中会有关于 SAI相关接口的描述，这部分是 NXP原厂编写的，我们不需要做任何修改

```c
  sai2: sai@0202c000 {
    compatible = "fsl,imx6ul-sai",
           "fsl,imx6sx-sai";
    reg = <0x0202c000 0x4000>;
    interrupts = <GIC_SPI 98 IRQ_TYPE_LEVEL_HIGH>;
    clocks = <&clks IMX6UL_CLK_SAI2_IPG>,
       <&clks IMX6UL_CLK_DUMMY>,
       <&clks IMX6UL_CLK_SAI2>,
       <&clks 0>, <&clks 0>;
    clock-names = "bus", "mclk0", "mclk1", "mclk2", "mclk3";
    dma-names = "rx", "tx";
    dmas = <&sdma 37 24 0>, <&sdma 38 24 0>;
    status = "disabled";
  };
```

我们需要将其打开，也就是设置 status属性的值为“okay”

```json
&sai2 {
	pinctrl-names = "default";
	pinctrl-0 = <&pinctrl_sai2>;

	assigned-clocks = <&clks IMX6UL_CLK_SAI2_SEL>,
			  <&clks IMX6UL_CLK_SAI2>;
	assigned-clock-parents = <&clks IMX6UL_CLK_PLL4_AUDIO_DIV>;
	assigned-clock-rates = <0>, <11289600>;

	status = "okay";
};
```

默认使用的引脚的驱动如下

```json
pinctrl_sai2: sai2grp {
  fsl,pins = <
    MX6UL_PAD_JTAG_TDI__SAI2_TX_BCLK	0x17088
    MX6UL_PAD_JTAG_TDO__SAI2_TX_SYNC	0x17088
    MX6UL_PAD_JTAG_TRST_B__SAI2_TX_DATA	0x11088
    MX6UL_PAD_JTAG_TCK__SAI2_RX_DATA	0x11088
    MX6UL_PAD_JTAG_TMS__SAI2_MCLK		0x17088
  >;
};
```

#### sound节点

可以参考Documentation/devicetree/bindings/sound/imx-audio-wm8962.txt, 使用的驱动文件是sound/soc/fsl/imx-wm8960.c, 这部分是wm8960以及SAI部分的匹配连接使用的节点, 理论这个文件是需要我们自己进行编写的文件

```json
sound {
  compatible = "fsl,imx6ul-evk-wm8960",
       "fsl,imx-audio-wm8960";
  model = "wm8960-audio";
  cpu-dai = <&sai2>;			/* CPU使用的dai是sai2 */
  audio-codec = <&codec>;	/* 使用的codec节点是codec */
  asrc-controller = <&asrc>;
  codec-master;
  gpr = <&gpr 4 0x100000 0x100000>;
  /*
               * hp-det = <hp-det-pin hp-det-polarity>;
   * hp-det-pin: JD1 JD2  or JD3
   * hp-det-polarity = 0: hp detect high for headphone
   * hp-det-polarity = 1: hp detect high for speaker
   */
  hp-det = <3 0>;
  /* hp-det-gpios = <&gpio5 4 0>;
     mic-det-gpios = <&gpio5 4 0>; */
  audio-routing =
    "Headphone Jack", "HP_L",
    "Headphone Jack", "HP_R",
    "Ext Spk", "SPK_LP",
    "Ext Spk", "SPK_LN",
    "Ext Spk", "SPK_RP",
    "Ext Spk", "SPK_RN",
    "LINPUT2", "Mic Jack",
    "LINPUT3", "Mic Jack",
    "RINPUT1", "Main MIC",
    "RINPUT2", "Main MIC",
    "Mic Jack", "MICB",
    "Main MIC", "MICB",
    "CPU-Playback", "ASRC-Playback",
    "Playback", "CPU-Playback",
    "ASRC-Capture", "CPU-Capture",
    "CPU-Capture", "Capture";
};
```

+   **compatible**：非常重要，用于匹配相应的驱动文件，有两个属性值，在整个 linux内核源码中搜索这两个属性值即可找到对应的驱动文件，这里找到的驱动文件为：sound/soc/fsl/imx-wm8960.c。
+   **model**：最终用户看到的此声卡名字，这里设置为“wm8960-audio”。
+   **cpu-dai**：CPU DAI(Digital Audio Interface)句柄，这里是sai2这个节点。
+   **audio-codec**：音频解码芯片句柄，也就是 WM8960 芯片，这里为“codec1”和“codec2”这两个节点。
+   **gpr**：控制 I.MX6ULL SAI MCLK接口输出 11.289MHz时钟。
+   **asrc-controller**：asrc 控制器，asrc 全称为 Asynchronous Sample Rate Converters，翻译过来就是异步采样频率转化器。
+   **hp-det**：耳机插入检测引脚设置，第一个参数为检测引脚，3表示JD3为检测引脚。第二个参数设置检测电平，设置为 0的时候，hp检测到高电平表示耳机插入；设置为 1的时候，hp检测到高电平表示是喇叭，也就是耳机拔出了。
+   **audio-routing**：音频器件一系列的连接设置，每个条目都是一对字符串，第一个字符串是连接的sink，第二个是连接的 source(源)

## ALSA框架

ALSA 是 Advanced Linux Sound Architecture（高级的 Linux 声音体系）的缩写，目前已经成为了 linux下的主流音频体系架构，提供了音频和 MIDI 的支持

alsa-lib 是一套 Linux 应用层的 C 语言函数库，为音频应用程序开发提供了一套统一、标准的接口，应用程序只需调用这一套 API 即可完成对底层声卡设备的操控，譬如播放与录音

用户空间的 alsa-lib 对应用程序提供了统一的 API 接口，这样可以隐藏驱动层的实现细节，简化了应用程序的实现难度、无需应用程序开发人员直接去读写音频设备节点。所以对于我们来说，学习音频应用编程其实就是学习 alsa-lib 库函数的使用、如何基于 alsa-lib 库函数开发音频应用程序。

### ASoc

建立在标准ALSA驱动层上，为了更好地支持嵌入式处理器和移动设备
中的音频Codec的一套软件体系。在ASoc出现之前，内核对于SoC中的音频已经有部分的支持，不过会有一些局限性：

1.  Codec驱动与SoC CPU的底层耦合过于紧密，这种不理想会导致代码的重复，例如，仅是wm8731的驱动，当时Linux中有分别针对4个平台的驱动代码。
2.  音频事件没有标准的方法来通知用户，例如耳机、麦克风的插拔和检测，这些事件在移动设备中是非常普通的，而且通常都需要特定于机器的代码进行重新对音频路劲进行配置。
3.  当进行播放或录音时，驱动会让整个codec处于上电状态，这对于PC没问题，但对于移动设备来说，这意味着浪费大量的电量。同时也不支持通过改变过取样频率和偏置电流来达到省电的目的。

ASoC正是为了解决上述种种问题而提出的，目前已经被整合至内核的代码树中：sound/soc。ASoC不能单独存在，他只是建立在标准ALSA驱动上的一个它必须和标准的ALSA驱动框架相结合才能工作。

>   我们实际主要需要处理的Machine部分的文档为Documentation/sound/alsa/soc/machine.txt

## 配置

```
-> Device Drivers
  -> Sound card support (SOUND [=y])
    -> Advanced Linux Sound Architecture (SND [=y])
      -> <> OSS Mixer API //不选择
      -> <> OSS PCM (digital audio) API //不选择
```

```
-> Device Drivers
  -> Sound card support (SOUND [=y])
    -> Advanced Linux Sound Architecture (SND [=y])
      -> ALSA for SoC audio support (SND_SOC [=y])
        -> SoC Audio for Freescale CPUs
          -> <*> Asynchronous Sample Rate Converter (ASRC) module support
          //选中
          -> <*> SoC Audio support for i.MX boards with wm8960 //选中
```

## 使用

移植成功以后可以在`/dev/snd`目录查看对应的音频驱动

+   **controlC0**：用于声卡控制，C0表示声卡 0。
+   **pcmC0D0c** 和 **pcmC0D1c**：用于录音的pcm设备，其中的“COD0”和“C0D1”分别表示声卡0中的设备0和设备1，最后面的“c”是capture的缩写，表示录音。
+   **pcmC0D0p** 和 **pcmC0D1p**：用于播放的pcm设备，其中的“COD0”和“C0D1”分别表示声卡0中的设备0和设备1，最后面的“p”是 playback的缩写，表示放音。
+   **timer**：定时器。

在实际使用的时候需要移植alsa-lib和alsa-utils