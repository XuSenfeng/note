# 序列模型

实际工作里面又很多的数据是有时间序列的, 比如电影的评分会受到评奖的影响, 同样题材电影随时间变化, 导演的负面报道等

还有音乐, 语言和文本等, 以及人的交互, 预测股票等

## 统计工具

处理序列数据需要统计工具和新的深度神经网络架构。

![image-20250205210840704](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502052108828.png)

其中，用xt表示价格，即在时间步（timestep）t∈Z+时，观察到的价格xt。请注意，t对于本文中的序列通常 是离散的，并在整数或其子集上变化。假设一个交易员想在t日的股市中表现良好，于是通过以下途径预测xt

x~t~∼ P(x~t~ | x~t~−1,...,x~1~)

![image-20250205211512307](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502052115355.png)

> 正向和反向, 反向不一定是成立的, 已知结果推原理

![image-20250205211828134](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502052118182.png)

使用前面的样本推出来一个和前面样本相同的新的样本, 需要计算f和p, 有几种假设

![image-20250205212009505](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502052120554.png)

这样计算的时候所需要计算的数据数量是一定的, 是参数的数量总是不变的，至少 在t >τ时如此，这就使我们能够训练一个上面提及的深度网络。这种模型被称为**自回归模型**

![image-20250205212335849](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502052123894.png)

保留一些对过去观测的总结h~t~, 是一个向量或者一个数之类的数据, 是一个不断更新的数据, 这样可以减少相关的变量, 计算更加容易, 由于h~t~从未被观测到，这类模型也被称 为隐变量自回归模型

## 实际使用

这里写一个使用四个数据预测下一个数据的模型

```python
%matplotlib inline
import torch
from torch import nn
from d2l import torch as d2l
```

生成一个初始的数据

```python
T = 1000 # 总共产生1000个点
time = torch.arange(1, T + 1, dtype=torch.float32)
x = torch.sin(0.01 * time) + torch.normal(0, 0.2, (T,))
d2l.plot(time, [x], 'time', 'x', xlim=[1, 1000], figsize=(6, 3))
```

![image-20250205215501661](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502052155713.png)

```python
tau = 4
features = torch.zeros((T- tau, tau))
for i in range(tau):
    features[:, i] = x[i: T- tau + i]
labels = x[tau:].reshape((-1, 1))
# 每一项记录前面的4个点，预测是下一个点
print(features[0],features.shape, labels.shape)
"""
tensor([-0.1637,  0.2549,  0.0939,  0.1010]) torch.Size([996, 4]) torch.Size([996, 1])
"""
```

使用前四个数据为输入, 下一个数据是输出, 下面划分训练的数据集

```python
batch_size, n_train = 16, 600
 # 只有前n_train个样本用于训练
train_iter = d2l.load_array((features[:n_train], labels[:n_train]),
        batch_size, is_train=True)
```

```python
# 初始化网络权重的函数
def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.xavier_uniform_(m.weight)
 # 一个简单的多层感知机
def get_net():
    net = nn.Sequential(nn.Linear(4, 10),
                        nn.ReLU(),
                        nn.Linear(10, 1))
    net.apply(init_weights)
    return net
# 平方损失。注意：MSELoss计算平方误差时不带系数1/2
# 均方误差（Mean Squared Error，MSE）是回归问题中最常用的性能度量
loss = nn.MSELoss(reduction='none')
```

建立一个简单的网络

````python
onestep_preds = net(features)
d2l.plot([time, time[tau:]],
    [x.detach().numpy(), onestep_preds.detach().numpy()], 'time',
    'x', legend=['data', '1-step preds'], xlim=[1, 1000],
    figsize=(6, 3))
````



预测一下

![image-20250205215646885](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502052156935.png)

在实际使用的时候, 我们需要使用自己预测的数据作为参数预测下一个数据

```python
multistep_preds = torch.zeros(T)
multistep_preds[: n_train + tau] = x[: n_train + tau]
for i in range(n_train + tau, T):
    # 使用前面的数据预测为下一个的参数
    multistep_preds[i] = net(
        multistep_preds[i- tau:i].reshape((1,-1)))
```

```python
d2l.plot([time, time[tau:], time[n_train + tau:]],
    [x.detach().numpy(), onestep_preds.detach().numpy(),
    multistep_preds[n_train + tau:].detach().numpy()], 'time',
    'x', legend=['data', '1-step preds', 'multistep preds'],
    xlim=[1, 1000], figsize=(6, 3))
```

![image-20250205215935851](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502052159904.png)

下面是一个随着预测范围增大出现的偏移情况

```python
max_steps = 64
features = torch.zeros((T- tau- max_steps + 1, tau + max_steps))
 # 列i（i<tau）是来自x的观测，其时间步从（i）到（i+T-tau-max_steps+1）
for i in range(tau):
    features[:, i] = x[i: i + T- tau- max_steps + 1]
# 列i（i>=tau）是来自（i-tau+1）步的预测，其时间步从（i）到（i+T-tau-max_steps+1）
# 针对tau到tau + max_steps范围内的每一个i，
# 模型net使用之前tau个时间步长的数据来对时间步i进行预测。
# 预测结果被重塑以匹配样本数量。
for i in range(tau, tau + max_steps):
    features[:, i] = net(features[:, i- tau:i]).reshape(-1)
```

features前四个是原始的数据, 之后是使用这四个数据依次预测得到的数据

```python
steps = (1, 4, 16, 64)
d2l.plot([time[tau + i- 1: T- max_steps + i] for i in steps],
    [features[:, (tau + i- 1)].detach().numpy() for i in steps], 'time', 'x',
    legend=[f'{i}-step preds' for i in steps], xlim=[5, 1000],
    figsize=(6, 3))
```

![image-20250205223542214](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502052235296.png)

