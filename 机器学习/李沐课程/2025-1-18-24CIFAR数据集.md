# CIFAR数据集

是一个kaggle里面的一个比赛, 是一个比较大的数据集, 下面记录一下使用图片以及一个csv分类的时候的几种处理方式

## 在加载的时候分类

首先需要提取出来不同的类别

```python
leaves_labels = sorted(list(set(labels_dataframe['label'])))
n_classes = len(leaves_labels)
```

使用这个了别可以建立一个对应的表, 建立以后还需要一个返回的表

```python
class_to_num = dict(zip(leaves_labels, range(n_classes)))
num_to_class = {v:k for k,v in class_to_num.items()}
"""
{0: 'abies_concolor',
 1: 'abies_nordmanniana',
 2: 'acer_campestre',
 3: 'acer_ginnala',
 4: 'acer_griseum',
 5: 'acer_negundo',
 6: 'acer_palmatum',
 ...
"""
```

下面建立一个Dataset的子类, 实现数据的初始化以及给数据的标号进行返回对应的数据

```python
class LeavesData(Dataset):
    def __init__(self, csv_path, file_path, mode='train', valid_ratio=0.2, resize_height=256, resize_width=256):
        """
        Args:
            csv_path (string): csv 文件路径
            img_path (string): 图像文件所在路径
            mode (string): 训练模式还是测试模式
            valid_ratio (float): 验证集比例
        """
        self.file_path = file_path
        self.resize_height = resize_height
        self.resize_width = resize_width
        self.mode = mode
        
        # 读取 csv 文件
        self.data_info = pd.read_csv(csv_path)
        self.data_len = len(self.data_info.index)
        self.train_len = int(self.data_len * (1 - valid_ratio))

        if mode == 'train':
            # 训练集, 分割出来一部分数据
            self.train_image = np.asarray(self.data_info.iloc[0:self.train_len]['image'])
            self.train_label = np.asarray(self.data_info.iloc[0:self.train_len]['label'])
            self.image_arr = self.train_image
            self.label_arr = self.train_label
            self.data_len = len(self.train_image) # 记录数据的大小
        elif mode == 'valid':
            # 验证集
            self.valid_image = np.asarray(self.data_info.iloc[self.train_len:]['image'])
            self.valid_label = np.asarray(self.data_info.iloc[self.train_len:]['label'])
            self.image_arr = self.valid_image
            self.label_arr = self.valid_label
            self.data_len = len(self.valid_image)
        else:
            # 测试集
            self.test_image = np.asarray(self.data_info.iloc[0:]['image'])
            self.image_arr = self.test_image
            self.data_len = len(self.test_image)

        print('Finished reading the {} set of Leaves Dataset ({} samples found)'.format(mode, self.data_len))

    def __getitem__(self, index):
        # 从 image_arr中得到索引对应的文件名
        single_image_name = self.image_arr[index]
        # 读取图像文件
        img_as_img = Image.open(self.file_path + single_image_name)
        
        # 如果需要将灰度图转换为 RGB 彩色图
        if img_as_img.mode != 'RGB':
            img_as_img = img_as_img.convert('RGB')
        
        normalize = torchvision.transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])
        # 对数据进行一次预处理
        if self.mode == "train":                                                
            train_augs = torchvision.transforms.Compose([
                torchvision.transforms.RandomResizedCrop(224),
                torchvision.transforms.RandomHorizontalFlip(),
                torchvision.transforms.ToTensor(), normalize])
            img_as_img = train_augs(img_as_img)
        else:
            test_augs = torchvision.transforms.Compose([
                torchvision.transforms.Resize(256),
                torchvision.transforms.CenterCrop(224),
                torchvision.transforms.ToTensor(), normalize])
            img_as_img = test_augs(img_as_img)

        # 得到图像的 label
        if self.mode == 'test':
            label = -1
        else:
            label = self.label_arr[index]
            label = class_to_num[label] # 把标号转为数组tensor
            label = torch.tensor(label)

        return img_as_img, label
    
    def __len__(self):
        return self.data_len
```

数据集的加载

```python
train_path = "../data/train.csv"
test_path = "../data/test.csv"
img_path = "../data/"

train_dataset = LeavesData(train_path, img_path, mode='train')
valid_dataset = LeavesData(train_path, img_path, mode='valid')
test_dataset = LeavesData(test_path, img_path, mode='test')

train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)
valid_loader = DataLoader(dataset=valid_dataset, batch_size=128)
test_loader = DataLoader(dataset=test_dataset, batch_size=128)

for i, data in enumerate(train_loader):
    inputs, labels = data
    print(inputs.size(), labels)
    break
"""
torch.Size([128, 3, 224, 224]) tensor([164,  69, 118,  25, 116,  40, 130,  50, 153, 133,  94,  76,  58,   3,
        104,   5, 126,   2,   0, 125,  25,  51, 141,  14,  36,  77, 107,  10,
         59, 101,  59,  81, 123,  95,  30,  61,  40, 162, 174, 110, 145,  58,
         31, 164,  45, 107,  28, 159,  11,  67,  22, 131,  57,  78,  86, 123,
        155, 130,  83,  14, 108, 108, 161, 147, 108,  28,  69, 106,  75, 144,
         80, 128, 111,  32,  96,  84,  59,  23,  53, 107,  14, 135,  42,   2,
         68,   7,  71,   4,  37,  65, 126,  57,  77, 145,  24,  52,  71,  37,
          0,  99,  32,  70, 173, 147, 144,  71,  64,  92,  12,  28, 162,  68,
         20, 145, 115,  65,  45, 132,  69, 111,  39, 130,  17, 157, 130, 142,
         99,  30])
"""
```

## 按照文件夹进行记录

```python
def read_csv_file(fname):
    """读取文件给文件标签返回一个字典"""
    with open(fname, 'r') as f:
        lines = f.readlines()
    # rstrip() 方法用于删除字符串末尾的空白字符, split() 方法用于把一个字符串分割成字符串列表
    tokens = [line.rstrip().split(',') for line in lines]
    return dict((tokens[0], tokens[1]) for i, tokens in enumerate(tokens))

labels = read_csv_file(os.path.join(data_dir, 'train.csv'))
```

> 读取一个csv文件, 以字典的形式进行返回

+ 建立一个复制的函数, 把文件按照csv文件里面的分类进行按文件夹存储

```python
def copyfile(filename, target_dir):
    """将文件复制到目标目录。"""
    os.makedirs(target_dir, exist_ok=True)
    shutil.copy(filename, target_dir)

# data_dir: 数据集目录, labels: {filename: label}, valid_ratio: 验证集中的样本占比
def reorg_train_valid(data_dir, labels, valid_ratio):
    # 将返回一个按出现次数由高到低排列的元组列表，
    # 其中每个元组包含一个标签和该标签出现的次数。
    # collections.Counter用于统计标签的个数, most_common()方法返回最常见的n个元素
    n = collections.Counter(labels.values()).most_common()[-1][1]
    # 返回小于或等于指定数值的最大整数值
    n_valid_per_label = max(1, math.floor(n * valid_ratio)) 
    label_count = {}
    for file in os.listdir(os.path.join(data_dir, 'images')):
        # 读取文件标签
        file = os.path.join('images', file)
        file = file.replace('\\', '/')
        label = labels[file]
        fname = os.path.join(data_dir, file)
        # 将文件复制到目标目录
        copyfile(
            fname,
            os.path.join(data_dir, 'train_valid_test', 'train_valid', label))
        # 如果标签不在label_count中或者label_count[label] < n_valid_per_label
        if label not in label_count or label_count[label] < n_valid_per_label:
            copyfile(
                fname,
                os.path.join(data_dir, 'train_valid_test', 'valid', label))
            # 返回指定键的值, 如果值不在字典中返回默认值0, 对记录的标签数加1
            label_count[label] = label_count.get(label, 0) + 1 
        else:
            copyfile(
                fname,
                os.path.join(data_dir, 'train_valid_test', 'train', label))
    return n_valid_per_label
```

+ 读取数据集

```python
def reorg_test(data_dir):
    for file in os.listdir(os.path.join(data_dir, 'images_test')):
        # 读取文件标签
        file = os.path.join('images_test', file)
        file = file.replace('\\', '/')
        copyfile(
            os.path.join(data_dir, file),
            os.path.join(data_dir, 'train_valid_test', 'test', 'unknown'))
```

> 记录测试文件为unknow类型

+ 实际的建立函数

```python
def reorg_leave_data(data_dir,valid_ratio):
    labels = read_csv_file(os.path.join(data_dir, 'train.csv'))
    reorg_train_valid(data_dir, labels, valid_ratio)
    reorg_test(data_dir)

valid_ratio = 0.1
reorg_leave_data(data_dir, valid_ratio)
```

+ 数据预处理

```python
transform_train = torchvision.transforms.Compose([
    # 在高度和宽度上将图像放大到244像素的大小
    torchvision.transforms.RandomResizedCrop(224, scale=(0.64, 1.0), ratio=(1.0, 1.0)),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(),
    # 对图像的每个通道做标准化
    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])

transform_test = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
```

+ 应用

```python
train_ds, train_valid_ds = [
    torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'train_valid_test', folder),
        transform=transform_train)
    for folder in ['train', 'train_valid']]
valid_ds, test_ds = [
    torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'train_valid_test', folder),
        transform=transform_test)
    for folder in ['valid', 'test']]
```

