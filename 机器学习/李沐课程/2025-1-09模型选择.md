# 模型选择

## 训练误差以及泛化误差

分别在数据以及训练集上面的误差, 一般关注第二个

## 验证数据集以及测试数据集

验证数据集: 这一个数据集可以用于评估模型的好坏

测试数据集: 这个数据集只使用一次, 用于最后的测试

实际使用的时候可能出现数据的数量比较小, 这时候可以使用K-则交叉验证

### K-则交叉验证

把数据集分割为K块, 其中一个作为验证数据集, 其他的数据作为训练数据集, 依次遍历所有的数据集, 获取所有误差的均值

#### 代码实现

```python
# 进行
def get_k_fold_data(k, i, X, y):
    assert k > 1
    fold_size = X.shape[0] // k # 每一次的验证集大小
    X_train, y_train = None, None
    for j in range(k):
        idx = slice(j * fold_size, (j + 1) * fold_size)
        X_part, y_part = X[idx, :], y[idx]
        if j == i:
            X_valid, y_valid = X_part, y_part
        elif X_train is None:
            X_train, y_train = X_part, y_part
        else:
            X_train = torch.cat([X_train, X_part], 0) # 沿着0轴拼接
            y_train = torch.cat([y_train, y_part], 0)
    return X_train, y_train, X_valid, y_valid

def k_fold(k, X_train, y_train, num_epochs,
           learning_rate, weight_decay, batch_size):
    train_l_sum, valid_l_sum = 0, 0
    for i in range(k):
        data = get_k_fold_data(k, i, X_train, y_train)
        net = get_net()
        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,
                                   weight_decay, batch_size)
        train_l_sum += train_ls[-1] # 取最后一次训练的值
        valid_l_sum += valid_ls[-1]
        if i == 0:
            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],
                     xlabel='epoch', ylabel='rmse', xlim=[1, num_epochs],
                     legend=['train', 'valid'], yscale='log')
        print(f'fold {i + 1}, train log rmse {float(train_ls[-1]):f}, '
              f'valid log rmse {float(valid_ls[-1]):f}')
    return train_l_sum / k, valid_l_sum / k
```



## 欠拟合过拟合

![image-20250109161219268](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501091612338.png)

> 模型过于复杂的时候可以记录所有的数据, 泛化性比较差

![image-20250109161233734](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501091612787.png)

> 模型的复杂度

![image-20250109161302322](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501091613379.png)

模型的容量难以估计, 不同种类的模型之间更难以比较

给定一个模型的种类, 一般关注两个点

+ 参数的个数
+ 参数的值的范围

### VC维

对于一个分类模型, VC等于一个最大的数据集, 不管如何给定标号, 都存在一个模型对他完整分类

![image-20250109161326218](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501091613280.png)

实际这一个的应用很难

### 数据复杂度

+ 样本的数量
+ 每个样本的元素个数
+ 时间空间结构
+ 多样性

### 实际测试

试用以下的函数进行测试, 给不同数量的输入参数预测权重

![image-20250109162108727](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501091621764.png)

```python
# 欠拟合过拟合
import math
import numpy as np
import torch 
from torch import nn
from d2l import torch as d2l
```

+ 代码实现上面的表达式, 记录一下初始的x在features, 中间每一项的值x^n^/n!在poly_features, 用于之后的训练输入, 以及实际的输出y在labels

````python
max_degree = 20
n_train, n_test = 100, 100
true_w = np.zeros(max_degree)
true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])
# 获取一个随机的特征, [2n, 1]的x数组
features = np.random.normal(size=(n_train + n_test, 1))
np.random.shuffle(features)
# 进行指数变换, 获取一个[2n, max_degree]数组, 每一行依次是x^0, x^1, x^2, ..., x^(max_degree-1)
poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))
for i in range(max_degree):
    # 对每一行的数字依次除以i!, 也就是gamma(i+1)
    poly_features[:, i] /= math.gamma(i + 1)
# 进行一次线性变换, 乘以权重, 加上噪声, 得到y
labels = np.dot(poly_features, true_w)
labels += np.random.normal(scale=0.1, size=labels.shape)
````

+ 转为tensor

```python
# 将数据转换为tensor
true_w, features, poly_features, labels = [
    torch.tensor(x, dtype=torch.float32)
    for x in [true_w, features, poly_features, labels]]
# 第一个时输入参数, 第二个是平方除以阶乘, 第三个是乘以权重的输出
features[:2], poly_features[:2], labels[:2]
```

+ 获取一个平均loss的评估函数

```python
def evaluate_loss(net, data_iter, loss):  #@save
    """评估给定数据集上模型的损失。"""
    metric = d2l.Accumulator(2)  # 损失的总和, 样本数量
    for X, y in data_iter:
        l = loss(net(X), y)
        metric.add(l.sum(), l.numel())
    return metric[0] / metric[1]
```

+ 实际的训练函数

```python
def train(train_features, test_features, train_labels, test_labels,
          num_epochs=400):
    loss = nn.MSELoss() # 损失函数均方差
    input_shape = train_features.shape[-1]
    # 线性回归模型,bias是False, 因为我们已经在特征中加入了偏置
    net = nn.Sequential(nn.Linear(input_shape, 1, bias=False))
    batch_size = min(10, train_labels.shape[0])
    # 将数据集转换为迭代器
    train_iter = d2l.load_array((train_features, train_labels.reshape(-1, 1)),
                                batch_size)
    test_iter = d2l.load_array((test_features, test_labels.reshape(-1, 1)),
                                 batch_size, is_train=False)
    trainer = torch.optim.SGD(net.parameters(), lr=0.01)
    # 图示显示
    animator = d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log',
                            xlim=[1, num_epochs], ylim=[1e-3, 1e2],
                            legend=['train', 'test'])
    for epoch in range(num_epochs):
        d2l.train_epoch_ch3(net, train_iter, loss, trainer)
        if epoch == 0 or (epoch + 1) % 20 == 0:
            animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),
                                     evaluate_loss(net, test_iter, loss)))
    print('weight:', net[0].weight.data.numpy()) 
```

+ 开始测试
+ 正常的拟合, 使用四个权重, 所以给四个预测

```python
train(poly_features[:n_train, :4], poly_features[n_train:, :4],
        labels[:n_train], labels[n_train:])

"""
weight: [[ 5.0277095  1.287504  -3.4781575  5.320093 ]]
"""
```

![image-20250109162927882](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501091629930.png)

+ 给的输入数据比较小, 预测的维度比较低

```python
# 欠拟合, 实际的数据数量比较低, 但是模型的复杂度比较高
train(poly_features[:n_train, :2], poly_features[n_train:, :2],
        labels[:n_train], labels[n_train:])

"""
weight: [[3.604659  3.4564216]]
"""
```

![image-20250109163015513](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501091630562.png)

+ 给的输入过多

```python
train(poly_features[:n_train, :], poly_features[n_train:, :],
        labels[:n_train], labels[n_train:])

"""
weight: [[ 4.94952154e+00  1.40046442e+00 -3.01533484e+00  4.69035625e+00
  -1.56668198e+00  1.22568822e+00 -4.53702867e-01  2.31323943e-01
   1.18733019e-01  1.92391336e-01 -2.90535507e-03  3.65933515e-02
  -1.56559631e-01 -1.77428693e-01 -2.16690585e-01 -1.79554939e-01
   1.89996302e-01  1.67450756e-01 -1.12046316e-01  1.59917325e-02]]
"""
```

![image-20250109163047561](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501091630613.png)

## 权重衰退weight_decay

[权重衰减weight_decay参数从入门到精通_weight decay-CSDN博客](https://blog.csdn.net/zhaohongfei_358/article/details/129625803)

一种用于处理过拟合的方法, 在控制模型的容量的时候, 可以控制模型的参数个数以及控制参数的范围

![image-20250109220937109](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501092209180.png)

可以通过显示w的大小来进行实现, 通常限制b的作用不大, 通过计算使得误差函数最小

![image-20250109221417939](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501092214005.png)

![image-20250109221451957](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501092214017.png)

![image-20250109222032740](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501092220823.png)

这个绿色的椭圆表示，当W1和W2取绿色椭圆上的点时，Loss都是2。所以，当我们没有惩罚项时，对于Loss=2，取椭圆上的这些点都可以。若取到右上角的点，那么 W1和W2 的值就会比较大，所以我们希望W1和W2尽量往左下靠。

> ![image-20250109223058788](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501092230841.png)
>
> 当w离原点比较远的时候, 会在下降函数里面占比比较大, 所以把实际的值拉向原点
>
> 1. 模型的权重越大，Loss就会越大。
> 2. λ越大，权重衰减的就越厉害
> 3. 若 λ过大，那么原本Loss的占比就会较低，最后模型就光顾着让模型权重变小了，最终模型效果就会变
>
> **注:** 实际使用的数值一般是0.001-0.0001

![image-20250109222448554](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501092224623.png)

比实际的更新函数多减去一项, 这一个方式使得通过L2的正则项是的模型的参数不会太大, 控制模型的复杂度, 正则项权重是控制模型复杂度的超参数

### 实际实现

![image-20250110184540176](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501101845421.png)

```python
%matplotlib inline
import torch
from torch import nn
from d2l import torch as d2l
```

+ 初始化数据集

```python
# 生成数据集, 使用较小的数据集容易发生过拟合
n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5
# true_w 实际是一个200维的向量，每个元素都是0.01, true_b是一个标量，值为0.05
true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05
# 生成数据集一个20*200的x矩阵，每一行都是一个200维的向量，共20行, 和一个20*1的y向量
train_data = d2l.synthetic_data(true_w, true_b, n_train)
train_iter = d2l.load_array(train_data, batch_size)
# x 100 * 200 × w 200 * 1 = y 100 * 1
test_data = d2l.synthetic_data(true_w, true_b, n_test)
test_iter = d2l.load_array(test_data, batch_size, is_train=False)
```

+ 初始化一下使用的参数

```python
def init_params():
    w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)
    b = torch.zeros(1, requires_grad=True)
    return [w, b]
```

+ 一个计算惩罚函数

```python
def l2_penalty(w):
    # 这里只惩罚w，不惩罚b, 对w进行平方求和再除以2, w只有一维
    return torch.sum(w.pow(2)) / 2
```

+ 实际的训练函数

```python
def train(lambd):
    # 获取实际使用的训练初始参数
    w, b = init_params()
    # 初始化两个函数
    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss
    num_epochs, lr = 200, 0.003
    # 用于显示图像
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',
                            xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            with torch.enable_grad():
                l = loss(net(X), y) + l2_penalty(w) * lambd # 添加了L2范数惩罚项
            l.sum().backward()
            d2l.sgd([w, b], lr, batch_size)
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss),
                                     d2l.evaluate_loss(net, test_iter, loss)))
    print('L2 norm of w:', torch.norm(w).item())
```

+ 实验

```python
train(lambd=0) # 没有惩罚项
```

![image-20250110230824685](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501102308830.png)

> 直接发生过拟合

```python
train(lambd=3) # 惩罚项为3
```

![image-20250110230856371](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501102308466.png)

### 简单实现

```python
def train_concise(wd):
    net = nn.Sequential(nn.Linear(num_inputs, 1))
    for param in net.parameters():
        param.data.normal_()
    loss = nn.MSELoss()
    num_epochs, lr = 100, 0.003
    # 带有权重衰减的优化器, params是一个字典，每个参数都有自己的权重衰减
    # 这里的net[0].weight和net[0].bias都是参数, 作用于权重衰减的只有net[0].weight
    trainer = torch.optim.SGD([{
        "params": net[0].weight,
        'weight_decay': wd}, {
        "params" : net[0].bias}], lr=lr) # 对权重进行衰减
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',
                            xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            with torch.enable_grad():
                trainer.zero_grad()
                l = loss(net(X), y)
            l.backward()
            trainer.step()
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss),
                                     d2l.evaluate_loss(net, test_iter, loss)))
    print('L2 norm of w:', net[0].weight.norm().item())
```

实际的结果和上面差不多

![image-20250110232140913](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501102321005.png)

![image-20250110232147856](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501102321938.png)
