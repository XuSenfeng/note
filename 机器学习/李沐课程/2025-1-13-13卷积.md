# 卷积

## 计算交叉相乘

在使用MLP进行处理图片的时候, 现在的图片像素比较大, 会导致分类的时候进行一次单隐藏层放大元素的个数可能比所有的个体的数量都高

图片识别两个原则: 1. 平移不变性, 同一个图像出现在图片的不同位置是等价的 2. 局部性, 使用局部的信息即可获取

把输入和输出变为一个矩阵, 权重是一个四维的张量

> 在矩阵运算的时候，其实最后都可以转成我们常见的二维矩阵运算，遵循的原则是：在多维矩阵相乘中，需最后两维满足shape匹配原则，最后两维才是有数据的矩阵，前面的维度只是矩阵的排列而已
>
> [【全面理解多维矩阵运算】多维（三维四维）矩阵向量运算-超强可视化 - 知乎](https://zhuanlan.zhihu.com/p/337829793)

![image-20250113154428046](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131544152.png)

![image-20250113154418438](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131544505.png)

![image-20250113110117738](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131101851.png)

![image-20250113110624570](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131106620.png)

> 上面的右侧式子对v的下标进行变化, 使用[X]~i,j~和[H]~i,j~分别表示输入图像和隐藏表示中位置（i,j）处的像素
>
>  为了使每个隐藏神经元都能接收到每个输入像素的信息，我们将参数从权重矩阵（如同我们先前在多层感知机中所做的那样）替换为四阶权重张量W。假设U包含偏置参数，我们可以将全连接层形式化地表示为
>
> ![image-20250113121226604](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131212684.png)

### 平移不变

检测对象在输入X中的平移，应该仅导致隐藏表示H中的平移。也就是说，V和U实际上不依赖于(i,j)的值，即[V]~i,j,a,b~=[V]~a,b~。并且U是一个常数，比如u。

![image-20250113121324829](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131213868.png)

这就是*卷积*（convolution）。我们是在使用系数[V]~a,b~对位置(i,j)附近的像素(i+a,j+b)进行加权得到[H]i,j。 注意，[V]~a,b~的系数比[V]~i,j,a,b~少很多，因为前者不再依赖于图像中的位置。

### 局部性

为了收集用来训练参数[H]i,j的相关信息，我们不应偏离到距(i,j)很远的地方。这意味着在|a|>Δ或|b|>Δ的范围之外，我们可以设置[V]a,b=0。

![image-20250113121708434](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131217493.png)

卷积神经网络是包含卷积层的一类特殊的神经网络。 在深度学习研究社区中，V被称为*卷积核*（convolution kernel）或者*滤波器*（filter），亦或简单地称之为该卷积层的*权重*，通常该权重是可学习的参数。

### 优势

以前，多层感知机可能需要数十亿个参数来表示网络中的一层，而现在卷积神经网络通常只需要几百个参数，而且不需要改变输入或隐藏表示的维数。 参数大幅减少的代价是，我们的特征现在是平移不变的，并且当确定每个隐藏活性值时，每一层只包含局部的信息。

以上所有的权重学习都将依赖于归纳偏置。当这种偏置与现实相符时，我们就能得到样本有效的模型，并且这些模型能很好地泛化到未知数据中。 但如果这偏置与现实不符时，比如当图像不满足平移不变时，我们的模型可能难以拟合我们的训练数据。

### 卷积

我们记得cross-correlation的loop顺序是**从左到右，从上到下**，

而convolution是**从右到左，从下到上**

![image-20250113154609553](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131546680.png)

它相当于将filter翻转了一次再进行cross-correlation

> 由于使用起来的效果相同, 所以实际没有使用严格的卷积

## 卷积层

### 二维交叉相关

![image-20250113153354169](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131533544.png)

对应位置相乘再相加, 19 = 0\*0 + 1\*1 + 3\*2 + 4\*3

输出大小略小于输入大小。这是因为卷积核的宽度和高度大于1， 而卷积核只与图像中每个大小完全适合的位置进行互相关运算。 所以，输出大小等于输入大小n~h~×n~w~减去卷积核大小k~h~×k~w~，

![image-20250113153704413](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131537458.png)

实际使用的时候可以使用一个图像乘以一次卷积获取一个图像处理的效果

也可以使用一维的(文本, 语言, 时序), 三维的(视频, 医学图像, 气象地图)

### 填充和步幅

每一次的卷积会导致图像的缩小, 使用大的卷积核缩小的更快, 想使用更深的就不可行

填充, 在外部加入额外的行和列

![image-20250113171136774](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131711921.png)

这时候输出的图像变为

![image-20250113171224768](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131712828.png)

> 添加p~h~行填充（大约一半在顶部，一半在底部）和p~w~列填充（左侧大约一半，右侧一半）
>
> 我们需要设置ph=k~h~−1和pw=k~w~−1
>
> 假设kh是奇数，我们将在高度的两侧填充ph/2行。 如果kh是偶数，则一种可能性是在输入顶部填充⌈ph/2⌉行，在底部填充⌊ph/2⌋行

```python
def comp_conv2d(conv2d, X):
    # (1, 1)是加一个batch_size和通道数, 为了适应conv2d的输入
    X = X.reshape((1, 1) + X.shape)
    Y = conv2d(X)
    return Y.reshape(Y.shape[2:]) # 去掉前两个维度

# 这里的padding=1是为了保持输入和输出的形状, 在四周各填充一排0
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)
X = torch.rand(size=(8, 8))
comp_conv2d(conv2d, X).shape
"""
torch.Size([8, 8])
"""
conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))
comp_conv2d(conv2d, X).shape
"""
torch.Size([8, 8])
"""
```

步幅: 移动窗口的时候移动的位置大小

当垂直步幅为sh、水平步幅为sw时，输出形状为

![image-20250113171735937](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131717010.png)

如果我们设置了p~h~=k~h~−1和p~w~=k~w~−1，则输出形状将简化为

![image-20250113171926074](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131719116.png)

可以整除的时候![image-20250113171942348](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131719582.png)

```python
onv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)
comp_conv2d(conv2d, X).shape
"""
torch.Size([4, 4])
"""
conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))
comp_conv2d(conv2d, X).shape
"""
torch.Size([2, 2])
(8 - (3 + 1) + (3 - 1)) / 2     (8 + 2 - (5 - 1) + (4 - 1)) / 4
"""
```

> 通常使用的卷积核的大小是一个单数的

#### 实际使用

一般填充使得图像大小不变, 步幅一般计算量允许的时候使用1, 核大小一般是最重要的参数

### 多输入和输出通道

彩色的图片有RGB三个通道, 在处理多通道的时候, 每一个通道都有自己的卷积核, 结果是所有的卷积核的和

![image-20250113181908364](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131819465.png)

实际的输出是一个单通道的, 如果希望有多个输出, 可以提高卷积核的个数

输入X : c~i~×n~h~×n~w~

核W : c~o~×c~i~×m~h~×m~w~

输出Y : c~o~×m~h~×m~w~

> 每一个不同的输出通道识别不同的东西

### 1×1卷积层

不识别空间模式, 只是一个融合通道

![image-20250113182939083](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131829186.png)

1×1卷积层需要的权重维度为c~o~×c~i~，再额外加上一个偏置, 

### 通用二维卷积

![image-20250113183353792](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501131833871.png)

> 偏差是每一个单层的卷积核都有的



## 总结

实际是把输入和核矩阵进行运算, 获取输出的过程, 核矩阵和偏移是可以学习的, 核矩阵的大小是超参数

## 代码实现

### 一维

```python
def corr2d(X, K):
    # 获取卷积核的高和宽
    h, w = K.shape
    # 初始化输出张量Y
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    # 以及遍历计算
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()
    return Y
```

+ 可以建立一个卷积层

```python
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
```

+ 尝试检测一下边缘, 这里使用的卷积核是指定的, 检测垂直的边缘

```python
# 假设这是一个黑白的图像, 检测一下他的边缘
X = torch.ones((6, 8))
X[:, 2:6] = 0
"""
tensor([[1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.]])
"""
K = torch.tensor([[1.0, -1.0]])
Y = corr2d(X, K)
"""
tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])
"""
```

+ 实际训练获取一个卷积核

```python
# 输入和输出的通道数都是1, 卷积核的大小是(1, 2)
conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)
# 这里的第一个1是batch_size, 第二个1是通道数, 6是高, 8是宽
X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))

# 手写一个梯度下降
for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat - Y) ** 2
    conv2d.zero_grad()
    l.sum().backward()
    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad
    if (i + 1) % 2 == 0:
        print(f'batch {i + 1}, loss {l.sum():.3f}')
        
conv2d.weight.data
"""
tensor([[[[ 1.0025, -0.9663]]]])
"""
```

### 多维

+ 多输入(通道)

```python
def corr2d_multi_in(X, K):
    # 首先沿着X和K的第0维(通道维)遍历, 然后将结果相加
    return sum(corr2d(x, k) for x, k in zip(X, K))
```

+ 数据测试

```python
# 两个输入通道2 * 2 * 3
X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],
                     [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])
# 两个卷积核通道2 * 2 * 2, 输出是一个通道
K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])

corr2d_multi_in(X, K)
```

+ 多输入多输出

```python
def corr2d_multi_in_out(X, K):
    # 对K的第0维遍历, 每次都对输入X执行一次互相关运算, 最后将所有结果堆叠在一起
    # 这里的torch.stack是将多个tensor堆叠在一起, 0是堆叠的维度(新建的维度)
    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)
```

+ 测试

```python
K2 = torch.stack((K, K + 1, K + 2), 0)
corr2d_multi_in_out(X, K2), K2.shape
"""
(tensor([[[ 56.,  72.],
          [104., 120.]],
 
         [[ 76., 100.],
          [148., 172.]],
 
         [[ 96., 128.],
          [192., 224.]]]),
 torch.Size([3, 2, 2, 2]))
"""

```

+ 证明1x1和全连接等价

```python
# 1x1的卷积实际上是一个全连接层
def corr2d_multi_in_out_1x1(X, K):
    c_i, h, w = X.shape
    c_o = K.shape[0]
    X = X.reshape((c_i, h * w))
    K = K.reshape((c_o, c_i))
    Y = torch.matmul(K, X)
    return Y.reshape((c_o, h, w))

X = torch.rand(size=(3, 3, 3))
K = torch.rand(size=(2, 3, 1, 1))

Y1 = corr2d_multi_in_out_1x1(X, K)
Y2 = corr2d_multi_in_out(X, K)
Y1 == Y2
```

## 简单使用

```python
nn.Conv2d(3, 2, kernel_size=1, bias=False)
```

> 输入输出通道数, 卷积核的大小, 是不是有偏移