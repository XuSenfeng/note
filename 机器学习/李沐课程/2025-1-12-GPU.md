# GPU

检测

```python
import torch
from torch import nn

torch.device('cpu'), torch.cuda.device('cuda:0')
torch.cuda.device_count()
```

实际使用的时候可以检测一下GPU是不是可以使用

```python
def try_gpu(i=0):  #@save
    if torch.cuda.device_count() >= i + 1:
        return torch.device(f'cuda:{i}')
    return torch.device('cpu')
```

也可以返回一下所有的GPU

```python
def try_all_gpus():  #@save
    devices = [torch.device(f'cuda:{i}')
               for i in range(torch.cuda.device_count())]
    return devices if devices else [torch.device('cpu')]
```

在默认的时候可以使用`.device`查看当前的设备

```python
x = torch.tensor([1, 2, 3])
x.device
"""
device(type='cpu')
"""
```

可以在建立一个变量的时候尝试放在GPU

```python
x = torch.ones(2, 3, device=try_gpu())
x
"""
tensor([[1., 1., 1.],
        [1., 1., 1.]], device='cuda:0')
"""
```

在实际计算两个数据时候, 这两个数据尽量在一个设备上面, 数据的挪动很消耗资源, 所以会直接报错

```python
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
```

神经网络可以使用`.to`把这一个神经网络进行转移, 实际是把模型的参数放上去