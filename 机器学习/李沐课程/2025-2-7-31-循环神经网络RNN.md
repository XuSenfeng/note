# 循环神经网络RNN

其中单词xt在时间步t的条件概率仅取决于前面n−1个单词。对于时 间步t−(n−1)之前的单词，如果我们想将其可能产生的影响合并到xt上，需要增加n，然而模型参数的数量 也会随之呈指数增长，因为词表V需要存储|V|n个数字，因此与其将P(xt |xt−1,...,xt−n+1)模型化，不如使 用隐变量模型：

![image-20250209144302181](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502091443337.png)

其中ht−1是隐状态（hiddenstate），也称为隐藏变量（hiddenvariable），它存储了到时间步t−1的序列信 息。

![image-20250209144320811](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502091443853.png)

隐状态是 在给定步骤所做的任何事情（以技术角度来定义）的输入，并且这些状态只能通过先前时间步的数据来计算。

![image-20250209144409205](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502091444364.png)

![image-20250209144512447](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502091445485.png)

循环神经网络的参数包括隐藏层的权重W~xh~ ∈ R^d×h^,W~hh~ ∈ R^h×h^和偏置b~h~ ∈ R^1×h^，以及输出层的权 重W~hq~ ∈R^h×q^ 和偏置b~q~ ∈R^1×q^。

在实际计算的时候, 隐状态中X~t~W~xh~+H~t−1~W~hh~的计算，相当于X~t~和H~t−1~的拼接与W~xh~和W~hh~的拼接的矩阵乘法。这一部分的计算可以使用一个0维度的拼接和一个1维度的拼接进行简化处理

```python
X, W_xh = torch.normal(0, 1, (3, 1)), torch.normal(0, 1, (1, 4))
H, W_hh = torch.normal(0, 1, (3, 4)), torch.normal(0, 1, (4, 4))
torch.matmul(X, W_xh) + torch.matmul(H, W_hh)
# 结果和下面的计算是一样的
torch.matmul(torch.cat((X, H), 1), torch.cat((W_xh, W_hh), 0))
"""
tensor([[-2.6746, -0.6725, -3.2530, -1.5621],
        [-2.5695,  2.5248,  0.0943,  0.1504],
        [ 1.5933,  0.4725,  0.0299, -0.1567]])
"""
```

## 模型实现

```python
%matplotlib inline
import math
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l
```

+ 加载一下使用的数据, 这里的数据是按照字符进行分割的
+ vocab: 输入字母输出对应的编号

```python
batch_size, num_steps = 32, 35
train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)
print(len(vocab))
for X, y in train_iter:
    print(X.shape)
    print(y.shape)
    break
"""
28
torch.Size([32, 35])
torch.Size([32, 35])
"""
print(vocab.token_freqs[:10])
print(list(vocab.token_to_idx.items())[:10])
print(vocab['a'])
"""
[(' ', 29927), ('e', 17838), ('t', 13515), ('a', 11704), ('i', 10138)]
[('<unk>', 0), (' ', 1), ('e', 2), ('t', 3), ('a', 4)]
4
"""
```

之后会使用one_hot的函数, 这个函数的作用是把一个tensor增加一个最低维度, 把上层的数字对应位置置1, 其他的为0, 第二个参数是最低维度的参数数量

```python
F.one_hot(torch.tensor([0, 2]), len(vocab)) # 把索引转换为独热向量(只有对应索引的位置为1)
"""
tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0]])
"""
X = torch.arange(10).reshape((2, 5)) # X是按照(批量大小, 时间步数)排列的
F.one_hot(X.T, len(vocab)).shape # X.T是按照(时间步数, 批量大小)排列的, 所以要转置
"""
torch.Size([5, 2, 28])
"""

```

现在实现计算的过程, 计算的时候需要使用的参数自己进行一下初始化

![image-20250209150307695](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502091503725.png)

```python
def get_params(vocab_size, num_hiddens, device):
    # 这里的输出参数的数量是28(之后的x会使用one_hot进行拉伸)
    num_inputs = num_outputs = vocab_size
    def normal(shape):
        return torch.randn(size=shape, device=device) * 0.01
    # 隐藏层参数
    W_xh = normal((num_inputs, num_hiddens))
    W_hh = normal((num_hiddens, num_hiddens))
    b_h = torch.zeros(num_hiddens, device=device)
    # 输出层参数
    W_hq = normal((num_hiddens, num_outputs))
    b_q = torch.zeros(num_outputs, device=device)
    # 附加梯度
    params = [W_xh, W_hh, b_h, W_hq, b_q]
    for param in params:
        param.requires_grad_(True)
    return params
```

在实际计算的时候, 需要一个初始化一个状态, 之后在运算的时候根据新的输入不断迭代, 这里初始化的时候是初始化为一个全零的向量

```python
# 在初始化时返回隐状态。这个函数的返
# 回是一个张量，张量全用0填充，形状为（批量大小，隐藏单元数）
def init_rnn_state(batch_size, num_hiddens, device):
    return (torch.zeros((batch_size, num_hiddens), device=device), )
```

有了参数以后就可以使用这部分的参数开始计算了, 单次输入的计算如下

```python
# 在一个时间步内计算隐状态和输出
def rnn(inputs, state, params):
    # inputs的形状：(时间步数量，批量大小，词表大小)
    W_xh, W_hh, b_h, W_hq, b_q = params
    H, = state
    outputs = []
    # X的形状：(批量大小，词表大小)
    for X in inputs:
        # X和H的形状：(批量大小，词表大小)，W_xh的形状：(词表大小，隐藏单元数)
        # tanh激活函数
        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)
        Y = torch.mm(H, W_hq) + b_q
        outputs.append(Y) # 对于每一个x都有一个输出, 可以进行拼接
    # 返回输出(批量大小和长度的乘积)和更新后的隐藏状态
    return torch.cat(outputs, dim=0), (H,)
```

下面实现一个网络

```python
class RNNModelScratch: #@save
    """从零开始实现的循环神经网络模型"""
    def __init__(self, vocab_size, num_hiddens, device,
                    get_params, init_state, forward_fn):
        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens
        # 获取初始化的隐藏层参数
        self.params = get_params(vocab_size, num_hiddens, device) 
        self.init_state, self.forward_fn = init_state, forward_fn

    def __call__(self, X, state):
        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)
        return self.forward_fn(X, state, self.params)
    
    def begin_state(self, batch_size, device):
        return self.init_state(batch_size, self.num_hiddens, device)
```

简单测试一下

```python
num_hiddens = 512
net = RNNModelScratch(len(vocab), num_hiddens, 
                    d2l.try_gpu(), get_params,
                    init_rnn_state, rnn)
# 这里的X是2*5的矩阵，所以batch_size=2, num_steps=5
state = net.begin_state(X.shape[0], d2l.try_gpu())
Y, new_state = net(X.to(d2l.try_gpu()), state)
# Y的形状：(时间步数 * 批量大小, 词表大小)，new_state[0]的形状：(批量大小, 隐藏单元数)
Y.shape, len(new_state), new_state[0].shape, len(vocab)
"""
(torch.Size([10, 28]), 1, torch.Size([2, 512]), 28)
"""
```

建立一个预测函数, 使用目前的函数以及, 首先使用输入的信息获取一个状态, 之后基于这个状态进行计算

```python
def predict_ch8(prefix, num_preds, net, vocab, device): #@save
    """在prefix后面生成新字符"""
    state = net.begin_state(batch_size=1, device=device)
    outputs = [vocab[prefix[0]]] # outputs记录prefix加上预测的num_preds个字符
    # 每次获取输出的最后一个字符作为输入
    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))
    # 在循环遍历prefix中的开始字符时，我们不断地将隐状态传递到下一个时间步，但是不生成任何输出。这
    # 被称为预热（warm‐up）期
    for y in prefix[1:]: # 预热期
        _, state = net(get_input(), state)
        outputs.append(vocab[y]) # prefix中的字符已知，直接添加到outputs中
    for _ in range(num_preds): # 预测num_preds步
        y, state = net(get_input(), state)
        outputs.append(int(y.argmax(dim=1).reshape(1))) # 添加预测的字符
    return ''.join([vocab.idx_to_token[i] for i in outputs])
```

```python
predict_ch8('time traveller ', 10, net, vocab, d2l.try_gpu())
"""
'time traveller iwjpvrrrrr'
"""
```

在实际计算的时候为了避免出现梯度太大的情况, 可以使用梯度裁剪的功能, 把梯度限制在一定范围

![image-20250209153747983](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502091537058.png)

```python
def grad_clipping(net, theta): #@save
    """裁剪梯度"""
    if isinstance(net, nn.Module):
        params = [p for p in net.parameters() if p.requires_grad]
    else:
        params = net.params
    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))
    if norm > theta:
        # 如果梯度的L2范数大于theta，则裁剪它
        for param in params:
            param.grad[:] *= theta / norm
```

下面做一个实际的训练函数

```python
#@save 单次训练
def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):
    """训练网络一个迭代周期（定义见第8章）"""
    state, timer = None, d2l.Timer()
    metric = d2l.Accumulator(2) # 训练损失之和,词元数量
    for X, Y in train_iter:
        if state is None or use_random_iter:
            # 在第一次迭代或使用随机抽样时初始化state, 
            # 随机的批量两个样本之间的隐藏状态是不一样的, 不连续
            state = net.begin_state(batch_size=X.shape[0], device=device)
        else:
            if isinstance(net, nn.Module) and not isinstance(state, tuple):
                # state对于nn.GRU是个张量
                state.detach_() # 不再跟踪梯度
            else:
                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量
                for s in state:
                    s.detach_()
        y = Y.T.reshape(-1)
        X, y = X.to(device), y.to(device)
        y_hat, state = net(X, state)
        l = loss(y_hat, y.long()).mean()
        if isinstance(updater, torch.optim.Optimizer):
            updater.zero_grad()
            l.backward()
            grad_clipping(net, 1)
            updater.step()
        else:
            l.backward()
            grad_clipping(net, 1)
            # 因为已经调用了mean函数
            updater(batch_size=1)
        metric.add(l * y.numel(), y.numel())
    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()
```

```python
def train_ch8(net, train_iter, vocab, lr, num_epochs, device,
        use_random_iter=False):
    """训练模型（定义见第8章）"""
    loss = nn.CrossEntropyLoss()
    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',
    legend=['train'], xlim=[10, num_epochs])
    # 初始化
    if isinstance(net, nn.Module):
        updater = torch.optim.SGD(net.parameters(), lr)
    else:
        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)
    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)
    # 训练和预测
    for epoch in range(num_epochs):
        ppl, speed = train_epoch_ch8(
            net, train_iter, loss, updater, device, use_random_iter)
        if (epoch + 1) % 10 == 0:
            print(predict('time traveller'))
            animator.add(epoch + 1, [ppl])
    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')
    print(predict('time traveller'))
    print(predict('traveller'))
```

开始训练

```python
# 使用顺序进行训练
num_epochs, lr = 500, 1
train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())
"""
困惑度 1.0, 43298.7 词元/秒 cuda:0
time traveller for so it will be convenient to speak of himwas e
travelleryou can show black is white by argument said filby
"""
```

![image-20250209154003544](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502091540632.png)

```python
predict_ch8('time traveller ', 50, net, vocab, d2l.try_gpu())
"""
'time traveller for so it will be convenient to speak of himwas ex'
"""
```

乱序的训练

```python
net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params,
    init_rnn_state, rnn)
train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu(),
    se_random_iter=True)
"""
困惑度 1.4, 42731.5 词元/秒 cuda:0
time travellerit s against reason said filbywh t ingo the goongs
travellerit s against reason said filbywh t ingo the goongs
"""
```

![image-20250209154148436](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502091541519.png)

> 实际使用的时候由于这个模型可以记录的信息是有限的, 所以使用顺序和乱序的区别是不大的

### 简单实现

```python
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l
batch_size, num_steps = 32, 35
train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)
```

+ 初始化一下rnn层

```python
num_hiddens = 256
rnn_layer = nn.RNN(len(vocab), num_hiddens)
```

+ 初始化一个状态

```python
state = torch.zeros((1, batch_size, num_hiddens))
state.shape
```

简单实验一下这个层

```python
# 这里的X相当于35 * 32 * 28的张量, 是实际的输入32 * 35的转置再使用one_hot编码
X = torch.rand(size=(num_steps, batch_size, len(vocab)))
Y, state_new = rnn_layer(X, state)
Y.shape, state_new.shape
"""
(torch.Size([35, 32, 256]), torch.Size([1, 32, 256]))
"""
```

```python
#@save
class RNNModel(nn.Module):
    """循环神经网络模型"""
    def __init__(self, rnn_layer, vocab_size, **kwargs):
        super(RNNModel, self).__init__(**kwargs)
        self.rnn = rnn_layer
        self.vocab_size = vocab_size
        self.num_hiddens = self.rnn.hidden_size
        # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1
        if not self.rnn.bidirectional:
            self.num_directions = 1
            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)
        else:
            self.num_directions = 2
            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)

    def forward(self, inputs, state):
        X = F.one_hot(inputs.T.long(), self.vocab_size)
        X = X.to(torch.float32)
        Y, state = self.rnn(X, state)
        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)
        # 它的输出形状是(时间步数*批量大小,词表大小)。
        output = self.linear(Y.reshape((-1, Y.shape[-1])))
        return output, state
    # 暂时没有用到
    def begin_state(self, device, batch_size=1):
        if not isinstance(self.rnn, nn.LSTM):
            # nn.GRU以张量作为隐状态
            return torch.zeros((self.num_directions * self.rnn.num_layers,
                    batch_size, self.num_hiddens),
                    device=device)
        else:
            # nn.LSTM以元组作为隐状态
            return (torch.zeros((
                        self.num_directions * self.rnn.num_layers,
                        batch_size, self.num_hiddens), device=device),
                    torch.zeros((
                        self.num_directions * self.rnn.num_layers,
                        batch_size, self.num_hiddens), device=device))
```

```python
device = d2l.try_gpu()
net = RNNModel(rnn_layer, vocab_size=len(vocab))
net = net.to(device)
d2l.predict_ch8('time traveller', 10, net, vocab, device)
"""
'time travellergsvsssssss'
"""
```

```python
num_epochs, lr = 500, 1
d2l.train_ch8(net, train_iter, vocab, lr, num_epochs, device)
```

![image-20250209160451772](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502091604881.png)

## 总结

![image-20250213164923400](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/picture/202502131649576.png)

> n : sequence_lengt，设定的句子最大长度
> m : hidden_size，输入特征向量的隐藏层大小
> k : hidden_size_rnn，rnn的隐藏层大小
> p : num_labels，输出标签的总类别数

就有：

> (x1,...,xn)：维度(n,m)
> xt ：维度(1,m)
> U ：维度 (m,k)
> W ：维度 (k,k)
> St ：维度 (1,k)
> V ：维度 (k,p)

下面，运算一下向量之间计算：

> xt∗U -> 获得向量的维度(1,k)
> St−1∗W -> 获得向量的维度(1,k)
> xt∗U+St−1∗W -> 获得向量的维度(1,k)
> f(xt∗U+St−1∗W) -> 获得向量的维度(1,k)
> St∗V -> 获得向量的维度(1,p)
> g(St∗V) -> 获得向量的维度(1,p)
