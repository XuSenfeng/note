# 微调

实际标注一个大的数据集是很贵的, 通常我们在一个大的数据集上面训练的模型进行微调

一个神经网络一般有两区域, 一部分是进行特征的提取, 另一部分是进行线性分类

微调的含义是一个已经训练好的特征提取模型应该可以对所有形式的数据进行特征提取, 使用已经训练好的数据作为模型的初始化的参数

训练是在目标训练集上面的正常的任务, 但是使用更强的正则化, 更小的学习率, 原数据集需要远远复杂于现有的数据集, 也可以有目标数据集里面的部分标号

神经网络里面底层的信息一般比较通用, 高层的特征和数据集相关, 可以固定底部的一部分层的参数不参与更新(数据集很小的时候可以使用)

## 实际使用

```python
%matplotlib inline
import os
import torch 
import torchvision
from torch import nn
from d2l import torch as d2l
```

+ 下载数据集

```python
d2l.DATA_HUB['hotdog'] = (d2l.DATA_URL + 'hotdog.zip',
             'fba480ffa8aa7e0febbb511d181409f899b9baa5')
data_dir = d2l.download_extract('hotdog')
```

+ 加载数据集

```python
train_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))
test_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test'))
```

+ 看一下数据

```python
hotdogs = [train_imgs[i][0] for i in range(8)]
not_hotdogs = [train_imgs[-i - 1][0] for i in range(8)]
d2l.show_images(hotdogs + not_hotdogs, 2, 8, scale=1.4)
```

![image-20250117231751401](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501172317497.png)

+ 对数据进行一些处理

```python
# 用于在训练期间加载图像的数据集, 作用是将图像转换为模型的输入
# 使用这个数据集的时候, normalize参数将被传递给torchvision.transforms.Compose,
# 用于标准化每个通道, 这里的数据是已经训练好的模型, 所以使用了预训练模型的参数
# 对应RGB通道的均值和标准差
normalize = torchvision.transforms.Normalize([0.485, 0.456, 0.406],
                                                [0.229, 0.224, 0.225])
train_augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomResizedCrop(224),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(), normalize])

test_augs = torchvision.transforms.Compose([
    torchvision.transforms.Resize(256),
    torchvision.transforms.CenterCrop(224),
    torchvision.transforms.ToTensor(), normalize])
```

+ 使用预加载的模型

```python
pretrained_net = torchvision.models.resnet18(pretrained=True) # 预训练模型
pretrained_net.fc # 最后一层全连接层
```

+ 模型的最后一层使用2个输出的线性层

```python
finetune_net = torchvision.models.resnet18(pretrained=True)
# 重新定义最后一层全连接层的输出个数等于2
finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2) 
# 初始化最后一层全连接层的权重
nn.init.xavier_uniform_(finetune_net.fc.weight)
```

+ 实际训练的时候最后的分类层学习率比较大

```python
def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5, param_group=True):
    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'train'), transform=train_augs),
        batch_size, shuffle=True)
    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'test'), transform=test_augs),
        batch_size)
    devices = d2l.try_all_gpus()
    loss = nn.CrossEntropyLoss(reduction="none")
    if param_group:
        params_1x = [param for name, param in net.named_parameters()
                     if name not in ['fc.weight', 'fc.bias']]
        # 将最后一层全连接层的学习率设为已经预训练过的层的10倍
        trainer = torch.optim.SGD([{'params': params_1x}, 
                                   {'params': net.fc.parameters(), 
                                    'lr': learning_rate * 10}],
                                  lr=learning_rate, weight_decay=0.001)
    else:
        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)
    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)
```

+ 开始训练

```python
train_fine_tuning(finetune_net, 5e-5)
```

![image-20250117232058664](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501172320728.png)

![image-20250117232027224](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501172320301.png)

+ 对比没有使用默认参数的训练

```python
scratch_net = torchvision.models.resnet18()
scratch_net.fc = nn.Linear(scratch_net.fc.in_features, 2)
train_fine_tuning(scratch_net, 5e-4, param_group=False)
```

![image-20250117232042588](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501172320668.png)