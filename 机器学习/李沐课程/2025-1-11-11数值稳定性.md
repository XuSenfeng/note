# 数值稳定性

![image-20250111171922663](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111719115.png)

这里的y是经过所有层以后还有一个损失函数以后得结果

![image-20250111172213613](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111722686.png)

这是计算了很多次的矩阵乘法, 会导致梯度爆炸以及梯度消失

梯度爆炸: 获取到一个很大的数字

梯度消失: 获取的是一个很小的数字

![image-20250111172851544](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111728616.png)

![image-20250111173153592](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111731685.png)

梯度爆炸导致的问题: 少出域值(infinity)对于16位的浮点数尤其严重, 同时对于学习率很敏感, 导致参数很难调

![image-20250111173454284](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111734398.png)

使用这个函数的时候在极端的数值的时候函数的梯度很小, 求导会导致很多个小数相乘

![image-20250111173740419](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111737468.png)

如果过数值过小, 梯度值变为0, 导致训练没有进展, 对于底部的层最为严重, 顶层的网络训练比较好, 下面的层实际没有起作用

## 解决方法

目标: 使梯度值在一个合理的区间里面

方法: 

+ 乘法变为加法ResNet, LSTM
+ 归一化: 梯度归一化, 梯度剪裁
+ 合理的权重初始化以及合理的激活函数

实际实现:

每一层的输出以及梯度看做一个随机变量, 使他们的输出以及方差保持一致

![image-20250111174634233](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111746501.png)

### 权重初始化

在合理的区间里面初始化参数

训练开始的时候容易有数据的不稳定, 远离最优解的位置的数值不稳定, 损失函数表面比较复杂, 最优解附近的比较平

使用N~(0, 0.01)在比较小的网络可以使用

#### 没有激活函数的时候

![image-20250111175129593](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111751662.png)

![image-20250111175338122](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111753214.png)

![image-20250111175931950](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111759022.png)

> 想要满足输入和输出的方差是一样的时候, 需要满足右边的式子

<img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111802764.png" alt="image-20250111180224615" style="zoom:200%;" />

总结: 这一个等式很难满足, 除非某一层的输入和输出的项是相同的

![image-20250111182644081](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111826166.png)

#### 有激活函数

![image-20250111183116734](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111831826.png)

![image-20250111183200544](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111832620.png)

实际在使用的时候激活函数要基本满足`f(x) = x`

![image-20250111183339198](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202501111833325.png)

> 在零点的附近其他的两个函数比较接近x

#### 总结

合理的设计激活函数以及初始化权重可以提高数值的稳定性

### 代码实现

[参数初始化不当导致训练不稳定-腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/2469173)

```python
import numpy as np
# Xavier初始化
def xavier_init(shape):
    in_dim, out_dim = shape
    limit = np.sqrt(6 / (in_dim + out_dim)) # 限制, sqrt是开方
    return np.random.uniform(-limit, limit, size=shape) # 生成一个均匀分布的随机数
```



