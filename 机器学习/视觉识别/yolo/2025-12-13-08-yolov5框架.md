# YolV5æ¡†æž¶

## æ¨¡åž‹ç»“æž„æž„å»ºåŽŸç†

åœ¨`yolov5/models/yolov5*.yaml`æ–‡ä»¶é‡Œé¢æ˜¯å¯¹åº”çš„æ¨¡åž‹çš„ç»“æž„

Backbone æå–å¤šå°ºåº¦ç‰¹å¾ â†’ Head èžåˆç‰¹å¾ â†’ Detect è¾“å‡ºæ£€æµ‹ç»“æžœ

![image-20251213181802181](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/mac-picture/image-20251213181802181.png)

```yaml
# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license

# Parameters
nc: 80 # number of classes é»˜è®¤çš„åˆ†ç±»æ•°
# å®žé™…çš„å±‚çš„é‡å¤æ•°é‡ä¼šä¹˜è¿™ä¸ªæ•°å­—
depth_multiple: 0.33 # model depth multiple æ·±åº¦ä¹˜æ•°ï¼ŒæŽ§åˆ¶ç½‘ç»œçš„æ·±åº¦ï¼ˆC3 æ¨¡å—çš„é‡å¤æ¬¡æ•°ï¼‰ã€‚å€¼è¶Šå°ï¼ŒC3 é‡å¤æ¬¡æ•°è¶Šå°‘
# å®žé™…çš„è¾“å‡ºé€šé“æ•°ä¼šä¹˜ä»¥è¿™ä¸ª
width_multiple: 0.50 # layer channel multiple å®½åº¦ä¹˜æ•°ï¼ŒæŽ§åˆ¶ç½‘ç»œçš„é€šé“æ•°ï¼ˆæ¯å±‚å·ç§¯çš„è¾“å‡ºé€šé“æ•°ï¼‰ã€‚å€¼è¶Šå°ï¼Œé€šé“æ•°è¶Šå°‘ï¼Œæ¨¡åž‹è¶Šçª„
anchors: # é”šæ¡† é¢„å®šä¹‰çš„è¾¹ç•Œæ¡†å°ºå¯¸ï¼Œç”¨äºŽåŒ¹é…ä¸åŒå¤§å°çš„ç›®æ ‡
  - [10, 13, 16, 30, 33, 23] # P3/8
  - [30, 61, 62, 45, 59, 119] # P4/16
  - [116, 90, 156, 198, 373, 326] # P5/32

# YOLOv5 v6.0 backbone
# è´Ÿè´£ç‰¹å¾æå–ï¼ŒåŸºäºŽ CSPNet ç»“æž„ï¼Œé€šè¿‡å·ç§¯ + æ®‹å·®æ¨¡å—æå–å¤šå°ºåº¦è¯­ä¹‰ç‰¹å¾
# fromï¼šè¾“å…¥æ¥æºï¼Œ-1 è¡¨ç¤ºä¸Šä¸€å±‚ï¼Œæ•°å­—è¡¨ç¤ºå¯¹åº”å±‚çš„ç´¢å¼•ï¼ˆå¦‚ 6 è¡¨ç¤ºç¬¬ 6 å±‚ï¼‰ï¼›
# numberï¼šè¯¥æ¨¡å—çš„é‡å¤æ¬¡æ•°ï¼›
# moduleï¼šæ¨¡å—åç§°ï¼ˆConv/C3/SPPF ç­‰ï¼‰ï¼›
# argsï¼šæ¨¡å—çš„å‚æ•°ï¼ˆå¦‚å·ç§¯é€šé“æ•°ã€æ ¸å¤§å°ç­‰ï¼‰
# è¾“å‡º P3/P4/P5 ä¸‰ä¸ªå°ºåº¦çš„ç‰¹å¾å›¾ï¼ˆä¸‹é‡‡æ · 8/16/32 å€ï¼‰
backbone:
  # [from, number, module, args]
  [
    # 0-P1/2 Conv æ¨¡å—ï¼ˆå·ç§¯ + BN+SiLU æ¿€æ´»ï¼‰ï¼š
    # è¾“å‡º 64 é€šé“ï¼Œå·ç§¯æ ¸ 6Ã—6ï¼Œæ­¥é•¿ 2ï¼Œå¡«å…… 2 â†’ ä¸‹é‡‡æ · 2 å€ï¼ˆP1/2ï¼‰ã€‚
    [-1, 1, Conv, [64, 6, 2, 2]], 
    [-1, 1, Conv, [128, 3, 2]], # 1-P2/4
    # C3 æ¨¡å—ï¼ˆCSPNet æ ¸å¿ƒï¼Œ3 ä¸ªå·ç§¯ + æ®‹å·®å—ï¼‰ï¼šé‡å¤ 3 æ¬¡ï¼Œé€šé“ 128 â†’ å¢žå¼ºç‰¹å¾è¡¨è¾¾ï¼Œæ— ä¸‹é‡‡æ ·
    [-1, 3, C3, [128]],
    [-1, 1, Conv, [256, 3, 2]], # 3-P3/8
    [-1, 6, C3, [256]],
    [-1, 1, Conv, [512, 3, 2]], # 5-P4/16
    [-1, 9, C3, [512]],
    [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32
    [-1, 3, C3, [1024]],
    [-1, 1, SPPF, [1024, 5]], # 9
  ]

# YOLOv5 v6.0 head
# å®žçŽ°å¤šå°ºåº¦ç‰¹å¾èžåˆï¼Œå¹¶é€šè¿‡ Detect æ¨¡å—è¾“å‡ºæ£€æµ‹ç»“æžœï¼ˆè¾¹ç•Œæ¡†ã€ç½®ä¿¡åº¦ã€ç±»åˆ«ï¼‰
# å…ˆä¸Šé‡‡æ ·èžåˆæµ…å±‚ç‰¹å¾ï¼ˆç»†èŠ‚ï¼‰ï¼Œå†ä¸‹é‡‡æ ·èžåˆæ·±å±‚ç‰¹å¾ï¼ˆè¯­ä¹‰ï¼‰ï¼Œæœ€ç»ˆè¾“å‡º 3 ä¸ªå°ºåº¦çš„æ£€æµ‹åˆ†æ”¯
head: [
  # 1Ã—1 å·ç§¯é™ç»´ï¼šå°† P5 ç‰¹å¾ä»Ž 1024 é€šé“åŽ‹ç¼©åˆ° 512 â†’ å‡å°‘è®¡ç®—é‡ï¼Œä¸ºä¸Šé‡‡æ ·åšå‡†å¤‡
    [-1, 1, Conv, [512, 1, 1]],
    # ä¸Šé‡‡æ ·ï¼šæœ€è¿‘é‚»æ’å€¼ï¼Œå°†ç‰¹å¾å›¾æ”¾å¤§ 2 å€ â†’ åŒ¹é… P4 å°ºåº¦ï¼ˆ16 å€ä¸‹é‡‡æ ·ï¼‰
    [-1, 1, nn.Upsample, [None, 2, "nearest"]],
    # ç‰¹å¾æ‹¼æŽ¥ï¼šå°†ä¸Šé‡‡æ ·åŽçš„ P5 ç‰¹å¾ï¼ˆ11 å±‚ï¼‰ä¸Ž Backbone çš„ P4 ç‰¹å¾ï¼ˆ6 å±‚ï¼‰æŒ‰é€šé“ç»´åº¦æ‹¼æŽ¥
    #  â†’ èžåˆæ·±å±‚è¯­ä¹‰ + ä¸­å±‚ç»†èŠ‚
    [[-1, 6], 1, Concat, [1]], # cat backbone P4
    # C3 æ¨¡å—ï¼šé‡å¤ 3 æ¬¡ï¼Œé€šé“ 512ï¼Œ
    # False è¡¨ç¤ºæ— æ®‹å·® â†’ èžåˆåŽç‰¹å¾æçº¯ï¼ˆHead éƒ¨åˆ†çš„ C3 æ— æ®‹å·®ï¼Œé™ä½Žè®¡ç®—é‡ï¼‰
    [-1, 3, C3, [512, False]], # 13

    [-1, 1, Conv, [256, 1, 1]],
    [-1, 1, nn.Upsample, [None, 2, "nearest"]],
    [[-1, 4], 1, Concat, [1]], # cat backbone P3
    [-1, 3, C3, [256, False]], # 17 (P3/8-small)

    [-1, 1, Conv, [256, 3, 2]],
    [[-1, 14], 1, Concat, [1]], # cat head P4
    [-1, 3, C3, [512, False]], # 20 (P4/16-medium)

    [-1, 1, Conv, [512, 3, 2]],
    [[-1, 10], 1, Concat, [1]], # cat head P5
    # C3 æ¨¡å—ï¼šP5/32 å°ºåº¦æ£€æµ‹åˆ†æ”¯ï¼ˆå¤§ç›®æ ‡ï¼‰ï¼Œè¾“å‡º 1024 é€šé“ç‰¹å¾ã€‚
    [-1, 3, C3, [1024, False]], # 23 (P5/32-large)

    # Detect æ¨¡å—ï¼šè¾“å…¥ 17/20/23 å±‚çš„ 3 ä¸ªå°ºåº¦ç‰¹å¾
    # ç»“åˆç±»åˆ«æ•° nc å’Œé”šæ¡† anchorsï¼Œè¾“å‡ºæœ€ç»ˆæ£€æµ‹ç»“æžœ
    [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5)
  ]
```

å¯ä»¥ä½¿ç”¨tensorboardè¿›è¡Œå¯è§†åŒ–`tensorboard --logdir runs`, è¿™é‡Œçš„runsæ˜¯yolov5çš„é»˜è®¤è¾“å‡ºæ–‡ä»¶ä»¶

![image-20251213204220227](https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/mac-picture/image-20251213204220227.png)

## ä»£ç 

```python
# Model
check_suffix(weights, ".pt")  # check weights
pretrained = weights.endswith(".pt")
if pretrained:
    with torch_distributed_zero_first(LOCAL_RANK):
        weights = attempt_download(weights)  # download if not found locally
    ckpt = torch_load(weights, map_location="cpu")  # load checkpoint to CPU to avoid CUDA memory leak
    # åˆ›å»ºæ¨¡åž‹çš„ä½ç½®
    # å‚æ•°æ˜¯ä¹‹å‰çš„é…ç½®æ–‡ä»¶, è¾“å…¥é€šé“æ•°, æ£€æµ‹çš„ç±»åˆ«, é”šæ¡†
    model = Model(cfg or ckpt["model"].yaml, ch=3, nc=nc, anchors=hyp.get("anchors")).to(device)  # create
    exclude = ["anchor"] if (cfg or hyp.get("anchors")) and not resume else []  # exclude keys
    csd = ckpt["model"].float().state_dict()  # checkpoint state_dict as FP32
    csd = intersect_dicts(csd, model.state_dict(), exclude=exclude)  # intersect
    model.load_state_dict(csd, strict=False)  # load
    LOGGER.info(f"Transferred {len(csd)}/{len(model.state_dict())} items from {weights}")  # report
else:
    model = Model(cfg, ch=3, nc=nc, anchors=hyp.get("anchors")).to(device)  # create
amp = check_amp(model)  # check AMP
```

+   å®žé™…ä½¿ç”¨çš„æ¨¡åž‹å¦‚ä¸‹

```python
Model = DetectionModel  # retain YOLOv5 'Model' class for backwards compatibility
```

+   æ¨¡åž‹çš„åˆå§‹åŒ–

```python
class DetectionModel(BaseModel):
    """YOLOv5 detection model class for object detection tasks, supporting custom configurations and anchors."""

    def __init__(self, cfg="yolov5s.yaml", ch=3, nc=None, anchors=None):
        """Initializes YOLOv5 model with configuration file, input channels, number of classes, and custom anchors."""
        super().__init__()
        # åŠ è½½é…ç½®æ–‡ä»¶
        if isinstance(cfg, dict):
            self.yaml = cfg  # model dict
        else:  # is *.yaml
            import yaml  # for torch hub

            self.yaml_file = Path(cfg).name
            with open(cfg, encoding="ascii", errors="ignore") as f:
                self.yaml = yaml.safe_load(f)  # model dict
			
        # Define model, é‡æ–°å®šä¹‰ä¸€ä¸‹é€šé“æ•°
        ch = self.yaml["ch"] = self.yaml.get("ch", ch)  # input channels
        # é…ç½®ç›®æ ‡ç±»åˆ«
        if nc and nc != self.yaml["nc"]:
            LOGGER.info(f"Overriding model.yaml nc={self.yaml['nc']} with nc={nc}")
            self.yaml["nc"] = nc  # override yaml value
        if anchors:
            LOGGER.info(f"Overriding model.yaml anchors with anchors={anchors}")
            self.yaml["anchors"] = round(anchors)  # override yaml value
        # èŽ·å–å®žé™…çš„æ¨¡åž‹
        self.model, self.save = parse_model(deepcopy(self.yaml), ch=[ch])  # model, savelist
        self.names = [str(i) for i in range(self.yaml["nc"])]  # default names
        self.inplace = self.yaml.get("inplace", True)

        # Build strides, anchors
        m = self.model[-1]  # Detect()
        if isinstance(m, (Detect, Segment)):

            def _forward(x):
                """Passes the input 'x' through the model and returns the processed output."""
                return self.forward(x)[0] if isinstance(m, Segment) else self.forward(x)

            s = 256  # 2x min stride
            m.inplace = self.inplace
            m.stride = torch.tensor([s / x.shape[-2] for x in _forward(torch.zeros(1, ch, s, s))])  # forward
            check_anchor_order(m)
            m.anchors /= m.stride.view(-1, 1, 1)
            self.stride = m.stride
            self._initialize_biases()  # only run once

        # Init weights, biases
        initialize_weights(self)
        self.info()
        LOGGER.info("")
```

+   å¤„ç†é…ç½®æ–‡ä»¶ç”Ÿæˆæ¨¡åž‹

```python
def parse_model(d, ch):
    """Parses a YOLOv5 model from a dict `d`, configuring layers based on input channels `ch` and model architecture."""
    LOGGER.info(f"\n{'':>3}{'from':>18}{'n':>3}{'params':>10}  {'module':<40}{'arguments':<30}")
    # èŽ·å–æ¨¡åž‹çš„ä¿¡æ¯
    anchors, nc, gd, gw, act, ch_mul = (
        d["anchors"],
        d["nc"],
        d["depth_multiple"],
        d["width_multiple"],
        d.get("activation"),
        d.get("channel_multiple"),
    )
    # æ¿€æ´»å‡½æ•°
    if act:
        Conv.default_act = eval(act)  # redefine default activation, i.e. Conv.default_act = nn.SiLU()
        LOGGER.info(f"{colorstr('activation:')} {act}")  # print
    # ç¡®ä¿å·ç§¯å±‚çš„è¾“å‡ºé€šé“æ•°æ˜¯ ch_mul çš„æ•´æ•°å€ï¼Œæ ¸å¿ƒç›®çš„æ˜¯é€‚é…ç¡¬ä»¶è®¡ç®—æ•ˆçŽ‡
    if not ch_mul:
        ch_mul = 8
    # è®¡ç®—é”šæ¡†çš„æ•°é‡
    na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # number of anchors
    # è®¡ç®—è¾“å‡ºçš„æ ‘ç«‹æ•°é‡, +5æŒ‡çš„æ˜¯åæ ‡ä»¥åŠç½®ä¿¡åº¦
    no = na * (nc + 5)  # number of outputs = anchors * (classes + 5)
		
    # å±‚
    # è®°å½•æ‰€æœ‰éœ€è¦è¢«åŽç»­å±‚å¤ç”¨çš„å±‚ç´¢å¼•, è¿™äº›å±‚çš„ç‰¹å¾ä¼šè¢«åŽç»­Concat/Detectå±‚å¤ç”¨
    # è¾“å‡ºé€šé“æ•°
    layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out
    for i, (f, n, m, args) in enumerate(d["backbone"] + d["head"]):  # from, number, module, args
        # moduleè¿›è¡Œå®žä¾‹åŒ–, å­—ç¬¦ä¸²=>å®žé™…çš„å¯¹è±¡ 
        m = eval(m) if isinstance(m, str) else m  # eval strings
        # å¤„ç†å‚æ•°
        for j, a in enumerate(args):
            with contextlib.suppress(NameError):
                args[j] = eval(a) if isinstance(a, str) else a  # eval strings
				# å®žé™…çš„å¾ªçŽ¯æ¬¡æ•°ä¹˜depth_multiple, å’Œ1æ¯”è¾ƒ
        n = n_ = max(round(n * gd), 1) if n > 1 else n  # depth gain
        # ä¾æ®ä¸åŒçš„æ¨¡åž‹æž„é€ å‚æ•°
        if m in {
            Conv,
            GhostConv,
            Bottleneck,
            GhostBottleneck,
            SPP,
            SPPF,
            DWConv,
            MixConv2d,
            Focus,
            CrossConv,
            BottleneckCSP,
            C3,
            C3TR,
            C3SPP,
            C3Ghost,
            nn.ConvTranspose2d,
            DWConvTranspose2d,
            C3x,
        }:
          	# fæ˜¯-1, å®žé™…æ˜¯ä¸Šä¸€å±‚çš„è¾“å‡º, ç¬¬äºŒä¸ªè®°å½•é…ç½®æ–‡ä»¶çš„è¾“å‡ºé€šé“
            c1, c2 = ch[f], args[0]
            # ä¹˜ä¸Šwidth_multipleåŒæ—¶ä¿è¯å¯ä»¥æ•´é™¤
            if c2 != no:  # if not output
                c2 = make_divisible(c2 * gw, ch_mul)
						
            args = [c1, c2, *args[1:]]
            # ä»¥ä¸‹å‡ ç§çš„è¯éœ€è¦æ’å…¥å‚æ•°nè¡¨ç¤ºå¾ªçŽ¯çš„æ¬¡æ•°
            if m in {BottleneckCSP, C3, C3TR, C3Ghost, C3x}:
                args.insert(2, n)  # number of repeats
                n = 1
        elif m is nn.BatchNorm2d:
            args = [ch[f]]
        elif m is Concat:
            c2 = sum(ch[x] for x in f)
        # TODO: channel, gw, gd
        elif m in {Detect, Segment}:
            args.append([ch[x] for x in f])
            if isinstance(args[1], int):  # number of anchors
                args[1] = [list(range(args[1] * 2))] * len(f)
            if m is Segment:
                args[3] = make_divisible(args[3] * gw, ch_mul)
        elif m is Contract:
            c2 = ch[f] * args[0] ** 2
        elif m is Expand:
            c2 = ch[f] // args[0] ** 2
        else:
            c2 = ch[f]
				# åˆ›å»ºåºåˆ—
        m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)  # module
        t = str(m)[8:-2].replace("__main__.", "")  # module type
        np = sum(x.numel() for x in m_.parameters())  # number params
        m_.i, m_.f, m_.type, m_.np = i, f, t, np  # attach index, 'from' index, type, number params
        LOGGER.info(f"{i:>3}{f!s:>18}{n_:>3}{np:10.0f}  {t:<40}{args!s:<30}")  # print
        save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  # append to savelist
        # è®°å½•å‡ºæ¥
        layers.append(m_)
        if i == 0:
            ch = []
        ch.append(c2)
    return nn.Sequential(*layers), sorted(save)
```

+   ä¸€ä¸ªå®žé™…çš„å±‚çš„ç¤ºä¾‹

```python
class Conv(nn.Module):
    """Applies a convolution, batch normalization, and activation function to an input tensor in a neural network."""
    default_act = nn.SiLU()  # default activation
		# è¾“å…¥è¾“å‡ºé€šé“æ•°, å·ç§¯æ ¸, æ­¥å¹…, æ˜¯ä¸æ˜¯paddings, groups, æ˜¯ä¸æ˜¯è†¨èƒ€, æ¿€æ´»å‡½æ•°
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
        """Initializes a standard convolution layer with optional batch normalization and activation."""
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()

    def forward(self, x):
        """Applies a convolution followed by batch normalization and an activation function to the input tensor `x`."""
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        """Applies a fused convolution and activation function to the input tensor `x`."""
        return self.act(self.conv(x))
```

