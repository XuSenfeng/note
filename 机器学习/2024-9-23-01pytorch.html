<!DOCTYPE html>

<html lang="zh-CN"  class="">


<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="keywords" content="">
    
    
    <meta name="description" content="">
    
    <meta name="generator" content="teedoc">
    <meta name="theme" content="teedoc-plugin-theme-default">
    
        
        <meta name="markdown-generator" content="teedoc-plugin-markdown-parser">
        
        <script>
MathJax = {"loader": {"load": ["output/svg"]}, "tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}, "svg": {"fontCache": "global"}};
</script>
        
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
        <meta name="html-generator" content="teedoc-plugin-jupyter-notebook-parser">
        
        <script src="/note/static/js/theme_default/pre_main.js"></script>
        
        <link rel="stylesheet" href="/note/static/css/theme_default/prism.min.css" type="text/css"/>
        
        <link rel="stylesheet" href="/note/static/css/theme_default/viewer.min.css" type="text/css"/>
        
        <link rel="stylesheet" href="/note/static/css/theme_default/dark.css" type="text/css"/>
        
        <link rel="stylesheet" href="/note/static/css/theme_default/light.css" type="text/css"/>
        
        <script src="/note/static/js/theme_default/jquery.min.js"></script>
        
        <script src="/note/static/js/theme_default/split.js"></script>
        
        <link rel="stylesheet" href="/note/static/css/search/style.css" type="text/css"/>
        
        <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?4d52982572d5512e9762879ebf063c86";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
        
        <meta name="blog-generator" content="teedoc-plugin-blog">
        
        <link rel="stylesheet" href="/note/static/css/gitalk/gitalk.css" type="text/css"/>
        
        <link rel="stylesheet" href="/note/static/css/gitalk/custom_gitalk.css" type="text/css"/>
        
        <link rel="stylesheet" href="/note/static/css/custom.css" type="text/css"/>
        
    
    
    <title>pytorch - XvSenfeng's Note</title>
    
    <script type="text/javascript">js_vars = {"teedoc-plugin-ad-hint": {"type": "hint", "label": "â˜†", "content": "è¿™æ˜¯ä¸€ä¸ªæ”¯æŒå›½é™…åŒ–çš„æ¶ˆæ¯ç¤ºä¾‹</br>å–œæ¬¢é¡¹ç›®è¯·<a target=\"_blank\" href=\"https://github.com/teedoc/teedoc\">ç‚¹ä¸‹ â˜† star </a>å“¦~ğŸ¦€ğŸ¦€", "show_times": 2, "show_after_s": 432000, "date": "2021-11-16 14:40", "color": "#a0421d", "link_color": "#e53935", "link_bg_color": "#e6ae5c", "bg_color": "#ffcf89", "color_hover": "white", "bg_color_hover": "#f57c00", "close_color": "#eab971"}}</script>
    <script type="text/javascript">metadata = {"tags": ["AI æœºå™¨å­¦ä¹ "], "date": "2026-02-05", "update": [], "ts": 1770297751, "author": "", "brief": "", "cover": "", "layout": "post"}</script>
</head>


<body class="type_doc">
    
    <div id="navbar">
        <div id="navbar_menu">
            <a class="site_title" href="/note/">
                
                    <img class="site_logo" src="/note/static/image/logo.png" alt="XvSenfeng logo">
                
                
                    <h2>XvSenfeng</h2>
                
        </a>
            <a id="navbar_menu_btn"></a>
        </div>
        <div id="navbar_items">
            <div>
                <ul id="nav_left">
<li class=""><a  href="/note/blog/">åšå®¢</a></li>
<li class=""><a  href="/note/Linux/">Linux</a></li>
<li class=""><a  href="/note/ä»£ç åˆ†æ/">ä»£ç åˆ†æ</a></li>
<li class=""><a  href="/note/ä½¿ç”¨è½¯ä»¶/">ä½¿ç”¨è½¯ä»¶</a></li>
<li class=""><a  href="/note/åµŒå…¥å¼/">åµŒå…¥å¼</a></li>
<li class=""><a  href="/note/æ‰‹æœºå®‰å“/">æ‰‹æœºå®‰å“</a></li>
<li class="active"><a  href="/note/æœºå™¨å­¦ä¹ /">æœºå™¨å­¦ä¹ </a></li>
<li class=""><a  href="/note/ç¼–ç¨‹åŸºç¡€/">ç¼–ç¨‹åŸºç¡€</a></li>
<li class=""><a  href="/note/ç½‘ç»œ/">ç½‘ç»œ</a></li>
</ul>

            </div>
            <div>
                <ul id="nav_right">
<li class=""><a target="_blank" href="https://github.com/XuSenfeng/note/">github</a></li>
</ul>

                <ul class="nav_plugins"><li><a id="google_translate_element"><img class="icon" src="/note/static/image/google_translate/translate.svg"/>Translate</a></li></ul><ul class="nav_plugins"><li><a id="themes" class="light"></a></li></ul><ul class="nav_plugins"><li><a id="search"><span class="icon"></span><span class="placeholder">æœç´¢</span>
                            <div id="search_hints">
                                <span id="search_input_hint">è¾“å…¥å…³é”®è¯ï¼Œå¤šå…³é”®è¯ç©ºæ ¼éš”å¼€</span>
                                <span id="search_loading_hint">æ­£åœ¨åŠ è½½ï¼Œè¯·ç¨å€™ã€‚ã€‚ã€‚</span>
                                <span id="search_download_err_hint">ä¸‹è½½æ–‡ä»¶å¤±è´¥ï¼Œè¯·åˆ·æ–°é‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œ</span>
                                <span id="search_other_docs_result_hint">æ¥è‡ªå…¶å®ƒæ–‡æ¡£çš„ç»“æœ</span>
                                <span id="search_curr_doc_result_hint">å½“å‰æ–‡æ¡£æœç´¢ç»“æœ</span>
                            </div></a></li></ul>
            </div>
        </div>
    </div>
    
    <div id="wrapper">
        <div id="sidebar_wrapper">
            <div id="sidebar">
                <div id="sidebar_title">
                    
                </div>
                <ul class="show">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /2024-10-5-Transformers.html"><span class="label">2024-10-5-Transformers</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /2024-10-6-Juoyter.html"><span class="label">2024-10-6-Juoyter</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /2024-10-7-Pandasåº“.html"><span class="label">2024-10-7-Pandasåº“</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /2024-10-9-transformså®æˆ˜.html"><span class="label">2024-10-9-transformså®æˆ˜</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /2024-9-21-LLM.html"><span class="label">2024-9-21-LLM</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /2024-9-22-vLLM.html"><span class="label">2024-9-22-vLLM</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /2024-9-22-æ·±åº¦å­¦ä¹ ç¯å¢ƒ.html"><span class="label">2024-9-22-æ·±åº¦å­¦ä¹ ç¯å¢ƒ</span><span class=""></span></a></li>
<li class="active with_link"><a href="/note/æœºå™¨å­¦ä¹ /2024-9-23-01pytorch.html"><span class="label">2024-9-23-01pytorch</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /2024-9-8-æœºå™¨å­¦ä¹ .html"><span class="label">2024-9-8-æœºå™¨å­¦ä¹ </span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /index.html"><span class="label">README</span><span class=""></span></a></li>
<li class="not_active no_link"><a><span class="label">rvæ¨¡å‹éƒ¨ç½²</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2025-11-28-00-é©±åŠ¨ç§»æ¤.html"><span class="label">2025-11-28-00-é©±åŠ¨ç§»æ¤</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2025-11-28-01-ç¯å¢ƒæ­å»º.html"><span class="label">2025-11-28-01-ç¯å¢ƒæ­å»º</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2025-12-2-02-åŸºç¡€æ¦‚å¿µ.html"><span class="label">2025-12-2-02-åŸºç¡€æ¦‚å¿µ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2025-12-3-03-RKNN_Toolkit2.html"><span class="label">2025-12-3-03-RKNN_Toolkit2</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2025-12-3-04-RKLLM.html"><span class="label">2025-12-3-04-RKLLM</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2026-2-2-05-RKNNå¼€å‘.html"><span class="label">2026-2-2-05-RKNNå¼€å‘</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">vllmä»£ç åˆ†æ</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /vllmä»£ç åˆ†æ/2024-12-31-00-æ•´ä½“æ¡†æ¶.html"><span class="label">2024-12-31-00-æ•´ä½“æ¡†æ¶</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /vllmä»£ç åˆ†æ/2024-12-31-01-collect_env.html"><span class="label">2024-12-31-01-collect_env</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">å…·èº«æ™ºèƒ½</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å…·èº«æ™ºèƒ½/2026-2-2-åŸºç¡€æ¦‚å¿µ.html"><span class="label">2026-2-2-åŸºç¡€æ¦‚å¿µ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å…·èº«æ™ºèƒ½/2026-2-3-02-ä»¿çœŸ.html"><span class="label">2026-2-3-02-ä»¿çœŸ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å…·èº«æ™ºèƒ½/2026-2-3-03-å§¿æ€è§£ç®—.html"><span class="label">2026-2-3-03-å§¿æ€è§£ç®—</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å…·èº«æ™ºèƒ½/2026-2-4-04-SO-ARM101.html"><span class="label">2026-2-4-04-SO-ARM101</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">å®é™…åº”ç”¨</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-1-30-ollama.html"><span class="label">2025-1-30-ollama</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-12-10-è¯­éŸ³è¯†åˆ«.html"><span class="label">2025-12-10-è¯­éŸ³è¯†åˆ«</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-12-22-QLearning.html"><span class="label">2025-12-22-QLearning</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-2-16-dify.html"><span class="label">2025-2-16-dify</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-2-16-langChain.html"><span class="label">2025-2-16-langChain</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-2-23-langchain2.html"><span class="label">2025-2-23-langchain2</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-2-26-Loraå¾®è°ƒ.html"><span class="label">2025-2-26-Loraå¾®è°ƒ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-3-20-COZE.html"><span class="label">2025-3-20-COZE</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-4-2-MCP.html"><span class="label">2025-4-2-MCP</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">åµŒå…¥å¼ç§»æ¤</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /åµŒå…¥å¼ç§»æ¤/00ç»†èŠ.html"><span class="label">00ç»†èŠ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /åµŒå…¥å¼ç§»æ¤/2025-12-18-01-æ¨¡å‹é‡åŒ–.html"><span class="label">2025-12-18-01-æ¨¡å‹é‡åŒ–</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">ææ²è¯¾ç¨‹</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/0000-0-0-00åŸºç¡€numpy.html"><span class="label">0000-0-0-00åŸºç¡€numpy</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/0000-0-0-00åŸºç¡€pandas.html"><span class="label">0000-0-0-00åŸºç¡€pandas</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2024-10-31-01.html"><span class="label">2024-10-31-01</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2024-11-03-02æ•°æ®ç±»å‹.html"><span class="label">2024-11-03-02æ•°æ®ç±»å‹</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-08-03åŸºç¡€å‡½æ•°.html"><span class="label">2025-1-08-03åŸºç¡€å‡½æ•°</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-08-04æ•°æ®é›†.html"><span class="label">2025-1-08-04æ•°æ®é›†</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-08-05æ„ŸçŸ¥æœº.html"><span class="label">2025-1-08-05æ„ŸçŸ¥æœº</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-09æ¨¡å‹é€‰æ‹©.html"><span class="label">2025-1-09æ¨¡å‹é€‰æ‹©</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-10-10ä¸¢å¼ƒæ³•.html"><span class="label">2025-1-10-10ä¸¢å¼ƒæ³•</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-11-11æ•°å€¼ç¨³å®šæ€§.html"><span class="label">2025-1-11-11æ•°å€¼ç¨³å®šæ€§</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-12-12å±‚å’Œå—.html"><span class="label">2025-1-12-12å±‚å’Œå—</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-12-GPU.html"><span class="label">2025-1-12-GPU</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-12-å®æˆ˜æ¯”èµ›.html"><span class="label">2025-1-12-å®æˆ˜æ¯”èµ›</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-13-13å·ç§¯.html"><span class="label">2025-1-13-13å·ç§¯</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-13-14æ± åŒ–.html"><span class="label">2025-1-13-14æ± åŒ–</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-14-15LeNet.html"><span class="label">2025-1-14-15LeNet</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-14-16AlexNet.html"><span class="label">2025-1-14-16AlexNet</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-14-17VGG.html"><span class="label">2025-1-14-17VGG</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-14-18NiN.html"><span class="label">2025-1-14-18NiN</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-14-19GoogLeNet.html"><span class="label">2025-1-14-19GoogLeNet</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-15-20æ‰¹é‡å½’ä¸€åŒ–.html"><span class="label">2025-1-15-20æ‰¹é‡å½’ä¸€åŒ–</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-15-21æ®‹å·®ç½‘ç»œResNet.html"><span class="label">2025-1-15-21æ®‹å·®ç½‘ç»œResNet</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-16-èŠ¯ç‰‡.html"><span class="label">2025-1-16-èŠ¯ç‰‡</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-17-22æ•°æ®å¢å¹¿.html"><span class="label">2025-1-17-22æ•°æ®å¢å¹¿</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-17-23å¾®è°ƒ.html"><span class="label">2025-1-17-23å¾®è°ƒ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-18-24CIFARæ•°æ®é›†.html"><span class="label">2025-1-18-24CIFARæ•°æ®é›†</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-19-25ç›®æ ‡æ£€æµ‹.html"><span class="label">2025-1-19-25ç›®æ ‡æ£€æµ‹</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-23-26åŒºåŸŸå·ç§¯ç¥ç»ç½‘ç»œ.html"><span class="label">2025-1-23-26åŒºåŸŸå·ç§¯ç¥ç»ç½‘ç»œ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-1-27è¯­ä¹‰åˆ†å‰².html"><span class="label">2025-2-1-27è¯­ä¹‰åˆ†å‰²</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-10-33é•¿çŸ­æœŸè®°å¿†LSTM.html"><span class="label">2025-2-10-33é•¿çŸ­æœŸè®°å¿†LSTM</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-10-34æ·±åº¦å¾ªç¯ç½‘ç»œ.html"><span class="label">2025-2-10-34æ·±åº¦å¾ªç¯ç½‘ç»œ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-10-35-BPTT.html"><span class="label">2025-2-10-35-BPTT</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-10-36åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ.html"><span class="label">2025-2-10-36åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-11-37ç¼–ç å™¨è§£ç å™¨.html"><span class="label">2025-2-11-37ç¼–ç å™¨è§£ç å™¨</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-11-38seq2seq.html"><span class="label">2025-2-11-38seq2seq</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-11-39æŸæœç´¢.html"><span class="label">2025-2-11-39æŸæœç´¢</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-11-40æ³¨æ„åŠ›æœºåˆ¶.html"><span class="label">2025-2-11-40æ³¨æ„åŠ›æœºåˆ¶</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-13-41æ³¨æ„åŠ›seq2seq.html"><span class="label">2025-2-13-41æ³¨æ„åŠ›seq2seq</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-15-42è‡ªæ³¨æ„åŠ›.html"><span class="label">2025-2-15-42è‡ªæ³¨æ„åŠ›</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-15-43Transformer.html"><span class="label">2025-2-15-43Transformer</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-15-44BERT.html"><span class="label">2025-2-15-44BERT</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-5-28æ ·å¼è¿ç§».html"><span class="label">2025-2-5-28æ ·å¼è¿ç§»</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-5-29åºåˆ—æ¨¡å‹.html"><span class="label">2025-2-5-29åºåˆ—æ¨¡å‹</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-6-30æ–‡å­—å¤„ç†.html"><span class="label">2025-2-6-30æ–‡å­—å¤„ç†</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-7-31-å¾ªç¯ç¥ç»ç½‘ç»œRNN.html"><span class="label">2025-2-7-31-å¾ªç¯ç¥ç»ç½‘ç»œRNN</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-9-32-é—¨æ§å¾ªç¯å•å…ƒGRU.html"><span class="label">2025-2-9-32-é—¨æ§å¾ªç¯å•å…ƒGRU</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">è§†è§‰è¯†åˆ«</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/2025-12-12-04-ç»å…¸ç®—æ³•.html"><span class="label">2025-12-12-04-ç»å…¸ç®—æ³•</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/2025-12-12-05-YoloV1.html"><span class="label">2025-12-12-05-YoloV1</span><span class=""></span></a></li>
<li class="not_active no_link"><a><span class="label">K230</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/K230/2026-1-1-01-SDKç¼–è¯‘.html"><span class="label">2026-1-1-01-SDKç¼–è¯‘</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/K230/2026-1-10-03-Linuxä»£ç å¼€å‘.html"><span class="label">2026-1-10-03-Linuxä»£ç å¼€å‘</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/K230/2026-1-3-02-åŸºç¡€åŸç†.html"><span class="label">2026-1-3-02-åŸºç¡€åŸç†</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">MaixCAM</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-11-02-æ¨¡å‹è®­ç»ƒ.html"><span class="label">2025-12-11-02-æ¨¡å‹è®­ç»ƒ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-11-03-å¸¸ç”¨çš„æ¨¡å‹.html"><span class="label">2025-12-11-03-å¸¸ç”¨çš„æ¨¡å‹</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-14-04-Yoloæ¨¡å‹è½¬æ¢.html"><span class="label">2025-12-14-04-Yoloæ¨¡å‹è½¬æ¢</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-14-05-MaixCDKåŸºç¡€ä½¿ç”¨.html"><span class="label">2025-12-14-05-MaixCDKåŸºç¡€ä½¿ç”¨</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-16-06-maixcdkå·¥å…·.html"><span class="label">2025-12-16-06-maixcdkå·¥å…·</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-17-07-ç»„ä»¶.html"><span class="label">2025-12-17-07-ç»„ä»¶</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-17-08-Cameraç¤ºä¾‹.html"><span class="label">2025-12-17-08-Cameraç¤ºä¾‹</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-17-09-APP.html"><span class="label">2025-12-17-09-APP</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-18-06-æ¨¡å‹ç›¸å…³å‚æ•°.html"><span class="label">2025-12-18-06-æ¨¡å‹ç›¸å…³å‚æ•°</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-19-07-AIç¼–è¯‘å™¨.html"><span class="label">2025-12-19-07-AIç¼–è¯‘å™¨</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-19-08-æ¨¡å‹å®ç°.html"><span class="label">2025-12-19-08-æ¨¡å‹å®ç°</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-20-09-MaixPyç¼–è¯‘.html"><span class="label">2025-12-20-09-MaixPyç¼–è¯‘</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-3-00-èµ„æ–™.html"><span class="label">2025-12-3-00-èµ„æ–™</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-5-01ç¼–è¯‘ä¸‹è½½.html"><span class="label">2025-12-5-01ç¼–è¯‘ä¸‹è½½</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">yolo</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-12-02-åŸºç¡€ä½¿ç”¨.html"><span class="label">2025-12-12-02-åŸºç¡€ä½¿ç”¨</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-12-03-æ•°æ®é›†.html"><span class="label">2025-12-12-03-æ•°æ®é›†</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-12-04-é¢„æµ‹.html"><span class="label">2025-12-12-04-é¢„æµ‹</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-05-è®­ç»ƒ.html"><span class="label">2025-12-13-05-è®­ç»ƒ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-06-yolov5åŸºç¡€ä½¿ç”¨.html"><span class="label">2025-12-13-06-yolov5åŸºç¡€ä½¿ç”¨</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-07-AutoDLæœåŠ¡å™¨è®­ç»ƒ.html"><span class="label">2025-12-13-07-AutoDLæœåŠ¡å™¨è®­ç»ƒ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-08-yolov5æ¡†æ¶.html"><span class="label">2025-12-13-08-yolov5æ¡†æ¶</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-09-ä¿®æ”¹ç½‘ç»œ.html"><span class="label">2025-12-13-09-ä¿®æ”¹ç½‘ç»œ</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-10-æ¨¡å‹éƒ¨ç½².html"><span class="label">2025-12-13-10-æ¨¡å‹éƒ¨ç½²</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-4-01-yoloå®‰è£….html"><span class="label">2025-12-4-01-yoloå®‰è£…</span><span class=""></span></a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
        </div>
        <div id="article">
            <div id="menu_wrapper">
                <div id="menu">
                </div>
            </div>
            <div id="content_wrapper">
                <div id="content_body">
                    <div id="article_head">
                        <div id="article_title">
                            
                            <h1>pytorch</h1>
                            
                        </div>
                        <div id="article_tags">
                            <ul>
                            
                                <li>AI æœºå™¨å­¦ä¹ </li>
                            
                            </ul>
                        </div>
                        <div id="article_info">
                        <div id="article_info_left">
                            <span class="article_author">
                                
                            </span>
                            
                                <span class="article_date" title="æœ€åä¿®æ”¹æ—¥æœŸï¼š 2026-02-05">
                                    2026-02-05
                                </span>
                            
                        </div>
                        <div id="article_info_right">
                            
                            <div id="source_link">
                                <a href="https://github.com/XuSenfeng/note/tree/master/doc/æœºå™¨å­¦ä¹ /2024-9-23-01pytorch.md" target="_blank">
                                    ç¼–è¾‘æœ¬é¡µ
                                </a>
                            </div>
                            
                        </div>
                        </div>
                    </div>
                    <div id="article_tools">
                        <span></span>
                        <span id="toc_btn"></span>
                    </div>
                    <div id="update_history">
                        
                    </div>
                    <div id="article_content">
                        
                            <h1 id="pytorch">pytorch</h1>
<h2 id="%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8">åŸºç¡€å…¥é—¨</h2>
<p>å¯ä»¥ä½¿ç”¨dirå’Œhelpä¸¤ä¸ªå‡½æ•°è¿›è¡Œæ¢ç´¢ä½¿ç”¨pytorch</p>
<p>ä½¿ç”¨dirå¯ä»¥å¯¹ä¸€ä¸ªåŒ…è¿›è¡Œæ‰“å¼€æ“ä½œ, ä½¿ç”¨helpå¯ä»¥è·å–æŸä¸€ä¸ªåŒ…çš„å…·ä½“ä½¿ç”¨</p>
<p><img src="C:%5CUsers%5Cjinhua%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240923172733947.png" alt="image-20240923172733947" /></p>
<h3 id="%E5%90%8D%E8%AF%8D">åè¯</h3>
<h4 id="%E5%BC%A0%E9%87%8F">å¼ é‡</h4>
<p><a href="https://zhuanlan.zhihu.com/p/48982978#:~:text=%E5%9C%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%87%8C%EF%BC%8CTen"  target="_blank">ç¬”è®° | ä»€ä¹ˆæ˜¯å¼ é‡ï¼ˆtensorï¼‰&amp; æ·±åº¦å­¦ä¹  - çŸ¥ä¹ (zhihu.com)</a></p>
<p>åœ¨æ·±åº¦å­¦ä¹ é‡Œï¼Œ<strong>Tensorå®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªå¤šç»´æ•°ç»„ï¼ˆmultidimensional arrayï¼‰</strong>ã€‚</p>
<p>è€ŒTensorçš„ç›®çš„æ˜¯<strong>èƒ½å¤Ÿåˆ›é€ æ›´é«˜ç»´åº¦çš„çŸ©é˜µã€å‘é‡</strong>ã€‚</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409252313363.jpeg" alt="img" /></p>
<p>ä¸¾ä¸ªç®€å•çš„ä¾‹å­ï¼Œ<a href="https://zhida.zhihu.com/search?content_id=9946792&amp;content_type=Article&amp;match_order=1&amp;q=%E5%BD%A9%E8%89%B2%E5%9B%BE%E5%83%8F%E6%96%87%E4%BB%B6&amp;zhida_source=entity"  target="_blank">å½©è‰²å›¾åƒæ–‡ä»¶</a>ï¼ˆRGBï¼‰ä¸€èˆ¬éƒ½ä¼šå¤„ç†æˆ3-d tensorï¼Œæ¯ä¸ª2d arrayä¸­çš„elementè¡¨ç¤ºä¸€ä¸ªåƒç´ ï¼ŒRä»£è¡¨Redï¼ŒGä»£è¡¨Greenï¼ŒBä»£è¡¨Blueï¼š</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409252314013.webp" alt="img" /></p>
<p>å†æ¥çœ‹çœ‹Tensorå¯¹è±¡çš„3ä¸ªå±æ€§ï¼š</p>
<ol>
<li><strong>rank</strong>ï¼š<a href="https://zhida.zhihu.com/search?content_id=9946792&amp;content_type=Article&amp;match_order=1&amp;q=number+of+dimensions&amp;zhida_source=entity"  target="_blank">number of dimensions</a></li>
<li><strong>shape</strong>: number of rows and columns</li>
<li><strong>type</strong>: data type of tensor's elements</li>
</ol>
<h4 id="%E5%8D%B7%E7%A7%AF">å·ç§¯</h4>
<p><a href="https://b23.tv/T4gTHYC"  target="_blank">https://b23.tv/T4gTHYC</a></p>
<p>å·ç§¯, å®é™…å¯ä»¥ç†è§£ä¸ºä¸¤ä¸ªå‡½æ•°çš„ç›¸äº’ä½œç”¨</p>
<p>æ•°å­¦ä¸Šï¼Œå…¶è¿ç»­å‡½æ•°çš„è§£æå¼å†™ä½œï¼š</p>
<p>$ F(x) = \int_{-\infty}^{+\infty}f(\tau)\,g(x -\tau)$</p>
<p>$ F(x) = \sum_{\tau=1}^N f(\tau)\,g(x -\tau)$</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409252256263.gif" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" /></p>
<p>é€šå¸¸æƒ…å†µä¸‹ï¼Œf ( Ï„ ) è¡¨ç¤ºè¢«ç§¯å‡½æ•°ï¼Œè€Œ g ( x âˆ’ Ï„ )  è¡¨ç¤ºå·ç§¯æ ¸å‡½æ•°ã€‚è¿™é‡Œå¤šè¯´ä¸€å¥ï¼Œä¹‹æ‰€ä»¥ä¸ä½¿ç”¨ f ( x ) è¡¨ç¤ºåŸå‡½æ•°è€Œç”¨ f ( Ï„ ) ï¼Œè€Œä¸”å¼ºè°ƒ f ( Ï„ ) æ˜¯è¢«ç§¯å‡½æ•°ï¼Œæ˜¯å› ä¸º f ( x )  ä¸ f ( Ï„ ) ä¹‹é—´è¿˜å­˜åœ¨ç€å¦‚ä¸‹å…³ç³»ï¼š<br />
$ f(x) = \int_{-\infty}^{+\infty}f(\tau)d\tau$</p>
<p>ä¸Šå¼è¡¨æ˜çš„æ“ä½œåœ¨ç›´è§‚ä¸Šç†è§£æ˜¯å…ˆå¯¹å·ç§¯æ ¸ç¿»è½¬ï¼Œç„¶åä¸è¾“å…¥ç‚¹ä¹˜ã€æ±‚å’Œå¾—åˆ°è¾“å‡ºã€‚åœ¨æœºå™¨å­¦ä¹ é¢†åŸŸå°¤å…¶æ˜¯æ·±åº¦å­¦ä¹ ä¸­ï¼Œå·ç§¯çš„å®ç°é€šå¸¸çœå»äº†å·ç§¯æ ¸ç¿»è½¬è¿™ä¸€æ­¥ï¼Œå› ä¸ºæ·±åº¦å­¦ä¹ ä¸­çš„å·ç§¯æ ¸å‚æ•°æ˜¯ä¸æ–­å­¦ä¹ æ›´æ–°ï¼Œå› æ­¤æœ‰æ²¡æœ‰ç¿»è½¬å¹¶æ²¡æœ‰æ€§è´¨ä¸Šçš„å½±å“ã€‚ä¸¥æ ¼å®šä¹‰ä¸Šè¯´ï¼Œæ·±åº¦å­¦ä¹ ä¸­çš„å·ç§¯å®é™…ä¸Šæ˜¯å¦ä¸€ç§æ“ä½œï¼š<a href="https://zhida.zhihu.com/search?content_id=105153470&amp;content_type=Article&amp;match_order=1&amp;q=%E4%BA%92%E7%9B%B8%E5%85%B3&amp;zhida_source=entity"  target="_blank">äº’ç›¸å…³</a> <a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Cross-correlation"  target="_blank">Cross-Correlation</a>ã€‚å…¬å¼è¡¨ç¤ºå¦‚ä¸‹</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409252334611.png" alt="image-20240925233420506" /></p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409252334905.webp" alt="åŠ¨å›¾" /></p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409252335303.png" alt="image-20240925233512203" /></p>
<p>ä¸è€ƒè™‘ paddingï¼Œä»¥ stride ä¸º 1ï¼Œé‚£ä¹ˆæˆ‘ä»¬è¿›è¡Œå·ç§¯è®¡ç®—å¾—åˆ°çš„ç»“æœä¸º</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409252335091.png" alt="image-20240925233556003" /></p>
<h4 id="%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F">å·ç§¯çš„ä¸‰ç§æ¨¡å¼</h4>
<p>æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­é€šå¸¸ä¼šå®ç°ä¸‰ç§ä¸åŒçš„å·ç§¯æ¨¡å¼ï¼Œåˆ†åˆ«æ˜¯ SAMEã€VALIDã€FULLã€‚è¿™ä¸‰ç§æ¨¡å¼çš„æ ¸å¿ƒåŒºåˆ«åœ¨äº<strong>å·ç§¯æ ¸è¿›è¡Œå·ç§¯æ“ä½œçš„ç§»åŠ¨åŒºåŸŸä¸åŒ</strong>ï¼Œè¿›è€Œå¯¼è‡´è¾“å‡ºçš„å°ºå¯¸ä¸åŒã€‚æˆ‘ä»¬ä»¥ä¸€ä¸ªä¾‹å­æ¥çœ‹è¿™ä¸‰ç§æ¨¡å¼çš„åŒºåˆ«ï¼Œè¾“å…¥å›¾ç‰‡çš„å°ºå¯¸æ˜¯ 5Ã—5 ï¼Œå·ç§¯æ ¸å°ºå¯¸æ˜¯ 3Ã—3 ï¼Œstride å– 1ã€‚</p>
<ul>
<li>FULL æ¨¡å¼</li>
</ul>
<p>FULL æ¨¡å¼ä¸‹å·ç§¯æ ¸<strong>ä»ä¸è¾“å…¥æœ‰ä¸€ä¸ªç‚¹çš„ç›¸äº¤çš„åœ°æ–¹å°±å¼€å§‹å·ç§¯</strong>ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè“æ¡†çš„ä½ç½®å°±æ˜¯å·ç§¯æ ¸ç¬¬ä¸€ä¸ªå·ç§¯çš„åœ°æ–¹ï¼Œç°è‰²éƒ¨åˆ†æ˜¯ä¸ºäº†å·ç§¯èƒ½å¤Ÿæ­£å¸¸è¿›è¡Œçš„ paddingï¼ˆä¸€èˆ¬å¡« 0ï¼‰ã€‚å› æ­¤ FULL æ¨¡å¼ä¸‹å·ç§¯æ ¸ç§»åŠ¨åŒºåŸŸæœ€å¤§ï¼Œå·ç§¯åè¾“å‡ºçš„å°ºå¯¸ä¹Ÿæœ€å¤§ã€‚</p>
<p><img src="https://pica.zhimg.com/80/v2-23ba5f401533b72b0214bd51a091000c_720w.webp" alt="img" /></p>
<ul>
<li>VALID æ¨¡å¼</li>
</ul>
<p>VALID æ¨¡å¼ä¸ FULL æ¨¡å¼ç›¸åï¼Œ<strong>åœ¨æ•´ä¸ªå·ç§¯æ ¸ä¸è¾“å…¥é‡å çš„åœ°æ–¹æ‰å¼€å§‹å·ç§¯æ“ä½œ</strong>ï¼Œå› æ­¤ä¸éœ€è¦ paddingï¼Œè¾“å‡ºçš„å°ºå¯¸ä¹Ÿæœ€å°</p>
<p><img src="https://pic4.zhimg.com/80/v2-fc57effd13fdf64eeb375f57e65e309d_720w.webp" alt="img" /></p>
<ul>
<li>SAME æ¨¡å¼</li>
</ul>
<p>SAME æ¨¡å¼æ˜¯æœ€å¸¸ç”¨çš„ä¸€ç§æ¨¡å¼ï¼ŒSAME çš„æ„æ€æ˜¯å·ç§¯åè¾“å‡ºçš„å°ºå¯¸ä¸è¾“å…¥å°ºå¯¸ä¿æŒä¸€è‡´ï¼ˆå‡å®š stride ä¸º 1ï¼‰ã€‚é€šè¿‡å°†å·ç§¯æ ¸çš„ä¸­å¿ƒä¸è¾“å…¥çš„ç¬¬ä¸€ä¸ªç‚¹è¿›è¡Œå¯¹é½ç¡®å®šå·ç§¯æ ¸èµ·å§‹ä½ç½®ï¼Œç„¶åè¡¥é½å¯¹åº” padding å³å¯ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¯ä»¥çœ‹åˆ°å·ç§¯è¾“å‡ºçš„å°ºå¯¸ä¸å‡ºå…¥ä¿æŒä¸€è‡´ã€‚</p>
<p><img src="https://pic4.zhimg.com/80/v2-a18f53d4f4d60a0eb6d1940d06bd5af5_720w.webp" alt="img" /></p>
<p>SAME æ¨¡å¼ä¸‹å½“å·ç§¯æ ¸è¾¹é•¿ä¸ºå¶æ•°æ—¶ï¼Œå¯ä»¥é€šè¿‡åœ¨å…¶ä¸­ä¸€è¾¹å¢åŠ å¤šä¸€è¡Œï¼ˆåˆ—ï¼‰paddingï¼Œå³ä¸å¯¹ç§°çš„ padding å®ç°è¾“å‡ºå°ºå¯¸ä¸è¾“å…¥å°ºå¯¸ä¿æŒä¸€è‡´ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼ˆå·ç§¯æ ¸å°ºå¯¸ä¸º 2Ã—2 ï¼‰</p>
<p><img src="https://pica.zhimg.com/80/v2-0ace23e8761226979fbe7ecd0a1905c8_720w.webp" alt="img" /></p>
<p>ä»¥ä¸Šä¸‰ç§æ¨¡å¼åŒºåˆ«åœ¨äºå·ç§¯æ ¸è¿›è¡Œå·ç§¯æ“ä½œçš„ç§»åŠ¨åŒºåŸŸä¸åŒï¼Œå…¶å®æ˜¯ç¡®å®šäº†æ‰€éœ€çš„ paddingã€‚</p>
<h4 id="%E6%B1%A0%E5%8C%96%E5%B1%82Pooling-layers">æ± åŒ–å±‚Pooling layers</h4>
<p>å®ƒå®é™…ä¸Šæ˜¯ä¸€ç§å½¢å¼çš„é™é‡‡æ ·ã€‚æœ‰å¤šç§ä¸åŒå½¢å¼çš„éçº¿æ€§æ± åŒ–å‡½æ•°ï¼Œè€Œå…¶ä¸­â€œæœ€å¤§æ± åŒ–ï¼ˆMax poolingï¼‰â€æ˜¯æœ€ä¸ºå¸¸è§çš„ã€‚å®ƒæ˜¯å°†è¾“å…¥çš„å›¾åƒåˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªçŸ©å½¢åŒºåŸŸï¼Œå¯¹æ¯ä¸ªå­åŒºåŸŸè¾“å‡ºæœ€å¤§å€¼ã€‚ç›´è§‰ä¸Šï¼Œè¿™ç§æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°åŸå› åœ¨äºï¼Œåœ¨å‘ç°ä¸€ä¸ªç‰¹å¾ä¹‹åï¼Œå®ƒçš„ç²¾ç¡®ä½ç½®è¿œä¸åŠå®ƒå’Œå…¶ä»–ç‰¹å¾çš„ç›¸å¯¹ä½ç½®çš„å…³ç³»é‡è¦ã€‚æ± åŒ–å±‚ä¼šä¸æ–­åœ°å‡å°æ•°æ®çš„ç©ºé—´å¤§å°ï¼Œå› æ­¤å‚æ•°çš„æ•°é‡å’Œè®¡ç®—é‡ä¹Ÿä¼šä¸‹é™ï¼Œè¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šä¹Ÿæ§åˆ¶äº†è¿‡æ‹Ÿåˆã€‚é€šå¸¸æ¥è¯´ï¼ŒCNNçš„å·ç§¯å±‚ä¹‹é—´éƒ½ä¼šå‘¨æœŸæ€§åœ°æ’å…¥æ± åŒ–å±‚ã€‚<br />
<img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409262220821.png" alt="img" /></p>
<h4 id="%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB">éçº¿æ€§æ¿€æ´»</h4>
<p><strong>ReLu</strong>ï¼Œå…¨ç§°æ˜¯Rectified Linear Unitï¼Œä¸­æ–‡åç§°æ˜¯çº¿æ€§æ•´æµå‡½æ•°ï¼Œæ˜¯åœ¨ç¥ç»ç½‘ç»œä¸­å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°ã€‚é€šå¸¸æ„ä¹‰ä¸‹ï¼Œå…¶æŒ‡ä»£æ•°å­¦ä¸­çš„æ–œå¡å‡½æ•°ï¼Œå³F(X) = max(0, x) ã€‚å…¶å¯¹åº”çš„å‡½æ•°å›¾åƒå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409262259886.png" alt="image-20240926225959744" /></p>
<ul>
<li><strong>Sigmoidï¼Œ</strong>æ˜¯å¸¸ç”¨çš„è¿ç»­ã€å¹³æ»‘çš„så‹æ¿€æ´»å‡½æ•°ï¼Œä¹Ÿè¢«ç§°ä¸ºé€»è¾‘ï¼ˆLogisticï¼‰å‡½æ•°ã€‚å¯ä»¥å°†ä¸€ä¸ªå®æ•°æ˜ å°„åˆ° <img src="https://www.zhihu.com/equation?tex=%280%2C+1%29&amp;consumer=ZHI_MENG" alt="(0, 1)" /> çš„åŒºé—´ï¼Œç”¨æ¥åšäºŒåˆ†ç±»ã€‚å…¶å‡½æ•°å®šä¹‰ä¸º  $f(x) = \frac{1}{1 + e^{-x}}$ï¼Œå‡½æ•°å›¾åƒå¦‚ä¸‹æ‰€ç¤ºï¼š</li>
</ul>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409262300639.webp" alt="img" /></p>
<ul>
<li><strong>Tanhå‡½æ•°</strong>ç§°ä¸ºåŒæ›²æ­£åˆ‡å‡½æ•°ï¼Œå‡½æ•°å®šä¹‰ä¸º $f(x) = tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$ï¼Œå€¼åŸŸä¸º (-1,1)(0, 1) ï¼Œå‡½æ•°å›¾åƒå¦‚ä¸‹ï¼š</li>
</ul>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409262300689.webp" alt="img" /></p>
<p>å¼•å…¥éçº¿æ€§æ¿€æ´»å‡½æ•°çš„ç›®çš„æ˜¯æé«˜ç¥ç»ç½‘ç»œçš„éçº¿æ€§æ‹Ÿåˆèƒ½åŠ›ï¼Œå¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚å› æ­¤ï¼Œåœ¨è¡¨è¯‰è¿‡ç¨‹ä¸­ï¼Œåœ¨æ²¡æœ‰æ˜ç¡®æŒ‡æ˜çš„æƒ…å†µä¸‹ï¼Œæ¿€æ´»å‡½æ•°æŒ‡ä»£éçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚ç»è¿‡ä¸¥æ ¼çš„æ•°å­¦æ¨å¯¼ï¼Œå¦‚æœç½‘ç»œä¸­æ²¡æœ‰ä½¿ç”¨æ¿€æ´»å‡½æ•°ï¼Œæ¯ä¸€å±‚çš„èŠ‚ç‚¹çš„è¾“å…¥éƒ½æ˜¯ä¸Šå±‚è¾“å‡ºçš„çº¿æ€§å‡½æ•°ï¼Œæ— è®ºç¥ç»ç½‘ç»œä¸­çš„éšå«å±‚æœ‰å¤šå°‘ï¼Œæœ€åçš„è¾“å‡ºç»“æœéƒ½æ˜¯ç½‘ç»œè¾“å…¥çš„çº¿æ€§æ‹Ÿåˆï¼Œå³éšå«å±‚æ²¡æœ‰å‘æŒ¥å…¶ä½œç”¨ã€‚ä¸ºæ­¤ï¼Œå¼•å…¥éçº¿æ€§å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°æ¥æé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚</p>
<p>ä¸¾ä¸ªæ —å­ï¼šå¦‚æœä¸ä½¿ç”¨éçº¿æ€§å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨é€»è¾‘å›å½’åšç®€å•çš„çº¿æ€§åˆ’åˆ†ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p>
<p><img src="https://pic1.zhimg.com/v2-7a857d55584ce83c1b877ae96383c0c6_b.webp?consumer=ZHI_MENG" alt="img" /></p>
<p>ä½¿ç”¨ç®€å•çš„çº¿æ€§åˆ’åˆ†æ— æ³•æœ‰æ•ˆåˆ’åˆ†æ•°æ®ç±»åˆ«ï¼Œå¯¹æ­¤éœ€è¦å¼•å…¥éçº¿æ€§ï¼Œä¸ºæ•°æ®é›†åˆ’åˆ†æé«˜æœ‰æ•ˆçš„æ–¹å¼ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p>
<p><img src="https://picx.zhimg.com/v2-e042df59cf85ccb712141d152d958d8d_b.webp?consumer=ZHI_MENG" alt="img" /></p>
<p>ç”±æ­¤å¯è§ï¼Œå¼•å…¥æ¿€æ´»å‡½æ•°èƒ½å¤Ÿæ­£ç¡®æœ‰æ•ˆåˆ’åˆ†æ•°æ®ç±»åˆ«ã€‚å¼•å…¥éçº¿æ€§å› ç´ ï¼Œä½¿å¾—ç¥ç»ç½‘ç»œèƒ½å¤Ÿæ›´å¥½åœ°è§£å†³å¤æ‚é—®é¢˜ã€‚</p>
<h4 id="Normalization-Layer">Normalization Layer</h4>
<p><a href="https://zhuanlan.zhihu.com/p/647813604"  target="_blank">ä¸€æ–‡ææ‡‚Batch Normalization å’Œ Layer Normalization - çŸ¥ä¹ (zhihu.com)</a></p>
<p>Normalizationï¼šè§„èŒƒåŒ–æˆ–æ ‡å‡†åŒ–ï¼Œå°±æ˜¯æŠŠè¾“å…¥æ•°æ®Xï¼Œåœ¨è¾“é€ç»™ç¥ç»å…ƒä¹‹å‰å…ˆå¯¹å…¶è¿›è¡Œå¹³ç§»å’Œä¼¸ç¼©å˜æ¢ï¼Œå°†Xçš„åˆ†å¸ƒè§„èŒƒåŒ–æˆåœ¨å›ºå®šåŒºé—´èŒƒå›´çš„<a href="https://zhida.zhihu.com/search?content_id=232088974&amp;content_type=Article&amp;match_order=1&amp;q=%E6%A0%87%E5%87%86%E5%88%86%E5%B8%83&amp;zhida_source=entity"  target="_blank">æ ‡å‡†åˆ†å¸ƒ</a>ã€‚</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409271852225.png" alt="image-20240927185243068" /></p>
<p>Î¼ï¼š<a href="https://zhida.zhihu.com/search?content_id=232088974&amp;content_type=Article&amp;match_order=1&amp;q=%E5%B9%B3%E7%A7%BB%E5%8F%82%E6%95%B0&amp;zhida_source=entity"  target="_blank">å¹³ç§»å‚æ•°</a> ï¼ŒÎ´ï¼šç¼©æ”¾å‚æ•° ï¼Œb ï¼šå†å¹³ç§»å‚æ•°ï¼Œ g å†ç¼©æ”¾å‚æ•°ï¼Œå¾—åˆ°çš„æ•°æ®ç¬¦åˆå‡å€¼ä¸º b ã€æ–¹å·®ä¸ºg^2 çš„åˆ†å¸ƒã€‚</p>
<p>Normalization çš„ä½œç”¨å¾ˆæ˜æ˜¾ï¼ŒæŠŠæ•°æ®æ‹‰å›<a href="https://zhida.zhihu.com/search?content_id=232088974&amp;content_type=Article&amp;match_order=1&amp;q=%E6%A0%87%E5%87%86%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83&amp;zhida_source=entity"  target="_blank">æ ‡å‡†æ­£æ€åˆ†å¸ƒ</a>ï¼Œå› ä¸º<a href="https://zhida.zhihu.com/search?content_id=232088974&amp;content_type=Article&amp;match_order=1&amp;q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;zhida_source=entity"  target="_blank">ç¥ç»ç½‘ç»œ</a>çš„Blockå¤§éƒ¨åˆ†éƒ½æ˜¯<a href="https://zhida.zhihu.com/search?content_id=232088974&amp;content_type=Article&amp;match_order=1&amp;q=%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97&amp;zhida_source=entity"  target="_blank">çŸ©é˜µè¿ç®—</a>ï¼Œä¸€ä¸ªå‘é‡ç»è¿‡çŸ©é˜µè¿ç®—åå€¼ä¼šè¶Šæ¥è¶Šå¤§ï¼Œä¸ºäº†ç½‘ç»œçš„ç¨³å®šæ€§ï¼Œæˆ‘ä»¬éœ€è¦åŠæ—¶æŠŠå€¼æ‹‰å›æ­£æ€åˆ†å¸ƒã€‚</p>
<p>Normalizationæ ¹æ®æ ‡å‡†åŒ–æ“ä½œçš„ç»´åº¦ä¸åŒå¯ä»¥åˆ†ä¸ºbatch Normalizationå’ŒLayer Normalizationï¼Œä¸ç®¡åœ¨å“ªä¸ªç»´åº¦ä¸Šåšnoramlizationï¼Œæœ¬è´¨éƒ½æ˜¯ä¸ºäº†è®©æ•°æ®åœ¨è¿™ä¸ªç»´åº¦ä¸Šå½’ä¸€åŒ–ï¼Œå› ä¸ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸Šä¸€å±‚ä¼ é€’ä¸‹å»çš„å€¼åƒå¥‡ç™¾æ€ªï¼Œä»€ä¹ˆæ ·å­çš„åˆ†å¸ƒéƒ½æœ‰ã€‚BatchNormå°±æ˜¯é€šè¿‡å¯¹<a href="https://zhida.zhihu.com/search?content_id=232088974&amp;content_type=Article&amp;match_order=1&amp;q=batch+size&amp;zhida_source=entity"  target="_blank">batch size</a>è¿™ä¸ªç»´åº¦å½’ä¸€åŒ–æ¥è®©åˆ†å¸ƒç¨³å®šä¸‹æ¥ã€‚LayerNormåˆ™æ˜¯é€šè¿‡å¯¹<a href="https://zhida.zhihu.com/search?content_id=232088974&amp;content_type=Article&amp;match_order=1&amp;q=Hidden+size&amp;zhida_source=entity"  target="_blank">Hidden size</a>è¿™ä¸ªç»´åº¦å½’ä¸€åŒ–æ¥è®©æŸå±‚çš„åˆ†å¸ƒç¨³å®šã€‚</p>
<p>å¯ä»¥è¿™æ ·ç†è§£ï¼Œæ·±åº¦ç½‘ç»œæ¯ä¸€å±‚ç½‘ç»œæ˜¯ç›¸å¯¹ç‹¬ç«‹çš„ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯ä¸€å±‚ç½‘ç»œå¯ä»¥å•ç‹¬çœ‹æˆä¸€ä¸ªClassifier.ä¸åœå¯¹ä¸Šä¸€å±‚çš„è¾“å‡ºæ•°æ®è¿›è¡Œåˆ†ç±»ï¼Œæ¯ä¸€å±‚è¾“å‡ºçš„æ•°æ®åˆ†å¸ƒåˆä¸ä¸€æ ·ï¼Œè¿™å°±ä¼šå‡ºç°Internal Covariate Shiftï¼ˆ<a href="https://zhida.zhihu.com/search?content_id=232088974&amp;content_type=Article&amp;match_order=1&amp;q=%E5%86%85%E9%83%A8%E5%8D%8F%E5%8F%98%E9%87%8F&amp;zhida_source=entity"  target="_blank">å†…éƒ¨åå˜é‡</a>åç§»ï¼‰. éšç€ç½‘ç»œçš„å±‚æ•°ä¸æ–­å¢å¤§ï¼Œè¿™ç§è¯¯å·®å°±ä¼šä¸æ–­ç§¯ç´¯ï¼Œæœ€ç»ˆå¯¼è‡´æ•ˆæœæ¬ ä½³ã€‚æ˜¾ç„¶å¯¹<a href="https://zhida.zhihu.com/search?content_id=232088974&amp;content_type=Article&amp;match_order=1&amp;q=%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86&amp;zhida_source=entity"  target="_blank">æ•°æ®é¢„å¤„ç†</a>åªèƒ½è§£å†³ç¬¬ä¸€å±‚çš„é—®é¢˜ï¼Œä¹‹åéœ€è¦Normalizationç­‰æ–¹æ³•æ¥è§£å†³ã€‚</p>
<h4 id="Recuurent-Layers%E5%BE%AA%E7%8E%AF%E5%B1%82">Recuurent Layerså¾ªç¯å±‚</h4>
<p>Recurrent Layersçš„ä¸»è¦ä½œç”¨æ˜¯åœ¨ç¥ç»ç½‘ç»œä¸­æä¾›è®°å¿†åŠŸèƒ½ï¼Œä½¿å¾—ç½‘ç»œèƒ½å¤Ÿå¤„ç†æ—¶é—´åºåˆ—æ•°æ®æˆ–å…·æœ‰æ—¶é—´ç›¸å…³æ€§çš„æ•°æ®ã€‚é€šè¿‡åœ¨ç½‘ç»œä¸­å¼•å…¥å¾ªç¯è¿æ¥ï¼ŒRecurrent Layerså¯ä»¥å°†å…ˆå‰çš„è¾“å‡ºä½œä¸ºè¾“å…¥ä¼ é€’ç»™ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œä»è€Œå…è®¸ç½‘ç»œåœ¨å¤„ç†åºåˆ—æ•°æ®æ—¶è€ƒè™‘åˆ°ä¹‹å‰çš„ä¿¡æ¯ã€‚è¿™ç§è®°å¿†æœºåˆ¶èƒ½å¤Ÿå¸®åŠ©ç½‘ç»œæ›´å¥½åœ°ç†è§£å’Œé¢„æµ‹åºåˆ—æ•°æ®ä¸­çš„æ¨¡å¼å’Œè¶‹åŠ¿ï¼ŒåŒæ—¶ä¹Ÿæœ‰åŠ©äºè§£å†³çŸ­æœŸè®°å¿†å’Œæ¢¯åº¦æ¶ˆå¤±ç­‰é—®é¢˜ã€‚å› æ­¤ï¼ŒRecurrent Layersåœ¨è¯­è¨€æ¨¡å‹ã€æœºå™¨ç¿»è¯‘ã€æ—¶é—´åºåˆ—é¢„æµ‹ç­‰ä»»åŠ¡ä¸­å…·æœ‰é‡è¦ä½œç”¨ã€‚</p>
<h4 id="Transform-Layer">Transform Layer</h4>
<p>è§£å†³ç‰¹å®šé—®é¢˜çš„æ—¶å€™ä½¿ç”¨</p>
<h4 id="Linear-Layer">Linear Layer</h4>
<p>çº¿æ€§å±‚, å¯¹è¾“å…¥çš„æ¯ä¸€ä¸ªæ•°æ®ä¹˜ä»¥ä¸€ä¸ªæƒé‡, ä¹‹åç›¸åŠ </p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409271917063.png" alt="image-20240927191723938" /></p>
<h4 id="Dropout-Layers">Dropout Layers</h4>
<p>éšæœºå§ä¸€éƒ¨åˆ†çš„å…ƒç´ å˜ä¸º0, é˜²æ­¢æ•°æ®è¿‡æ‹Ÿåˆ, é˜²æ­¢åœ¨å®é™…å¤„ç†æ•°çš„æ—¶å€™æ³›ç”¨æ€§ä¸å¼º</p>
<h4 id="Sparse-Layer">Sparse Layer</h4>
<p>ç”¨äºè‡ªç„¶è¯­è¨€çš„å¤„ç†</p>
<h4 id="%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">æŸå¤±å‡½æ•°å’Œåå‘ä¼ æ’­</h4>
<p>Loss: å®é™…è·å–çš„æ•°æ®å’ŒçœŸå®çš„æ•°æ®ä¹‹é—´çš„å·®è·, å¯ä»¥ä½¿ç”¨è¿™ä¸€ä¸ªè®¡ç®—å®é™…è¾“å‡ºå’Œç›®æ ‡çš„å·®è·, ä¹Ÿå¯ä»¥ä¸ºæ›´æ–°è¾“å‡ºæä¾›ä¾æ®(åå‘ä¼ æ’­)</p>
<h3 id="%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE">åŠ è½½æ•°æ®</h3>
<p>è¯»å–æ•°æ®çš„æ—¶å€™ä¸»è¦æœ‰ä¸¤ä¸ªç±», dataset, dataloader</p>
<p>dataset: å¯¹æ•°æ®è¿›è¡Œåˆ†ç±»å¹¶è¿›è¡Œç¼–å·, è·å–æ•°æ®çš„lableå€¼</p>
<p>dataloader: å¯¹æ•°æ®è¿›è¡Œæ‰“åŒ…, ä¸ºåé¢çš„ç½‘ç»œæä¾›ä¸åŒçš„æ•°æ®å½¢å¼</p>
<p><strong>æ•°æ®é›†:</strong> ä¸€èˆ¬ä½¿ç”¨ä¸€ä¸‹çš„æ ‡è¯†æ–¹æ³•</p>
<ol>
<li>æŠŠä¸åŒçš„æ•°æ®æŒ‰ç…§æ–‡ä»¶å¤¹åˆ†ç±», æ–‡ä»¶å¤¹çš„åå­—æ ‡è¯†è¿™ä¸€ä¸ªæ•°æ®é›†çš„type</li>
<li>ä½¿ç”¨å•ç‹¬çš„æ–‡ä»¶æ ‡è¯†å›¾ç‰‡çš„lable</li>
<li>ä¹‹é—´æŠŠlableå†™åœ¨å›¾ç‰‡çš„åå­—</li>
</ol>

<pre class="language-c"><code class="language-c">from torch.utils.data import Dataset
help(Dataset)
</code></pre>
<blockquote>

<pre class="language-bash"><code class="language-bash">Help on class Dataset in module torch.utils.data.dataset:

class Dataset(typing.Generic)
 |  An abstract class representing a :class:`Dataset`.
 |
 |  All datasets that represent a map from keys to data samples should subclass
 |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a
 |  data sample for a given key. Subclasses could also optionally overwrite
 |  :meth:`__len__`, which is expected to return the size of the dataset by many
 |  :class:`~torch.utils.data.Sampler` implementations and the default options
 |  of :class:`~torch.utils.data.DataLoader`. Subclasses could also
 |  optionally implement :meth:`__getitems__`, for speedup batched samples
 |  loading. This method accepts list of indices of samples of batch and returns
 |  list of samples.
 |
 |  .. note::
 |    :class:`~torch.utils.data.DataLoader` by default constructs an index
 |    sampler that yields integral indices.  To make it work with a map-style
 |    dataset with non-integral indices/keys, a custom sampler must be provided.
 |
 |  Method resolution order:
 |      Dataset
 |      typing.Generic
 |      builtins.object
 |
 |  Methods defined here:
 |
 |  __add__(self, other: 'Dataset[T_co]') -&gt; 'ConcatDataset[T_co]'
 |
 |  __getitem__(self, index) -&gt; +T_co
 |
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |
 |  __dict__
 |      dictionary for instance variables
 |
 |  __weakref__
 |      list of weak references to the object
 |
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |
 |  __annotations__ = {}
 |
 |  __orig_bases__ = (typing.Generic[+T_co],)
 |
 |  __parameters__ = (+T_co,)
 |
 |  ----------------------------------------------------------------------
 |  Class methods inherited from typing.Generic:
 |
 |  __class_getitem__(...)
 |      Parameterizes a generic class.
 |
 |      At least, parameterizing a generic class is the *main* thing this
 |      method does. For example, for some generic class `Foo`, this is called
 |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.
 |
 |      However, note that this method is also called when defining generic
 |      classes in the first place with `class Foo[T]: ...`.
 |
 |  __init_subclass__(...)
 |      Function to initialize subclasses.
</code></pre>
<p>ä¹Ÿå¯ä»¥ä½¿ç”¨<code>Dataset??</code>è¿™ä¸€ä¸ªæ–¹å¼è·å–çš„ä¿¡æ¯æ¯”è¾ƒæ¸…æ™°</p>

<pre class="language-bash"><code class="language-bash">Init signature: Dataset()
Source:        
class Dataset(Generic[T_co]):
    r&quot;&quot;&quot;An abstract class representing a :class:`Dataset`.

    All datasets that represent a map from keys to data samples should subclass
    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a
    data sample for a given key. Subclasses could also optionally overwrite
    :meth:`__len__`, which is expected to return the size of the dataset by many
    :class:`~torch.utils.data.Sampler` implementations and the default options
    of :class:`~torch.utils.data.DataLoader`. Subclasses could also
    optionally implement :meth:`__getitems__`, for speedup batched samples
    loading. This method accepts list of indices of samples of batch and returns
    list of samples.
    æ‰€æœ‰çš„æ•°æ®é›†å­ç±»éœ€è¦é›†æˆè¿™ä¸€ä¸ªç±», é‡å†™__getitem__

    .. note::
      :class:`~torch.utils.data.DataLoader` by default constructs an index
      sampler that yields integral indices.  To make it work with a map-style
      dataset with non-integral indices/keys, a custom sampler must be provided.
    &quot;&quot;&quot;

    def __getitem__(self, index) -&gt; T_co:
        raise NotImplementedError(&quot;Subclasses of Dataset should implement __getitem__.&quot;)

    # def __getitems__(self, indices: List) -&gt; List[T_co]:
    # Not implemented to prevent false-positives in fetcher check in
    # torch.utils.data._utils.fetch._MapDatasetFetcher

    def __add__(self, other: &quot;Dataset[T_co]&quot;) -&gt; &quot;ConcatDataset[T_co]&quot;:
        return ConcatDataset([self, other])

    # No `def __len__(self)` default?
    # See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]
    # in pytorch/torch/utils/data/sampler.py
File:           e:\jhy\python\anaconda-test\.conda\lib\site-packages\torch\utils\data\dataset.py
Type:           type
Subclasses:     IterableDataset, TensorDataset, StackDataset, ConcatDataset, Subset, MapDataPipe
</code></pre>
</blockquote>
<h3 id="%E5%AE%9E%E6%88%98">å®æˆ˜</h3>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409231942661.png" alt="image-20240923194200555" /></p>
<p>åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™ç”±äºéœ€è¦ä½¿ç”¨åˆ°å›¾ç‰‡çš„è¯»å–, æ‰€ä»¥ä¸ºè¿™é‡Œè¦å®‰è£…OpenCV<code>pip install opencv-python</code>, ä¹Ÿå¯ä»¥ä½¿ç”¨PILé‡Œé¢çš„Image</p>

<pre class="language-python"><code class="language-python">from torch.utils.data import Dataset
from PIL import Image
import os

# dir_path = &quot;./hymenoptera_data/train/ants&quot;
# img_path_list = os.listdir(dir_path)
# print(img_path_list)

# path = os.path.join(root_dir, lable_dir)
# print(path)
# img_path = &quot;./hymenoptera_data/train/ants/0013035.jpg&quot;
# img = Image.open(img_path)
# print(img.size)
# img.show()
class Mydata(Dataset):
    def __init__(self, read_dir, lable_dir):
        # åˆå§‹åŒ–
        self.root_dir = read_dir
        self.lable_dir = lable_dir
        self.path = os.path.join(self.root_dir, self.lable_dir)
        self.img_path_list = os.listdir(self.path)



    def __getitem__(self, index):
        &quot;&quot;&quot;
        Return the image and lable of the index-th sample
        å¯ä»¥ä½¿å¯¹è±¡ä½¿ç”¨å¼•ç”¨çš„æ–¹å¼è¿›è¡Œè°ƒç”¨
        &quot;&quot;&quot;
        img_name = self.img_path_list[index]
        img_path = os.path.join(self.path, img_name)
        img = Image.open(img_path)
        lable = self.lable_dir
        return img, lable

    def __len__(self):
        return len(self.img_path_list)

# è·å–ç¬¬ä¸€ä¸ªæ•°æ®é›†
root_dir = &quot;./hymenoptera_data/train&quot;
ants_lable_dir = &quot;ants&quot;
ants_mydata = Mydata(root_dir, ants_lable_dir)
img, lable = ants_mydata[0]
img.show()

bees_lable_dir = &quot;bees&quot;
bees_mydata = Mydata(root_dir, bees_lable_dir)
bees_img, bees_lable = bees_mydata[0]
bees_img.show()
</code></pre>
<p>è¿™ä¸¤ä¸ªæ•°æ®é›†å¯ä»¥ä½¿ç”¨<code>+</code>è¿›è¡Œåˆå¹¶</p>

<pre class="language-python"><code class="language-python">train_dataset = ants_mydata + bees_mydata
</code></pre>
<h2 id="tensorboard">tensorboard</h2>
<p>TensorBoard æ˜¯ä¸€ç»„ç”¨äºæ•°æ®å¯è§†åŒ–çš„å·¥å…·ã€‚å®ƒåŒ…å«åœ¨æµè¡Œçš„å¼€æºæœºå™¨å­¦ä¹ åº“ Tensorflow ä¸­ã€‚TensorBoard çš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š</p>
<ol>
<li>å¯è§†åŒ–æ¨¡å‹çš„ç½‘ç»œæ¶æ„</li>
<li>è·Ÿè¸ªæ¨¡å‹æŒ‡æ ‡ï¼Œå¦‚æŸå¤±å’Œå‡†ç¡®æ€§ç­‰</li>
<li>æ£€æŸ¥æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸­æƒé‡ã€åå·®å’Œå…¶ä»–ç»„ä»¶çš„ç›´æ–¹å›¾</li>
<li>æ˜¾ç¤ºéè¡¨æ ¼æ•°æ®ï¼ŒåŒ…æ‹¬å›¾åƒã€æ–‡æœ¬å’ŒéŸ³é¢‘</li>
<li>å°†é«˜ç»´åµŒå…¥æŠ•å½±åˆ°ä½ç»´ç©ºé—´</li>
</ol>
<p>è¿™ä¸€ä¸ªåœ¨torché‡Œé¢æœ‰è°ƒç”¨æ¨¡å—çš„, ä½¿ç”¨<code>pip install tensorboard</code>å®‰è£…</p>

<pre class="language-c"><code class="language-c">from torch.utils.tensorboard import SummaryWriter

write = SummaryWriter(&quot;logs&quot;)  # æ˜¯è¦ç”¨è¿™ä¸€ä¸ªæ–‡ä»¶å¤¹å­˜æ”¾æ•°æ®

# write.add_image()
for i in range(100):
    write.add_scalar(&quot;y=x&quot;, i, i)   # ç”»å›¾çš„æ—¶å€™ï¼Œyè½´æ˜¯iï¼Œxè½´æ˜¯i, ä¸åŒçš„æ–‡ä»¶éœ€è¦ä½¿ç”¨ä¸åŒçš„title

write.close()
</code></pre>
<blockquote>
<p>ä¹‹åä½¿ç”¨å‘½ä»¤<code>tensorboard --logdir=logs</code>å³å¯æ‰“å¼€ç”Ÿæˆçš„æ–‡ä»¶(è¿™é‡Œçš„å‚æ•°æ˜¯æ•°æ®ä¿å­˜çš„é‚£ä¸€ä¸ªæ–‡ä»¶å¤¹), å¯ä»¥ä½¿ç”¨<code>--port=port</code>è®¾ç½®ç«¯å£, é»˜è®¤çš„æ—¶å€™ä¼šä½¿ç”¨ç½‘é¡µ<a href="http://localhost:6006/%E8%BF%9B%E8%A1%8C%E6%98%BE%E7%A4%BA"  target="_blank">http://localhost:6006/%E8%BF%9B%E8%A1%8C%E6%98%BE%E7%A4%BA</a></p>
</blockquote>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409232334463.png" alt="image-20240923233445226" /></p>
<h3 id="%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87">æ˜¾ç¤ºå›¾ç‰‡</h3>

<pre class="language-python"><code class="language-python">from torch.utils.tensorboard import SummaryWriter
import numpy as np
from PIL import Image

write = SummaryWriter(&quot;logs&quot;)  # æ˜¯è¦ç”¨è¿™ä¸€ä¸ªæ–‡ä»¶å¤¹å­˜æ”¾æ•°æ®
image_path = &quot;hymenoptera_data/train/ants/0013035.jpg&quot;

img =Image.open(image_path)
img_array = np.array(img)
# åœ¨ä½¿ç”¨npè¿™ä¸€ä¸ªæ ¼å¼çš„æ—¶å€™éœ€è¦åŠ ä¸Šdataformatsè¿™ä¸€ä¸ªå‚æ•°
# ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯çª—å£åŒºåˆ†, ç¬¬äºŒä¸ªæ˜¯å›¾ç‰‡æ•°æ®, ç¬¬ä¸‰ä¸ªæ˜¯ç¬¬å‡ æ­¥(å¯ä»¥ä½¿ç”¨æ»‘å—æ¢æ­¥)
write.add_image(&quot;test&quot;, img_array, 1, dataformats='HWC')  
</code></pre>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409241001865.png" alt="image-20240924100139724" /></p>
<h3 id="%E6%98%BE%E7%A4%BA%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B">æ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹</h3>

<pre class="language-python"><code class="language-python"># è¿™é‡Œçš„jiaoæ˜¯è®­ç»ƒä½¿ç”¨çš„ä¸€ä¸ªMoudle
# inputæ˜¯è¾“å…¥çš„æ•°æ®
writer = SummaryWriter(&quot;logs&quot;)
writer.add_graph(jiao, input)
writer.close()
</code></pre>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409272257605.png" alt="image-20240927225748432" /></p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409272258867.png" alt="image-20240927225841697" /></p>
<h2 id="transforms">transforms</h2>
<h3 id="ToTensor">ToTensor</h3>
<p>ToTensoræ•°æ®ç±»å‹: ä½¿ç”¨<code>from torchvision import transforms</code>æ–‡ä»¶ä¸‹é¢çš„ToTensorå¯ä»¥æŠŠPILæˆ–è€…ä¸€ä¸ª<code>numpy.ndarray</code>è½¬æ¢ä¸ºä¸€ä¸ªtensoræ•°æ®ç±»å‹, è¿™ä¸€ä¸ªæ•°æ®ç±»å‹å®é™…æ˜¯å¯¹å›¾ç‰‡è¿›è¡Œä¸€äº›æ–¹ä¾¿ç¥ç»ç½‘ç»œçš„å°è£…</p>

<pre class="language-python"><code class="language-python">from torchvision import transforms
from PIL import Image

image_path = &quot;hymenoptera_data/train/ants/0013035.jpg&quot;
img = Image.open(image_path)

# 1. ToTensor
trans1 = transforms.ToTensor()
img_tensor = trans1(img)
</code></pre>

<pre class="language-python"><code class="language-python">import cv2
cv_img = cv2.imread(image_path)
</code></pre>
<blockquote>
<p>ä½¿ç”¨è¿™ç§æ–¹å¼æ‰“å¼€çš„æ–‡ä»¶æ˜¯ä¸€ä¸ª<code>numpy.ndarray</code>æ ¼å¼çš„å›¾ç‰‡</p>
</blockquote>

<pre class="language-python"><code class="language-python">from torchvision import transforms
from PIL import Image
from torch.utils.tensorboard import SummaryWriter

image_path = &quot;hymenoptera_data/train/ants/0013035.jpg&quot;
img = Image.open(image_path)

writer = SummaryWriter(&quot;logs&quot;)

# 1. ToTensor
trans1 = transforms.ToTensor()
img_tensor = trans1(img)
print(img_tensor)

writer.add_image(&quot;ToTensor&quot;, img_tensor)
</code></pre>
<p>å¯ä»¥ä½¿ç”¨è¿™ä¸€ä¸ªæ–¹å¼æ˜¾ç¤ºå›¾ç‰‡</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409241221068.png" alt="image-20240924122156943" /></p>
<h3 id="Compose">Compose</h3>
<p>æŠŠå¤šä¸ªtransformé›†åˆåœ¨ä¸€èµ·, åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™å¯ä»¥æŠŠå¤šä¸ªå¤„ç†çš„transformæ”¾åœ¨ä¸€èµ·, ä¾æ¬¡æ‰§è¡Œ</p>
<p>è¿™ä¸€ä¸ªåˆå§‹åŒ–çš„æ—¶å€™çš„å‚æ•°æ˜¯ä¸€ä¸ªæ•°åˆ—</p>

<pre class="language-python"><code class="language-python">trans4 = transforms.Compose([
    transforms.Resize((300, 300)),
    transforms.ToTensor()
])
img_tensor = trans4(img)
writer.add_image(&quot;Compose&quot;, img_tensor, 1)
</code></pre>
<h3 id="Normalize">Normalize</h3>
<p>ç”¨äºå¤„ç†å›¾ç‰‡çš„å·®å¼‚, å‚æ•°æ˜¯å‡å€¼å’Œæ ‡å‡†å·®, éœ€è¦æŒ‰ç…§é€šé“çš„ä¸ªæ•°ä¼ è¿›å»ä¸€ä¸ªæ•°åˆ—</p>
<p>è¿™ä¸€ä¸ªå‚æ•°æ•°å€¼æ˜¯éœ€è¦è®¡ç®—è·å–çš„</p>
<p>å®é™…çš„normalå¤„ç†äº‹input[channel] = (input[channel] - mean[channel]) / std[channel]</p>
<p>å¦‚å…¬å¼æ‰€ç¤ºï¼Œé€šè¿‡å‡å»å‡å€¼å¹¶é™¤ä»¥æ ‡å‡†å·®ï¼Œæˆ‘ä»¬å¯ä»¥å°†å›¾åƒæ•°æ®çš„åˆ†å¸ƒè½¬æ¢ä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1ï¼‰ã€‚è¿™æ ·ï¼Œæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°±å¯ä»¥æ›´å®¹æ˜“åœ°å­¦ä¹ åˆ°æ•°æ®çš„ç‰¹å¾ã€‚</p>
<blockquote>
<p>æ•°æ®æ ‡å‡†åŒ–ï¼šå¦‚ä¸Šæ‰€è¿°ï¼Œtransforms.Normalize()å‡½æ•°å¯ä»¥å¯¹å›¾åƒæ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œä½¿æ•°æ®åˆ†å¸ƒç¬¦åˆæ ‡å‡†æ­£æ€åˆ†å¸ƒã€‚è¿™æœ‰åŠ©äºæ¨¡å‹æ›´å¿«åœ°æ”¶æ•›ï¼Œå¹¶æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚<br />
æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼šé€šè¿‡å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥å‡å°‘æ¨¡å‹å¯¹ç‰¹å®šæ•°æ®é›†çš„è¿‡æ‹Ÿåˆï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚<br />
åŠ é€Ÿæ¨¡å‹è®­ç»ƒï¼šæ ‡å‡†åŒ–çš„æ•°æ®å¯ä»¥ä½¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´å¿«åœ°å­¦ä¹ åˆ°æ•°æ®çš„ç‰¹å¾ï¼Œä»è€ŒåŠ é€Ÿæ¨¡å‹çš„è®­ç»ƒé€Ÿåº¦ã€‚</p>
</blockquote>

<pre class="language-python"><code class="language-python"># 2. Normalize
print(img_tensor[0][0][0])
trans2 = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
img_tensor = trans2(img_tensor)
print(img_tensor[0][0][0])
</code></pre>
<h3 id="Resize">Resize</h3>
<p><code>size((h, w))</code>æˆ–è€…<code>size(int)</code>ç¬¬ä¸€ä¸ªä¼šæŠŠå›¾åƒè¿›è¡Œå˜æ¢, ç¬¬äºŒä¸ªä¼šä½¿å¾—è¿™ä¸€ä¸ªå›¾å½¢æ¯”è¾ƒå°çš„ä¸€ä¸ªè¾¹å’Œè¿™ä¸€ä¸ªæ•°å­—ä¸€æ ·</p>
<p>If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means a maximum of two leading dimensions</p>
<p>ä¹Ÿå¯ä»¥ä½¿ç”¨PILæ ¼å¼çš„æ•°æ®</p>
<blockquote>
<p>ToTensorçš„è½¬æ¢æ ¼å¼æ˜¯</p>
<p>Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]</p>
</blockquote>

<pre class="language-python"><code class="language-python">print(img.size)
trans3 = transforms.Resize((300, 300))
img_tensor = trans3(img)
print(img_tensor)
print(img_tensor.size)
</code></pre>
<h2 id="Dataset">Dataset</h2>
<p>è¿™é‡Œé€‰å–å…¶ä¸­ä¸€ä¸ªæ•°æ®é›†</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409241842098.png" alt="image-20240924184250991" /></p>
<blockquote>
<p>The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.</p>
</blockquote>

<pre class="language-python"><code class="language-python">import torchvision
from PIL import Image

# è·å–CIFAR10æ•°æ®é›†
train_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=True, download=True)
test_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=False, download=True)

# è·å–æ•°æ®é›†çš„å¤§å°
print(len(train_set))
print(len(test_set))

# è·å–æ•°æ®é›†çš„æ ‡ç­¾
print(train_set.classes)
print(test_set.classes)

print(train_set[1])
print(test_set[1])

# æ˜¾ç¤ºå›¾ç‰‡
train_set[1][0].show()
test_set[1][0].show()
</code></pre>
<blockquote>

<pre class="language-bash"><code class="language-bash">PS E:\JHY\python\anaconda-test&gt; &amp; e:/JHY/python/anaconda-test/.conda/python.exe e:/JHY/python/anaconda-test/my_dataset.py
Files already downloaded and verified
Files already downloaded and verified
50000
10000
['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
(&lt;PIL.Image.Image image mode=RGB size=32x32 at 0x218909AD370&gt;, 9)
(&lt;PIL.Image.Image image mode=RGB size=32x32 at 0x218909AD160&gt;, 8)
</code></pre>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409241919607.png" alt="image-20240924191954360" /></p>
</blockquote>
<p>å¯ä»¥ç›´æ¥ä½¿ç”¨å·¥å…·é›†åœ¨è·å–æ•°æ®é›†çš„æ—¶å€™è¿›è¡ŒåŠ å·¥</p>

<pre class="language-python"><code class="language-python">import torchvision
from PIL import Image
from torch.utils.tensorboard import SummaryWriter
# åˆå§‹åŒ–æ•°æ®é›†çš„è½¬æ¢
dataset_tramsforms = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor()
])


# è·å–CIFAR10æ•°æ®é›†, ç›´æ¥è¿›è¡Œè½¬æ¢
train_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=True, download=True, transform=dataset_tramsforms)
test_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=False, download=True, transform=dataset_tramsforms)

writer = SummaryWriter(&quot;logs&quot;)
for i in range(10):
    img, lable = train_set[i]
    writer.add_image(&quot;train_set&quot;, img, i)

for i in range(10):
    img, lable = test_set[i]
    writer.add_image(&quot;test_set&quot;, img, i)

writer.close()
# print(test_set[0])
</code></pre>
<h2 id="Dataloader">Dataloader</h2>
<p>ä¸€ä¸ªåŠ è½½å™¨, æŠŠæ•°æ®åŠ è½½åˆ°ç¥ç»ç½‘ç»œé‡Œé¢, ä»dataseté‡Œé¢å–æ•°æ®, å–çš„æ–¹æ³•å’Œæ•°é‡æ˜¯éœ€è¦ä½¿ç”¨dataloaderè¿›è¡Œè®¾ç½®çš„</p>
<h3 id="%E5%8F%82%E6%95%B0">å‚æ•°</h3>
<ul>
<li><strong>dataset</strong> (<a href="https://pytorch.org/docs/1.0.0/data.html#torch.utils.data.Dataset"  target="_blank"><em>Dataset</em></a>) â€“ dataset from which to load the data.</li>
<li><strong>batch_size</strong> (<a href="https://docs.python.org/3/library/functions.html#int"  target="_blank"><em>int</em></a><em>,</em> <em>optional</em>) â€“ how many samples per batch to load (default: <code>1</code>).ä¸€æ¬¡åŠ è½½çš„æ•°é‡</li>
<li><strong>shuffle</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"  target="_blank"><em>bool</em></a><em>,</em> <em>optional</em>) â€“ set to <code>True</code> to have the data reshuffled at every epoch (default: <code>False</code>).è¿™æ•°æ®æ˜¯ä¸æ˜¯éœ€è¦æ‰“ä¹±, ä¸€èˆ¬ä½¿ç”¨true</li>
<li><strong>sampler</strong> (<a href="https://pytorch.org/docs/1.0.0/data.html#torch.utils.data.Sampler"  target="_blank"><em>Sampler</em></a><em>,</em> <em>optional</em>) â€“ defines the strategy to draw samples from the dataset. If specified, <code>shuffle</code> must be False.</li>
<li><strong>batch_sampler</strong> (<a href="https://pytorch.org/docs/1.0.0/data.html#torch.utils.data.Sampler"  target="_blank"><em>Sampler</em></a><em>,</em> <em>optional</em>) â€“ like sampler, but returns a batch of indices at a time. Mutually exclusive with <code>batch_size</code>, <code>shuffle</code>, <code>sampler</code>, and <code>drop_last</code>.</li>
<li><strong>num_workers</strong> (<a href="https://docs.python.org/3/library/functions.html#int"  target="_blank"><em>int</em></a><em>,</em> <em>optional</em>) â€“ how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: <code>0</code>)æ˜¯ä¸æ˜¯ä½¿ç”¨å¤šè¿›ç¨‹è¿›è¡ŒåŠ è½½, Windowsä¸‹é¢è¿™ä¸€ä¸ªå¯èƒ½æœ‰é—®é¢˜</li>
<li><strong>collate_fn</strong> (<em>callable</em><em>,</em> <em>optional</em>) â€“ merges a list of samples to form a mini-batch.</li>
<li><strong>pin_memory</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"  target="_blank"><em>bool</em></a><em>,</em> <em>optional</em>) â€“ If <code>True</code>, the data loader will copy tensors into CUDA pinned memory before returning them.</li>
<li><strong>drop_last</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"  target="_blank"><em>bool</em></a><em>,</em> <em>optional</em>) â€“ set to <code>True</code> to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If <code>False</code> and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: <code>False</code>)é™¤ä¸å°½çš„æ—¶å€™å‰©ä¸‹çš„é‚£å‡ å¼ ç‰Œæ˜¯ä¸æ˜¯è¦èˆå»</li>
<li><strong>timeout</strong> (<em>numeric</em><em>,</em> <em>optional</em>) â€“ if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: <code>0</code>)</li>
<li><strong>worker_init_fn</strong> (<em>callable</em><em>,</em> <em>optional</em>) â€“ If not <code>None</code>, this will be called on each worker subprocess with the worker id (an int in <code>[0, num_workers - 1]</code>) as input, after seeding and before data loading. (default: <code>None</code>)</li>
</ul>

<pre class="language-python"><code class="language-python">import torchvision
from torch.utils.data import DataLoader

# åˆå§‹åŒ–æ•°æ®é›†çš„è½¬æ¢
dataset_tramsforms = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor()
])

test_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=False, download=True, transform=dataset_tramsforms)

test_loader = DataLoader(test_set, batch_size=4, shuffle=True, num_workers=0, drop_last=False)

img, targrt = test_set[0]
print(img.shape)
print(targrt)

for data in test_loader:
    imgs, targets = data
    print(imgs.shape)
    print(targets)
    break
</code></pre>
<blockquote>

<pre class="language-bash"><code class="language-bash">PS E:\JHY\python\anaconda-test&gt; &amp; e:/JHY/python/anaconda-test/.conda/python.exe e:/JHY/python/anaconda-test/my_dataloader.py
Files already downloaded and verified
torch.Size([3, 32, 32])
3
torch.Size([4, 3, 32, 32])
tensor([5, 9, 5, 9])
</code></pre>
<p>è¿™é‡Œæ˜¯æŠŠå›¾ç‰‡æŒ‰ç…§å››ä¸ªä¸€ç»„è¿›è¡Œæ‰“åŒ…, çŸ³ç¬‹è¿™ä¸€ä¸ªè¿”å›çš„æ˜¯ä¸¤ä¸ªtensoræ•°æ®ç±»å‹</p>
</blockquote>

<pre class="language-python"><code class="language-python">wrier = SummaryWriter(&quot;logs&quot;)
step = 0
for data in test_loader:
    imgs, targets = data
    wrier.add_images(&quot;test_loader&quot;, imgs, step)  # è¿™é‡Œä½¿ç”¨imagesåŠ è½½å¤šä¸ªå›¾ç‰‡
    step += 1
</code></pre>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409251910926.png" alt="image-20240925191028788" /></p>
<h2 id="%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA">ç½‘ç»œæ­å»º</h2>
<p>è¿™ä¸€ä¸ªç³»åˆ—çš„å·¥å…·ä¸»è¦æ˜¯åœ¨torch.nné‡Œé¢</p>
<ul>
<li>Container: ä¸€ä¸ªç¥ç»ç½‘ç»œçš„æ¡†æ¶</li>
<li>Convolution Layers: å·ç§¯å±‚</li>
<li>Pooling Layers: æ± åŒ–å±‚</li>
<li>Padding Layers:</li>
<li>...</li>
</ul>
<h3 id="Container">Container</h3>
<p>è¿™é‡Œé¢æœ€å¸¸ç”¨çš„æ˜¯Moudleè¿™ä¸€ä¸ªç±», æ˜¯æ‰€æœ‰ç¥ç»ç½‘ç»œçš„åŸºç±»</p>
<p>å®é™…çš„å¤„ç†æ•°æ®çš„å‡½æ•°æ˜¯æ¯ä¸€ä¸ªç±»é‡Œé¢çš„forwardè¿™ä¸€ä¸ªå‡½æ•°</p>

<pre class="language-python"><code class="language-python">import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
       x = F.relu(self.conv1(x)) # ä¸€æ¬¡å·ç§¯, ä¸€æ¬¡éçº¿æ€§å¤„ç†
       return F.relu(self.conv2(x)) # å†æ¬¡è¿›è¡Œå·ç§¯éçº¿æ€§è·å–è¾“å‡º
</code></pre>

<pre class="language-c"><code class="language-c">from torch import nn
import torch

class My_Moudle(nn.Module):
    def __init__(self):
        super(My_Moudle, self).__init__()


    def forward(self, x):
        return x + 1


if __name__ == &quot;__main__&quot;:
    x = torch.tensor(1.0)
    model = My_Moudle()
    y = model(x)
    print(y)
</code></pre>

<pre class="language-bash"><code class="language-bash">PS E:\JHY\python\anaconda-test&gt; &amp; e:/JHY/python/anaconda-test/.conda/python.exe e:/JHY/python/anaconda-test/my_moudle.py
tensor(2.)
</code></pre>
<h3 id="Sequential">Sequential</h3>

<pre class="language-python"><code class="language-python"># Example of using Sequential
model = nn.Sequential(
          nn.Conv2d(1,20,5),
          nn.ReLU(),
          nn.Conv2d(20,64,5),
          nn.ReLU()
        )

# Example of using Sequential with OrderedDict
model = nn.Sequential(OrderedDict([
          ('conv1', nn.Conv2d(1,20,5)),
          ('relu1', nn.ReLU()),
          ('conv2', nn.Conv2d(20,64,5)),
          ('relu2', nn.ReLU())
        ]))
</code></pre>
<h3 id="%E5%B1%82">å±‚</h3>
<h4 id="%E5%8D%B7%E7%A7%AF%E5%B1%82Convolution-Layers">å·ç§¯å±‚Convolution Layers</h4>
<p>è¿™é‡Œçš„é‡Œé¢æ¯”è¾ƒå¸¸ç”¨çš„æ˜¯Conv1d, Conv2d, è¿™ä¸€ä¸ªæ–‡ä»¶çš„æ“ä½œå®é™…æ˜¯å¯¹functionalè¿™ä¸€ä¸ªæ–‡ä»¶çš„æ“ä½œè¿›è¡Œçš„å°è£…</p>
<p><a href="https://gitcode.com/gh_mirrors/co/conv_arithmetic/blob/master/README.md?utm_source=csdn_github_accelerator&amp;isLogin=1"  target="_blank">conv_arithmetic:A technical report on convolution arithmetic in the context of deep learning - GitCode</a></p>
<ul>
<li>Conv2d</li>
</ul>

<pre class="language-python"><code class="language-python">torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)
</code></pre>
<img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409261824662.png" alt="image-20240926182432173" style="zoom:150%;" />
<p>in_channels</p>
<p>â€‹	è¾“å…¥çš„é€šé“æ•°</p>
<p>out_channels</p>
<p>â€‹	è¾“å‡ºçš„é€šé“æ•°, å®é™…æ˜¯ä½¿ç”¨å‡ ä¸ªä¸åŒçš„å·ç§¯æ ¸ç”Ÿæˆå¤šä¸ªç»“æœ</p>
<p>kernel_size<br />
â€ƒâ€ƒå·ç§¯æ ¸çš„å¤§å°ï¼Œä¸€èˆ¬æˆ‘ä»¬ä¼šä½¿ç”¨5x5ã€3x3è¿™ç§å·¦å³ä¸¤ä¸ªæ•°ç›¸åŒçš„å·ç§¯æ ¸ï¼Œå› æ­¤è¿™ç§æƒ…å†µåªéœ€è¦å†™kernel_size = 5è¿™æ ·çš„å°±è¡Œäº†ã€‚å¦‚æœå·¦å³ä¸¤ä¸ªæ•°ä¸åŒï¼Œæ¯”å¦‚3x5çš„å·ç§¯æ ¸ï¼Œé‚£ä¹ˆå†™ä½œkernel_size = (3, 5)ï¼Œæ³¨æ„éœ€è¦å†™ä¸€ä¸ªtupleï¼Œè€Œä¸èƒ½å†™ä¸€ä¸ªåˆ—è¡¨ï¼ˆlistï¼‰ã€‚é‡Œé¢çš„æ•°å­—æ˜¯ä¸éœ€è¦è®¾ç½®çš„, ä¼šåœ¨è®­ç»ƒçš„æ—¶å€™è¿›è¡Œè°ƒæ•´çš„</p>
<p>stride = 1<br />
â€ƒâ€ƒå·ç§¯æ ¸åœ¨å›¾åƒçª—å£ä¸Šæ¯æ¬¡å¹³ç§»çš„é—´éš”ï¼Œå³æ‰€è°“çš„æ­¥é•¿ã€‚è¿™ä¸ªæ¦‚å¿µå’ŒTensorflowç­‰å…¶ä»–æ¡†æ¶æ²¡ä»€ä¹ˆåŒºåˆ«ï¼Œä¸å†å¤šè¨€ã€‚</p>
<p>padding</p>
<p>â€‹	æ‹“å±•çš„å¤§å°</p>
<p>dilationç©ºæ´å·ç§¯, ä¸€èˆ¬ä¸ä½¿ç”¨</p>
<p><img src="https://raw.gitcode.com/gh_mirrors/co/conv_arithmetic/files/master/gif/dilation.gif" alt="img" /></p>
<p>groups</p>
<p>bias=True</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409261935794.png" alt="image-20240926193519679" /></p>
<blockquote>
<p>åŸç†</p>

<pre class="language-python"><code class="language-python">torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) 
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><strong>input</strong> â€“ input tensor of shape (minibatchÃ—in_channelsÃ—iHÃ—iW)è¾“å…¥çš„éœ€è¦æ˜¯ä¸€ä¸ªå››ç»´çš„æ•°ç»„, å¯ä»¥ä½¿ç”¨reshipå‡½æ•°è¿›è¡Œå˜æ¢</li>
<li><strong>weight</strong> â€“ filters of shape (out_channelsÃ—in_channelsgroupsÃ—kHÃ—kW)</li>
<li><strong>bias</strong> â€“ optional bias tensor of shape (out_channelsout_channels). Default: <code>None</code></li>
<li><strong>stride</strong> â€“ the stride of the convolving kernel. Can be a single number or a tuple (sH, sW). Default: 1</li>
<li><strong>padding</strong> â€“ implicit zero paddings on both sides of the input. Can be a single number or a tuple (padH, padW). Default: 0 å¡«å……</li>
<li><strong>dilation</strong> â€“ the spacing between kernel elements. Can be a single number or a tuple (dH, dW). Default: 1</li>
<li><strong>groups</strong> â€“ split input into groups, in_channelsin_channels should be divisible by the number of groups. Default: 1</li>
</ul>

<pre class="language-python"><code class="language-python">import torch
import torch.nn.functional as F

input = torch.tensor([[1, 2, 0, 3, 1], 
                      [0, 1, 2, 3, 1], 
                      [1, 2, 1, 0, 0], 
                      [5, 2, 3, 1, 1], 
                      [2, 1, 0, 1, 1]])

kernel = torch.tensor([[1, 2, 1],
                      [0, 1, 0],
                      [2, 1, 0]])
&quot;&quot;&quot;
ç»“æœ
1*1 + 2*2 + 0*1 + 0*0 + 1*1 + 0*2 + 1*2 + 2*1 + 0*3 = 10
1*2 + 2*0 + 1*3 + 0*1 + 1*2 + 0*3 + 2*2 + 1*3 + 0*0 = 12
...
&quot;&quot;&quot;

# è¿™é‡Œçš„å‚æ•°æ˜¯(N, C, H, W), Næ˜¯batch_size(æ¯ä¸€æ¬¡è®­ç»ƒçš„æ—¶å€™å›¾ç‰‡çš„æ•°é‡), Cæ˜¯é€šé“æ•°(äºŒç»´å‘é‡æ˜¯1), Hæ˜¯é«˜, Wæ˜¯å®½
input = torch.reshape(input, (1, 1, 5, 5))
kernel = torch.reshape(kernel, (1, 1, 3, 3))

print(input.shape)
print(kernel.shape)

output = F.conv2d(input, kernel, stride=1, padding=0)  # è¿™é‡Œçš„strideæ˜¯æ­¥é•¿, paddingæ˜¯å¡«å……
print(output)

</code></pre>

<pre class="language-bash"><code class="language-bash">PS E:\JHY\python\anaconda-test&gt; &amp; e:/JHY/python/anaconda-test/.conda/python.exe e:/JHY/python/anaconda-test/my_conv.py
torch.Size([1, 1, 5, 5])
torch.Size([1, 1, 3, 3])
tensor([[[[10, 12, 12],
          [18, 16, 16],
          [13,  9,  3]]]])
</code></pre>
</blockquote>

<pre class="language-python"><code class="language-python">import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.utils.tensorboard import SummaryWriter

dateset = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=False, download=True, 
                                       transform=torchvision.transforms.ToTensor())

dataloader = DataLoader(dateset, batch_size=64)

class JIAO(nn.Module):
    def __init__(self):
        super(JIAO, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)

    def forward(self, x):
        x = self.conv1(x)
        return x

jiao = JIAO()
&quot;&quot;&quot;
JIAO(
  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))
)
&quot;&quot;&quot;
print(jiao) 

writer = SummaryWriter(&quot;logs&quot;)
step = 0

for data in dataloader:
    imgs, targets = data
    output = jiao(imgs)
    print(imgs.shape) # torch.Size([64, 3, 32, 32])
    print(output.shape) # torch.Size([64, 6, 30, 30])
    writer.add_images(&quot;input&quot;, imgs, step)
    ## è¿™é‡Œçš„3æ˜¯è¾“å‡ºé€šé“æ•°, 30æ˜¯è¾“å‡ºçš„é«˜å’Œå®½, ä½¿ç”¨-1æ˜¯è‡ªåŠ¨è®¡ç®—, 3æ˜¯å¯ä»¥æ˜¾ç¤ºçš„é€šé“æ•°
    output = torch.reshape(output, (-1, 3, 30, 30)) 
    writer.add_images(&quot;output&quot;, output, step)
    step += 1

writer.close()
</code></pre>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409261932362.png" alt="image-20240926193224030" /></p>
<h4 id="%E6%B1%A0%E5%8C%96%E5%B1%82-Pooling-layers">æ± åŒ–å±‚ Pooling layers</h4>
<p>MaxPool: æœ€å¤§æ± åŒ–</p>
<p>MaxUnpool: ä¸Šé‡‡æ ·</p>
<p>...</p>
<p>æœ€å¸¸ä½¿ç”¨çš„MaxPool2d</p>
<ul>
<li>MaxPool2d</li>
</ul>
<p>class torch.nn.MaxPool2d(kernel_size, stride=None, padding=0,  dilation=1,return_indices=False, ceil_mode=False)</p>
<blockquote>
<ul>
<li><strong>kernel_size</strong> â€“ the size of the window to take a max overç”Ÿæˆçš„çª—å£</li>
<li><strong>stride</strong> â€“ the stride of the window. Default value is <code>kernel_size</code></li>
<li><strong>padding</strong> â€“ implicit zero padding to be added on both sides</li>
<li><strong>dilation</strong> â€“ a parameter that controls the stride of elements in the window</li>
<li><strong>return_indices</strong> â€“ if <code>True</code>, will return the max indices along with the outputs. Useful when Unpooling later</li>
<li><strong>ceil_mode</strong> â€“ when True, will use ceil instead of floor to compute the output shapeå½“ä¸€ä¸ªå–å€¼èŒƒå›´ä¸èƒ½å…¨éƒ¨è¦†ç›–çš„æ—¶å€™æ˜¯ä¸æ˜¯è¿›è¡Œèˆå»æ“ä½œ</li>
</ul>
</blockquote>
<h4 id="%E5%9E%AB%E5%B1%82Padding-Layer">å«å±‚Padding Layer</h4>
<p>ä½¿ç”¨æ•°å­—è¿›è¡Œå¡«å……, å‡ ä¹ç”¨ä¸åˆ°</p>
<h4 id="%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BBNon-Linear-Activactions">éçº¿æ€§æ¿€æ´»Non-Linear Activactions</h4>
<p>ä¸»è¦ä½¿ç”¨çš„æ˜¯ReLu, Sigmoid, Tanhè¿™å‡ ä¸ªç®—æ³•ä½¿ç”¨çš„æ–¹å¼å’Œå‰é¢çš„åŸºæœ¬ä¸€æ ·</p>
<h4 id="Normalization-Layers">Normalization Layers</h4>
<p>è¿™ä¸€ä¸ªä¸å¸¸ä½¿ç”¨, ä¸»è¦ç”¨çš„å‡½æ•°æ˜¯BatchNorm2dè¿™ä¸€ä¸ªå‡½æ•°, å®ƒçš„å‚æ•°mun_featuresæŒ‡çš„æ˜¯channelçš„æ•°é‡</p>
<h4 id="Liner-Layer">Liner Layer</h4>
<p>å‚æ•°å®é™…æ˜¯inputå’Œoutputçš„å¤§å°, æƒé‡æ˜¯æŒ‰ç…§è¾“å…¥çš„æ•°æ®è®¡ç®—çš„</p>
<p>ä¾‹: å®é™…çš„è®¡ç®—å¯ä»¥æŠŠä¸€ä¸ª1x1x4096çš„æ•°æ®è½¬æ¢ä¸º1x1x1000</p>
<h4 id="flatten">flatten</h4>
<p>æŠŠè¾“å…¥çš„æ•°æ®å±•å¼€ä¸ºä¸€è¡Œ</p>
<h4 id="%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">æŸå¤±å‡½æ•°å’Œåå‘ä¼ æ’­</h4>
<ul>
<li>L1loss</li>
</ul>

<pre class="language-python"><code class="language-python">classtorch.nn.L1Loss(size_average=None, reduce=None, reduction='elementwise_mean')
</code></pre>
<p>ä½¿ç”¨è¿™ä¸€ä¸ªå¯ä»¥è®¡ç®—ç»“æœå’ŒçœŸå®å€¼ä¹‹é—´çš„ç»å¯¹å€¼, å¯ä»¥ä½¿ç”¨reductionæ§åˆ¶æ˜¯å¹³å‡è¿˜æ˜¯æ±‚å’Œ</p>

<pre class="language-python"><code class="language-python">&gt;&gt;&gt; loss = nn.L1Loss()
&gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)
&gt;&gt;&gt; target = torch.randn(3, 5)
&gt;&gt;&gt; output = loss(input, target)
&gt;&gt;&gt; output.backward()
</code></pre>
<p>inputå’Œtargetéœ€è¦æ˜¯ç›¸åŒçš„å›¾å½¢</p>
<ul>
<li>MSELOSS</li>
</ul>
<p>è®¡ç®—å¹³æ–¹å·®çš„å¹³å‡æ•°</p>
<ul>
<li>CrossEntorpyLossäº¤å‰ç†µ</li>
</ul>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409272323402.png" alt="image-20240927232316235" /></p>
<p>æœ‰å¤šä¸ªåˆ†ç±»çš„æ—¶å€™, æ¯”å¦‚è¯´æœ‰ä¸‰ä¸ªåˆ†ç±»çš„æ—¶å€™, ä¸€å¼ å›¾ç‰‡çš„è¾“å‡ºæ˜¯[0.1, 0.2, 0.3], åˆ†åˆ«æ ‡å‡†0, 1, 2è¿™ä¸‰ä¸ªç±», å®é™…çš„åˆ†ç±»åº”è¯¥æ˜¯1</p>
<p>å®é™…è®¡ç®—çš„æ—¶å€™xæ˜¯è·å–çš„[0.1, 0.2, 0.3], classæ˜¯1</p>
<p>loss(x, class) = -0.2 + log(exp(0.1) + exp(0.2) + exp(0.3))</p>
<blockquote>
<p>expæ˜¯æŒ‡æ•°å‡½æ•°$e^x$</p>
</blockquote>

<pre class="language-python"><code class="language-python">x = torch.tensor([0.1, 0.2, 0.3])
y = torch.tensor([1])
x = torch.reshape(x, (1, 3))
loss_cross = nn.CrossEntorpyLoss()
result_cross = loss_cross(x, y)
print(result_cross)
</code></pre>

<pre class="language-python"><code class="language-python">
from torch import nn
from torch.nn import Conv2d
from torch.nn import MaxPool2d
from torch.nn import Flatten
import torch
from torch.utils.tensorboard import SummaryWriter
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader

# åˆå§‹åŒ–æ•°æ®é›†çš„è½¬æ¢
dataset_tramsforms = transforms.Compose([
    torchvision.transforms.ToTensor()
])

train_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=False, download=True, transform=dataset_tramsforms)
dataloader = DataLoader(train_set, batch_size=64)


class JIAO(nn.Module):
    def __init__(self):
        super(JIAO, self).__init__()
        self.moudle1 = nn.Sequential(
            Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=4),
            nn.MaxPool2d(kernel_size=2),
            Conv2d(32, 32, 5, padding=2),
            nn.MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            nn.MaxPool2d(2),
            Flatten(),
            nn.Linear(64*4*4, 64),
            nn.Linear(64, 10)
        )

    def forward(self, x):
        x = self.moudle1(x)
        return x

jiao = JIAO()
loss = nn.CrossEntropyLoss()

for data in dataloader:
    imgs, labels = data
    output = jiao(imgs)
    result_loss = loss(output, labels)
    print(result_loss)
    result_loss.backward() # åå‘ä¼ æ’­, å¯ä»¥ä½¿ç”¨è¿™ä¸€ä¸ªè®¡ç®—å‡ºæ¥ä¸€ä¸ªæ¢¯åº¦, ä¹‹åè¿›ä¸€æ­¥ä¼˜åŒ–
    break
</code></pre>
<h4 id="%E4%BC%98%E5%8C%96%E5%99%A8optim">ä¼˜åŒ–å™¨optim</h4>

<pre class="language-python"><code class="language-python">for input, target in dataset:
    optimizer.zero_grad()
    output = model(input)
    loss = loss_fn(output, target)
    loss.backward()
    optimizer.step()
</code></pre>
<blockquote>
<ul>
<li><strong>params</strong> (<em>iterable</em>) â€“ iterable of parameters to optimize or dicts defining parameter groups, æ¨¡å‹çš„å‚æ•°</li>
<li><strong>rho</strong> (<a href="https://docs.python.org/3/library/functions.html#float"  target="_blank"><em>float</em></a><em>,</em> <em>optional</em>) â€“ coefficient used for computing a running average of squared gradients (default: 0.9)å­¦ä¹ é€Ÿç‡</li>
<li><strong>eps</strong> (<a href="https://docs.python.org/3/library/functions.html#float"  target="_blank"><em>float</em></a><em>,</em> <em>optional</em>) â€“ term added to the denominator to improve numerical stability (default: 1e-6)</li>
<li><strong>lr</strong> (<a href="https://docs.python.org/3/library/functions.html#float"  target="_blank"><em>float</em></a><em>,</em> <em>optional</em>) â€“ coefficient that scale delta before it is applied to the parameters (default: 1.0)</li>
<li><strong>weight_decay</strong> (<a href="https://docs.python.org/3/library/functions.html#float"  target="_blank"><em>float</em></a><em>,</em> <em>optional</em>) â€“ weight decay (L2 penalty) (default: 0)</li>
</ul>
</blockquote>
<h4 id="%E7%8E%B0%E6%9C%89%E7%9A%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8Bmodels">ç°æœ‰çš„ç½‘ç»œæ¨¡å‹models</h4>
<p><a href="https://pytorch.org/docs/0.4.1/torchvision/models.html"  target="_blank">torchvision.models â€” PyTorch master documentation</a></p>
<p>æ¯”è¾ƒå¸¸ç”¨çš„æ—¶å€™vgg16, vgg19</p>

<pre class="language-python"><code class="language-python">torchvision.models.vgg16(pretrained=False, **kwargs)
</code></pre>
<p><strong>pretrained</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"  target="_blank"><em>bool</em></a>) â€“ If True, returns a model pre-trained on ImageNet(åœ¨ImageNeté‡Œé¢è®­ç»ƒå‡ºæ¥çš„æ•°æ®, è¿™ä¸€ä¸ªç½‘ç»œé‡Œé¢å¯ä»¥è¿›è¡Œ1000ä¸ªåˆ†ç±», ä½†æ˜¯ç”±äºè¿™ä¸€ä¸ªæ•°æ®é›†æ¯”è¾ƒå¤§, æ‰€ä»¥æ–¹ä¾¿ä¸‹è½½)</p>

<pre class="language-python"><code class="language-python">vgg16_true.add_module(&quot;add_linear&quot;, torch.nn.Linear(1000, 10)) # æ·»åŠ æ–°çš„å±‚
</code></pre>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409281709126.png" alt="image-20240928170922809" /></p>

<pre class="language-python"><code class="language-python">vgg16_true.classifier.add_module(&quot;add_linear&quot;, torch.nn.Linear(1000, 10)) # æ·»åŠ æ–°çš„å±‚(åœ¨ç°æœ‰çš„å±‚é‡Œé¢)
</code></pre>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409281711469.png" alt="image-20240928171141329" /></p>
<p>ä¹Ÿå¯ä»¥ä½¿ç”¨</p>

<pre class="language-python"><code class="language-python">vgg16_true.classifier[6] = nn.Linear(4096, 10) # ä¿®æ”¹åŸæœ‰çš„å±‚
</code></pre>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409281714434.png" alt="image-20240928171449315" /></p>
<h2 id="%E5%AE%9E%E6%88%98">å®æˆ˜</h2>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409272236547.png" alt="image-20240927223634375" /></p>
<p>é¦–å…ˆæŠŠæ•°æ®è¿›è¡Œä¸€æ¬¡å·ç§¯æ‰©å±•ä¸€ä¸‹å±‚æ•°, ä¹‹åè¿›è¡Œä¸€æ¬¡æœ€å¤§å€¼æ± åŒ–, ä¹‹åå†æ¬¡å·ç§¯ä¸€æ¬¡, ç„¶åæœ€å¤§å€¼æ± åŒ–, å†é‡å¤ä¸€ä¸‹ç„¶åå±•å¹³, æœ€åä½¿ç”¨çº¿æ€§å±‚å¤„ç†</p>

<pre class="language-python"><code class="language-python">from torch import nn
from torch.nn import Conv2d
from torch.nn import MaxPool2d
from torch.nn import Flatten
import torch
from torch.utils.tensorboard import SummaryWriter


class JIAO(nn.Module):
    def __init__(self):
        super(JIAO, self).__init__()
        # self.conv1 = Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=4)
        # self.maxpool1 = nn.MaxPool2d(kernel_size=2)
        # self.conv2 = Conv2d(32, 32, 5, padding=2)
        # self.maxpool2 = MaxPool2d(2)
        # self.conv3 = Conv2d(32, 64, 5, padding=2)
        # self.maxpool3 = MaxPool2d(2)
        # self.flatten = Flatten()
        # self.linear1 = nn.Linear(64*4*4, 64)
        # self.linear2 = nn.Linear(64, 10)
        # å¯ä»¥ä½¿ç”¨ä¸€ä¸‹çš„ä»£ç è¿›è¡Œç®€åŒ–
        self.moudle1 = nn.Sequential(
            Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=4),
            nn.MaxPool2d(kernel_size=2),
            Conv2d(32, 32, 5, padding=2),
            nn.MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            nn.MaxPool2d(2),
            Flatten(),
            nn.Linear(64*4*4, 64),
            nn.Linear(64, 10)
        )

    def forward(self, x):
        x = self.moudle1(x)
        return x

jiao = JIAO()
print(jiao)

input = torch.randn(64, 3, 32, 32)
output = jiao(input)
print(output.shape)

writer = SummaryWriter(&quot;logs&quot;)
writer.add_graph(jiao, input)
writer.close()
</code></pre>
<ul>
<li>åŠ åé¦ˆä»¥åŠä¼˜åŒ–å™¨</li>
</ul>

<pre class="language-python"><code class="language-python">from torch import nn
from torch.nn import Conv2d
from torch.nn import MaxPool2d
from torch.nn import Flatten
import torch
from torch.utils.tensorboard import SummaryWriter
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader

# åˆå§‹åŒ–æ•°æ®é›†çš„è½¬æ¢
dataset_tramsforms = transforms.Compose([
    torchvision.transforms.ToTensor()
])

train_set = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=False, download=True, transform=dataset_tramsforms)
dataloader = DataLoader(train_set, batch_size=64)


class JIAO(nn.Module):
    def __init__(self):
        super(JIAO, self).__init__()
        self.moudle1 = nn.Sequential(
            Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=4),
            nn.MaxPool2d(kernel_size=2),
            Conv2d(32, 32, 5, padding=2),
            nn.MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            nn.MaxPool2d(2),
            Flatten(),
            nn.Linear(64*4*4, 64),
            nn.Linear(64, 10)
        )

    def forward(self, x):
        x = self.moudle1(x)
        return x

jiao = JIAO()
loss = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(jiao.parameters(), lr=0.01)
for i in range(20):
    for data in dataloader:
        imgs, labels = data
        output = jiao(imgs)
        result_loss = loss(output, labels)
        optimizer.zero_grad() # æ¢¯åº¦æ¸…é›¶
        result_loss.backward() # åå‘ä¼ æ’­
        optimizer.step() # æ›´æ–°å‚æ•°
        print(result_loss)
        # break

</code></pre>
<h2 id="%E5%8A%A0%E8%BD%BD%E4%BF%9D%E5%AD%98">åŠ è½½ä¿å­˜</h2>
<ul>
<li>ç¬¬ä¸€ç§ç»“æ„åŠ å‚æ•°</li>
</ul>

<pre class="language-python"><code class="language-python">torch.save(vgg16_true, &quot;vgg16.pth&quot;) # ä¿å­˜æ¨¡å‹
</code></pre>
<blockquote>
<p>è®°å½•äº†æ¨¡å‹ä»¥åŠæ¨¡å‹é‡Œé¢çš„å‚æ•°</p>
</blockquote>

<pre class="language-python"><code class="language-python">torch.load(&quot;vgg16.pth&quot;)
</code></pre>
<blockquote>
<p>ä½¿ç”¨è¿™ä¸€ä¸ªæ–¹æ³•çš„æ—¶å€™, å¦‚æœåŠ è½½çš„æ˜¯ä¸€ä¸ªè‡ªå·±å®šä¹‰çš„ç±», è¿™ä¸€ä¸ªç±»éœ€è¦å¼•å…¥ä¸€ä¸‹</p>
</blockquote>
<ul>
<li>æ–¹æ³•äºŒåªè®°å½•å‚æ•°</li>
</ul>

<pre class="language-python"><code class="language-python">torch.save(vgg16_true.state_dict(), &quot;vgg16.pht&quot;) # ä¿å­˜æ¨¡å‹
</code></pre>
<p>æ¢å¤</p>

<pre class="language-python"><code class="language-python">vgg16 = torchvision.models.vgg16(pretrained=False)
vgg16.load_state_dict(torch.load(&quot;vgg16.pht&quot;)) # åŠ è½½æ¨¡å‹
</code></pre>
<blockquote>
<p><strong>æ³¨: </strong>ä½¿ç”¨è¿™ä¸€ä¸ªæ–¹å¼çš„æ—¶å€™éœ€è¦åˆå§‹åŒ–ä¸€ä¸ªModelå¯¹è±¡å†</p>
</blockquote>
<h2 id="%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83">å®Œæ•´çš„è®­ç»ƒ</h2>

<pre class="language-python"><code class="language-python">import torchvision
import torch
from torch.utils.tensorboard import SummaryWriter
# train_data = torchvision.datasets.ImageNet(root=&quot;./dataset_ImageNet&quot;, train=True, download=True,
#                                            transform=torchvision.transforms.ToTensor())

# vgg16_true = torchvision.models.vgg16(pretrained=True) # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹, ä½¿ç”¨æ•°æ®é›†è®­ç»ƒå¥½çš„å‚æ•°
# vgg16_flase = torchvision.models.vgg16(pretrained=False) # ä¸åŠ è½½é¢„è®­ç»ƒæ¨¡å‹, ä½¿ç”¨é»˜è®¤å‚æ•°

# print(vgg16_true)
# print(vgg16_flase)

train_data = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=True, download=True,
                                            transform=torchvision.transforms.ToTensor())
test_data = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=False, download=True,
                                            transform=torchvision.transforms.ToTensor())
# vgg16_true.add_module(&quot;add_linear&quot;, torch.nn.Linear(1000, 10)) # æ·»åŠ æ–°çš„å±‚
# vgg16_true.classifier.add_module(&quot;add_linear&quot;, torch.nn.Linear(1000, 10)) # æ·»åŠ æ–°çš„å±‚(åœ¨ç°æœ‰çš„å±‚é‡Œé¢)
# vgg16_true.classifier[6] = torch.nn.Linear(4096, 10) # ä¿®æ”¹åŸæœ‰çš„å±‚
# print(vgg16_true)

train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=64)
test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=64)


class JIAO(torch.nn.Module):
    def __init__(self):
        super(JIAO, self).__init__()
        self.moudle1 = torch.nn.Sequential(
            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2),
            torch.nn.MaxPool2d(kernel_size=2),
            torch.nn.Conv2d(32, 32, 5, padding=2),
            torch.nn.MaxPool2d(2),
            torch.nn.Conv2d(32, 64, 5, padding=2),
            torch.nn.MaxPool2d(2),
            torch.nn.Flatten(),
            torch.nn.Linear(64*4*4, 64),
            torch.nn.Linear(64, 10)
        )

    def forward(self, x):
        x = self.moudle1(x)
        return x

# æ‰§è¡Œçš„æ˜¯å½“å‰æ–‡ä»¶
if __name__ == &quot;__main__&quot;:

    jiao = JIAO()
    #æŸå¤±å‡½æ•°
    loss_fn = torch.nn.CrossEntropyLoss()
    #ä¼˜åŒ–å™¨
    learn_rate = 0.01 # 1e-2
    optimizer = torch.optim.SGD(jiao.parameters(), lr=learn_rate)

    writer = SummaryWriter(&quot;logs&quot;)

    #è®­ç»ƒ
    epoch = 20
    total_step = 0
    for i in range(epoch):
        for data in train_dataloader:
            imgs, labels = data
            output = jiao(imgs)
            result_loss = loss_fn(output, labels)
            optimizer.zero_grad() # æ¢¯åº¦æ¸…é›¶
            result_loss.backward() # åå‘ä¼ æ’­
            optimizer.step() # æ›´æ–°å‚æ•°
            # print(result_loss)
            # break
            total_step = total_step + 1
            if total_step % 100 == 0:
                print(&quot;epoch: &quot;, i, &quot;step: &quot;, total_step, &quot;loss: &quot;, result_loss)
                writer.add_scalar(&quot;train_loss&quot;, result_loss, total_step)

        # æµ‹è¯•
        total_test_loss = 0
        with torch.no_grad():
            for data in test_dataloader:
                img, target = data
                output = jiao(img)
                loss = loss_fn(output, target)
                total_test_loss += loss

        writer.add_scalar(&quot;test_loss&quot;, total_test_loss, i)
        print(&quot;epoch: &quot;, i, &quot;loss: &quot;, total_test_loss)

        torch.save(jiao, &quot;./my_mod/model_{}.pth&quot;.format(i))

    writer.close()
</code></pre>
<h2 id="%E6%AD%A3%E7%A1%AE%E7%8E%87">æ­£ç¡®ç‡</h2>
<p>åœ¨å®é™…è®­ç»ƒçš„æ—¶å€™è¾“å‡ºçš„æ˜¯å„ä¸ªé€‰é¡¹çš„æ¦‚ç‡, æ¯”å¦‚ä¸€ä¸ªåªæœ‰ä¸¤ä¸ªæ•°æ®çš„åˆ†ç±», å¯èƒ½è¾“å‡º1. [0.1, 0.2], 2. [0.3, 0.4]</p>
<p>ä½¿ç”¨Argmaxå¯ä»¥è·å–åˆ°Preds = [1][1]</p>
<p>å¦‚æœInput targetæ˜¯[0][1]</p>
<p>ä½¿ç”¨Preds == Input targetå¯ä»¥è·å–[False, True].sum = 1</p>

<pre class="language-python"><code class="language-python">import torch

outputs = torch.tensor([[0.1, 0.2], 
                        [0.3, 0.4], 
                        [0.5, 0.2]])

# output: tensor([1, 1, 0])
print(outputs.argmax(dim=1)) # dim=1è¡¨ç¤ºæŒ‰è¡Œå–æœ€å¤§å€¼çš„ç´¢å¼•
preds = outputs.argmax(dim=1)
targets = torch.tensor([1, 0, 0])
# output: tensor([ True, False,  True])
print(targets == preds)
print((targets == preds).sum().item()) # 2
</code></pre>

<pre class="language-python"><code class="language-python"># import torch

# outputs = torch.tensor([[0.1, 0.2], 
#                         [0.3, 0.4], 
#                         [0.5, 0.2]])

# # output: tensor([1, 1, 0])
# print(outputs.argmax(dim=1)) # dim=1è¡¨ç¤ºæŒ‰è¡Œå–æœ€å¤§å€¼çš„ç´¢å¼•
# preds = outputs.argmax(dim=1)
# targets = torch.tensor([1, 0, 0])
# # output: tensor([ True, False,  True])
# print(targets == preds)
# print((targets == preds).sum().item()) # 2

import torch
import torchvision
from my_model_pretraines import JIAO
test_data = torchvision.datasets.CIFAR10(root=&quot;./dataset&quot;, train=False, download=True,
                                            transform=torchvision.transforms.ToTensor())

test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=64)

module = torch.load(&quot;my_mod/model_19.pth&quot;)

# æµ‹è¯•ä¸€ä¸‹å‡†ç¡®ç‡

correct = 0
total = len(test_data)
with torch.no_grad():
    for data in test_dataloader:
        imgs, labels = data
        outputs = module(imgs)
        preds = outputs.argmax(dim=1)
        correct += (preds == labels).sum().item()

print(&quot;å‡†ç¡®ç‡: &quot;, correct / total)
</code></pre>
<h2 id="%E4%BD%BF%E7%94%A8GPU">ä½¿ç”¨GPU</h2>
<ul>
<li>æ–¹æ³•ä¸€</li>
</ul>
<p>ç½‘ç»œæ¨¡å‹, æ•°æ®(è¾“å…¥, æ ‡æ³¨)ä»¥åŠæŸå¤±å‡½æ•°æœ‰</p>
<p>åœ¨æ¨¡å‹ä½¿ç”¨çš„æ—¶å€™ç”¨<code>model = model.cuda()</code>, è¯¯å·®å‡½æ•°ä¹Ÿå¯ä»¥ä½¿ç”¨<code>loss_fn = loss_fn.cuda()</code></p>

<pre class="language-python"><code class="language-python">def train(jiao : JIAO, epoch : int, learn_rate : float, output_name : str, train_dataloader):
    jiao = jiao.cuda()
    total_step = 0
    #æŸå¤±å‡½æ•°
    loss_fn = torch.nn.CrossEntropyLoss()
    loss_fn = loss_fn .cuda()
    optimizer = torch.optim.SGD(jiao.parameters(), lr=learn_rate)

    for i in range(epoch):
        for data in train_dataloader:
            imgs, labels = data
            imgs = imgs.cuda()
            labels = labels.cuda()
            output = jiao(imgs)
            result_loss = loss_fn(output, labels)
            optimizer.zero_grad() # æ¢¯åº¦æ¸…é›¶
            result_loss.backward() # åå‘ä¼ æ’­
            optimizer.step()
            total_step = total_step + 1
            if total_step % 100 == 0:
                print(&quot;epoch: &quot;, i, &quot;step: &quot;, total_step, &quot;loss: &quot;, result_loss)
    torch.save(jiao, output_name)
</code></pre>
<ul>
<li>æ–¹æ³•äºŒ</li>
</ul>

<pre class="language-python"><code class="language-python">device = torch.device(&quot;cpu&quot;) # cuda / cuda:0 / cuda:1 å®šä¹‰ä¸€ä¸ªè®¾å¤‡
# ä¹‹åæŠŠæ¨¡å‹ä¹‹ç±»çš„ä½¿ç”¨toå®šä¹‰åˆ°è¿™ä¸€ä¸ªè®¾å¤‡
jiao = jiao.to(device)
loss_fn = loss_fn.to(device)
</code></pre>
<h2 id="%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83">æµ‹è¯•ç¯å¢ƒ</h2>
<p><a href="https://colab.research.google.com/"  target="_blank">æ¬¢è¿ä½¿ç”¨ Colaboratory - Colab (google.com)</a></p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409282212141.png" alt="image-20240928221225921" /></p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409282212783.png" alt="image-20240928221248593" /></p>
<h2 id="%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B5%8B%E8%AF%95">æ¨¡å‹çš„æµ‹è¯•</h2>
<p>ä½¿ç”¨ä»¥åŠè®­ç»ƒå¥½çš„æ¨¡å‹, æä¾›è¾“å…¥, å¯ä»¥åœ¨githubä¸Šé¢æ‰¾, æœç´¢github</p>

<pre class="language-python"><code class="language-python">import PIL
import PIL.Image
import torchvision
import torch
from my_model_pretraines import JIAO

img_path = &quot;./img/shi.png&quot;
img = PIL.Image.open(img_path)
classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
print(img)
img = img.convert(&quot;RGB&quot;)

transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize((32, 32)),
    torchvision.transforms.ToTensor()
])

img = transform(img)
# print(img.shape)
moudle = torch.load(&quot;my_mod/model.pth&quot;) # å¦‚æœgpuè®­ç»ƒæƒ³åœ¨cpuä½¿ç”¨ï¼Œéœ€è¦åŠ ä¸Šmap_location=torch.device(&quot;cpu&quot;)
moudle = moudle.cuda()
img = torch.reshape(img, (1, 3, 32, 32))
img = img.cuda()
moudle.eval()   # æŠŠè¿™ä¸€ä¸ªæ¨¡å‹è®¾ç½®ä¸ºæµ‹è¯•æ¨¡å¼
with torch.no_grad():
    output = moudle(img)
print(output)
result = output.argmax(dim=1)
print(&quot;filename = {}, class = {}&quot;.format(img_path, classes[result.item()]))
</code></pre>

                        
                    </div>
                </div>
                <div id="previous_next">
                    <div id="previous">
                        
                        <a href="/note/æœºå™¨å­¦ä¹ /2024-9-22-æ·±åº¦å­¦ä¹ ç¯å¢ƒ.html">
                            <span class="icon"></span>
                            <span class="label">2024-9-22-æ·±åº¦å­¦ä¹ ç¯å¢ƒ</span>
                        </a>
                        
                    </div>
                    <div id="next">
                        
                        <a href="/note/æœºå™¨å­¦ä¹ /2024-9-8-æœºå™¨å­¦ä¹ .html">
                            <span class="label">2024-9-8-æœºå™¨å­¦ä¹ </span>
                            <span class="icon"></span>
                        </a>
                        
                    </div>
                </div>
                <div id="comments-container"></div>
            </div>
            <div id="toc_wrapper">
                <div id="toc">
                    <div id="toc_content">
                            
                    </div>
                </div>
            </div>
        </div>
    </div>
    <a id="to_top" href="#"></a>
    <div id="doc_footer">
        <div id="footer">
            <div id="footer_top">
                <ul>
<li><a>é“¾æ¥</a><ul><li><a target="_blank" href="https://teedoc.neucrack.com">ç½‘ç«™ä½¿ç”¨ teedoc ç”Ÿæˆ</a></li>
<li><a target="_blank" href="https://neucrack.com">Copyright Â© 2021 Neucrack</a></li>
<li><a  href="/note/sitemap.xml">ç½‘ç«™åœ°å›¾</a></li>
</ul>
</li>
<li><a>æºç </a><ul><li><a target="_blank" href="https://github.com/XuSenfeng/note/">github</a></li>
<li><a target="_blank" href="https://github.com/teedoc/teedoc">æœ¬ç½‘ç«™æºæ–‡ä»¶</a></li>
</ul>
</li>
</ul>

            </div>
            <div id="footer_bottom">
                <ul>
<li><a target="_blank" href="https://beian.miit.gov.cn">æ¸ICPå¤‡19015320å·</a></li>
<li><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44030602004109">ç²¤å…¬ç½‘å®‰å¤‡44030602004109å·</a></li>
</ul>

            </div>
        </div>
    </div>
    
        <script src="/note/teedoc-plugin-markdown-parser/mermaid.min.js"></script>
    
        <script>mermaid.initialize({startOnLoad:true});</script>
    
        <script type="text/javascript">
                var transLoaded = false;
                var loading = false;
                var domain = "translate.google.com";
                var domainDefault = domain;
                var storeDomain = localStorage.getItem("googleTransDomain");
                if(storeDomain){
                    domain = storeDomain;
                    console.log("load google translate domain from local storage:" + domain);
                }
                function getUrl(domain){
                    if(domain == "/")
                        return "/static/js/google_translate/element.js?cb=googleTranslateElementInit";
                    else
                        return "https://" + domain + "/translate_a/element.js?cb=googleTranslateElementInit";
                }
                var url = getUrl(domain);
                console.log("google translate domain:" + domain + ", url: " + url);
                function googleTranslateElementInit() {
                    new google.translate.TranslateElement({pageLanguage: "auto", layout: google.translate.TranslateElement.InlineLayout.SIMPLE}, 'google_translate_element');
                }
                function loadJS( url, callback ){
                    var script = document.createElement('script');
                    fn = callback || function(){ };
                    script.type = 'text/javascript';
                    if(script.readyState){
                        script.onreadystatechange = function(){
                            if( script.readyState == 'loaded' || script.readyState == 'complete' ){
                                script.onreadystatechange = null;
                                fn();
                            }
                        };
                    }else{
                        script.onload = function(){
                            fn();
                        };
                    }
                    script.src = url;
                    document.getElementsByTagName('head')[0].appendChild(script);
                }
                function removeHint(){
                    var hint = document.getElementById("loadingTranslate");
                    if(hint){
                        hint.remove();
                    }
                }
                var btn = document.getElementById("google_translate_element");
                btn.onclick = function(){
                    if(transLoaded) return;
                    if(loading){
                        var flag = confirm("loading from " + domain + ", please wait, or change domain?");
                        if(flag){
                            newDomain = prompt("domain, default: " + domainDefault + ", now: " + domain);
                            if(newDomain){
                                domain = newDomain;
                                console.log(domain);
                                url = getUrl(domain);
                                loadJS(url, function(){
                                    localStorage.setItem("googleTransDomain", domain);
                                    removeHint()
                                    transLoaded = true;
                                });
                            }
                        }
                        return;
                    }
                    btn.innerHTML = '<span id="loadingTranslate"><img class="icon" src="/note/static/image/google_translate/translate.svg"/>Loading ...</span>';
                    loading = true;
                    loadJS(url, function(){
                        localStorage.setItem("googleTransDomain", domain);
                        removeHint()
                        transLoaded = true;
                    });
                }
                </script>
            
    
        <script src="/note/static/js/theme_default/tocbot.min.js"></script>
    
        <script src="/note/static/js/theme_default/main.js"></script>
    
        <script src="/note/static/js/theme_default/viewer.min.js"></script>
    
        <script src="/note/static/css/theme_default/prism.min.js"></script>
    
        <script src="/note/static/js/search/search_main.js"></script>
    
        <script src="/note/static/js/plugin_blog/main.js"></script>
    
        <link rel="stylesheet" href="/note/static/js/add_hint/style.css" type="text/css"/>
    
        <script src="/note/static/js/add_hint/main.js"></script>
    
        <script src="/note/static/js/gitalk/gitalk.min.js"></script>
    
        <script src="/note/static/js/gitalk/main.js"></script>
    
        <script src="/note/static/js/custom.js"></script>
    
</body>

</html>