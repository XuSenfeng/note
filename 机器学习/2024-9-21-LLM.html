<!DOCTYPE html>

<html lang="zh-CN"  class="">


<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="keywords" content="">
    
    
    <meta name="description" content="">
    
    <meta name="generator" content="teedoc">
    <meta name="theme" content="teedoc-plugin-theme-default">
    
        
        <meta name="markdown-generator" content="teedoc-plugin-markdown-parser">
        
        <script>
MathJax = {"loader": {"load": ["output/svg"]}, "tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}, "svg": {"fontCache": "global"}};
</script>
        
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
        <meta name="html-generator" content="teedoc-plugin-jupyter-notebook-parser">
        
        <script src="/note/static/js/theme_default/pre_main.js"></script>
        
        <link rel="stylesheet" href="/note/static/css/theme_default/prism.min.css" type="text/css"/>
        
        <link rel="stylesheet" href="/note/static/css/theme_default/viewer.min.css" type="text/css"/>
        
        <link rel="stylesheet" href="/note/static/css/theme_default/dark.css" type="text/css"/>
        
        <link rel="stylesheet" href="/note/static/css/theme_default/light.css" type="text/css"/>
        
        <script src="/note/static/js/theme_default/jquery.min.js"></script>
        
        <script src="/note/static/js/theme_default/split.js"></script>
        
        <link rel="stylesheet" href="/note/static/css/search/style.css" type="text/css"/>
        
        <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?4d52982572d5512e9762879ebf063c86";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
        
        <meta name="blog-generator" content="teedoc-plugin-blog">
        
        <link rel="stylesheet" href="/note/static/css/gitalk/gitalk.css" type="text/css"/>
        
        <link rel="stylesheet" href="/note/static/css/gitalk/custom_gitalk.css" type="text/css"/>
        
        <link rel="stylesheet" href="/note/static/css/custom.css" type="text/css"/>
        
    
    
    <title>LLM - XvSenfeng's Note</title>
    
    <script type="text/javascript">js_vars = {"teedoc-plugin-ad-hint": {"type": "hint", "label": "☆", "content": "这是一个支持国际化的消息示例</br>喜欢项目请<a target=\"_blank\" href=\"https://github.com/teedoc/teedoc\">点下 ☆ star </a>哦~🦀🦀", "show_times": 2, "show_after_s": 432000, "date": "2021-11-16 14:40", "color": "#a0421d", "link_color": "#e53935", "link_bg_color": "#e6ae5c", "bg_color": "#ffcf89", "color_hover": "white", "bg_color_hover": "#f57c00", "close_color": "#eab971"}}</script>
    <script type="text/javascript">metadata = {"tags": ["AI 机器学习"], "date": "2026-02-05", "update": [], "ts": 1770297751, "author": "", "brief": "", "cover": "", "layout": "post"}</script>
</head>


<body class="type_doc">
    
    <div id="navbar">
        <div id="navbar_menu">
            <a class="site_title" href="/note/">
                
                    <img class="site_logo" src="/note/static/image/logo.png" alt="XvSenfeng logo">
                
                
                    <h2>XvSenfeng</h2>
                
        </a>
            <a id="navbar_menu_btn"></a>
        </div>
        <div id="navbar_items">
            <div>
                <ul id="nav_left">
<li class=""><a  href="/note/blog/">博客</a></li>
<li class=""><a  href="/note/Linux/">Linux</a></li>
<li class=""><a  href="/note/代码分析/">代码分析</a></li>
<li class=""><a  href="/note/使用软件/">使用软件</a></li>
<li class=""><a  href="/note/嵌入式/">嵌入式</a></li>
<li class=""><a  href="/note/手机安卓/">手机安卓</a></li>
<li class="active"><a  href="/note/机器学习/">机器学习</a></li>
<li class=""><a  href="/note/编程基础/">编程基础</a></li>
<li class=""><a  href="/note/网络/">网络</a></li>
</ul>

            </div>
            <div>
                <ul id="nav_right">
<li class=""><a target="_blank" href="https://github.com/XuSenfeng/note/">github</a></li>
</ul>

                <ul class="nav_plugins"><li><a id="google_translate_element"><img class="icon" src="/note/static/image/google_translate/translate.svg"/>Translate</a></li></ul><ul class="nav_plugins"><li><a id="themes" class="light"></a></li></ul><ul class="nav_plugins"><li><a id="search"><span class="icon"></span><span class="placeholder">搜索</span>
                            <div id="search_hints">
                                <span id="search_input_hint">输入关键词，多关键词空格隔开</span>
                                <span id="search_loading_hint">正在加载，请稍候。。。</span>
                                <span id="search_download_err_hint">下载文件失败，请刷新重试或检查网络</span>
                                <span id="search_other_docs_result_hint">来自其它文档的结果</span>
                                <span id="search_curr_doc_result_hint">当前文档搜索结果</span>
                            </div></a></li></ul>
            </div>
        </div>
    </div>
    
    <div id="wrapper">
        <div id="sidebar_wrapper">
            <div id="sidebar">
                <div id="sidebar_title">
                    
                </div>
                <ul class="show">
<li class="not_active with_link"><a href="/note/机器学习/2024-10-5-Transformers.html"><span class="label">2024-10-5-Transformers</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/2024-10-6-Juoyter.html"><span class="label">2024-10-6-Juoyter</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/2024-10-7-Pandas库.html"><span class="label">2024-10-7-Pandas库</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/2024-10-9-transforms实战.html"><span class="label">2024-10-9-transforms实战</span><span class=""></span></a></li>
<li class="active with_link"><a href="/note/机器学习/2024-9-21-LLM.html"><span class="label">2024-9-21-LLM</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/2024-9-22-vLLM.html"><span class="label">2024-9-22-vLLM</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/2024-9-22-深度学习环境.html"><span class="label">2024-9-22-深度学习环境</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/2024-9-23-01pytorch.html"><span class="label">2024-9-23-01pytorch</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/2024-9-8-机器学习.html"><span class="label">2024-9-8-机器学习</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/index.html"><span class="label">README</span><span class=""></span></a></li>
<li class="not_active no_link"><a><span class="label">rv模型部署</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/机器学习/rv模型部署/2025-11-28-00-驱动移植.html"><span class="label">2025-11-28-00-驱动移植</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/rv模型部署/2025-11-28-01-环境搭建.html"><span class="label">2025-11-28-01-环境搭建</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/rv模型部署/2025-12-2-02-基础概念.html"><span class="label">2025-12-2-02-基础概念</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/rv模型部署/2025-12-3-03-RKNN_Toolkit2.html"><span class="label">2025-12-3-03-RKNN_Toolkit2</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/rv模型部署/2025-12-3-04-RKLLM.html"><span class="label">2025-12-3-04-RKLLM</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/rv模型部署/2026-2-2-05-RKNN开发.html"><span class="label">2026-2-2-05-RKNN开发</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">vllm代码分析</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/机器学习/vllm代码分析/2024-12-31-00-整体框架.html"><span class="label">2024-12-31-00-整体框架</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/vllm代码分析/2024-12-31-01-collect_env.html"><span class="label">2024-12-31-01-collect_env</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">具身智能</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/机器学习/具身智能/2026-2-2-基础概念.html"><span class="label">2026-2-2-基础概念</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/具身智能/2026-2-3-02-仿真.html"><span class="label">2026-2-3-02-仿真</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/具身智能/2026-2-3-03-姿态解算.html"><span class="label">2026-2-3-03-姿态解算</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/具身智能/2026-2-4-04-SO-ARM101.html"><span class="label">2026-2-4-04-SO-ARM101</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">实际应用</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/机器学习/实际应用/2025-1-30-ollama.html"><span class="label">2025-1-30-ollama</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/实际应用/2025-12-10-语音识别.html"><span class="label">2025-12-10-语音识别</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/实际应用/2025-12-22-QLearning.html"><span class="label">2025-12-22-QLearning</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/实际应用/2025-2-16-dify.html"><span class="label">2025-2-16-dify</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/实际应用/2025-2-16-langChain.html"><span class="label">2025-2-16-langChain</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/实际应用/2025-2-23-langchain2.html"><span class="label">2025-2-23-langchain2</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/实际应用/2025-2-26-Lora微调.html"><span class="label">2025-2-26-Lora微调</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/实际应用/2025-3-20-COZE.html"><span class="label">2025-3-20-COZE</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/实际应用/2025-4-2-MCP.html"><span class="label">2025-4-2-MCP</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">嵌入式移植</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/机器学习/嵌入式移植/00细聊.html"><span class="label">00细聊</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/嵌入式移植/2025-12-18-01-模型量化.html"><span class="label">2025-12-18-01-模型量化</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">李沐课程</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/0000-0-0-00基础numpy.html"><span class="label">0000-0-0-00基础numpy</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/0000-0-0-00基础pandas.html"><span class="label">0000-0-0-00基础pandas</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2024-10-31-01.html"><span class="label">2024-10-31-01</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2024-11-03-02数据类型.html"><span class="label">2024-11-03-02数据类型</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-08-03基础函数.html"><span class="label">2025-1-08-03基础函数</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-08-04数据集.html"><span class="label">2025-1-08-04数据集</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-08-05感知机.html"><span class="label">2025-1-08-05感知机</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-09模型选择.html"><span class="label">2025-1-09模型选择</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-10-10丢弃法.html"><span class="label">2025-1-10-10丢弃法</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-11-11数值稳定性.html"><span class="label">2025-1-11-11数值稳定性</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-12-12层和块.html"><span class="label">2025-1-12-12层和块</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-12-GPU.html"><span class="label">2025-1-12-GPU</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-12-实战比赛.html"><span class="label">2025-1-12-实战比赛</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-13-13卷积.html"><span class="label">2025-1-13-13卷积</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-13-14池化.html"><span class="label">2025-1-13-14池化</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-14-15LeNet.html"><span class="label">2025-1-14-15LeNet</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-14-16AlexNet.html"><span class="label">2025-1-14-16AlexNet</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-14-17VGG.html"><span class="label">2025-1-14-17VGG</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-14-18NiN.html"><span class="label">2025-1-14-18NiN</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-14-19GoogLeNet.html"><span class="label">2025-1-14-19GoogLeNet</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-15-20批量归一化.html"><span class="label">2025-1-15-20批量归一化</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-15-21残差网络ResNet.html"><span class="label">2025-1-15-21残差网络ResNet</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-16-芯片.html"><span class="label">2025-1-16-芯片</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-17-22数据增广.html"><span class="label">2025-1-17-22数据增广</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-17-23微调.html"><span class="label">2025-1-17-23微调</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-18-24CIFAR数据集.html"><span class="label">2025-1-18-24CIFAR数据集</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-19-25目标检测.html"><span class="label">2025-1-19-25目标检测</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-1-23-26区域卷积神经网络.html"><span class="label">2025-1-23-26区域卷积神经网络</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-1-27语义分割.html"><span class="label">2025-2-1-27语义分割</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-10-33长短期记忆LSTM.html"><span class="label">2025-2-10-33长短期记忆LSTM</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-10-34深度循环网络.html"><span class="label">2025-2-10-34深度循环网络</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-10-35-BPTT.html"><span class="label">2025-2-10-35-BPTT</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-10-36双向循环神经网络.html"><span class="label">2025-2-10-36双向循环神经网络</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-11-37编码器解码器.html"><span class="label">2025-2-11-37编码器解码器</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-11-38seq2seq.html"><span class="label">2025-2-11-38seq2seq</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-11-39束搜索.html"><span class="label">2025-2-11-39束搜索</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-11-40注意力机制.html"><span class="label">2025-2-11-40注意力机制</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-13-41注意力seq2seq.html"><span class="label">2025-2-13-41注意力seq2seq</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-15-42自注意力.html"><span class="label">2025-2-15-42自注意力</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-15-43Transformer.html"><span class="label">2025-2-15-43Transformer</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-15-44BERT.html"><span class="label">2025-2-15-44BERT</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-5-28样式迁移.html"><span class="label">2025-2-5-28样式迁移</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-5-29序列模型.html"><span class="label">2025-2-5-29序列模型</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-6-30文字处理.html"><span class="label">2025-2-6-30文字处理</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-7-31-循环神经网络RNN.html"><span class="label">2025-2-7-31-循环神经网络RNN</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/李沐课程/2025-2-9-32-门控循环单元GRU.html"><span class="label">2025-2-9-32-门控循环单元GRU</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">视觉识别</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/2025-12-12-04-经典算法.html"><span class="label">2025-12-12-04-经典算法</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/2025-12-12-05-YoloV1.html"><span class="label">2025-12-12-05-YoloV1</span><span class=""></span></a></li>
<li class="not_active no_link"><a><span class="label">K230</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/K230/2026-1-1-01-SDK编译.html"><span class="label">2026-1-1-01-SDK编译</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/K230/2026-1-10-03-Linux代码开发.html"><span class="label">2026-1-10-03-Linux代码开发</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/K230/2026-1-3-02-基础原理.html"><span class="label">2026-1-3-02-基础原理</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">MaixCAM</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-11-02-模型训练.html"><span class="label">2025-12-11-02-模型训练</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-11-03-常用的模型.html"><span class="label">2025-12-11-03-常用的模型</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-14-04-Yolo模型转换.html"><span class="label">2025-12-14-04-Yolo模型转换</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-14-05-MaixCDK基础使用.html"><span class="label">2025-12-14-05-MaixCDK基础使用</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-16-06-maixcdk工具.html"><span class="label">2025-12-16-06-maixcdk工具</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-17-07-组件.html"><span class="label">2025-12-17-07-组件</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-17-08-Camera示例.html"><span class="label">2025-12-17-08-Camera示例</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-17-09-APP.html"><span class="label">2025-12-17-09-APP</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-18-06-模型相关参数.html"><span class="label">2025-12-18-06-模型相关参数</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-19-07-AI编译器.html"><span class="label">2025-12-19-07-AI编译器</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-19-08-模型实现.html"><span class="label">2025-12-19-08-模型实现</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-20-09-MaixPy编译.html"><span class="label">2025-12-20-09-MaixPy编译</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-3-00-资料.html"><span class="label">2025-12-3-00-资料</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/MaixCAM/2025-12-5-01编译下载.html"><span class="label">2025-12-5-01编译下载</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">yolo</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/yolo/2025-12-12-02-基础使用.html"><span class="label">2025-12-12-02-基础使用</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/yolo/2025-12-12-03-数据集.html"><span class="label">2025-12-12-03-数据集</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/yolo/2025-12-12-04-预测.html"><span class="label">2025-12-12-04-预测</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/yolo/2025-12-13-05-训练.html"><span class="label">2025-12-13-05-训练</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/yolo/2025-12-13-06-yolov5基础使用.html"><span class="label">2025-12-13-06-yolov5基础使用</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/yolo/2025-12-13-07-AutoDL服务器训练.html"><span class="label">2025-12-13-07-AutoDL服务器训练</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/yolo/2025-12-13-08-yolov5框架.html"><span class="label">2025-12-13-08-yolov5框架</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/yolo/2025-12-13-09-修改网络.html"><span class="label">2025-12-13-09-修改网络</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/yolo/2025-12-13-10-模型部署.html"><span class="label">2025-12-13-10-模型部署</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/note/机器学习/视觉识别/yolo/2025-12-4-01-yolo安装.html"><span class="label">2025-12-4-01-yolo安装</span><span class=""></span></a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
        </div>
        <div id="article">
            <div id="menu_wrapper">
                <div id="menu">
                </div>
            </div>
            <div id="content_wrapper">
                <div id="content_body">
                    <div id="article_head">
                        <div id="article_title">
                            
                            <h1>LLM</h1>
                            
                        </div>
                        <div id="article_tags">
                            <ul>
                            
                                <li>AI 机器学习</li>
                            
                            </ul>
                        </div>
                        <div id="article_info">
                        <div id="article_info_left">
                            <span class="article_author">
                                
                            </span>
                            
                                <span class="article_date" title="最后修改日期： 2026-02-05">
                                    2026-02-05
                                </span>
                            
                        </div>
                        <div id="article_info_right">
                            
                            <div id="source_link">
                                <a href="https://github.com/XuSenfeng/note/tree/master/doc/机器学习/2024-9-21-LLM.md" target="_blank">
                                    编辑本页
                                </a>
                            </div>
                            
                        </div>
                        </div>
                    </div>
                    <div id="article_tools">
                        <span></span>
                        <span id="toc_btn"></span>
                    </div>
                    <div id="update_history">
                        
                    </div>
                    <div id="article_content">
                        
                            <h1 id="LLM">LLM</h1>
<p><a href="https://zhuanlan.zhihu.com/p/622518771"  target="_blank">什么是LLM大语言模型？Large Language Model，从量变到质变 - 知乎 (zhihu.com)</a></p>
<p>Large Language ModelLLM的特点是<strong>规模庞大，包含数十亿的参数</strong>，帮助它们学习语言数据中的复杂模式。这些模型通常基于深度学习架构，如转化器</p>
<p>当数据达到一定的数量的时候, 模型产生明显的性能提升, 以及出现小模型里面不存在的性能，比如上下文学习（in-context learning）</p>
<ol>
<li>上下文学习。GPT-3 正式引入了上下文学习能力：假设语言模型已经提供了自然语言指令和多个任务描述，它可以通过完成输入文本的词序列来生成测试实例的预期输出，而无需额外的训练或梯度更新。</li>
<li>指令遵循。通过对自然语言描述（即指令）格式化的<a href="https://zhida.zhihu.com/search?q=%E5%A4%9A%E4%BB%BB%E5%8A%A1&amp;zhida_source=entity&amp;is_preview=1"  target="_blank">多任务</a>数据集的混合进行微调，LLM 在微小的任务上表现良好，这些任务也以指令的形式所描述。这种能力下，指令调优使 LLM 能够在不使用显式样本的情况下通过理解任务指令来执行新任务，这可以大大提高泛化能力。</li>
<li>循序渐进的推理。对于小语言模型，通常很难解决涉及多个推理步骤的复杂任务，例如数学学科单词问题。同时，通过思维链推理策略，LLM 可以通过利用涉及中间推理步骤的 prompt 机制来解决此类任务得出最终答案。据推测，这种能力可能是通过代码训练获得的。</li>
</ol>
<h3 id="%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F">训练方式</h3>
<p>训练语言模型需要向其提供大量的文本数据，模型利用这些数据来学习人类语言的结构、语法和语义。这个过程通常是通过无监督学习完成的，使用一种叫做自我监督学习的技术。在自我监督学习中，模型通过预测序列中的下一个词或标记，为输入的数据生成自己的标签，并给出之前的词。</p>
<p><a href="https://arxiv.org/pdf/2303.18223"  target="_blank">2303.18223 (arxiv.org)</a></p>
<h3 id="%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B">发展历程</h3>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409211019711.png" alt="image-20240921101930636" /></p>
<p>经历了从语言处理到任务处理, 可以细分为统计语言模型Statistical Language Model=&gt;神经语言模型Neural Language Model=&gt;预训练语言模型Pre-trained Language Model, PLM=&gt; 大语言模型</p>
<p>现在面临的问题有不清楚为什么大语言模型会出现一些不同的特性, 研究团体比较难去训练一些大模型, 由于训练数据不能公开, 训练出来的模型不能顺应人类的道德观以及数据可能造假</p>
<h2 id="%E8%B5%84%E6%96%99">资料</h2>
<p><a href="https://github.com/RUCAIBox/LLMSurvey"  target="_blank">RUCAIBox/LLMSurvey: The official GitHub page for the survey paper &quot;A Survey of Large Language Models&quot;.</a></p>
<p><a href="https://llmbook-zh.github.io/LLMBook.pdf"  target="_blank">LLMBook.pdf (llmbook-zh.github.io)</a></p>
<h2 id="%E6%9E%84%E5%BB%BA">构建</h2>
<ol>
<li>预训练, 使用与下游任务无关的大规模数据进行模型参数的初 始训练，可以认为是为模型参数找到一个较好的“初值点”。本质上 是在做一个世界知识的压缩</li>
</ol>
<blockquote>
<p>在进行这一个步骤的时候, 需要对数据进行严格的清洗, 去除有害的信息, 提高数据的质量</p>
<p>最后将清洗后的数据进行词元化（Tokenization） 流，并且切分成批次（Batch）</p>
</blockquote>
<ol start="2">
<li>指令微调与人类对齐</li>
</ol>
<p>但是由于预训练任务形式所限，这些模型更擅长于文本补全，并 不适合直接解决具体的任务。</p>
<p>通过使用任务输入与输出的配对数据进行模型训练， 可以使得语言模型较好地掌握通过问答形式进行任务求解的能力。它主要起到了对于模型能力的激发作用，而不是 知识注入作用。</p>
<p>首次建立了神经语言模型性能与三 个主要因素——模型规模（𝑁）、数据规模（𝐷）和计算算力（𝐶）之间的幂律关系</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409211204806.png" alt="image-20240921120422758" /></p>
<blockquote>
<p>GPT使用的有代码数据训练, 人类对齐</p>
<p>（1）使用人类反馈、（2）协助人类评估和（3）进行对齐研究。</p>
<p>员引入了“红队攻击”（Red Teaming）机制减少生成有害或有毒的内容。</p>
</blockquote>
<h2 id="%E8%B5%84%E6%BA%90">资源</h2>
<p><a href="https://github.com/RUCAIBox/LLMSurvey/"  target="_blank">RUCAIBox/LLMSurvey: The official GitHub page for the survey paper &quot;A Survey of Large Language Models&quot;.</a></p>
<h3 id="%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B">开源模型</h3>
<p>经过预训练的公开模型检查点（Model Checkpoint）用户可以根据自身研究或开发需求，灵活选择 并下载使用这些检查点。</p>
<blockquote>
<p>在机器学习和深度学习领域，检查点是指在训练模型时定期保存模型的参数和优化器状态到磁盘上的文件。这样，在训练过程中可以随时将模型的状态保存下来，以便在需要的时候恢复模型的状态，继续训练或进行推理。</p>
</blockquote>
<ul>
<li>LLaMA 和 LLaMA-2. LLaMA [34] 是 Meta AI 在 2023 年 2 月发布的一系列 大语言模型，有 7B、13B、30B 和 65B 四种参数规模版本，是当时性能非常优异 的开源模型之一</li>
</ul>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409212253202.png" alt="image-20240921225323134" /></p>
<ul>
<li>ChatGLM. ChatGLM [59, 60] 是智谱 AI 和清华大学联合开发的中英双语对 话式模型，最早发布于 2023 年 5 月，并一直进行迭代优化，目前已经更新到了 ChatGLM-3。</li>
<li>InternLM 和 InternLM-2. InternLM [64] 是上海人工智能实验室开发的多语 言开源大模型, 并且支持数十类插件，有较强的工具调用能力。</li>
<li>Falcon. Falcon [61] 是阿布扎比的技术创新研究院（TII）发布的一系列语言 模型</li>
<li>Baichuan 和 Baichuan-2. Baichuan [62] 是百川智能公司于 2023 年 6 月发布的开源可商用大语言模型，参数规模为 7B，支持中英双语</li>
<li>Qwen. Qwen [66] 是阿里巴巴公司开源的多语大模型系列，首次公开发布 于 2023 年 8 月，且仍在继续更新。在语言理解、推理、数学等方面均展现出了优秀的模型能力</li>
<li>Mistral. Mistral [67] 是 Mistral AI 在 2023 年 9 月公开发布的具有 7B 参数的 大语言模型, 并且在代码生成方面的 表现接近于专门为代码任务微调的 Code LLaMA (7B)。在解码效率上，Mistral 采 用了分组查询注意力技术</li>
</ul>
<h3 id="%E5%85%AC%E5%BC%80API">公开API</h3>
<p>语言模型 API. 目前最常用的 GPT 系列模型 API 包括 GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo。开发者可以使用自己的数据来微调 GPT-3.5 Turbo， 以便更好地适用于个性化的应用场景，例如提高模型的指令遵循能力、定制化输 出格式以及定制化语气等</p>
<h3 id="%E6%95%B0%E6%8D%AE%E9%9B%86">数据集</h3>
<h4 id="%E7%BD%91%E9%A1%B5">网页</h4>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409221007241.png" alt="image-20240921230515571" /></p>
<h4 id="%E4%B9%A6%E7%B1%8D">书籍</h4>
<p>使用小说, 诗歌戏曲等</p>
<h4 id="%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91">维基百科</h4>
<h4 id="%E4%BB%A3%E7%A0%81">代码</h4>
<h4 id="%E5%BE%AE%E8%B0%83%E6%95%B0%E6%8D%AE%E9%9B%86">微调数据集</h4>
<p>在预训练之后，指令微调（也称为有监督微调）是增强或激活大语言模型特 定能力的重要方法之一（例如指令遵循能力）。</p>
<p>它们分为三种主要类型，即自然语 言处理任务数据集、日常对话数据集和合成数据集。</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409212321730.png" alt="image-20240921232110679" /></p>
<h2 id="%E9%A2%84%E8%AE%AD%E7%BB%83">预训练</h2>
<p>预训练是研发大语言模型的第一个训练阶段，也是最为重要的一个阶段。有 效的预训练能够为大语言模型的能力奠定坚实的基础</p>
<p>通过在大规模语料上进行 预训练，大语言模型可以获得通用的语言理解与生成能力，掌握较为广泛的世界 知识，具备解决众多下游任务的性能潜力。</p>
<p><img src="https://picture-01-1316374204.cos.ap-beijing.myqcloud.com/image/202409220916808.png" alt="image-20240922091613766" /></p>
<p>在实际的数据过滤的时候, 需要根据不同的数据种类选择不同的过滤规则, 首先需要过滤低质量的数据比如广告, 之后使用不同语言的高质量数据</p>
<blockquote>
<p>英语的高质量开源数据比较多, 所以在使用非英语的时候也会使用大量英语数据</p>
</blockquote>
<p>还可以使用语言里面的标点符号的数量, 单词的比例之类的数值进行筛选, 以及关键词筛选, 过滤掉个人信息等</p>
<p>也可以训练一个文本质量分类器</p>
<blockquote>
<p>在实际训练的时候可以同时使用多种不同的方法</p>
</blockquote>
<p>在处理有用户数据的资料的时候可以把出现次数比较少的资料里面的信息替换, 比较多的不进行使用, 以及在数据输出的时候对数据再次进行过滤</p>
<h3 id="%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D">数据去重</h3>
<p>对预训练数据进行去重处理是一个重要步骤。由于大语言模型具有较强的数 据拟合与记忆能力，很容易习得训练数据中的重复模式，可能导致对于这些模式 的过度学习。</p>
<ul>
<li>计算粒度</li>
</ul>
<p>可以删除包含重复单词和短语的低质量句子，因为它们可能会在 语言建模中引入重复的表达模式</p>
<p>在文档级别上，现有方法主要依靠单词或 𝑛 元词组的重叠这类表层特征，来衡量文档的重叠比率，进而检测和删除包含相似 内容的重复文档</p>
<ul>
<li>用于去重的匹配方法</li>
</ul>
<p>计算出字符串的相似度, 一般来说这一个算法的消耗比较大(可以使用MinHash算法)</p>
<blockquote>
<p>MinHash 是一种估计两个集合之间相似度的技术，最初被引入到信息检索领域，旨 在迅速判断文档间的相似性。其核心思想在于，通过哈希处理集合元素，并选择最 小的哈希值作为集合的表示。随后，通过比较两个集合的最小哈希值，便能大致估 算出它们的相似度。</p>
</blockquote>
<h3 id="%E6%95%B0%E6%8D%AE%E5%BD%B1%E5%93%8D">数据影响</h3>
<ul>
<li>数量</li>
</ul>
<p>语言模型的性能会随着训练数据数量的增加而提 升，符合扩展法则。</p>
<ul>
<li>数据的质量</li>
</ul>
<p>使用低质量的数据会导致模型训练过程不稳定, 容易造成模型训练不收敛等问题</p>
<p>大语言模型所掌握的知识信息也来源于预 训练数据，这意味着如果模型在包含事实性错误的、过时的数据上进行训练，那 么它在处理相关主题时可能会产生不准确或虚假的信息</p>
<p>在现有的文献中，普遍认为重复数据对于模型训练及最终性能会 带来不良影响。</p>
<p>数据是大语言模型掌握知识与建立能力的基础，而 语言模型是对于训练数据语义的压缩。一旦数据中包含有偏、有毒、隐私的内容， 将会对于模型造成严重的不良影响。</p>
<ul>
<li>数据集污染</li>
</ul>
<p>为了有效评估模型性能，通常需要构建相应的评测基准，来衡量大语言模型 在不同方面的能力, 在进行模型评测时，可能会发现某些评估基准所包含的数据，实 际上已出现在预训练数据或者微调数据中</p>
<p>数据集污染问题可能导致模型在与测试 数据集相关甚至高度重合的语料上进行训练，从而原本用于衡量模型在少样本或 零样本场景下的性能评测，转变为了领域内的测试任务。</p>
<h2 id="%E5%90%8D%E8%AF%8D%E8%AE%B0%E5%BD%95">名词记录</h2>
<p><strong>词元:</strong> 在大模型训练中，词元是指文本数据中的最小单位，通常是单词、短语或者符号。词元的作用是构建模型的输入数据，通过将文本数据转换为词元的形式，模型可以更好地理解和处理文本信息。词元可以帮助模型捕捉文本数据中的语义和结构特征，从而提高模型的性能和准确性。在训练过程中，词元也可以通过向量化表示，使得模型能够更好地学习文本数据中的语义信息。因此，词元在大模型训练中起着非常重要的作用。</p>
<p><strong>参数: </strong>在进行大模型训练时，通常需要设置和调整的参数包括但不限于以下内容：</p>
<ol>
<li>学习率（learning rate）：控制模型在训练过程中更新参数的速率，以避免过拟合或欠拟合。</li>
<li>批大小（batch size）：指定每次迭代训练时所使用的样本数量，影响模型的收敛速度和训练效果。</li>
<li>优化算法（optimizer）：选择用于调整模型参数的优化算法，如随机梯度下降（SGD）、Adam等。</li>
<li>损失函数（loss function）：定义用于评估模型输出与真实标签之间差异的函数，用于优化模型的训练过程。</li>
<li>正则化参数（regularization）：控制模型的复杂度，防止过拟合，包括L1正则化、L2正则化等。</li>
<li>学习率衰减（learning rate decay）：设置学习率随训练轮次递减的策略，帮助模型更好地收敛。</li>
<li>训练轮次（epochs）：指定模型进行训练的轮次数量，通常通过交叉验证等技术确定合适的训练轮次。</li>
<li>数据增强参数（data augmentation）：用于增加训练数据样本的多样性，提高模型的泛化能力。</li>
<li>GPU/CPU使用设备参数：指定模型训练时使用的计算设备，如GPU或CPU。</li>
<li>模型保存与加载参数：设置模型在训练过程中的保存与加载策略，以便后续模型调用和部署。</li>
</ol>
<p>以上是一些在大模型训练中常见的参数内容，具体的设置和调整可根据实际情况和任务需求进行进一步的定制。</p>
<p><strong>泛化能力: </strong></p>
<p><strong>迁移学习:</strong> 类比调动</p>

                        
                    </div>
                </div>
                <div id="previous_next">
                    <div id="previous">
                        
                        <a href="/note/机器学习/2024-10-9-transforms实战.html">
                            <span class="icon"></span>
                            <span class="label">2024-10-9-transforms实战</span>
                        </a>
                        
                    </div>
                    <div id="next">
                        
                        <a href="/note/机器学习/2024-9-22-vLLM.html">
                            <span class="label">2024-9-22-vLLM</span>
                            <span class="icon"></span>
                        </a>
                        
                    </div>
                </div>
                <div id="comments-container"></div>
            </div>
            <div id="toc_wrapper">
                <div id="toc">
                    <div id="toc_content">
                            
                    </div>
                </div>
            </div>
        </div>
    </div>
    <a id="to_top" href="#"></a>
    <div id="doc_footer">
        <div id="footer">
            <div id="footer_top">
                <ul>
<li><a>链接</a><ul><li><a target="_blank" href="https://teedoc.neucrack.com">网站使用 teedoc 生成</a></li>
<li><a target="_blank" href="https://neucrack.com">Copyright © 2021 Neucrack</a></li>
<li><a  href="/note/sitemap.xml">网站地图</a></li>
</ul>
</li>
<li><a>源码</a><ul><li><a target="_blank" href="https://github.com/XuSenfeng/note/">github</a></li>
<li><a target="_blank" href="https://github.com/teedoc/teedoc">本网站源文件</a></li>
</ul>
</li>
</ul>

            </div>
            <div id="footer_bottom">
                <ul>
<li><a target="_blank" href="https://beian.miit.gov.cn">渝ICP备19015320号</a></li>
<li><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44030602004109">粤公网安备44030602004109号</a></li>
</ul>

            </div>
        </div>
    </div>
    
        <script src="/note/teedoc-plugin-markdown-parser/mermaid.min.js"></script>
    
        <script>mermaid.initialize({startOnLoad:true});</script>
    
        <script type="text/javascript">
                var transLoaded = false;
                var loading = false;
                var domain = "translate.google.com";
                var domainDefault = domain;
                var storeDomain = localStorage.getItem("googleTransDomain");
                if(storeDomain){
                    domain = storeDomain;
                    console.log("load google translate domain from local storage:" + domain);
                }
                function getUrl(domain){
                    if(domain == "/")
                        return "/static/js/google_translate/element.js?cb=googleTranslateElementInit";
                    else
                        return "https://" + domain + "/translate_a/element.js?cb=googleTranslateElementInit";
                }
                var url = getUrl(domain);
                console.log("google translate domain:" + domain + ", url: " + url);
                function googleTranslateElementInit() {
                    new google.translate.TranslateElement({pageLanguage: "auto", layout: google.translate.TranslateElement.InlineLayout.SIMPLE}, 'google_translate_element');
                }
                function loadJS( url, callback ){
                    var script = document.createElement('script');
                    fn = callback || function(){ };
                    script.type = 'text/javascript';
                    if(script.readyState){
                        script.onreadystatechange = function(){
                            if( script.readyState == 'loaded' || script.readyState == 'complete' ){
                                script.onreadystatechange = null;
                                fn();
                            }
                        };
                    }else{
                        script.onload = function(){
                            fn();
                        };
                    }
                    script.src = url;
                    document.getElementsByTagName('head')[0].appendChild(script);
                }
                function removeHint(){
                    var hint = document.getElementById("loadingTranslate");
                    if(hint){
                        hint.remove();
                    }
                }
                var btn = document.getElementById("google_translate_element");
                btn.onclick = function(){
                    if(transLoaded) return;
                    if(loading){
                        var flag = confirm("loading from " + domain + ", please wait, or change domain?");
                        if(flag){
                            newDomain = prompt("domain, default: " + domainDefault + ", now: " + domain);
                            if(newDomain){
                                domain = newDomain;
                                console.log(domain);
                                url = getUrl(domain);
                                loadJS(url, function(){
                                    localStorage.setItem("googleTransDomain", domain);
                                    removeHint()
                                    transLoaded = true;
                                });
                            }
                        }
                        return;
                    }
                    btn.innerHTML = '<span id="loadingTranslate"><img class="icon" src="/note/static/image/google_translate/translate.svg"/>Loading ...</span>';
                    loading = true;
                    loadJS(url, function(){
                        localStorage.setItem("googleTransDomain", domain);
                        removeHint()
                        transLoaded = true;
                    });
                }
                </script>
            
    
        <script src="/note/static/js/theme_default/tocbot.min.js"></script>
    
        <script src="/note/static/js/theme_default/main.js"></script>
    
        <script src="/note/static/js/theme_default/viewer.min.js"></script>
    
        <script src="/note/static/css/theme_default/prism.min.js"></script>
    
        <script src="/note/static/js/search/search_main.js"></script>
    
        <script src="/note/static/js/plugin_blog/main.js"></script>
    
        <link rel="stylesheet" href="/note/static/js/add_hint/style.css" type="text/css"/>
    
        <script src="/note/static/js/add_hint/main.js"></script>
    
        <script src="/note/static/js/gitalk/gitalk.min.js"></script>
    
        <script src="/note/static/js/gitalk/main.js"></script>
    
        <script src="/note/static/js/custom.js"></script>
    
</body>

</html>