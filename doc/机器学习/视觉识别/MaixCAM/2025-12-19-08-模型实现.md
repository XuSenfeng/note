# 模型实现

```cpp
class YOLOv8 : public YOLO11
  
YOLOv8(const string &model = "", bool dual_buff = true)
: YOLO11(model, "yolov8", dual_buff)
{
}
```

YOLOv8的模型实际是使用YOLOv11的模型的实现, 使用type_str区分不同的模型

使用下面的结构体记录模型在转换为NPU模型以后得输出位置

```cpp
  struct _OutIdxes
  {
      // mode 1
      int det0;     // 1x144x80x80
      int det1;     // 1x144x40x40
      int det2;     // 1x144x20x20

      // mode 2
      int dfl;      // 1x1x4x8400
      int sigmoid;  // 1x80x8400

      // optional node
      // seg mask        1x32x160x160
      // seg mask weight 1x32x8400
      int seg_mask;
      int seg_mask_weight;

      // obb  1x1x8400
      int obb_angle;
      // pose 1x51x8400
      int pose;
  };
```

-   `det0 / det1 / det2`（mode 1）
    -   分别对应 3 个不同尺度的检测特征图：
        -   `det0`: 1×144×80×80（stride=8，大特征图，检测小目标）
        -   `det1`: 1×144×40×40（stride=16）
        -   `det2`: 1×144×20×20（stride=32，小特征图，检测大目标）
    -   通常 channel 数 = `num_classes + reg_max*4`，里面既有分类分数也有 bbox 回归分布。
-   `dfl`（mode 2）
    -   DFL（Distribution Focal Loss）回归输出的索引。
    -   形状类似 1×1×4×8400 或 1×4×8400×1，对应每个 anchor 的 4 个边界框距离的离散分布。
-   `sigmoid`（mode 2）
    -   分类/置信度输出的索引。
    -   形状类似 1×80×8400（80 类 × 8400 anchor），后处理时会做 sigmoid 得到每一类的概率。
-   `seg_mask`（可选，分割模型）
    -   语义分割的特征图（如 1×32×160×160），是“原始掩码特征”。
    -   后处理时，会通过 `seg_mask_weight` 和检测到的框一起，组合出每个目标的最终分割掩码。
-   `seg_mask_weight`（可选，分割模型）
    -   对应每个 anchor 的 mask 权重（1×32×8400）。
    -   可以理解为每个目标在 32 个 mask 通道上的线性组合系数，用来从 `seg_mask` 生成该目标的像素级掩码。
-   `obb_angle`（可选，旋转框 OBB 模型）
    -   旋转框的角度输出节点索引（1×1×8400），每个 anchor 一个角度值。
    -   有的模型角度输出需要 sigmoid 映射到角度范围，有的则不需要，所以代码里还有 `_obb_need_sigmoid` 来区分。
-   `pose`（可选，姿态/关键点模型）
    -   关键点输出的索引（约 1×51×8400：17 点×(x,y,score)×8400）。
    -   后处理时会根据这个节点解出每个检测框里的关键点坐标和置信度。

## 模型加载

```cpp
_model = new nn::NN(model, _dual_buff);
```

首先使用加载的`_model`实际用来加载模型, 首先比对一下模型的type是不是对的, 使用`std::map<std::string, std::string> extra_info();`获取配置文件里面的信息

+   比对模型的类型
+   加载`mean/scale`到数组里面
+   获取到实际的分类的labels对应的名字
+   使用的分类类型
+   判断一下模型的输入张量的形状（例如 `[1, 3, 640, 640]` 或 `[1, 640, 640, 3]`）, 记录在_input_size里面
+   解析一下**YOLO11 模型的各个输出节点，并记住它们的位置和布局**