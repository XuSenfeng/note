# 修改网络

+   加入新的网络结构定义
+   设置传递参数的细节
+   添加一个新的配置文件, 定义实际使用的层

>   网络改变以后很是可以使用原有的权重, 会自动做一部分的迁移

## C2f

是一个YoloV8里面引入的模块, C2f会使用到Bottleneck, 参数和原本的不一样, 需要复制过来, 改一个名字作为区分, 之后在参数配置的位置加上这个模块即可, 这个模块和C3是一样的, 所以可以直接在所有C3的位置添加

```python
class Bottleneck(nn.Module):
    """Standard bottleneck."""

    def __init__(
        self, c1: int, c2: int, shortcut: bool = True, g: int = 1, k: tuple[int, int] = (3, 3), e: float = 0.5
    ):
        """Initialize a standard bottleneck module.

        Args:
            c1 (int): Input channels.
            c2 (int): Output channels.
            shortcut (bool): Whether to use shortcut connection.
            g (int): Groups for convolutions.
            k (tuple): Kernel sizes for convolutions.
            e (float): Expansion ratio.
        """
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, k[0], 1)
        self.cv2 = Conv(c_, c2, k[1], 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Apply bottleneck with optional shortcut connection."""
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))

class C2f(nn.Module):
    """Faster Implementation of CSP Bottleneck with 2 convolutions."""

    def __init__(self, c1: int, c2: int, n: int = 1, shortcut: bool = False, g: int = 1, e: float = 0.5):
        """Initialize a CSP bottleneck with 2 convolutions.

        Args:
            c1 (int): Input channels.
            c2 (int): Output channels.
            n (int): Number of Bottleneck blocks.
            shortcut (bool): Whether to use shortcut connections.
            g (int): Groups for convolutions.
            e (float): Expansion ratio.
        """
        super().__init__()
        self.c = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, 2 * self.c, 1, 1)
        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass through C2f layer."""
        y = list(self.cv1(x).chunk(2, 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))

    def forward_split(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass using split() instead of chunk()."""
        y = self.cv1(x).split((self.c, self.c), 1)
        y = [y[0], y[1]]
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))
```

配置的yaml文件里面可以吧所有的C3改为C2f

>   如何层的位置会影响到后面的层需要处理一下两层合并时候的索引配置

## 替换主干网络

### Mobilenet

#### 不同

1. 传统卷积的问题

传统卷积核同时完成 “空间特征提取” 和 “通道融合”，计算量公式：`计算量 = 卷积核尺寸×卷积核尺寸 × 输入通道数(M) × 输出通道数(N) × 特征图尺寸(Df×Df)`例：3×3 卷积、输入通道 32、输出通道 64、特征图 32×32 → 计算量 = 3×3×32×64×32×32 ≈ 18.9M 次运算。

2. 深度可分离卷积的拆解

将传统卷积拆为两步，总计算量仅为传统卷积的 `1/N + 1/(K×K)`（N 为输出通道数，K 为卷积核尺寸），通常可降低 **8~9 倍** 计算量：

正确名称是 **MobileNet**（移动端网络）—— 由 Google 团队提出的**轻量级卷积神经网络（CNN）**，核心设计目标是在**移动端 / 嵌入式设备**（算力、内存有限的场景）中实现高效的视觉任务（分类、检测、分割），同时尽可能保持精度。

| 步骤                  | 作用                                                         | 计算量（以上例）         |
| --------------------- | ------------------------------------------------------------ | ------------------------ |
| 深度卷积（Depthwise） | 对**每个输入通道单独做空间卷积**（只提取空间特征，不融合通道），卷积核数 = 输入通道数 | 3×3×32×1×32×32 ≈ 0.98M   |
| 逐点卷积（Pointwise） | 用 1×1 卷积核**融合通道特征**（只融合通道，不提取空间特征），卷积核数 = 输出通道数 | 1×1×32×64×32×32 ≈ 2.1M   |
| 总计                  | 深度卷积 + 逐点卷积                                          | ≈3.08M（仅为传统的 1/6） |

#### 移植

在实际移植的时候是根据这个模型的结构, 对原有的网络进行一部分的替换, 还是使用配置文件, 我们需要使用的是他的特征提取部分的网络

```python
from torchvision import models
model = models.mobilenet_v3_small(pretrained=True ,progress=True)
# 查看一下安装yolo输入的话各层输出
from torchinfo import summary
summary(model, input_size=(1, 3, 640, 640))
"""
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
MobileNetV3                                        [1, 1000]                 --
├─Sequential: 1-1                                  [1, 576, 20, 20]          --
│    └─ConvNormActivation: 2-1                     [1, 16, 320, 320]         --
│    │    └─Conv2d: 3-1                            [1, 16, 320, 320]         432
│    │    └─BatchNorm2d: 3-2                       [1, 16, 320, 320]         32
│    │    └─Hardswish: 3-3                         [1, 16, 320, 320]         --
│    └─InvertedResidual: 2-2                       [1, 16, 160, 160]         --
│    │    └─Sequential: 3-4                        [1, 16, 160, 160]         744
│    └─InvertedResidual: 2-3                       [1, 24, 80, 80]           --
│    │    └─Sequential: 3-5                        [1, 24, 80, 80]           3,864
│    └─InvertedResidual: 2-4                       [1, 24, 80, 80]           --
│    │    └─Sequential: 3-6                        [1, 24, 80, 80]           5,416
│    └─InvertedResidual: 2-5                       [1, 40, 40, 40]           --
│    │    └─Sequential: 3-7                        [1, 40, 40, 40]           13,736
│    └─InvertedResidual: 2-6                       [1, 40, 40, 40]           --
│    │    └─Sequential: 3-8                        [1, 40, 40, 40]           57,264
│    └─InvertedResidual: 2-7                       [1, 40, 40, 40]           --
│    │    └─Sequential: 3-9                        [1, 40, 40, 40]           57,264
│    └─InvertedResidual: 2-8                       [1, 48, 40, 40]           --
│    │    └─Sequential: 3-10                       [1, 48, 40, 40]           21,968
│    └─InvertedResidual: 2-9                       [1, 48, 40, 40]           --
│    │    └─Sequential: 3-11                       [1, 48, 40, 40]           29,800
│    └─InvertedResidual: 2-10                      [1, 96, 20, 20]           --
│    │    └─Sequential: 3-12                       [1, 96, 20, 20]           91,848
│    └─InvertedResidual: 2-11                      [1, 96, 20, 20]           --
│    │    └─Sequential: 3-13                       [1, 96, 20, 20]           294,096
│    └─InvertedResidual: 2-12                      [1, 96, 20, 20]           --
│    │    └─Sequential: 3-14                       [1, 96, 20, 20]           294,096
│    └─ConvNormActivation: 2-13                    [1, 576, 20, 20]          --
│    │    └─Conv2d: 3-15                           [1, 576, 20, 20]          55,296
│    │    └─BatchNorm2d: 3-16                      [1, 576, 20, 20]          1,152
│    │    └─Hardswish: 3-17                        [1, 576, 20, 20]          --
├─AdaptiveAvgPool2d: 1-2                           [1, 576, 1, 1]            --
├─Sequential: 1-3                                  [1, 1000]                 --
│    └─Linear: 2-14                                [1, 1024]                 590,848
│    └─Hardswish: 2-15                             [1, 1024]                 --
│    └─Dropout: 2-16                               [1, 1024]                 --
│    └─Linear: 2-17                                [1, 1000]                 1,025,000
====================================================================================================
Total params: 2,542,856
Trainable params: 2,542,856
Non-trainable params: 0
Total mult-adds (M): 446.48
====================================================================================================
Input size (MB): 4.92
Forward/backward pass size (MB): 184.56
Params size (MB): 10.17
Estimated Total Size (MB): 199.65
====================================================================================================
"""
# 查看一下实际的实现, 使用features部分的网络
model
"""
MobileNetV3(
  (features): Sequential(
    (0): ConvNormActivation(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): Hardswish()
    )
    (1): InvertedResidual(
      (block): Sequential(
        (0): ConvNormActivation(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (2): ConvNormActivation(
          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    
		...
		
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (classifier): Sequential(
    (0): Linear(in_features=576, out_features=1024, bias=True)
    (1): Hardswish()
    (2): Dropout(p=0.2, inplace=True)
    (3): Linear(in_features=1024, out_features=1000, bias=True)
  )
)
"""

```

在实际移植的时候, 由于之后需要对提取出来的不同大小特征合并, 所以需要对不同层的输出进行匹配, 替换的是backbone部分的

如果手动进行所有的层的移植, 是一个很麻烦的, 这里的module使用一个Sequential类型的, 所以可以使用数组的方式提取其中一部分的模块`model.features[:4]`, 所以可以直接使用这个方式进行分割

```python
from torch import nn
class MobileNetV3(nn.Module):
    def __init__(self, slice):
        super(MobileNetV3, self).__init__()
        self.model = None
        if slice == 1:
            self.model = models.mobilenet_v3_small(pretrained=True ,progress=True).features[:4]
        elif slice == 2:
            self.model = models.mobilenet_v3_small(pretrained=True ,progress=True).features[4:9]
        elif slice == 3:
            self.model = models.mobilenet_v3_small(pretrained=True ,progress=True).features[9:]

    def forward(self, x):
        x = self.model(x)
        return x
```

```yaml
backbone:
  # [from, number, module, args]
  # 这里的24, 48, 576是输出的通道数, 使用之前打印的数据即可获取
  [
		[-1, 1, MobileNetV3, [24, 1]],
		[-1, 1, MobileNetV3, [48, 2]],
		[-1, 1, MobileNetV3, [576, 1]]
  ]
```

```python
elif m is MobileNetV3:
    c2 = args[0] # 记录输出通道
    args = args[1:] # 实际使用的参数
```

