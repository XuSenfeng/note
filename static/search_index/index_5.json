{"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-14-04-Yoloæ¨¡å‹è½¬æ¢.html":{"title":"Yoloæ¨¡å‹è½¬æ¢","content":"# Yoloæ¨¡å‹è½¬æ¢ https://www.zhihu.com/tardis/zm/art/26328918714?source_id 1005 https://wiki.sipeed.com/maixpy/doc/zh/ai_model_converter/maixcam.html MaixCamä½¿ç”¨çš„æ¨¡å‹æ˜¯MUDæè¿°æ¨¡å‹, æ¨¡å‹ç»Ÿä¸€æè¿°æ–‡ä»¶, model universal description file, æœ¬èº«æ˜¯ä¸€ä¸ª `ini`æ ¼å¼çš„æ–‡æœ¬æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨æ–‡æœ¬ç¼–è¾‘å™¨ç¼–è¾‘ ä¸€èˆ¬ MUD æ–‡ä»¶ä¼šä¼´éšä¸€ä¸ªæˆ–è€…å¤šä¸ªå®é™…çš„æ¨¡å‹æ–‡ä»¶ï¼Œæ¯”å¦‚å¯¹äº MaixCAMï¼Œ å®é™…çš„æ¨¡å‹æ–‡ä»¶æ˜¯`.cvimodel`æ ¼å¼ï¼Œ MUD æ–‡ä»¶åˆ™æ˜¯å¯¹å®ƒåšäº†ä¸€äº›æè¿°è¯´æ˜ ```ini [basic] type cvimodel model yolov8n.cvimodel [extra] model_type yolov8 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 labels person, bicycle, car, ``` ## è½¬æ¢ å‡†å¤‡å¥½ä½ çš„ onnx æ¨¡å‹ï¼Œ ç„¶ååœ¨https://netron.app/ æŸ¥çœ‹ä½ çš„æ¨¡å‹ï¼Œç¡®ä¿ä½ çš„æ¨¡å‹ä½¿ç”¨çš„ç®—å­åœ¨è½¬æ¢å·¥å…·çš„æ”¯æŒåˆ—è¡¨ä¸­ï¼Œè½¬æ¢å·¥å…·çš„æ”¯æŒåˆ—è¡¨å¯ä»¥åœ¨[ç®—èƒ½ TPU SDK](https://developer.sophgo.com/thread/473.html)çš„ **CVITEK_TPU_SDKå¼€å‘æŒ‡å—.pdf** ä¸­çœ‹åˆ°åˆ—è¡¨ ```python from ultralytics import YOLO import sys print(sys.path) net_name '../ultralytics/runs/detect/train4/weights/best.pt' input_width 320 input_height 224 # Load a model model YOLO(net_name) # load an official model path model.export(format \"onnx\", imgsz [input_height, input_width], dynamic False, simplify True, opset 17) # export the model to ONNX format print(path) ``` ### å®‰è£…docker ```bash docker pull sophgo/tpuc_dev:latest # æŒ‚è½½ä¸€ä¸‹macçš„ä¸€ä¸ªç›®å½• docker run privileged name tpu env v /home/$USER/data:/home/${USER}/data it sophgo/tpuc_dev # mac docker run privileged name tpu env v /Users/$USER/data:/home/${USER}/data it sophgo/tpuc_dev wget https://github.com/sophgo/tpu mlir/releases#:~:text tpu_mlir%2D1.25%2Dpy3%2Dnone%2Dany.whl pip install tpu_mlir*.whl ``` æ–‡ä»¶è·¯å¾„ ```bash . â”œâ”€â”€ 1.jpg â”œâ”€â”€ best.onnx â”œâ”€â”€ best.pt â”œâ”€â”€ calling20221009.mp4 â”œâ”€â”€ conver.sh â”œâ”€â”€ tpu_mlir 1.25 py3 none any.whl â”œâ”€â”€ val â”‚ â”œâ”€â”€ frame_510.jpg â”‚ â”œâ”€â”€ frame_540.jpg â”‚ â””â”€â”€ frame_780.jpg â””â”€â”€ workspace â”œâ”€â”€ _weight_map.csv â”œâ”€â”€ best.mlir â”œâ”€â”€ best.ref_files.json â”œâ”€â”€ best_bf16 â”‚ â”œâ”€â”€ final.mlir â”‚ â””â”€â”€ ref_files.json â”œâ”€â”€ best_bf16.cvimodel â”œâ”€â”€ best_bf16_tensor_info.txt â”œâ”€â”€ best_cali_table â”œâ”€â”€ best_cv181x_bf16.layer_group_cache.json â”œâ”€â”€ best_cv181x_bf16.layer_group_config.json â”œâ”€â”€ best_cv181x_bf16_final.mlir â”œâ”€â”€ best_cv181x_bf16_tpu.mlir â”œâ”€â”€ best_cv181x_int8.layer_group_cache.json â”œâ”€â”€ best_cv181x_int8.layer_group_config.json â”œâ”€â”€ best_cv181x_int8_sym_final.mlir â”œâ”€â”€ best_cv181x_int8_sym_tpu.mlir â”œâ”€â”€ best_in_f32.npz â”œâ”€â”€ best_int8 â”‚ â”œâ”€â”€ final.mlir â”‚ â””â”€â”€ ref_files.json â”œâ”€â”€ best_int8.cvimodel â”œâ”€â”€ best_int8_tensor_info.txt â”œâ”€â”€ best_opt.onnx.prototxt â”œâ”€â”€ best_origin.mlir â”œâ”€â”€ best_top_f32_all_weight.npz â”œâ”€â”€ best_top_outputs.npz â”œâ”€â”€ best_tpu_addressed_cv181x_bf16_weight.npz â”œâ”€â”€ best_tpu_addressed_cv181x_bf16_weight_fix.npz â”œâ”€â”€ best_tpu_addressed_cv181x_int8_sym_weight.npz â”œâ”€â”€ best_tpu_addressed_cv181x_int8_sym_weight_fix.npz â””â”€â”€ shape_pattern_qtable ``` ä½¿ç”¨è„šæœ¬ è¿™é‡Œé€‰å–çš„èŠ‚ç‚¹æ˜¯ä¸‹é¢çš„ä¸¤ä¸ª ![image 20251214153346489](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251214153346489.png) > â€œæˆªæ–­æ¨¡å‹è¾“å‡ºåˆ° CPU åå¤„ç†å‰çš„æ ¸å¿ƒå±‚â€ï¼Œè®©é‡åŒ–åªä½œç”¨äºçœŸæ­£éœ€è¦åŠ é€Ÿçš„ GPU / æ¨ç†èŠ¯ç‰‡è¿ç®—éƒ¨åˆ† > > ```bash #!/bin/bash set e net_name best input_w 320 input_h 224 # mean: 0, 0, 0 # std: 255, 255, 255 # mean # 1/std # mean: 0, 0, 0 # scale: 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 mkdir p workspace cd workspace # convert to mlir model_transform.py \\ model_name ${net_name} \\ model_def ../${net_name}.onnx \\ input_shapes [[1,3,${input_h},${input_w}]] \\ mean \"0,0,0\" \\ scale \"0.00392156862745098,0.00392156862745098,0.00392156862745098\" \\ keep_aspect_ratio \\ pixel_format rgb \\ channel_format nchw \\ output_names \"/model.22/dfl/conv/Conv_output_0,/model.22/Sigmoid_output_0\" \\ test_input ../1.jpg \\ test_result ${net_name}_top_outputs.npz \\ tolerance 0.99,0.99 \\ mlir ${net_name}.mlir # export bf16 model # not use quant_input, use float32 for easy coding model_deploy.py \\ mlir ${net_name}.mlir \\ quantize BF16 \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ model ${net_name}_bf16.cvimodel echo \"calibrate for int8 model\" # export int8 model run_calibration.py ${net_name}.mlir \\ dataset ../val \\ input_num 3 \\ o ${net_name}_cali_table echo \"convert to int8 model\" # export int8 model # add quant_input, use int8 for faster processing in maix.nn.NN.forward_image model_deploy.py \\ mlir ${net_name}.mlir \\ quantize INT8 \\ quant_input \\ calibration_table ${net_name}_cali_table \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ tolerance 0.9,0.6 \\ model ${net_name}_int8.cvimodel ``` `output_names` å°±æ˜¯æˆ‘ä»¬å‰é¢è¯´åˆ°çš„è¾“å‡ºèŠ‚ç‚¹çš„è¾“å‡ºåã€‚ `mean, scale` å°±æ˜¯è®­ç»ƒæ—¶ä½¿ç”¨çš„é¢„å¤„ç†æ–¹æ³•ï¼Œæ¯”å¦‚ `YOLOv5` å®˜æ–¹ä»£ç çš„é¢„å¤„ç†æ˜¯æŠŠå›¾åƒ RGB 3ä¸ªé€šé“åˆ†åˆ« ` mean`å†é™¤ä»¥`std`ï¼Œå¹¶ä¸”é»˜è®¤`mean` ä¸º`0`ï¼Œ `std`ä¸º`255`ï¼Œå³å°†å›¾åƒçš„å€¼å½’ä¸€ï¼Œè¿™é‡Œ`scale`å°±æ˜¯`1/std`ã€‚ä½ çš„æ¨¡å‹éœ€è¦æ ¹æ®å®é™…çš„é¢„å¤„ç†æ–¹æ³•ä¿®æ”¹ã€‚ `test_input` å°±æ˜¯è½¬æ¢æ—¶ç”¨æ¥æµ‹è¯•çš„å›¾åƒï¼Œè¿™é‡Œæ˜¯`../dog.jpg`ï¼Œæ‰€ä»¥å®é™…æ¨¡å‹è½¬æ¢æ—¶æˆ‘ä»¬éœ€è¦åœ¨æ­¤è„šæœ¬æ‰€åœ¨åŒç›®å½•æ”¾ä¸€å¼ `dog.jpg`çš„å›¾ï¼Œä½ çš„æ¨¡å‹æ ¹æ®ä½ çš„å®é™…æƒ…å†µæ›¿æ¢å›¾åƒã€‚ `tolerance` å°±æ˜¯é‡åŒ–å‰åå…è®¸çš„è¯¯å·®ï¼Œå¦‚æœè½¬æ¢æ¨¡å‹æ—¶æŠ¥é”™æç¤ºå€¼å°äºè®¾ç½®çš„è¿™ä¸ªå€¼ï¼Œè¯´æ˜è½¬å‡ºæ¥çš„æ¨¡å‹å¯èƒ½ç›¸æ¯” onnx æ¨¡å‹è¯¯å·®è¾ƒå¤§ï¼Œå¦‚æœä½ èƒ½å¤Ÿå®¹å¿ï¼Œå¯ä»¥é€‚å½“è°ƒå°è¿™ä¸ªé˜ˆå€¼è®©æ¨¡å‹è½¬æ¢é€šè¿‡ï¼Œä¸è¿‡å¤§å¤šæ•°æ—¶å€™éƒ½æ˜¯å› ä¸ºæ¨¡å‹ç»“æ„å¯¼è‡´çš„ï¼Œéœ€è¦ä¼˜åŒ–æ¨¡å‹ï¼Œä»¥åŠä»”ç»†çœ‹åå¤„ç†ï¼ŒæŠŠèƒ½å»é™¤çš„åå¤„ç†å»é™¤äº†ã€‚ `quantize` å³é‡åŒ–çš„æ•°æ®ç±»å‹ï¼Œåœ¨ MaixCAM ä¸Šæˆ‘ä»¬ä¸€èˆ¬ç”¨ INT8 æ¨¡å‹ï¼Œè¿™é‡Œæˆ‘ä»¬è™½ç„¶ä¹Ÿé¡ºä¾¿è½¬æ¢äº†ä¸€ä¸ª BF16 æ¨¡å‹ï¼ŒBF16 æ¨¡å‹çš„å¥½å¤„æ—¶ç²¾åº¦é«˜ï¼Œä¸è¿‡è¿è¡Œé€Ÿç‡æ¯”è¾ƒæ…¢ï¼Œèƒ½è½¬æˆ INT8 å°±æ¨èå…ˆç”¨ INT8,å®åœ¨ä¸èƒ½è½¬æ¢çš„æˆ–è€…ç²¾åº¦è¦æ±‚é«˜é€Ÿåº¦è¦æ±‚ä¸é«˜çš„å†è€ƒè™‘ BF16ã€‚ `dataset` è¡¨ç¤ºç”¨æ¥é‡åŒ–çš„æ•°æ®é›†ï¼Œä¹Ÿæ˜¯æ”¾åœ¨è½¬æ¢è„šæœ¬åŒç›®å½•ä¸‹ï¼Œæ¯”å¦‚è¿™é‡Œæ˜¯`images`æ–‡ä»¶å¤¹ï¼Œé‡Œé¢æ”¾æ•°æ®å³å¯ï¼Œå¯¹äº YOLOv5 æ¥è¯´å°±æ˜¯å›¾ç‰‡ï¼Œä» coco æ•°æ®é›†ä¸­å¤åˆ¶ä¸€éƒ¨åˆ†å…¸å‹åœºæ™¯çš„å›¾ç‰‡è¿‡æ¥å³å¯ã€‚ ç”¨` input_num` å¯ä»¥æŒ‡å®šå®é™…ä½¿ç”¨å›¾ç‰‡çš„æ•°é‡ï¼ˆå°äºç­‰äº images ç›®å½•ä¸‹å®é™…çš„å›¾ç‰‡ï¼‰ > èƒ½åœ¨`workspace`æ–‡ä»¶å¤¹ä¸‹çœ‹åˆ°æœ‰`**_int8.cvimodel` æ–‡ä»¶äº† ## é…ç½®æ–‡ä»¶ ```ini [basic] type cvimodel model best_bf16.cvimodel [extra] model_type yolov8 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 labels man, girl, car ``` è¿™é‡Œ`basic`éƒ¨åˆ†æŒ‡å®šäº†æ¨¡å‹æ–‡ä»¶ç±»åˆ«å’Œæ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œæ˜¯å¿…è¦çš„å‚æ•°ï¼Œæœ‰äº†è¿™ä¸ªå‚æ•°å°±èƒ½ç”¨`MaixPy`æˆ–è€…`MaixCDK`ä¸­çš„`maix.nn.NN`ç±»æ¥åŠ è½½å¹¶è¿è¡Œæ¨¡å‹äº†ã€‚ `extra`åˆ™æ ¹æ®ä¸åŒæ¨¡å‹çš„éœ€æ±‚è®¾è®¡ä¸åŒå‚æ•°ã€‚æ¯”å¦‚è¿™é‡Œå¯¹`YOLOv5`è®¾è®¡äº†è¿™äº›å‚æ•°ï¼Œä¸»è¦æ˜¯ é¢„å¤„ç†ã€åå¤„ç†ã€æ ‡ç­¾ç­‰å‚æ•°ã€‚å¯¹äº `MaixPy` å·²ç»æ”¯æŒäº†çš„æ¨¡å‹å¯ä»¥ç›´æ¥ä¸‹è½½å…¶æ¨¡å‹å¤åˆ¶ä¿®æ”¹ã€‚ä¹Ÿå¯ä»¥çœ‹å…·ä½“çš„ä»£ç ï¼Œæ¯”å¦‚[YOLOv5 çš„æºç ](https://github.com/sipeed/MaixCDK/blob/71d5b3980788e6b35514434bd84cd6eeee80d085/components/nn/include/maix_nn_yolov5.hpp#L73 L223)ï¼Œå¯ä»¥çœ‹åˆ°æºç ä½¿ç”¨äº†å“ªäº›å‚æ•°ã€‚ æ¯”å¦‚ä½ ç”¨`YOLOv5`è®­ç»ƒäº†æ£€æµ‹æ•°å­—`0~9`çš„æ¨¡å‹ï¼Œé‚£ä¹ˆéœ€è¦å°†`labels`æ”¹æˆ`0,1,2,3,4,5,6,7,8,9`ï¼Œå…¶å®ƒå‚æ•°å¦‚æœä½ æ²¡æ”¹è®­ç»ƒä»£ç ä¿æŒå³å¯ã€‚ å¦‚æœä½ éœ€è¦ç§»æ¤ `MaixPy` æ²¡æœ‰æ”¯æŒçš„æ¨¡å‹ï¼Œåˆ™å¯ä»¥æ ¹æ®æ¨¡å‹çš„é¢„å¤„ç†å’Œåå¤„ç†æƒ…å†µå®šä¹‰ `extra`, ç„¶åç¼–å†™å¯¹åº”çš„è§£ç ç±»ã€‚å¦‚æœä½ ä¸æƒ³ç”¨C++ä¿®æ”¹ MaixPy æºç ï¼Œä½ ä¹Ÿå¯ä»¥ç”¨MaixPy çš„`maix.nn.NN`ç±»åŠ è½½æ¨¡å‹ï¼Œç„¶åç”¨ `forward` æˆ–è€… `forward_image` æ–¹æ³•æˆ–è€…åŸå§‹è¾“å‡ºï¼Œåœ¨ Python å±‚é¢å†™åå¤„ç†ä¹Ÿå¯ä»¥ï¼Œåªæ˜¯è¿è¡Œæ•ˆç‡æ¯”è¾ƒä½ä¸å¤ªæ¨è > `basic` éƒ¨åˆ†æ˜¯å¿…éœ€çš„ï¼Œ`extra` éƒ¨åˆ†æ˜¯å¯é€‰çš„ã€‚ > > `basic` éƒ¨åˆ†æè¿°äº†æ¨¡å‹çš„ç±»å‹å’Œæ¨¡å‹è·¯å¾„ã€‚ > `type` è¡¨ç¤ºæ¨¡å‹ç±»å‹ï¼Œç›®å‰æ”¯æŒ `MaixCam` çš„ `cvimodel` ç±»å‹ã€‚ > `model` è¡¨ç¤ºæ¨¡å‹çš„ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äº MUD æ–‡ä»¶æ‰€åœ¨ä½ç½®ã€‚ > `extra` éƒ¨åˆ†æè¿°äº†æ¨¡å‹çš„é¢å¤–ä¿¡æ¯ï¼Œåº”ç”¨ç¨‹åºå¯ä»¥é€šè¿‡ `model.extra_info()` æ–¹æ³•è·å–ã€‚ > `model_type` è¡¨ç¤ºæ¨¡å‹çš„åŠŸèƒ½ç±»å‹ï¼Œå¦‚ `classifier`ï¼ˆåˆ†ç±»å™¨ï¼‰å’Œ `yolov2`ï¼ˆç›®æ ‡æ£€æµ‹ï¼‰ï¼Œæ­¤é¡¹ä¸ºå¯é€‰ã€‚ > `input_type` è¡¨ç¤ºæ¨¡å‹çš„è¾“å…¥ç±»å‹ï¼Œå¦‚ `bgr` å’Œ `gray`ï¼ˆç°åº¦å›¾ï¼‰ï¼Œæ­¤é¡¹ä¸ºå¯é€‰ã€‚ > `mean` è¡¨ç¤ºæ¨¡å‹è¾“å…¥çš„å‡å€¼ï¼Œæ­¤é¡¹ä¸ºå¯é€‰ã€‚ > `scale` è¡¨ç¤ºæ¨¡å‹è¾“å…¥çš„ç¼©æ”¾æ¯”ä¾‹ï¼Œæ­¤é¡¹ä¸ºå¯é€‰ã€‚ > `labels` è¡¨ç¤ºæ¨¡å‹æ ‡ç­¾æ–‡ä»¶çš„è·¯å¾„ï¼Œæ­¤é¡¹ä¸ºå¯é€‰ã€‚ ## Maix ```python from maix import camera, display, image, nn, app # detector nn.YOLO11(model \"/root/models/maixhub/my/model.mud\", dual_buff True) # cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) detector nn.YOLOv8(model \"/root/models/maixhub/my/my_model.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) disp.show(img) ```"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-12-04-é¢„æµ‹.html":{"title":"é¢„æµ‹","content":"# é¢„æµ‹ ## åŸºç¡€ä½¿ç”¨ ```python from ultralytics import YOLO yolo YOLO(\"yolov8n.pt\", task \"detect\") result yolo(source \"../ultralytics/ultralytics/assets/bus.jpg\") ``` åœ¨æ–‡ä»¶ultralytics/ultralytics/cfg/default.yamlé‡Œé¢å¯ä»¥æŸ¥çœ‹åˆ°ä½¿ç”¨çš„å‚æ•°, è¾“å…¥å¯ä»¥æ˜¯å›¾ç‰‡, è§†é¢‘, `screen`å±å¹•, `0`æ‘„åƒå¤´ ä½¿ç”¨å‚æ•°`save True`å¯ä»¥æŠŠç»“æœè®°å½•åœ¨`ultralytics/runs/detect/predict/bus.jpg`æ–‡ä»¶é‡Œé¢ conf: å¯ä¿¡åº¦é˜ˆå€¼ iou: äº¤å¹¶æ¯”ï¼ˆIoUï¼‰æ˜¯ç”¨äºéæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰çš„é˜ˆå€¼ã€‚è¾ƒä½çš„å€¼ä¼šé€šè¿‡æ¶ˆé™¤é‡å æ¡†æ¥å‡å°‘æ£€æµ‹æ•°é‡ï¼Œè¿™å¯¹äºå‡å°‘é‡å¤é¡¹å¾ˆæœ‰ç”¨ã€‚ ```python from ultralytics import YOLO import matplotlib.pyplot as plt import cv2 # ç”¨äºBGRè½¬RGBï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰ # 1. åŠ è½½YOLOv8é¢„è®­ç»ƒæ¨¡å‹ yolo YOLO(\"yolov8n.pt\", task \"detect\") # 2. æ¨ç†ï¼ˆé¢„æµ‹ï¼‰å¹¶ä¿å­˜ç»“æœ # save True ä¼šåœ¨é¡¹ç›®æ ¹ç›®å½•ç”Ÿæˆ runs/detect/predict æ–‡ä»¶å¤¹ï¼Œä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡ result yolo(source \"../ultralytics/ultralytics/assets/bus.jpg\", save True) # 3. æå–æ ‡æ³¨åçš„å›¾åƒæ•°ç»„ï¼ˆå…³é”®ï¼šYOLOè¿”å›çš„æ˜¯BGRæ ¼å¼ï¼Œmatplotlibéœ€è¦RGBï¼‰ annotated_img result[0].plot() # è¿”å›BGRæ ¼å¼çš„numpyæ•°ç»„ annotated_img_rgb cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB) # è½¬ä¸ºRGB # 4. ç»˜å›¾å¹¶æ˜¾ç¤ºï¼ˆé€‚é…æ™®é€šPythonè„šæœ¬ï¼‰ plt.figure(figsize (12, 8)) # è®¾ç½®ç”»å¸ƒå¤§å°ï¼ˆå¯é€‰ï¼‰ plt.imshow(annotated_img_rgb) # æ˜¾ç¤ºRGBæ ¼å¼çš„å›¾åƒ plt.axis('off') # å…³é—­åæ ‡è½´ï¼ˆå¯é€‰ï¼Œæ›´ç¾è§‚ï¼‰ plt.show() # æ ¸å¿ƒï¼šè§¦å‘å›¾åƒå¼¹çª—æ˜¾ç¤ºï¼ˆè„šæœ¬ä¸­å¿…é¡»åŠ ï¼‰ ``` é»˜è®¤çš„é€šé“æ˜¯bgr, éœ€è¦è½¬æ¢, è¿”å›çš„resultæ˜¯ä¸€ä¸ªæ•°ç»„çš„å½¢å¼ + plotæ˜¯å¯¹åº”çš„æ ‡æ³¨å¥½çš„å›¾åƒ + boxes: å¯¹åº”çš„è¾¹æ¡†çš„ä¿¡æ¯ ![image 20251213101506195](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213101506195.png) ```python result[0].boxes.xywh.cpu().numpy() # è·å–è¾¹ç•Œæ¡†çš„xywhåæ ‡ï¼ˆnumpyæ•°ç»„æ ¼å¼ï¼‰ ``` ![image 20251213101609131](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213101609131.png)"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-07-AutoDLæœåŠ¡å™¨è®­ç»ƒ.html":{"title":"AutoDLæœåŠ¡å™¨è®­ç»ƒ","content":"# AutoDLæœåŠ¡å™¨è®­ç»ƒ ![image 20251213161127778](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213161127778.png) ä½¿ç”¨åŸºç¡€æ¡†æ¶çš„PyTorch ![image 20251213161345656](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213161345656.png)"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-12-02-åŸºç¡€ä½¿ç”¨.html":{"title":"è®­ç»ƒ","content":"# è®­ç»ƒ ## YoloåŸºç¡€ æœ‰å››ç§æ¨¡å¼ + Train: è®­ç»ƒæ¨¡å¼ + Validation: éªŒè¯æ¨¡å¼ + Predict: é¢„æµ‹æ¨¡å¼ + Export: å¯¼å‡º ä»»åŠ¡ + Detectæ£€æµ‹ ![image 20251212101557400](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512121015641.png) ç‰©ä½“ä½ç½®è¯†åˆ« + Segmentationåˆ†å‰² ![image 20251212101643301](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512121016542.png) è¾¹ç¼˜è¯†åˆ« + Classification åˆ†ç±» + Pose: å§¿æ€æ£€æµ‹ + OBB ![image 20251212101838502](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512121018698.png) ## åŸºç¡€ä½¿ç”¨ ### æ£€æµ‹ [Object Detection Ultralytics YOLO Docs](https://docs.ultralytics.com/tasks/detect/) Yoloæ”¯æŒçš„åŸºç¡€æ¨¡å‹å¦‚ä¸‹ ![image 20251212102449016](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512121024134.png) å¯ä»¥ä½¿ç”¨è¿™é‡Œçš„æ¨¡å‹è¿›è¡ŒåŸºæœ¬çš„é¢„æµ‹ ```python from ultralytics import YOLO # Load a model model YOLO(\"yolo11n.pt\") # load an official model model YOLO(\"path/to/best.pt\") # load a custom model # Predict with the model results model(\"https://ultralytics.com/images/bus.jpg\") # predict on an image # Access the results for result in results: xywh result.boxes.xywh # center x, center y, width, height xywhn result.boxes.xywhn # normalized xyxy result.boxes.xyxy # top left x, top left y, bottom right x, bottom right y xyxyn result.boxes.xyxyn # normalized names [result.names[cls.item()] for cls in result.boxes.cls.int()] # class name of each box confs result.boxes.conf # confidence score of each box ``` ä¹Ÿå¯ä»¥ä½¿ç”¨å‘½ä»¤è¡Œ ```bash yolo detect predict model yolo11n.pt source 'https://ultralytics.com/images/bus.jpg' # predict with official model yolo detect predict model path/to/best.pt source 'https://ultralytics.com/images/bus.jpg' # predict with custom model ``` ### è®­ç»ƒ åœ¨å®é™…è®­ç»ƒçš„æ—¶å€™, éœ€è¦æŒ‡å®šå‡ºæ¥ä¸åŒçš„å±‚çš„å¤§å°ä»¥åŠä½œç”¨, æ‰€ä»¥éœ€è¦ä¸€ä¸ªé…ç½®æ–‡ä»¶, ç”±äºæ¨¡å—å°è£…çš„æ¯”è¾ƒå¥½, æ·»åŠ æ¨¡å—ä¸éœ€è¦ç†è§£å…¶ä»–éƒ¨åˆ†çš„ä»£ç , è¯»å–é…ç½®æ–‡ä»¶å³å¯çŸ¥é“æ€ä¹ˆè¿è¡Œ"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-4-01-yoloå®‰è£….html":{"title":"åŸºç¡€æ¦‚å¿µ","content":"# åŸºç¡€æ¦‚å¿µ [ä¸»é¡µ Ultralytics YOLO æ–‡æ¡£](https://docs.ultralytics.com/zh/) + V1: åœ¨è¯†åˆ«ä¸€ä¸ªç‰©ä½“çš„æ—¶å€™, é¦–å…ˆæå–ç‰©ä½“çš„ç‰¹å¾å€¼, å°†è¾“å…¥å›¾ç‰‡ï¼ˆä¾‹å¦‚448x448åƒç´ ï¼‰å‡åŒ€åˆ’åˆ†ä¸º **S x S** ä¸ªç½‘æ ¼, ä¾æ¬¡éå†ä¸€ä¸‹è¿™ä¸ªå›¾åƒ, åœ¨å›¾ç‰‡é‡Œé¢è®¡ç®—ç‰©ä½“çš„è¯†åˆ«æ¦‚ç‡ > æ¯ä¸ªè¾¹ç•Œæ¡†éœ€è¦é¢„æµ‹5ä¸ªå€¼ï¼š > > 1. `(x, y)`ï¼š**æ¡†çš„ä¸­å¿ƒç‚¹**ç›¸å¯¹äº**å½“å‰æ ¼å­**çš„åæ ‡ã€‚ > 2. `(w, h)`ï¼š**æ¡†çš„å®½åº¦å’Œé«˜åº¦**ç›¸å¯¹äº**æ•´å¼ å›¾ç‰‡**çš„æ¯”ä¾‹ã€‚ > 3. `confidence`ï¼ˆç½®ä¿¡åº¦ï¼‰ï¼šè¿™ä¸ªæ¡†åŒ…å«ä¸€ä¸ªç‰©ä½“çš„æŠŠæ¡æœ‰å¤šå¤§ï¼Ÿä»¥åŠæ¡†å¾—å‡†ä¸å‡†ï¼Ÿå…¬å¼æ˜¯ï¼š`Pr(Object) * IOU`ã€‚å¦‚æœæ ¼å­ä¸­æ²¡æœ‰ç‰©ä½“ä¸­å¿ƒï¼Œç½®ä¿¡åº¦åº”ä¸º0 + V2: åŒä¸€ä¸ªç‰¹å¾å€¼å¯¹åº”å¤šä¸ªçª—å£, ä»¥å‰æ¯ä¸ªæ ¼å­é¢„æµ‹çš„æ¡†å½¢çŠ¶æ˜¯éšä¾¿å­¦çš„ã€‚ç°åœ¨ï¼Œå®ƒå…ˆçœ‹çœ‹è®­ç»ƒæ•°æ®é‡Œæœ€å¸¸è§çš„ç‰©ä½“å½¢çŠ¶ï¼ˆæ¯”å¦‚äººç˜¦é«˜ã€æ±½è½¦æ‰é•¿ï¼‰ï¼Œè®°ä½5ç§å¸¸è§çš„â€œæ¡†æ¨¡æ¿â€ã€‚é¢„æµ‹æ—¶ï¼Œå®ƒå°±åœ¨è¿™äº›æ¨¡æ¿åŸºç¡€ä¸Šå¾®è°ƒ, ç”¨k meansèšç±»ç®—æ³•å¯¹æ•°æ®é›†ä¸­æ‰€æœ‰çœŸå®æ¡†çš„å®½é«˜è¿›è¡Œèšç±» + V3: ä½¿ç”¨ä¸åŒçš„ç½‘ç»œå»è¯†åˆ«å¤§å°ä¸åŒçš„ç‰©ä½“, ç½‘ç»œåœ¨**ä¸‰ä¸ªä¸åŒå°ºåº¦**ä¸Šè¿›è¡Œæ£€æµ‹, æœ€åä¼šå¾—åˆ°ä¸‰ç§ä¸åŒå°ºå¯¸çš„ç‰¹å¾å›¾ï¼š**å¤§çš„ï¼ˆå¦‚52x52ï¼‰ã€ä¸­çš„ï¼ˆ26x26ï¼‰ã€å°çš„ï¼ˆ13x13ï¼‰** + V4: ç»†èŠ‚å¤„ç†, åœ¨ä¹‹å‰çš„å¤„ç†çš„æ—¶å€™, ä¾æ¬¡å¤„ç†ä¸€å¼ å›¾ç‰‡, ç°åœ¨å¤„ç†å¤šå¼ å›¾ç‰‡æ‹¼åœ¨ä¸€èµ·, åŒæ—¶ä½¿ç”¨DropBlockéšæœºå»é™¤ä¸€äº›ç‚¹ä¹‹åè®­ç»ƒ, ç°åœ¨ç›´æ¥å»é™¤ä¸€ä¸ªåŒºåŸŸ, åŒæ—¶åœ¨ä¹‹å‰å®šä¹‰æ ‡ç­¾çš„æ—¶å€™ä½¿ç”¨çš„æ˜¯0å’Œ1, ç°åœ¨æŠŠæ ‡ç­¾æ”¹ä¸ºä¸€ä¸ªèŒƒå›´å€¼, é¿å…è¿‡æ‹Ÿåˆ è¿˜æœ‰åŠ å…¥æ³¨æ„åŠ›æœºåˆ¶, ç”¨äºå¤„ç†ä¸åŒçš„çª—å£ä¹‹é—´çš„å…³ç³», å®é™…ä½¿ç”¨çš„æ—¶å€™ä¸åªæ˜¯ä½¿ç”¨è‡ªå·±çš„ç‰¹å¾, åŒæ—¶ä¸€ä¸ªç‰©ä½“ä¸åŒçš„ä½ç½®çš„æƒé‡åº”è¯¥æ˜¯ä¸åŒçš„, ä¸€èˆ¬æ¥è¯´æ›´åŠ æ³¨é‡ç‰©ä½“çš„è¾¹ç•Œ + V5: V4çš„å·¥ç¨‹ç‰ˆé¡¹ç›® + V6: åŸºæœ¬å’ŒV5ä¸€æ · + V7: æ¨ç†æé€Ÿ, ç»Ÿä¸€å·ç§¯æ ¸çš„å¤§å°, 1x1çš„å·ç§¯å¯ä»¥åœ¨å¤–é¢è¡¥0, ç»Ÿä¸€ä¸º3x3çš„ + V8: ä¸€ä¸ªä¼˜åŒ–æ¯”è¾ƒå¥½çš„åŸºç¡€æ¨¡å‹, Yoloæ˜¯ä¸€ä¸ªç‰¹å¾æå–çš„æ¡†æ¶, å®é™…æå–å‡ºæ¥çš„ä¿¡æ¯å¯ä»¥åšä¸åŒçš„å¤„ç†è¾¾åˆ°ä¸åŒçš„æ•ˆæœ(æ£€æµ‹, åˆ†å‰², å§¿æ€...) + V9: åœ¨è®­ç»ƒçš„æ—¶å€™, ç”±äºæ¢¯åº¦ä¼ é€’æ˜¯åå‘çš„, æ‰€ä»¥åé¢çš„å±‚å­¦ä¹ çš„æ¯”è¾ƒå¥½ ,æ‰€ä»¥åœ¨æ¯”è¾ƒæµ…çš„å±‚è¿æ¥åˆ°è¾“å‡º + V10: æå‡é€Ÿåº¦ ## v8åŠä»¥å åŸºç¡€ç¯å¢ƒé‡Œé¢éœ€è¦ä½¿ç”¨torch ```bash pip install torch torchvision torchaudio jupyterlab ``` yoloçš„pythonåŒ…åœ¨æ–°ç‰ˆæœ¬æ”¹ä¸ºä½¿ç”¨ultralytics ```bash # Clone the ultralytics repository git clone https://github.com/ultralytics/ultralytics # Navigate to the cloned directory cd ultralytics # Install the package in editable mode for development pip install e . ``` ![image 20251212100850620](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512121008947.png) ## V5 ä½¿ç”¨python 3.9 ```python pip install torch 1.11.0 torchvision 0.12.0 torchaudio 0.11.0 # Clone the YOLOv5 repository git clone https://github.com/ultralytics/yolov5 # Navigate to the cloned directory cd yolov5 # Install required packages pip install r requirements.txt pip uninstall numpy y pip install numpy 1.26.4 ``` å¯ä»¥ä½¿ç”¨`python detect.py`æµ‹è¯•, ç»“æœè®°å½•åœ¨yolov5/runs/detect/exp3æ–‡ä»¶é‡Œé¢"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-08-yolov5æ¡†æ¶.html":{"title":"YolV5æ¡†æ¶","content":"# YolV5æ¡†æ¶ ## æ¨¡å‹ç»“æ„æ„å»ºåŸç† åœ¨`yolov5/models/yolov5*.yaml`æ–‡ä»¶é‡Œé¢æ˜¯å¯¹åº”çš„æ¨¡å‹çš„ç»“æ„ Backbone æå–å¤šå°ºåº¦ç‰¹å¾ â†’ Head èåˆç‰¹å¾ â†’ Detect è¾“å‡ºæ£€æµ‹ç»“æœ ![image 20251213181802181](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213181802181.png) ```yaml # Ultralytics ğŸš€ AGPL 3.0 License https://ultralytics.com/license # Parameters nc: 80 # number of classes é»˜è®¤çš„åˆ†ç±»æ•° # å®é™…çš„å±‚çš„é‡å¤æ•°é‡ä¼šä¹˜è¿™ä¸ªæ•°å­— depth_multiple: 0.33 # model depth multiple æ·±åº¦ä¹˜æ•°ï¼Œæ§åˆ¶ç½‘ç»œçš„æ·±åº¦ï¼ˆC3 æ¨¡å—çš„é‡å¤æ¬¡æ•°ï¼‰ã€‚å€¼è¶Šå°ï¼ŒC3 é‡å¤æ¬¡æ•°è¶Šå°‘ # å®é™…çš„è¾“å‡ºé€šé“æ•°ä¼šä¹˜ä»¥è¿™ä¸ª width_multiple: 0.50 # layer channel multiple å®½åº¦ä¹˜æ•°ï¼Œæ§åˆ¶ç½‘ç»œçš„é€šé“æ•°ï¼ˆæ¯å±‚å·ç§¯çš„è¾“å‡ºé€šé“æ•°ï¼‰ã€‚å€¼è¶Šå°ï¼Œé€šé“æ•°è¶Šå°‘ï¼Œæ¨¡å‹è¶Šçª„ anchors: # é”šæ¡† é¢„å®šä¹‰çš„è¾¹ç•Œæ¡†å°ºå¯¸ï¼Œç”¨äºåŒ¹é…ä¸åŒå¤§å°çš„ç›®æ ‡ [10, 13, 16, 30, 33, 23] # P3/8 [30, 61, 62, 45, 59, 119] # P4/16 [116, 90, 156, 198, 373, 326] # P5/32 # YOLOv5 v6.0 backbone # è´Ÿè´£ç‰¹å¾æå–ï¼ŒåŸºäº CSPNet ç»“æ„ï¼Œé€šè¿‡å·ç§¯ + æ®‹å·®æ¨¡å—æå–å¤šå°ºåº¦è¯­ä¹‰ç‰¹å¾ # fromï¼šè¾“å…¥æ¥æºï¼Œ 1 è¡¨ç¤ºä¸Šä¸€å±‚ï¼Œæ•°å­—è¡¨ç¤ºå¯¹åº”å±‚çš„ç´¢å¼•ï¼ˆå¦‚ 6 è¡¨ç¤ºç¬¬ 6 å±‚ï¼‰ï¼› # numberï¼šè¯¥æ¨¡å—çš„é‡å¤æ¬¡æ•°ï¼› # moduleï¼šæ¨¡å—åç§°ï¼ˆConv/C3/SPPF ç­‰ï¼‰ï¼› # argsï¼šæ¨¡å—çš„å‚æ•°ï¼ˆå¦‚å·ç§¯é€šé“æ•°ã€æ ¸å¤§å°ç­‰ï¼‰ # è¾“å‡º P3/P4/P5 ä¸‰ä¸ªå°ºåº¦çš„ç‰¹å¾å›¾ï¼ˆä¸‹é‡‡æ · 8/16/32 å€ï¼‰ backbone: # [from, number, module, args] [ # 0 P1/2 Conv æ¨¡å—ï¼ˆå·ç§¯ + BN+SiLU æ¿€æ´»ï¼‰ï¼š # è¾“å‡º 64 é€šé“ï¼Œå·ç§¯æ ¸ 6Ã—6ï¼Œæ­¥é•¿ 2ï¼Œå¡«å…… 2 â†’ ä¸‹é‡‡æ · 2 å€ï¼ˆP1/2ï¼‰ã€‚ [ 1, 1, Conv, [64, 6, 2, 2]], [ 1, 1, Conv, [128, 3, 2]], # 1 P2/4 # C3 æ¨¡å—ï¼ˆCSPNet æ ¸å¿ƒï¼Œ3 ä¸ªå·ç§¯ + æ®‹å·®å—ï¼‰ï¼šé‡å¤ 3 æ¬¡ï¼Œé€šé“ 128 â†’ å¢å¼ºç‰¹å¾è¡¨è¾¾ï¼Œæ— ä¸‹é‡‡æ · [ 1, 3, C3, [128]], [ 1, 1, Conv, [256, 3, 2]], # 3 P3/8 [ 1, 6, C3, [256]], [ 1, 1, Conv, [512, 3, 2]], # 5 P4/16 [ 1, 9, C3, [512]], [ 1, 1, Conv, [1024, 3, 2]], # 7 P5/32 [ 1, 3, C3, [1024]], [ 1, 1, SPPF, [1024, 5]], # 9 ] # YOLOv5 v6.0 head # å®ç°å¤šå°ºåº¦ç‰¹å¾èåˆï¼Œå¹¶é€šè¿‡ Detect æ¨¡å—è¾“å‡ºæ£€æµ‹ç»“æœï¼ˆè¾¹ç•Œæ¡†ã€ç½®ä¿¡åº¦ã€ç±»åˆ«ï¼‰ # å…ˆä¸Šé‡‡æ ·èåˆæµ…å±‚ç‰¹å¾ï¼ˆç»†èŠ‚ï¼‰ï¼Œå†ä¸‹é‡‡æ ·èåˆæ·±å±‚ç‰¹å¾ï¼ˆè¯­ä¹‰ï¼‰ï¼Œæœ€ç»ˆè¾“å‡º 3 ä¸ªå°ºåº¦çš„æ£€æµ‹åˆ†æ”¯ head: [ # 1Ã—1 å·ç§¯é™ç»´ï¼šå°† P5 ç‰¹å¾ä» 1024 é€šé“å‹ç¼©åˆ° 512 â†’ å‡å°‘è®¡ç®—é‡ï¼Œä¸ºä¸Šé‡‡æ ·åšå‡†å¤‡ [ 1, 1, Conv, [512, 1, 1]], # ä¸Šé‡‡æ ·ï¼šæœ€è¿‘é‚»æ’å€¼ï¼Œå°†ç‰¹å¾å›¾æ”¾å¤§ 2 å€ â†’ åŒ¹é… P4 å°ºåº¦ï¼ˆ16 å€ä¸‹é‡‡æ ·ï¼‰ [ 1, 1, nn.Upsample, [None, 2, \"nearest\"]], # ç‰¹å¾æ‹¼æ¥ï¼šå°†ä¸Šé‡‡æ ·åçš„ P5 ç‰¹å¾ï¼ˆ11 å±‚ï¼‰ä¸ Backbone çš„ P4 ç‰¹å¾ï¼ˆ6 å±‚ï¼‰æŒ‰é€šé“ç»´åº¦æ‹¼æ¥ # â†’ èåˆæ·±å±‚è¯­ä¹‰ + ä¸­å±‚ç»†èŠ‚ [[ 1, 6], 1, Concat, [1]], # cat backbone P4 # C3 æ¨¡å—ï¼šé‡å¤ 3 æ¬¡ï¼Œé€šé“ 512ï¼Œ # False è¡¨ç¤ºæ— æ®‹å·® â†’ èåˆåç‰¹å¾æçº¯ï¼ˆHead éƒ¨åˆ†çš„ C3 æ— æ®‹å·®ï¼Œé™ä½è®¡ç®—é‡ï¼‰ [ 1, 3, C3, [512, False]], # 13 [ 1, 1, Conv, [256, 1, 1]], [ 1, 1, nn.Upsample, [None, 2, \"nearest\"]], [[ 1, 4], 1, Concat, [1]], # cat backbone P3 [ 1, 3, C3, [256, False]], # 17 (P3/8 small) [ 1, 1, Conv, [256, 3, 2]], [[ 1, 14], 1, Concat, [1]], # cat head P4 [ 1, 3, C3, [512, False]], # 20 (P4/16 medium) [ 1, 1, Conv, [512, 3, 2]], [[ 1, 10], 1, Concat, [1]], # cat head P5 # C3 æ¨¡å—ï¼šP5/32 å°ºåº¦æ£€æµ‹åˆ†æ”¯ï¼ˆå¤§ç›®æ ‡ï¼‰ï¼Œè¾“å‡º 1024 é€šé“ç‰¹å¾ã€‚ [ 1, 3, C3, [1024, False]], # 23 (P5/32 large) # Detect æ¨¡å—ï¼šè¾“å…¥ 17/20/23 å±‚çš„ 3 ä¸ªå°ºåº¦ç‰¹å¾ # ç»“åˆç±»åˆ«æ•° nc å’Œé”šæ¡† anchorsï¼Œè¾“å‡ºæœ€ç»ˆæ£€æµ‹ç»“æœ [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5) ] ``` å¯ä»¥ä½¿ç”¨tensorboardè¿›è¡Œå¯è§†åŒ–`tensorboard logdir runs`, è¿™é‡Œçš„runsæ˜¯yolov5çš„é»˜è®¤è¾“å‡ºæ–‡ä»¶ä»¶ ![image 20251213204220227](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213204220227.png) ## ä»£ç  ```python # Model check_suffix(weights, \".pt\") # check weights pretrained weights.endswith(\".pt\") if pretrained: with torch_distributed_zero_first(LOCAL_RANK): weights attempt_download(weights) # download if not found locally ckpt torch_load(weights, map_location \"cpu\") # load checkpoint to CPU to avoid CUDA memory leak # åˆ›å»ºæ¨¡å‹çš„ä½ç½® # å‚æ•°æ˜¯ä¹‹å‰çš„é…ç½®æ–‡ä»¶, è¾“å…¥é€šé“æ•°, æ£€æµ‹çš„ç±»åˆ«, é”šæ¡† model Model(cfg or ckpt[\"model\"].yaml, ch 3, nc nc, anchors hyp.get(\"anchors\")).to(device) # create exclude [\"anchor\"] if (cfg or hyp.get(\"anchors\")) and not resume else [] # exclude keys csd ckpt[\"model\"].float().state_dict() # checkpoint state_dict as FP32 csd intersect_dicts(csd, model.state_dict(), exclude exclude) # intersect model.load_state_dict(csd, strict False) # load LOGGER.info(f\"Transferred {len(csd)}/{len(model.state_dict())} items from {weights}\") # report else: model Model(cfg, ch 3, nc nc, anchors hyp.get(\"anchors\")).to(device) # create amp check_amp(model) # check AMP ``` + å®é™…ä½¿ç”¨çš„æ¨¡å‹å¦‚ä¸‹ ```python Model DetectionModel # retain YOLOv5 'Model' class for backwards compatibility ``` + æ¨¡å‹çš„åˆå§‹åŒ– ```python class DetectionModel(BaseModel): \"\"\"YOLOv5 detection model class for object detection tasks, supporting custom configurations and anchors.\"\"\" def __init__(self, cfg \"yolov5s.yaml\", ch 3, nc None, anchors None): \"\"\"Initializes YOLOv5 model with configuration file, input channels, number of classes, and custom anchors.\"\"\" super().__init__() # åŠ è½½é…ç½®æ–‡ä»¶ if isinstance(cfg, dict): self.yaml cfg # model dict else: # is *.yaml import yaml # for torch hub self.yaml_file Path(cfg).name with open(cfg, encoding \"ascii\", errors \"ignore\") as f: self.yaml yaml.safe_load(f) # model dict \t\t\t # Define model, é‡æ–°å®šä¹‰ä¸€ä¸‹é€šé“æ•° ch self.yaml[\"ch\"] self.yaml.get(\"ch\", ch) # input channels # é…ç½®ç›®æ ‡ç±»åˆ« if nc and nc ! self.yaml[\"nc\"]: LOGGER.info(f\"Overriding model.yaml nc {self.yaml['nc']} with nc {nc}\") self.yaml[\"nc\"] nc # override yaml value if anchors: LOGGER.info(f\"Overriding model.yaml anchors with anchors {anchors}\") self.yaml[\"anchors\"] round(anchors) # override yaml value # è·å–å®é™…çš„æ¨¡å‹ self.model, self.save parse_model(deepcopy(self.yaml), ch [ch]) # model, savelist self.names [str(i) for i in range(self.yaml[\"nc\"])] # default names self.inplace self.yaml.get(\"inplace\", True) # Build strides, anchors m self.model[ 1] # Detect() if isinstance(m, (Detect, Segment)): def _forward(x): \"\"\"Passes the input 'x' through the model and returns the processed output.\"\"\" return self.forward(x)[0] if isinstance(m, Segment) else self.forward(x) s 256 # 2x min stride m.inplace self.inplace m.stride torch.tensor([s / x.shape[ 2] for x in _forward(torch.zeros(1, ch, s, s))]) # forward check_anchor_order(m) m.anchors / m.stride.view( 1, 1, 1) self.stride m.stride self._initialize_biases() # only run once # Init weights, biases initialize_weights(self) self.info() LOGGER.info(\"\") ``` + å¤„ç†é…ç½®æ–‡ä»¶ç”Ÿæˆæ¨¡å‹ ```python def parse_model(d, ch): \"\"\"Parses a YOLOv5 model from a dict `d`, configuring layers based on input channels `ch` and model architecture.\"\"\" LOGGER.info(f\"\\n{'':>3}{'from':>18}{'n':>3}{'params':>10} {'module':<40}{'arguments':<30}\") # è·å–æ¨¡å‹çš„ä¿¡æ¯ anchors, nc, gd, gw, act, ch_mul ( d[\"anchors\"], d[\"nc\"], d[\"depth_multiple\"], d[\"width_multiple\"], d.get(\"activation\"), d.get(\"channel_multiple\"), ) # æ¿€æ´»å‡½æ•° if act: Conv.default_act eval(act) # redefine default activation, i.e. Conv.default_act nn.SiLU() LOGGER.info(f\"{colorstr('activation:')} {act}\") # print # ç¡®ä¿å·ç§¯å±‚çš„è¾“å‡ºé€šé“æ•°æ˜¯ ch_mul çš„æ•´æ•°å€ï¼Œæ ¸å¿ƒç›®çš„æ˜¯é€‚é…ç¡¬ä»¶è®¡ç®—æ•ˆç‡ if not ch_mul: ch_mul 8 # è®¡ç®—é”šæ¡†çš„æ•°é‡ na (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors # number of anchors # è®¡ç®—è¾“å‡ºçš„æ ‘ç«‹æ•°é‡, +5æŒ‡çš„æ˜¯åæ ‡ä»¥åŠç½®ä¿¡åº¦ no na * (nc + 5) # number of outputs anchors * (classes + 5) \t\t # å±‚ # è®°å½•æ‰€æœ‰éœ€è¦è¢«åç»­å±‚å¤ç”¨çš„å±‚ç´¢å¼•, è¿™äº›å±‚çš„ç‰¹å¾ä¼šè¢«åç»­Concat/Detectå±‚å¤ç”¨ # è¾“å‡ºé€šé“æ•° layers, save, c2 [], [], ch[ 1] # layers, savelist, ch out for i, (f, n, m, args) in enumerate(d[\"backbone\"] + d[\"head\"]): # from, number, module, args # moduleè¿›è¡Œå®ä¾‹åŒ–, å­—ç¬¦ä¸² >å®é™…çš„å¯¹è±¡ m eval(m) if isinstance(m, str) else m # eval strings # å¤„ç†å‚æ•° for j, a in enumerate(args): with contextlib.suppress(NameError): args[j] eval(a) if isinstance(a, str) else a # eval strings \t\t\t\t# å®é™…çš„å¾ªç¯æ¬¡æ•°ä¹˜depth_multiple, å’Œ1æ¯”è¾ƒ n n_ max(round(n * gd), 1) if n > 1 else n # depth gain # ä¾æ®ä¸åŒçš„æ¨¡å‹æ„é€ å‚æ•° if m in { Conv, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF, DWConv, MixConv2d, Focus, CrossConv, BottleneckCSP, C3, C3TR, C3SPP, C3Ghost, nn.ConvTranspose2d, DWConvTranspose2d, C3x, }: \t# fæ˜¯ 1, å®é™…æ˜¯ä¸Šä¸€å±‚çš„è¾“å‡º, ç¬¬äºŒä¸ªè®°å½•é…ç½®æ–‡ä»¶çš„è¾“å‡ºé€šé“ c1, c2 ch[f], args[0] # ä¹˜ä¸Šwidth_multipleåŒæ—¶ä¿è¯å¯ä»¥æ•´é™¤ if c2 ! no: # if not output c2 make_divisible(c2 * gw, ch_mul) \t\t\t\t\t\t args [c1, c2, *args[1:]] # ä»¥ä¸‹å‡ ç§çš„è¯éœ€è¦æ’å…¥å‚æ•°nè¡¨ç¤ºå¾ªç¯çš„æ¬¡æ•° if m in {BottleneckCSP, C3, C3TR, C3Ghost, C3x}: args.insert(2, n) # number of repeats n 1 elif m is nn.BatchNorm2d: args [ch[f]] elif m is Concat: c2 sum(ch[x] for x in f) # TODO: channel, gw, gd elif m in {Detect, Segment}: args.append([ch[x] for x in f]) if isinstance(args[1], int): # number of anchors args[1] [list(range(args[1] * 2))] * len(f) if m is Segment: args[3] make_divisible(args[3] * gw, ch_mul) elif m is Contract: c2 ch[f] * args[0] ** 2 elif m is Expand: c2 ch[f] // args[0] ** 2 else: c2 ch[f] \t\t\t\t# åˆ›å»ºåºåˆ— m_ nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args) # module t str(m)[8: 2].replace(\"__main__.\", \"\") # module type np sum(x.numel() for x in m_.parameters()) # number params m_.i, m_.f, m_.type, m_.np i, f, t, np # attach index, 'from' index, type, number params LOGGER.info(f\"{i:>3}{f!s:>18}{n_:>3}{np:10.0f} {t:<40}{args!s:<30}\") # print save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x ! 1) # append to savelist # è®°å½•å‡ºæ¥ layers.append(m_) if i 0: ch [] ch.append(c2) return nn.Sequential(*layers), sorted(save) ``` + ä¸€ä¸ªå®é™…çš„å±‚çš„ç¤ºä¾‹ ```python class Conv(nn.Module): \"\"\"Applies a convolution, batch normalization, and activation function to an input tensor in a neural network.\"\"\" default_act nn.SiLU() # default activation \t\t# è¾“å…¥è¾“å‡ºé€šé“æ•°, å·ç§¯æ ¸, æ­¥å¹…, æ˜¯ä¸æ˜¯paddings, groups, æ˜¯ä¸æ˜¯è†¨èƒ€, æ¿€æ´»å‡½æ•° def __init__(self, c1, c2, k 1, s 1, p None, g 1, d 1, act True): \"\"\"Initializes a standard convolution layer with optional batch normalization and activation.\"\"\" super().__init__() self.conv nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups g, dilation d, bias False) self.bn nn.BatchNorm2d(c2) self.act self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity() def forward(self, x): \"\"\"Applies a convolution followed by batch normalization and an activation function to the input tensor `x`.\"\"\" return self.act(self.bn(self.conv(x))) def forward_fuse(self, x): \"\"\"Applies a fused convolution and activation function to the input tensor `x`.\"\"\" return self.act(self.conv(x)) ```"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-10-æ¨¡å‹éƒ¨ç½².html":{"title":"æ¨¡å‹éƒ¨ç½²","content":"# æ¨¡å‹éƒ¨ç½² ## TensorRT TensorRTæ˜¯å¯ä»¥åœ¨NVIDIAå„ç§GPUç¡¬ä»¶å¹³å°ä¸‹è¿è¡Œçš„ä¸€ä¸ªC++æ¨ç†æ¡†æ¶ã€‚æˆ‘ä»¬åˆ©ç”¨Pytorchã€TFæˆ–è€…å…¶ä»–æ¡†æ¶è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¯ä»¥è½¬åŒ–ä¸ºTensorRTçš„æ ¼å¼ï¼Œç„¶ååˆ©ç”¨TensorRTæ¨ç†å¼•æ“å»è¿è¡Œæˆ‘ä»¬è¿™ä¸ªæ¨¡å‹ï¼Œä»è€Œæå‡è¿™ä¸ªæ¨¡å‹åœ¨è‹±ä¼Ÿè¾¾GPUä¸Šè¿è¡Œçš„é€Ÿåº¦ã€‚é€Ÿåº¦æå‡çš„æ¯”ä¾‹æ˜¯æ¯”è¾ƒå¯è§‚çš„ã€‚ éœ€è¦å®‰è£…CUDAä»¥åŠCUDNN TensorRTå®˜æ–¹æ”¯æŒCaffeã€Tensorflowã€Pytorchã€ONNXç­‰æ¨¡å‹çš„è½¬æ¢, å¯¹ONNXçš„æ”¯æŒæœ€å¥½ï¼ŒTensorRT 8æœ€æ–°ç‰ˆONNXè½¬æ¢å™¨åˆæ”¯æŒäº†æ›´å¤šçš„opæ“ä½œã€‚è€Œæ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­ï¼ŒTensorRTå¯¹Pytorchçš„æ”¯æŒæ›´ä¸ºå‹å¥½ > MaixCAMä½¿ç”¨çš„ä¹Ÿæ˜¯è¿™ä¸ªæ ¼å¼çš„æ¨¡å‹ ## æ¨¡å‹è®­ç»ƒ ```python import warnings warnings.filterwarnings('ignore') from ultralytics import YOLO if __name__ '__main__': model YOLO('yolov8n.pt') # load a pretrained model (recommended for training) model.train(data 'my_dataset.yaml', cache False, imgsz 416, epochs 100, single_cls False, # æ˜¯å¦æ˜¯å•ç±»åˆ«æ£€æµ‹ batch 8, close_mosaic 10, # Mosaic æ˜¯ YOLO ä¸“å±å¢å¼ºï¼ˆæ‹¼æ¥ 4 å¼ å›¾ï¼‰ï¼Œæå‡å°ç›®æ ‡æ£€æµ‹æ•ˆæœ, è®­ç»ƒ10ä»¥åå…³é—­ Mosaic æ•ˆæœæ›´ä½³ workers 0, device 'mps', optimizer 'SGD', # ä¼˜åŒ–å™¨ç±»å‹ï¼ˆæ›´æ–°æ¨¡å‹å‚æ•°çš„ç®—æ³•ï¼‰ï¼š amp True, # Trueï¼šç”¨ FP16ï¼ˆåŠç²¾åº¦ï¼‰+FP32ï¼ˆå•ç²¾åº¦ï¼‰æ··åˆè®¡ç®—ï¼ŒåŠ é€Ÿè®­ç»ƒ ) ``` æµ‹è¯•`yolo detect predict model ../ultralytics/runs/detect/train4/weights/best.pt source ./calling20221009.mp4 show True` ## æ¨¡å‹å¯¼å‡º å¯ä»¥ä½¿ç”¨yoloæä¾›çš„export.pyæ–‡ä»¶è¿›è¡Œå¯¼å‡º `pip install onnx` ```python python export.py weights yolov5s.pt include onnx opset 13 ``` æŒ‡å®š**è¾ƒä½çš„ opset ç‰ˆæœ¬**ï¼ˆå¦‚ 16/13/12ï¼Œè¿™äº›ç‰ˆæœ¬å…¼å®¹æ€§æ›´å¥½ï¼‰"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-06-yolov5åŸºç¡€ä½¿ç”¨.html":{"title":"V5åŸºæœ¬ä½¿ç”¨","content":"# V5åŸºæœ¬ä½¿ç”¨ https://docs.ultralytics.com/yolov5/ ## æ£€æµ‹ ### é»˜è®¤dectect ä½¿ç”¨`python dectect.py`æ–‡ä»¶å³å¯ä½¿ç”¨ç¤ºä¾‹, å¯ä»¥æ·»åŠ ä¸€äº›è‡ªå®šä¹‰çš„å‚æ•° #### å…³é”®å‚æ•° ```python weights (str list[str], optional): Model path or Triton URL. Defaults to ROOT / 'yolov5s.pt'. source (str, optional): File/dir/URL/glob/screen/0(webcam). Defaults to ROOT / 'data/images'. data (str, optional): Dataset YAML path. Provides dataset configuration information. imgsz (list[int], optional): Inference size (height, width). Defaults to [640]. conf thres (float, optional): Confidence threshold. Defaults to 0.25. iou thres (float, optional): NMS IoU threshold. Defaults to 0.45. max det (int, optional): Maximum number of detections per image. Defaults to 1000. device (str, optional): CUDA device, i.e., '0' or '0,1,2,3' or 'cpu'. Defaults to \"\". view img (bool, optional): Flag to display results. Defaults to False. save txt (bool, optional): Flag to save results to *.txt files. Defaults to False. save csv (bool, optional): Flag to save results in CSV format. Defaults to False. save conf (bool, optional): Flag to save confidences in labels saved via save txt. Defaults to False. save crop (bool, optional): Flag to save cropped prediction boxes. Defaults to False. nosave (bool, optional): Flag to prevent saving images/videos. Defaults to False. classes (list[int], optional): List of classes to filter results by, e.g., ' classes 0 2 3'. Defaults to None. agnostic nms (bool, optional): Flag for class agnostic NMS. Defaults to False. augment (bool, optional): Flag for augmented inference. Defaults to False. visualize (bool, optional): Flag for visualizing features. Defaults to False. update (bool, optional): Flag to update all models in the model directory. Defaults to False. project (str, optional): Directory to save results. Defaults to ROOT / 'runs/detect'. name (str, optional): Sub directory name for saving results within project. Defaults to 'exp'. exist ok (bool, optional): Flag to allow overwriting if the project/name already exists. Defaults to False. line thickness (int, optional): Thickness (in pixels) of bounding boxes. Defaults to 3. hide labels (bool, optional): Flag to hide labels in the output. Defaults to False. hide conf (bool, optional): Flag to hide confidences in the output. Defaults to False. half (bool, optional): Flag to use FP16 half precision inference. Defaults to False. dnn (bool, optional): Flag to use OpenCV DNN for ONNX inference. Defaults to False. vid stride (int, optional): Video frame rate stride, determining the number of frames to skip in between consecutive frames. Defaults to 1. ``` ##### Weightsè®­ç»ƒå¥½çš„æ¨¡å‹ Model Size (pixels) mAPval 50 95 mAPval 50 Speed CPU b1 (ms) Speed V100 b1 (ms) Speed V100 b32 (ms) Params (M) FLOPs @640 (B) [YOLOv5n](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt) 640 28.0 45.7 **45** **6.3** **0.6** **1.9** **4.5** [YOLOv5s](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt) 640 37.4 56.8 98 6.4 0.9 7.2 16.5 [YOLOv5m](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt) 640 45.4 64.1 224 8.2 1.7 21.2 49.0 [YOLOv5l](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt) 640 49.0 67.3 430 10.1 2.7 46.5 109.1 [YOLOv5x](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt) 640 50.7 68.9 766 12.1 4.8 86.7 205.7 [YOLOv5n6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n6.pt) 1280 36.0 54.4 153 8.1 2.1 3.2 4.6 [YOLOv5s6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s6.pt) 1280 44.8 63.7 385 8.2 3.6 12.6 16.8 [YOLOv5m6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m6.pt) 1280 51.3 69.3 887 11.1 6.8 35.7 50.0 [YOLOv5l6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l6.pt) 1280 53.7 71.3 1784 15.8 10.5 76.8 111.4 [YOLOv5x6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x6.pt) + [[TTA\\]](https://docs.ultralytics.com/yolov5/tutorials/test_time_augmentation/) 1280 1536 55.0 **55.8** 72.7 **72.7** 3136 26.2 19.4 140.7 209.8 ##### source å¯ä»¥æŒ‡å®šå®é™…ä½¿ç”¨çš„è¾“å…¥æ–‡ä»¶, å¯ä»¥æ˜¯å›¾ç‰‡, è§†é¢‘, æ‘„åƒå¤´(`0`), å±å¹•(`screen`), å¯ä»¥ä½¿ç”¨list.txtæŒ‡å®šä¸€ç³»åˆ—å›¾ç‰‡ ##### conf thresç½®ä¿¡åº¦ é€‰æ¡†çš„ç½®ä¿¡åº¦çš„é˜ˆå€¼, å°äºè¿™ä¸ªçš„ä¸æ˜¾ç¤º ##### iou thres IoUé˜ˆå€¼ ### ä»£ç  ```python import torch # Load a YOLOv5 model (options: yolov5n, yolov5s, yolov5m, yolov5l, yolov5x) # è·¯å¾„ä»¥åŠä½¿ç”¨çš„æ¨¡å‹, ç¬¬ä¸‰ä¸ªå¯ä»¥ä½¿ç”¨githubä»¥åŠlocal # è¿™é‡ŒåŠ è½½çš„æ¨¡å‹æ–‡ä»¶å¤¹ä¸‹é¢éœ€è¦æœ‰ä¸€ä¸ªhubconf.pyæ–‡ä»¶ module torch.hub.load(\"../yolov5\", \"yolov5s.py\", source \"local\") # local repo # Default: yolov5s # å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„æ–¹æ³•è‡ªå®šä¹‰è·¯å¾„ # model torch.hub.load('.', 'custom', 'path/to/model.pt', source 'local') # local repo # Define the input image source (URL, local file, PIL image, OpenCV frame, numpy array, or list) img \"../yolov5/data/images/bus.jpg\" # Example image # Perform inference (handles batching, resizing, normalization automatically) results model(img) # Process the results (options: .print(), .show(), .save(), .crop(), .pandas()) results.print() # Print results to console results.show() # Display results in a window results.save() # Save results to runs/detect/exp ``` torch.hub.load å®é™…è¿”å›çš„ç±»å‹æ˜¯`class Detections:`, ä¸€èˆ¬æ¯”è¾ƒå¸¸ç”¨çš„å±æ€§ ```python self.pred pred # list of tensors pred[0] (xyxy, conf, cls) self.xyxy pred # xyxy pixels self.xywh [xyxy2xywh(x) for x in pred] # xywh pixels self.xyxyn [x / g for x, g in zip(self.xyxy, gn)] # xyxy normalized self.xywhn [x / g for x, g in zip(self.xywh, gn)] # xywh normalized ``` å¯ä»¥ä½¿ç”¨`result.show()`æ˜¾ç¤ºå›¾ç‰‡ ä½¿ç”¨`results.crop(save False)[3]['im'][:,:,:: 1]`è·å–ç¬¬å››ä¸ªç»“æœçš„å›¾ç‰‡ ```python from PIL import Image results.crop(save False)[3]['im'][:,:,:: 1] Image.fromarray(results.crop(save False)[3]['im'][:,:,:: 1]) ``` ## æ•°æ®é›† åŒæ ·å¯ä»¥ä½¿ç”¨çš„labelimg ä½¿ç”¨åŒæ ·çš„æ–‡ä»¶æ ¼å¼ + images: å­˜æ”¾ä½¿ç”¨çš„å›¾ç‰‡ + + train: è®­ç»ƒé›†çš„å›¾ç‰‡ + val: éªŒè¯é›†çš„å›¾ç‰‡ + labels: æ ‡ç­¾ + + train: è®­ç»ƒé›†çš„æ ‡ç­¾, å’Œè®­ç»ƒé›†çš„å›¾ç‰‡ä¸€ä¸€å¯¹åº” + val: éªŒè¯é›†çš„æ ‡ç­¾ é»˜è®¤çš„é…ç½®æ–‡ä»¶æ”¾åœ¨`yolov5/data`ä½ç½® ```yaml # Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..] path: ./datasets/bvn # dataset root dir train: images/train # train images (relative to 'path') 128 images val: images/val # val images (relative to 'path') 128 images test: # test images (optional) # Classes names: 0: man 1: girl 2: car ``` ## è®­ç»ƒ ![image 20251224192407439](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251224192407439.png) å¯ä»¥ä½¿ç”¨` data`å‚æ•°æŒ‡å®šä½¿ç”¨çš„é…ç½®æ–‡ä»¶ ,ä½¿ç”¨train.pyè¿›è¡Œè®­ç»ƒ ```bash python train.py ``` è¾“å‡ºçš„ä½ç½®åœ¨`yolov5/runs/train/exp`, å¯ä»¥ä½¿ç”¨`tensorboard logdir runs`æŸ¥çœ‹è®­ç»ƒæŒ‡æ ‡çš„å˜åŒ– ```bash python ./detect.py weights runs/train/exp/weights/best.pt source ./calling20221009.mp4 view img iou thres 0.35 ``` ### å¯¼å‡º å¯¼å‡ºçš„æ—¶å€™æŠ¥é”™ ```bash shape tuple((y[0] if isinstance(y, tuple) else y).shape) # model output shape ``` æ”¹ä¸º ```python # y å¯èƒ½æ˜¯ Tensorã€tuple æˆ– listï¼Œè¿™é‡Œç»Ÿä¸€å–ç¬¬ä¸€ä¸ª Tensor çš„ shape y0 y[0] if isinstance(y, (tuple, list)) else y shape tuple(y0.shape) # model output shape ``` ```bash python ./export.py \\ weights ./runs/train/exp/weights/best.pt \\ data ./data/my_dest.yaml \\ iou thres 0.35 \\ include onnx \\ opset 12 ``` è¾“å‡ºçš„æ¨¡å‹åœ¨`yolov5/runs/train/exp/weights/best.onnx` ### ç®€åŒ–æ¨¡å‹ ```bash python m onnxsim ./best.onnx best sim.onnx ```"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-12-03-æ•°æ®é›†.html":{"title":"æ•°æ®é›†","content":"# æ•°æ®é›† ## å¸¸ç”¨æ•°æ®é›† å¸¸ç”¨çš„æ•°æ®é›†æœ‰Cocoæ•°æ®é›†ä»¥åŠVOCæ•°æ®é›†, VOCä¸€èˆ¬ä½¿ç”¨çš„æ˜¯VOC2007å’ŒVOC2012 å¯ä»¥åœ¨roboflowç½‘é¡µ, é‡Œé¢æŸ¥æ‰¾, æœ‰ä¸åŒæ¨¡å‹çš„å¯¹åº”çš„æ ‡æ³¨ç±»å‹ ## æ•°æ®å‡†å¤‡ è·å–ä¸€ç³»åˆ—çš„å›¾ç‰‡, è§†é¢‘éœ€è¦å¯¼æˆå›¾ç‰‡çš„æ ¼å¼, å¯ä»¥é‡‡é›†æ‘„åƒå¤´çš„æ•°æ® ```python def capture_frame(camera_index: int 0, warmup: int 5): \"\"\"Grab a single frame with a short warmup to avoid black images on repeat runs.\"\"\" video cv2.VideoCapture(camera_index) if not video.isOpened(): raise RuntimeError(\"Cannot open camera\") # Throw away a few frames so the sensor adjusts between runs for _ in range(warmup): video.read() ret, frame video.read() video.release() if not ret: raise RuntimeError(\"Failed to read frame\") frame cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) plt.imshow(frame) plt.axis(\"off\") plt.show() capture_frame() ``` ä¹Ÿå¯ä»¥æå–è§†é¢‘é‡Œé¢çš„ ```python video_path \"calling20221009.mp4\" def capture_video_frame(video_path: str, frame_number: int 0): \"\"\"Capture a specific frame from a video file.\"\"\" video cv2.VideoCapture(video_path) if not video.isOpened(): raise RuntimeError(\"Cannot open video file\") video.set(cv2.CAP_PROP_POS_FRAMES, frame_number) ret, frame video.read() video.release() if not ret: raise RuntimeError(\"Failed to read frame\") frame cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) plt.imshow(frame) plt.axis(\"off\") plt.show() capture_video_frame(video_path, frame_number 10) ``` è®°å½•å¯ä»¥ä½¿ç”¨ ```python video cv2.VideoCapture(video_path) num 0 save_step 30 # Save every 30 frames while True: ret, frame video.read() if not ret: break if num % save_step 0: frame_rgb cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) plt.imsave(f\"frame_{num}.jpg\", frame_rgb) num + 1 video.release() ``` ## æ ‡æ³¨ ### labelimg ä½¿ç”¨labelimgè¿›è¡Œæ ‡æ³¨, éœ€è¦ä½¿ç”¨python3.9çš„ç¯å¢ƒ ```bash pip install labelimg ``` ç›´æ¥ä½¿ç”¨labelimageå³å¯å¯åŠ¨ <img src \"https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213103655706.png\" alt \"image 20251213103655706\" style \"zoom:50%;\" /> <img src \"https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213103730821.png\" alt \"image 20251213103730821\" style \"zoom:50%;\" /> ä½¿ç”¨å³é”®åˆ›å»ºä¸€ä¸ªæ ‡æ³¨æ¡† å¿«æ·é”®: + d: ä¸‹ä¸€å¼  + w: é€‰æ¡† <img src \"https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213111335448.png\" style \"zoom:50%;\" /> <img src \"https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213111347986.png\" style \"zoom:50%;\" /> â€‹\t`````````````````````\t````````````````![image 20251213111435989](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213111435989.png) ### ç½‘é¡µ https://www.makesense.ai/: å¯ä»¥è¿›è¡Œåœ¨çº¿çš„æ ‡æ³¨ä»¥åŠåŠ è½½è¾…åŠ©æ¨¡å‹è¿›è¡Œæ ‡æ³¨ å¯¼å‡º ![image 20251213111929520](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213111929520.png) ![image 20251213111943504](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213111943504.png) è·å–çš„æ•°æ®çš„æ ¼å¼æ˜¯ç›¸åŒçš„ ![image 20251213112019186](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213112019186.png) ![image 20251213112042536](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213112042536.png) ä½¿ç”¨yoloæ¨¡å‹è¿›è¡Œå¯¼å‡º"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-05-è®­ç»ƒ.html":{"title":"è®­ç»ƒ","content":"# è®­ç»ƒ https://docs.ultralytics.com/zh/modes/train/#augmentation settings and hyperparameters ## æ•°æ®å‡†å¤‡ + images: å­˜æ”¾ä½¿ç”¨çš„å›¾ç‰‡ + + train: è®­ç»ƒé›†çš„å›¾ç‰‡ + val: éªŒè¯é›†çš„å›¾ç‰‡ + labels: æ ‡ç­¾ + + train: è®­ç»ƒé›†çš„æ ‡ç­¾, å’Œè®­ç»ƒé›†çš„å›¾ç‰‡ä¸€ä¸€å¯¹åº” + val: éªŒè¯é›†çš„æ ‡ç­¾ ![image 20251213113717556](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213113717556.png) éœ€è¦æ”¾åœ¨datasetsæ–‡ä»¶å¤¹ä¸‹é¢ ![image 20251213115145922](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213115145922.png) è¿˜éœ€è¦ä¸€ä¸ªé…ç½®æ–‡ä»¶å¯ä»¥å‚è€ƒultralytics/ultralytics/cfg/datasetsä¸‹é¢çš„æ–‡ä»¶ ```yaml # Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..] path: bvn # dataset root dir train: images/train # train images (relative to 'path') è®­ç»ƒé›† val: images/val # val images (relative to 'path') éªŒè¯é›† test: # test images (relative to 'path') æµ‹è¯•é›†å¯é€‰ # Classes names: 0: man 1: girl 2: carbvn ``` ä¹‹åå³å¯ä½¿ç”¨å‘½ä»¤è¡Œè¿›è¡Œè®­ç»ƒ ```bash yolo task detect mode train model ./yolov8n.pt data ./bvn.yaml epochs 30 workers 1 batch 16 ``` ä¹Ÿå¯ä»¥ä½¿ç”¨ä»£ç è¿›è¡Œ ```python from ultralytics import YOLO module YOLO('yolov8n.pt') # load a pretrained model (recommended for training) module.train(data 'bvn.yaml', epochs 100, imgsz 640, batch 16, , device \"mps\") # ä½¿ç”¨Appleçš„mpsè¿›è¡Œè®­ç»ƒ ``` ### åŸºæœ¬å‚æ•° > é»˜è®¤å‚æ•°è®°å½•åœ¨æ–‡ä»¶`ultralytics/ultralytics/cfg/default.yaml`é‡Œé¢ YOLO æ¨¡å‹çš„è®­ç»ƒè®¾ç½®åŒ…æ‹¬è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„å„ç§è¶…å‚æ•°å’Œé…ç½®ã€‚è¿™äº›è®¾ç½®ä¼šå½±å“æ¨¡å‹çš„æ€§èƒ½ã€é€Ÿåº¦å’Œ[å‡†ç¡®æ€§](https://www.ultralytics.com/glossary/accuracy)ã€‚å…³é”®è®­ç»ƒè®¾ç½®åŒ…æ‹¬æ‰¹é‡å¤§å°ã€å­¦ä¹ ç‡ã€åŠ¨é‡å’Œæƒé‡è¡°å‡ã€‚æ­¤å¤–ï¼Œä¼˜åŒ–å™¨çš„é€‰æ‹©ã€[æŸå¤±å‡½æ•°](https://www.ultralytics.com/glossary/loss function)å’Œè®­ç»ƒæ•°æ®é›†ç»„æˆä¼šå½±å“è®­ç»ƒè¿‡ç¨‹ å‚æ•° ç±»å‹ é»˜è®¤å€¼ æè¿° : : : : `model` `str` `None` æŒ‡å®šç”¨äºè®­ç»ƒçš„æ¨¡å‹æ–‡ä»¶ã€‚æ¥å—æŒ‡å‘ `.pt` é¢„è®­ç»ƒæ¨¡å‹æˆ– `.yaml` é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚å¯¹äºå®šä¹‰æ¨¡å‹ç»“æ„æˆ–åˆå§‹åŒ–æƒé‡è‡³å…³é‡è¦ã€‚ `data` `str` `None` æ•°æ®é›†é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼ˆä¾‹å¦‚ï¼Œ `coco8.yaml`ï¼‰ã€‚æ­¤æ–‡ä»¶åŒ…å«æ•°æ®é›†ç‰¹å®šçš„å‚æ•°ï¼ŒåŒ…æ‹¬è®­ç»ƒå’Œ [éªŒè¯æ•°æ®çš„è·¯å¾„](https://www.ultralytics.com/glossary/validation data)ï¼Œç±»åˆ«åç§°å’Œç±»åˆ«æ•°é‡ã€‚ `epochs` `int` `100` è®­ç»ƒçš„æ€»è½®æ•°ã€‚æ¯ä¸ª[epoch](https://www.ultralytics.com/glossary/epoch)ä»£è¡¨å¯¹æ•´ä¸ªæ•°æ®é›†çš„ä¸€æ¬¡å®Œæ•´éå†ã€‚è°ƒæ•´æ­¤å€¼ä¼šå½±å“è®­ç»ƒæ—¶é•¿å’Œæ¨¡å‹æ€§èƒ½ã€‚ `time` `float` `None` æœ€é•¿è®­ç»ƒæ—¶é—´ï¼ˆä»¥å°æ—¶ä¸ºå•ä½ï¼‰ã€‚å¦‚æœè®¾ç½®æ­¤å‚æ•°ï¼Œå®ƒå°†è¦†ç›– `epochs` å‚æ•°ï¼Œå…è®¸è®­ç»ƒåœ¨æŒ‡å®šæ—¶é•¿åè‡ªåŠ¨åœæ­¢ã€‚é€‚ç”¨äºæ—¶é—´å—é™çš„è®­ç»ƒåœºæ™¯ã€‚ `patience` `int` `100` åœ¨éªŒè¯æŒ‡æ ‡æ²¡æœ‰æ”¹å–„çš„æƒ…å†µä¸‹ï¼Œç­‰å¾…å¤šå°‘ä¸ªepochåæå‰åœæ­¢è®­ç»ƒã€‚é€šè¿‡åœ¨æ€§èƒ½åœæ»æ—¶åœæ­¢è®­ç»ƒï¼Œæœ‰åŠ©äºé˜²æ­¢[è¿‡æ‹Ÿåˆ](https://www.ultralytics.com/glossary/overfitting)ã€‚ `batch` `int` æˆ– `float` `16` [æ‰¹æ¬¡å¤§å°](https://www.ultralytics.com/glossary/batch size)ï¼Œå…·æœ‰ä¸‰ç§æ¨¡å¼ï¼šè®¾ç½®ä¸ºæ•´æ•°ï¼ˆä¾‹å¦‚ï¼Œ `batch 16`ï¼‰ï¼Œè‡ªåŠ¨æ¨¡å¼ï¼ŒGPU å†…å­˜åˆ©ç”¨ç‡ä¸º 60%ï¼ˆ`batch 1`ï¼‰ï¼Œæˆ–å…·æœ‰æŒ‡å®šåˆ©ç”¨ç‡åˆ†æ•°çš„è‡ªåŠ¨æ¨¡å¼ï¼ˆ`batch 0.70`ï¼‰ã€‚ `imgsz` `int` `640` ç”¨äºè®­ç»ƒçš„ç›®æ ‡å›¾åƒå¤§å°ã€‚å›¾åƒè¢«è°ƒæ•´ä¸ºè¾¹é•¿ç­‰äºæŒ‡å®šå€¼çš„æ­£æ–¹å½¢ï¼ˆå¦‚æœ `rect False`ï¼‰ï¼Œä¸º YOLO æ¨¡å‹ä¿ç•™å®½é«˜æ¯”ï¼Œä½†ä¸ä¸º RT DETR ä¿ç•™ã€‚å½±å“æ¨¡å‹ [å‡†ç¡®æ€§](https://www.ultralytics.com/glossary/accuracy) å’Œè®¡ç®—å¤æ‚åº¦ã€‚ `save` `bool` `True` å¯ç”¨ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹å’Œæœ€ç»ˆæ¨¡å‹æƒé‡ã€‚å¯ç”¨äºæ¢å¤è®­ç»ƒæˆ–[æ¨¡å‹éƒ¨ç½²](https://www.ultralytics.com/glossary/model deployment)ã€‚ `save_period` `int` ` 1` ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹çš„é¢‘ç‡ï¼Œä»¥ epoch ä¸ºå•ä½æŒ‡å®šã€‚å€¼ä¸º 1 æ—¶ç¦ç”¨æ­¤åŠŸèƒ½ã€‚é€‚ç”¨äºåœ¨é•¿æ—¶é—´è®­ç»ƒæœŸé—´ä¿å­˜ä¸´æ—¶æ¨¡å‹ã€‚ `cache` `bool` `False` å¯ç”¨åœ¨å†…å­˜ä¸­ç¼“å­˜æ•°æ®é›†å›¾åƒï¼ˆ`True`/`ram`ï¼‰ï¼Œåœ¨ç£ç›˜ä¸Šç¼“å­˜ï¼ˆ`disk`ï¼‰ï¼Œæˆ–ç¦ç”¨ç¼“å­˜ï¼ˆ`False`ï¼‰ã€‚é€šè¿‡å‡å°‘ç£ç›˜ I/O æ¥æé«˜è®­ç»ƒé€Ÿåº¦ï¼Œä½†ä¼šå¢åŠ å†…å­˜ä½¿ç”¨é‡ã€‚ `device` `int` æˆ– `str` æˆ– `list` `None` æŒ‡å®šç”¨äºè®­ç»ƒçš„è®¡ç®—è®¾å¤‡ï¼šå•ä¸ª GPUï¼ˆ`device 0`ï¼‰ï¼Œå¤šä¸ª GPUï¼ˆ`device [0,1]`ï¼‰ï¼ŒCPUï¼ˆ`device cpu`ï¼‰ï¼Œé€‚ç”¨äº Apple èŠ¯ç‰‡çš„ MPSï¼ˆ`device mps`ï¼‰ï¼Œæˆ–è‡ªåŠ¨é€‰æ‹©æœ€ç©ºé—²çš„ GPUï¼ˆ`device 1`ï¼‰æˆ–å¤šä¸ªç©ºé—² GPU ï¼ˆ`device [ 1, 1]`) `workers` `int` `8` ç”¨äºæ•°æ®åŠ è½½çš„å·¥ä½œçº¿ç¨‹æ•°ï¼ˆæ¯ä¸ª `RANK` ï¼Œå¦‚æœæ˜¯å¤š GPU è®­ç»ƒï¼‰ã€‚å½±å“æ•°æ®é¢„å¤„ç†å’Œè¾“å…¥æ¨¡å‹çš„é€Ÿåº¦ï¼Œåœ¨å¤š GPU è®¾ç½®ä¸­å°¤å…¶æœ‰ç”¨ã€‚ `project` `str` `None` é¡¹ç›®ç›®å½•çš„åç§°ï¼Œè®­ç»ƒè¾“å‡ºä¿å­˜åœ¨æ­¤ç›®å½•ä¸­ã€‚å…è®¸æœ‰ç»„ç»‡åœ°å­˜å‚¨ä¸åŒçš„å®éªŒã€‚ `name` `str` `None` è®­ç»ƒè¿è¡Œçš„åç§°ã€‚ç”¨äºåœ¨é¡¹ç›®æ–‡ä»¶å¤¹ä¸­åˆ›å»ºä¸€ä¸ªå­ç›®å½•ï¼Œè®­ç»ƒæ—¥å¿—å’Œè¾“å‡ºå­˜å‚¨åœ¨è¯¥å­ç›®å½•ä¸­ã€‚ `exist_ok` `bool` `False` å¦‚æœä¸º Trueï¼Œåˆ™å…è®¸è¦†ç›–ç°æœ‰çš„ project/name ç›®å½•ã€‚é€‚ç”¨äºè¿­ä»£å®éªŒï¼Œæ— éœ€æ‰‹åŠ¨æ¸…é™¤ä¹‹å‰çš„è¾“å‡ºã€‚ `pretrained` `bool` æˆ– `str` `True` ç¡®å®šæ˜¯å¦ä»é¢„è®­ç»ƒæ¨¡å‹å¼€å§‹è®­ç»ƒã€‚å¯ä»¥æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œä¹Ÿå¯ä»¥æ˜¯åŠ è½½æƒé‡çš„ç‰¹å®šæ¨¡å‹çš„å­—ç¬¦ä¸²è·¯å¾„ã€‚å¢å¼ºè®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚ `optimizer` `str` `'auto'` è®­ç»ƒä¼˜åŒ–å™¨çš„é€‰æ‹©ã€‚é€‰é¡¹åŒ…æ‹¬ `SGD`, `Adam`, `AdamW`, `NAdam`, `RAdam`, `RMSProp` ç­‰ç­‰ï¼Œæˆ–è€… `auto` ç”¨äºåŸºäºæ¨¡å‹é…ç½®è‡ªåŠ¨é€‰æ‹©ã€‚å½±å“æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§ã€‚ `seed` `int` `0` è®¾ç½®è®­ç»ƒçš„éšæœºç§å­ï¼Œç¡®ä¿åœ¨ç›¸åŒé…ç½®ä¸‹è¿è¡Œç»“æœçš„å¯é‡å¤æ€§ã€‚ `deterministic` `bool` `True` å¼ºåˆ¶ä½¿ç”¨ç¡®å®šæ€§ç®—æ³•ï¼Œç¡®ä¿å¯é‡å¤æ€§ï¼Œä½†ç”±äºé™åˆ¶äº†éç¡®å®šæ€§ç®—æ³•ï¼Œå¯èƒ½ä¼šå½±å“æ€§èƒ½å’Œé€Ÿåº¦ã€‚ `single_cls` `bool` `False` åœ¨å¤šç±»åˆ«æ•°æ®é›†ä¸­ï¼Œå°†æ‰€æœ‰ç±»åˆ«è§†ä¸ºå•ä¸ªç±»åˆ«è¿›è¡Œè®­ç»ƒã€‚é€‚ç”¨äºäºŒå…ƒåˆ†ç±»ä»»åŠ¡æˆ–ä¾§é‡äºå¯¹è±¡æ˜¯å¦å­˜åœ¨è€Œéåˆ†ç±»æ—¶ã€‚ `classes` `list[int]` `None` æŒ‡å®šè¦è®­ç»ƒçš„ç±» ID åˆ—è¡¨ã€‚å¯ç”¨äºåœ¨è®­ç»ƒæœŸé—´è¿‡æ»¤æ‰å¹¶ä»…å…³æ³¨æŸäº›ç±»ã€‚ `rect` `bool` `False` å¯ç”¨æœ€å°å¡«å……ç­–ç•¥â€”â€”æ‰¹é‡ä¸­çš„å›¾åƒè¢«æœ€å°ç¨‹åº¦åœ°å¡«å……ä»¥è¾¾åˆ°ä¸€ä¸ªå…±åŒçš„å¤§å°ï¼Œæœ€é•¿è¾¹ç­‰äº `imgsz`ã€‚å¯ä»¥æé«˜æ•ˆç‡å’Œé€Ÿåº¦ï¼Œä½†å¯èƒ½ä¼šå½±å“æ¨¡å‹ç²¾åº¦ã€‚ `multi_scale` `bool` `False` é€šè¿‡å¢åŠ /å‡å°‘æ¥å¯ç”¨å¤šå°ºåº¦è®­ç»ƒ `imgsz` é«˜è¾¾ `0.5` åœ¨è®­ç»ƒæœŸé—´ã€‚è®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶åœ¨å¤šæ¬¡è¿­ä»£ä¸­æ›´åŠ å‡†ç¡® `imgsz` åœ¨æ¨ç†è¿‡ç¨‹ä¸­ã€‚ `cos_lr` `bool` `False` ä½¿ç”¨ä½™å¼¦[å­¦ä¹ ç‡](https://www.ultralytics.com/glossary/learning rate)è°ƒåº¦å™¨ï¼Œåœ¨ epochs ä¸ŠæŒ‰ç…§ä½™å¼¦æ›²çº¿è°ƒæ•´å­¦ä¹ ç‡ã€‚æœ‰åŠ©äºç®¡ç†å­¦ä¹ ç‡ï¼Œä»è€Œå®ç°æ›´å¥½çš„æ”¶æ•›ã€‚ `close_mosaic` `int` `10` åœ¨æœ€å N ä¸ª epochs ä¸­ç¦ç”¨ mosaic [æ•°æ®å¢å¼º](https://www.ultralytics.com/glossary/data augmentation)ï¼Œä»¥åœ¨å®Œæˆå‰ç¨³å®šè®­ç»ƒã€‚è®¾ç½®ä¸º 0 å¯ç¦ç”¨æ­¤åŠŸèƒ½ã€‚ `resume` `bool` `False` ä»ä¸Šæ¬¡ä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚è‡ªåŠ¨åŠ è½½æ¨¡å‹æƒé‡ã€ä¼˜åŒ–å™¨çŠ¶æ€å’Œ epoch è®¡æ•°ï¼Œæ— ç¼ç»§ç»­è®­ç»ƒã€‚ `amp` `bool` `True` å¯ç”¨è‡ªåŠ¨[æ··åˆç²¾åº¦](https://www.ultralytics.com/glossary/mixed precision)ï¼ˆAMPï¼‰è®­ç»ƒï¼Œå‡å°‘å†…å­˜ä½¿ç”¨ï¼Œå¹¶å¯èƒ½åœ¨å¯¹å‡†ç¡®æ€§å½±å“æœ€å°çš„æƒ…å†µä¸‹åŠ å¿«è®­ç»ƒé€Ÿåº¦ã€‚ `fraction` `float` `1.0` æŒ‡å®šç”¨äºè®­ç»ƒçš„æ•°æ®é›†æ¯”ä¾‹ã€‚å…è®¸åœ¨å®Œæ•´æ•°æ®é›†çš„å­é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨å®éªŒæˆ–èµ„æºæœ‰é™æ—¶éå¸¸æœ‰ç”¨ã€‚ `profile` `bool` `False` åœ¨è®­ç»ƒæœŸé—´å¯ç”¨ ONNX å’Œ TensorRT é€Ÿåº¦çš„åˆ†æï¼Œæœ‰åŠ©äºä¼˜åŒ–æ¨¡å‹éƒ¨ç½²ã€‚ `freeze` `int` æˆ– `list` `None` å†»ç»“æ¨¡å‹çš„å‰ N å±‚æˆ–æŒ‰ç´¢å¼•æŒ‡å®šçš„å±‚ï¼Œä»è€Œå‡å°‘å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚é€‚ç”¨äºå¾®è°ƒæˆ–[è¿ç§»å­¦ä¹ ](https://www.ultralytics.com/glossary/transfer learning)ã€‚ `lr0` `float` `0.01` åˆå§‹å­¦ä¹ ç‡ï¼ˆå³ `SGD 1E 2`, `Adam 1E 3`)ã€‚è°ƒæ•´æ­¤å€¼å¯¹äºä¼˜åŒ–è¿‡ç¨‹è‡³å…³é‡è¦ï¼Œå®ƒä¼šå½±å“æ¨¡å‹æƒé‡æ›´æ–°çš„é€Ÿåº¦ã€‚ `lrf` `float` `0.01` æœ€ç»ˆå­¦ä¹ ç‡ä½œä¸ºåˆå§‹é€Ÿç‡çš„ä¸€éƒ¨åˆ† (`lr0 * lrf`ï¼‰ï¼Œä¸è°ƒåº¦å™¨ç»“åˆä½¿ç”¨ä»¥éšæ—¶é—´è°ƒæ•´å­¦ä¹ ç‡ã€‚ `momentum` `float` `0.937` ç”¨äºSGD çš„åŠ¨é‡å› å­ï¼Œæˆ–ç”¨äº[Adam ä¼˜åŒ–å™¨](https://www.ultralytics.com/glossary/adam optimizer)çš„ beta1ï¼Œç”¨äºå°†è¿‡å»çš„æ¢¯åº¦çº³å…¥å½“å‰æ›´æ–°ã€‚ `weight_decay` `float` `0.0005` L2 [æ­£åˆ™åŒ–](https://www.ultralytics.com/glossary/regularization)é¡¹ï¼Œæƒ©ç½šå¤§æƒé‡ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚ `warmup_epochs` `float` `3.0` å­¦ä¹ ç‡é¢„çƒ­çš„ epochs æ•°ï¼Œå°†å­¦ä¹ ç‡ä»ä½å€¼é€æ¸å¢åŠ åˆ°åˆå§‹å­¦ä¹ ç‡ï¼Œä»¥åœ¨æ—©æœŸç¨³å®šè®­ç»ƒã€‚ `warmup_momentum` `float` `0.8` é¢„çƒ­é˜¶æ®µçš„åˆå§‹åŠ¨é‡ï¼Œåœ¨é¢„çƒ­æœŸé—´é€æ¸è°ƒæ•´åˆ°è®¾å®šçš„åŠ¨é‡ã€‚ `warmup_bias_lr` `float` `0.1` é¢„çƒ­é˜¶æ®µåå·®å‚æ•°çš„å­¦ä¹ ç‡ï¼Œæœ‰åŠ©äºç¨³å®šåˆå§‹ epochs ä¸­çš„æ¨¡å‹è®­ç»ƒã€‚ `box` `float` `7.5` [æŸå¤±å‡½æ•°](https://www.ultralytics.com/glossary/loss function)ä¸­æ¡†æŸå¤±åˆ†é‡çš„æƒé‡ï¼Œå½±å“å¯¹å‡†ç¡®é¢„æµ‹[è¾¹ç•Œæ¡†](https://www.ultralytics.com/glossary/bounding box)åæ ‡çš„é‡è§†ç¨‹åº¦ã€‚ `cls` `float` `0.5` åˆ†ç±»æŸå¤±åœ¨æ€»æŸå¤±å‡½æ•°ä¸­çš„æƒé‡ï¼Œå½±å“æ­£ç¡®ç±»åˆ«é¢„æµ‹ç›¸å¯¹äºå…¶ä»–æˆåˆ†çš„é‡è¦æ€§ã€‚ `dfl` `float` `1.5` åˆ†å¸ƒç„¦ç‚¹æŸå¤±çš„æƒé‡ï¼Œåœ¨æŸäº› YOLO ç‰ˆæœ¬ä¸­ç”¨äºç»†ç²’åº¦åˆ†ç±»ã€‚ `pose` `float` `12.0` åœ¨ä¸ºå§¿åŠ¿ä¼°è®¡è®­ç»ƒçš„æ¨¡å‹ä¸­ï¼Œå§¿åŠ¿æŸå¤±çš„æƒé‡ä¼šå½±å“å¯¹å‡†ç¡®é¢„æµ‹å§¿åŠ¿å…³é”®ç‚¹çš„å¼ºè°ƒã€‚ `kobj` `float` `2.0` å§¿åŠ¿ä¼°è®¡æ¨¡å‹ä¸­å…³é”®ç‚¹å¯¹è±¡æ€§æŸå¤±çš„æƒé‡ï¼Œç”¨äºå¹³è¡¡æ£€æµ‹ç½®ä¿¡åº¦å’Œå§¿åŠ¿å‡†ç¡®æ€§ã€‚ `nbs` `int` `64` ç”¨äºæŸå¤±å½’ä¸€åŒ–çš„æ ‡ç§°æ‰¹é‡å¤§å°ã€‚ `overlap_mask` `bool` `True` ç¡®å®šæ˜¯å¦åº”å°†å¯¹è±¡æ©ç åˆå¹¶ä¸ºå•ä¸ªæ©ç ä»¥è¿›è¡Œè®­ç»ƒï¼Œè¿˜æ˜¯ä¸ºæ¯ä¸ªå¯¹è±¡ä¿æŒåˆ†ç¦»ã€‚å¦‚æœå‘ç”Ÿé‡å ï¼Œåˆ™åœ¨åˆå¹¶æœŸé—´ï¼Œè¾ƒå°çš„æ©ç ä¼šè¦†ç›–åœ¨è¾ƒå¤§çš„æ©ç ä¹‹ä¸Šã€‚ `mask_ratio` `int` `4` åˆ†å‰²æ©ç çš„ä¸‹é‡‡æ ·ç‡ï¼Œå½±å“è®­ç»ƒæœŸé—´ä½¿ç”¨çš„æ©ç åˆ†è¾¨ç‡ã€‚ `dropout` `float` `0.0` åˆ†ç±»ä»»åŠ¡ä¸­ç”¨äºæ­£åˆ™åŒ–çš„ Dropout ç‡ï¼Œé€šè¿‡åœ¨è®­ç»ƒæœŸé—´éšæœºçœç•¥å•å…ƒæ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚ `val` `bool` `True` åœ¨è®­ç»ƒæœŸé—´å¯ç”¨éªŒè¯ï¼Œä»è€Œå¯ä»¥å®šæœŸè¯„ä¼°æ¨¡å‹åœ¨å•ç‹¬æ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚ `plots` `bool` `False` ç”Ÿæˆå¹¶ä¿å­˜è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡çš„å›¾è¡¨ï¼Œä»¥åŠé¢„æµ‹ç¤ºä¾‹ï¼Œä»è€Œæä¾›å¯¹æ¨¡å‹æ€§èƒ½å’Œå­¦ä¹ è¿›åº¦çš„å¯è§†åŒ–è§è§£ã€‚ `compile` `bool` æˆ– `str` `False` å¯ç”¨ PyTorch 2.x `torch.compile` ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è¿›è¡Œå›¾å½¢ç¼–è¯‘ `backend 'inductor'`ã€‚æ¥å— `True` â†’ `\"default\"`, `False` â†’ ç¦ç”¨ï¼Œæˆ–å­—ç¬¦ä¸²æ¨¡å¼ï¼Œä¾‹å¦‚ `\"default\"`, `\"reduce overhead\"`, `\"max autotune no cudagraphs\"`ã€‚å¦‚æœä¸æ”¯æŒï¼Œåˆ™ä¼šå‘å‡ºè­¦å‘Šå¹¶å›é€€åˆ° Eager æ¨¡å¼ã€‚ ### å¢å¼ºå‚æ•° æ•°æ®å¢å¼ºæŠ€æœ¯å¯¹äºæé«˜ YOLO æ¨¡å‹çš„é²æ£’æ€§å’Œæ€§èƒ½è‡³å…³é‡è¦ï¼Œå®ƒé€šè¿‡åœ¨[è®­ç»ƒæ•°æ®](https://www.ultralytics.com/glossary/training data)ä¸­å¼•å…¥å˜å¼‚æ€§ï¼Œå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°æ³›åŒ–åˆ°æœªè§è¿‡çš„æ•°æ®ã€‚ä¸‹è¡¨æ¦‚è¿°äº†æ¯ä¸ªæ•°æ®å¢å¼ºå‚æ•°çš„ç›®çš„å’Œæ•ˆæœ å‚æ•° ç±»å‹ é»˜è®¤å€¼ æ”¯æŒçš„ä»»åŠ¡ èŒƒå›´ æè¿° : : : : : : [`translate`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#translation translate) `float` `0.1` `detect`, `segment`, `pose`, `obb` `0.0 1.0` å°†å›¾åƒæ¨ªå‘å’Œçºµå‘å¹³ç§»ä¸€å°éƒ¨åˆ†ï¼Œå¸®åŠ©å­¦ä¹ detect éƒ¨åˆ†å¯è§çš„ç‰©ä½“ã€‚ [`shear`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#shear shear) `float` `0.0` `detect`, `segment`, `pose`, `obb` ` 180 +180` æŒ‰æŒ‡å®šçš„è§’åº¦é”™åˆ‡å›¾åƒï¼Œæ¨¡ä»¿ä»ä¸åŒè§’åº¦è§‚å¯Ÿç‰©ä½“çš„æ•ˆæœã€‚ [`scale`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#scale scale) `float` `0.5` `detect`, `segment`, `pose`, `obb`, `classify` `0 1` é€šè¿‡å¢ç›Šå› å­ç¼©æ”¾å›¾åƒï¼Œæ¨¡æ‹Ÿç‰©ä½“ä¸ç›¸æœºçš„ä¸åŒè·ç¦»ã€‚ [`perspective`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#perspective perspective) `float` `0.0` `detect`, `segment`, `pose`, `obb` `0.0 0.001` å¯¹å›¾åƒåº”ç”¨éšæœºé€è§†å˜æ¢ï¼Œå¢å¼ºæ¨¡å‹ç†è§£ 3D ç©ºé—´ä¸­ç‰©ä½“çš„èƒ½åŠ›ã€‚ [`mosaic`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#mosaic mosaic) `float` `1.0` `detect`, `segment`, `pose`, `obb` `0.0 1.0` å°†å››ä¸ªè®­ç»ƒå›¾åƒç»„åˆæˆä¸€ä¸ªï¼Œæ¨¡æ‹Ÿä¸åŒçš„åœºæ™¯ç»„æˆå’Œç‰©ä½“äº¤äº’ã€‚å¯¹äºå¤æ‚çš„åœºæ™¯ç†è§£éå¸¸æœ‰æ•ˆã€‚ [`mixup`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#mixup mixup) `float` `0.0` `detect`, `segment`, `pose`, `obb` `0.0 1.0` æ··åˆä¸¤ä¸ªå›¾åƒåŠå…¶æ ‡ç­¾ï¼Œåˆ›å»ºä¸€ä¸ªåˆæˆå›¾åƒã€‚é€šè¿‡å¼•å…¥æ ‡ç­¾å™ªå£°å’Œè§†è§‰å˜åŒ–ï¼Œå¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ [`hsv_v`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#brightness adjustment hsv_v) `float` `0.4` `detect`, `segment`, `pose`, `obb`, `classify` `0.0 1.0` é€šè¿‡ä¸€å°éƒ¨åˆ†ä¿®æ”¹å›¾åƒçš„æ˜åº¦ï¼ˆäº®åº¦ï¼‰ï¼Œå¸®åŠ©æ¨¡å‹åœ¨å„ç§å…‰ç…§æ¡ä»¶ä¸‹è¡¨ç°è‰¯å¥½ã€‚ [`hsv_s`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#saturation adjustment hsv_s) `float` `0.7` `detect`, `segment`, `pose`, `obb`, `classify` `0.0 1.0` é€šè¿‡ä¸€å°éƒ¨åˆ†æ”¹å˜å›¾åƒçš„é¥±å’Œåº¦ï¼Œä»è€Œå½±å“é¢œè‰²çš„å¼ºåº¦ã€‚å¯ç”¨äºæ¨¡æ‹Ÿä¸åŒçš„ç¯å¢ƒæ¡ä»¶ã€‚ [`hsv_h`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#hue adjustment hsv_h) `float` `0.015` `detect`, `segment`, `pose`, `obb`, `classify` `0.0 1.0` é€šè¿‡è‰²è½®çš„ä¸€å°éƒ¨åˆ†è°ƒæ•´å›¾åƒçš„è‰²è°ƒï¼Œä»è€Œå¼•å…¥é¢œè‰²å˜åŒ–ã€‚å¸®åŠ©æ¨¡å‹åœ¨ä¸åŒçš„å…‰ç…§æ¡ä»¶ä¸‹è¿›è¡Œæ³›åŒ–ã€‚ [`flipud`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#flip up down flipud) `float` `0.0` `detect`, `segment`, `pose`, `obb`, `classify` `0.0 1.0` ä»¥æŒ‡å®šçš„æ¦‚ç‡å°†å›¾åƒä¸Šä¸‹ç¿»è½¬ï¼Œå¢åŠ æ•°æ®å˜åŒ–ï¼Œè€Œä¸å½±å“ç‰©ä½“çš„ç‰¹å¾ã€‚ [`fliplr`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#flip left right fliplr) `float` `0.5` `detect`, `segment`, `pose`, `obb`, `classify` `0.0 1.0` ä»¥æŒ‡å®šçš„æ¦‚ç‡å°†å›¾åƒå·¦å³ç¿»è½¬ï¼Œæœ‰åŠ©äºå­¦ä¹ å¯¹ç§°ç‰©ä½“å¹¶å¢åŠ æ•°æ®é›†çš„å¤šæ ·æ€§ã€‚ [`erasing`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#random erasing erasing) `float` `0.4` `classify` `0.0 0.9` åœ¨è®­ç»ƒæœŸé—´éšæœºæ“¦é™¤å›¾åƒåŒºåŸŸï¼Œä»¥é¼“åŠ±æ¨¡å‹å…³æ³¨ä¸å¤ªæ˜æ˜¾çš„ç‰¹å¾ã€‚ [`degrees`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#rotation degrees) `float` `0.0` `detect`, `segment`, `pose`, `obb` `0.0 180` åœ¨æŒ‡å®šçš„è§’åº¦èŒƒå›´å†…éšæœºæ—‹è½¬å›¾åƒï¼Œæé«˜æ¨¡å‹è¯†åˆ«å„ç§æ–¹å‘ç‰©ä½“çš„èƒ½åŠ›ã€‚ [`cutmix`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#cutmix cutmix) `float` `0.0` `detect`, `segment`, `pose`, `obb` `0.0 1.0` ç»„åˆä¸¤å¼ å›¾åƒçš„éƒ¨åˆ†åŒºåŸŸï¼Œåˆ›å»ºå±€éƒ¨æ··åˆï¼ŒåŒæ—¶ä¿æŒæ¸…æ™°çš„åŒºåŸŸã€‚é€šè¿‡åˆ›å»ºé®æŒ¡åœºæ™¯æ¥å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚ [`copy_paste_mode`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#copy paste mode copy_paste_mode) `str` `flip` `segment` æŒ‡å®š `copy paste` è¦ä½¿ç”¨çš„ç­–ç•¥ã€‚é€‰é¡¹åŒ…æ‹¬ `'flip'` å’Œ `'mixup'`. [`copy_paste`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#copy paste copy_paste) `float` `0.0` `segment` `0.0 1.0` è·¨å›¾åƒå¤åˆ¶å’Œç²˜è´´å¯¹è±¡ä»¥å¢åŠ å¯¹è±¡å®ä¾‹ã€‚ [`bgr`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#bgr channel swap bgr) `float` `0.0` `detect`, `segment`, `pose`, `obb` `0.0 1.0` ä»¥æŒ‡å®šçš„æ¦‚ç‡å°†å›¾åƒé€šé“ä» RGB ç¿»è½¬åˆ° BGRï¼Œæœ‰åŠ©äºæé«˜å¯¹ä¸æ­£ç¡®é€šé“æ’åºçš„é²æ£’æ€§ã€‚ [`auto_augment`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#auto augment auto_augment) `str` `randaugment` `classify` åº”ç”¨é¢„å®šä¹‰çš„å¢å¼ºç­–ç•¥ï¼ˆ`'randaugment'`, `'autoaugment'`æˆ– `'augmix'`ï¼‰é€šè¿‡è§†è§‰å¤šæ ·æ€§æ¥å¢å¼ºæ¨¡å‹æ€§èƒ½ã€‚ [`augmentations`](https://docs.ultralytics.com/zh/guides/yolo data augmentation//#custom albumentations transforms augmentations) `list` `` `detect`, `segment`, `pose`, `obb` ç”¨äºé«˜çº§æ•°æ®å¢å¼ºçš„è‡ªå®šä¹‰ Albumentations è½¬æ¢Python ä»…é™Python APIï¼‰ã€‚æ¥å—è½¬æ¢å¯¹è±¡åˆ—è¡¨ï¼Œä»¥æ»¡è¶³ä¸“é—¨çš„å¢å¼ºéœ€æ±‚ã€‚ ### è‡ªå®šä¹‰é»˜è®¤é…ç½® ä½¿ç”¨å‘½ä»¤`yolo copy cfg`è¿™ä¸ªå‘½ä»¤ä¼šå¤åˆ¶ä¸€ä¸ªé…ç½®æ–‡ä»¶åˆ°å½“å‰çš„å·¥ç¨‹ç›®å½•é‡Œé¢ ä¹‹åå³å¯ä½¿ç”¨`yolo cfg defult_copy.yaml`æ‰§è¡Œ ## è¾“å‡ºç»“æœ ![image 20251213130551523](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213130551523.png) ## ä½¿ç”¨é¢„æµ‹ ```bash yolo detect predict model ../ultralytics/runs/detect/train4/weights/best.pt source ./calling20221009.mp4 show True ``` ![image 20251213130907816](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251213130907816.png)"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/yolo/2025-12-13-09-ä¿®æ”¹ç½‘ç»œ.html":{"title":"ä¿®æ”¹ç½‘ç»œ","content":"# ä¿®æ”¹ç½‘ç»œ + åŠ å…¥æ–°çš„ç½‘ç»œç»“æ„å®šä¹‰ + è®¾ç½®ä¼ é€’å‚æ•°çš„ç»†èŠ‚ + æ·»åŠ ä¸€ä¸ªæ–°çš„é…ç½®æ–‡ä»¶, å®šä¹‰å®é™…ä½¿ç”¨çš„å±‚ > ç½‘ç»œæ”¹å˜ä»¥åå¾ˆæ˜¯å¯ä»¥ä½¿ç”¨åŸæœ‰çš„æƒé‡, ä¼šè‡ªåŠ¨åšä¸€éƒ¨åˆ†çš„è¿ç§» ## C2f æ˜¯ä¸€ä¸ªYoloV8é‡Œé¢å¼•å…¥çš„æ¨¡å—, C2fä¼šä½¿ç”¨åˆ°Bottleneck, å‚æ•°å’ŒåŸæœ¬çš„ä¸ä¸€æ ·, éœ€è¦å¤åˆ¶è¿‡æ¥, æ”¹ä¸€ä¸ªåå­—ä½œä¸ºåŒºåˆ†, ä¹‹ååœ¨å‚æ•°é…ç½®çš„ä½ç½®åŠ ä¸Šè¿™ä¸ªæ¨¡å—å³å¯, è¿™ä¸ªæ¨¡å—å’ŒC3æ˜¯ä¸€æ ·çš„, æ‰€ä»¥å¯ä»¥ç›´æ¥åœ¨æ‰€æœ‰C3çš„ä½ç½®æ·»åŠ  ```python class Bottleneck(nn.Module): \"\"\"Standard bottleneck.\"\"\" def __init__( self, c1: int, c2: int, shortcut: bool True, g: int 1, k: tuple[int, int] (3, 3), e: float 0.5 ): \"\"\"Initialize a standard bottleneck module. Args: c1 (int): Input channels. c2 (int): Output channels. shortcut (bool): Whether to use shortcut connection. g (int): Groups for convolutions. k (tuple): Kernel sizes for convolutions. e (float): Expansion ratio. \"\"\" super().__init__() c_ int(c2 * e) # hidden channels self.cv1 Conv(c1, c_, k[0], 1) self.cv2 Conv(c_, c2, k[1], 1, g g) self.add shortcut and c1 c2 def forward(self, x: torch.Tensor) > torch.Tensor: \"\"\"Apply bottleneck with optional shortcut connection.\"\"\" return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x)) class C2f(nn.Module): \"\"\"Faster Implementation of CSP Bottleneck with 2 convolutions.\"\"\" def __init__(self, c1: int, c2: int, n: int 1, shortcut: bool False, g: int 1, e: float 0.5): \"\"\"Initialize a CSP bottleneck with 2 convolutions. Args: c1 (int): Input channels. c2 (int): Output channels. n (int): Number of Bottleneck blocks. shortcut (bool): Whether to use shortcut connections. g (int): Groups for convolutions. e (float): Expansion ratio. \"\"\" super().__init__() self.c int(c2 * e) # hidden channels self.cv1 Conv(c1, 2 * self.c, 1, 1) self.cv2 Conv((2 + n) * self.c, c2, 1) # optional act FReLU(c2) self.m nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k ((3, 3), (3, 3)), e 1.0) for _ in range(n)) def forward(self, x: torch.Tensor) > torch.Tensor: \"\"\"Forward pass through C2f layer.\"\"\" y list(self.cv1(x).chunk(2, 1)) y.extend(m(y[ 1]) for m in self.m) return self.cv2(torch.cat(y, 1)) def forward_split(self, x: torch.Tensor) > torch.Tensor: \"\"\"Forward pass using split() instead of chunk().\"\"\" y self.cv1(x).split((self.c, self.c), 1) y [y[0], y[1]] y.extend(m(y[ 1]) for m in self.m) return self.cv2(torch.cat(y, 1)) ``` é…ç½®çš„yamlæ–‡ä»¶é‡Œé¢å¯ä»¥å§æ‰€æœ‰çš„C3æ”¹ä¸ºC2f > å¦‚ä½•å±‚çš„ä½ç½®ä¼šå½±å“åˆ°åé¢çš„å±‚éœ€è¦å¤„ç†ä¸€ä¸‹ä¸¤å±‚åˆå¹¶æ—¶å€™çš„ç´¢å¼•é…ç½® ## æ›¿æ¢ä¸»å¹²ç½‘ç»œ ### Mobilenet #### ä¸åŒ 1. ä¼ ç»Ÿå·ç§¯çš„é—®é¢˜ ä¼ ç»Ÿå·ç§¯æ ¸åŒæ—¶å®Œæˆ â€œç©ºé—´ç‰¹å¾æå–â€ å’Œ â€œé€šé“èåˆâ€ï¼Œè®¡ç®—é‡å…¬å¼ï¼š`è®¡ç®—é‡ å·ç§¯æ ¸å°ºå¯¸Ã—å·ç§¯æ ¸å°ºå¯¸ Ã— è¾“å…¥é€šé“æ•°(M) Ã— è¾“å‡ºé€šé“æ•°(N) Ã— ç‰¹å¾å›¾å°ºå¯¸(DfÃ—Df)`ä¾‹ï¼š3Ã—3 å·ç§¯ã€è¾“å…¥é€šé“ 32ã€è¾“å‡ºé€šé“ 64ã€ç‰¹å¾å›¾ 32Ã—32 â†’ è®¡ç®—é‡ 3Ã—3Ã—32Ã—64Ã—32Ã—32 â‰ˆ 18.9M æ¬¡è¿ç®—ã€‚ 2. æ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„æ‹†è§£ å°†ä¼ ç»Ÿå·ç§¯æ‹†ä¸ºä¸¤æ­¥ï¼Œæ€»è®¡ç®—é‡ä»…ä¸ºä¼ ç»Ÿå·ç§¯çš„ `1/N + 1/(KÃ—K)`ï¼ˆN ä¸ºè¾“å‡ºé€šé“æ•°ï¼ŒK ä¸ºå·ç§¯æ ¸å°ºå¯¸ï¼‰ï¼Œé€šå¸¸å¯é™ä½ **8~9 å€** è®¡ç®—é‡ï¼š æ­£ç¡®åç§°æ˜¯ **MobileNet**ï¼ˆç§»åŠ¨ç«¯ç½‘ç»œï¼‰â€”â€” ç”± Google å›¢é˜Ÿæå‡ºçš„**è½»é‡çº§å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰**ï¼Œæ ¸å¿ƒè®¾è®¡ç›®æ ‡æ˜¯åœ¨**ç§»åŠ¨ç«¯ / åµŒå…¥å¼è®¾å¤‡**ï¼ˆç®—åŠ›ã€å†…å­˜æœ‰é™çš„åœºæ™¯ï¼‰ä¸­å®ç°é«˜æ•ˆçš„è§†è§‰ä»»åŠ¡ï¼ˆåˆ†ç±»ã€æ£€æµ‹ã€åˆ†å‰²ï¼‰ï¼ŒåŒæ—¶å°½å¯èƒ½ä¿æŒç²¾åº¦ã€‚ æ­¥éª¤ ä½œç”¨ è®¡ç®—é‡ï¼ˆä»¥ä¸Šä¾‹ï¼‰ æ·±åº¦å·ç§¯ï¼ˆDepthwiseï¼‰ å¯¹**æ¯ä¸ªè¾“å…¥é€šé“å•ç‹¬åšç©ºé—´å·ç§¯**ï¼ˆåªæå–ç©ºé—´ç‰¹å¾ï¼Œä¸èåˆé€šé“ï¼‰ï¼Œå·ç§¯æ ¸æ•° è¾“å…¥é€šé“æ•° 3Ã—3Ã—32Ã—1Ã—32Ã—32 â‰ˆ 0.98M é€ç‚¹å·ç§¯ï¼ˆPointwiseï¼‰ ç”¨ 1Ã—1 å·ç§¯æ ¸**èåˆé€šé“ç‰¹å¾**ï¼ˆåªèåˆé€šé“ï¼Œä¸æå–ç©ºé—´ç‰¹å¾ï¼‰ï¼Œå·ç§¯æ ¸æ•° è¾“å‡ºé€šé“æ•° 1Ã—1Ã—32Ã—64Ã—32Ã—32 â‰ˆ 2.1M æ€»è®¡ æ·±åº¦å·ç§¯ + é€ç‚¹å·ç§¯ â‰ˆ3.08Mï¼ˆä»…ä¸ºä¼ ç»Ÿçš„ 1/6ï¼‰ #### ç§»æ¤ åœ¨å®é™…ç§»æ¤çš„æ—¶å€™æ˜¯æ ¹æ®è¿™ä¸ªæ¨¡å‹çš„ç»“æ„, å¯¹åŸæœ‰çš„ç½‘ç»œè¿›è¡Œä¸€éƒ¨åˆ†çš„æ›¿æ¢, è¿˜æ˜¯ä½¿ç”¨é…ç½®æ–‡ä»¶, æˆ‘ä»¬éœ€è¦ä½¿ç”¨çš„æ˜¯ä»–çš„ç‰¹å¾æå–éƒ¨åˆ†çš„ç½‘ç»œ ```python from torchvision import models model models.mobilenet_v3_small(pretrained True ,progress True) # æŸ¥çœ‹ä¸€ä¸‹å®‰è£…yoloè¾“å…¥çš„è¯å„å±‚è¾“å‡º from torchinfo import summary summary(model, input_size (1, 3, 640, 640)) \"\"\" Layer (type:depth idx) Output Shape Param # MobileNetV3 [1, 1000] â”œâ”€Sequential: 1 1 [1, 576, 20, 20] â”‚ â””â”€ConvNormActivation: 2 1 [1, 16, 320, 320] â”‚ â”‚ â””â”€Conv2d: 3 1 [1, 16, 320, 320] 432 â”‚ â”‚ â””â”€BatchNorm2d: 3 2 [1, 16, 320, 320] 32 â”‚ â”‚ â””â”€Hardswish: 3 3 [1, 16, 320, 320] â”‚ â””â”€InvertedResidual: 2 2 [1, 16, 160, 160] â”‚ â”‚ â””â”€Sequential: 3 4 [1, 16, 160, 160] 744 â”‚ â””â”€InvertedResidual: 2 3 [1, 24, 80, 80] â”‚ â”‚ â””â”€Sequential: 3 5 [1, 24, 80, 80] 3,864 â”‚ â””â”€InvertedResidual: 2 4 [1, 24, 80, 80] â”‚ â”‚ â””â”€Sequential: 3 6 [1, 24, 80, 80] 5,416 â”‚ â””â”€InvertedResidual: 2 5 [1, 40, 40, 40] â”‚ â”‚ â””â”€Sequential: 3 7 [1, 40, 40, 40] 13,736 â”‚ â””â”€InvertedResidual: 2 6 [1, 40, 40, 40] â”‚ â”‚ â””â”€Sequential: 3 8 [1, 40, 40, 40] 57,264 â”‚ â””â”€InvertedResidual: 2 7 [1, 40, 40, 40] â”‚ â”‚ â””â”€Sequential: 3 9 [1, 40, 40, 40] 57,264 â”‚ â””â”€InvertedResidual: 2 8 [1, 48, 40, 40] â”‚ â”‚ â””â”€Sequential: 3 10 [1, 48, 40, 40] 21,968 â”‚ â””â”€InvertedResidual: 2 9 [1, 48, 40, 40] â”‚ â”‚ â””â”€Sequential: 3 11 [1, 48, 40, 40] 29,800 â”‚ â””â”€InvertedResidual: 2 10 [1, 96, 20, 20] â”‚ â”‚ â””â”€Sequential: 3 12 [1, 96, 20, 20] 91,848 â”‚ â””â”€InvertedResidual: 2 11 [1, 96, 20, 20] â”‚ â”‚ â””â”€Sequential: 3 13 [1, 96, 20, 20] 294,096 â”‚ â””â”€InvertedResidual: 2 12 [1, 96, 20, 20] â”‚ â”‚ â””â”€Sequential: 3 14 [1, 96, 20, 20] 294,096 â”‚ â””â”€ConvNormActivation: 2 13 [1, 576, 20, 20] â”‚ â”‚ â””â”€Conv2d: 3 15 [1, 576, 20, 20] 55,296 â”‚ â”‚ â””â”€BatchNorm2d: 3 16 [1, 576, 20, 20] 1,152 â”‚ â”‚ â””â”€Hardswish: 3 17 [1, 576, 20, 20] â”œâ”€AdaptiveAvgPool2d: 1 2 [1, 576, 1, 1] â”œâ”€Sequential: 1 3 [1, 1000] â”‚ â””â”€Linear: 2 14 [1, 1024] 590,848 â”‚ â””â”€Hardswish: 2 15 [1, 1024] â”‚ â””â”€Dropout: 2 16 [1, 1024] â”‚ â””â”€Linear: 2 17 [1, 1000] 1,025,000 Total params: 2,542,856 Trainable params: 2,542,856 Non trainable params: 0 Total mult adds (M): 446.48 Input size (MB): 4.92 Forward/backward pass size (MB): 184.56 Params size (MB): 10.17 Estimated Total Size (MB): 199.65 \"\"\" # æŸ¥çœ‹ä¸€ä¸‹å®é™…çš„å®ç°, ä½¿ç”¨featureséƒ¨åˆ†çš„ç½‘ç»œ model \"\"\" MobileNetV3( (features): Sequential( (0): ConvNormActivation( (0): Conv2d(3, 16, kernel_size (3, 3), stride (2, 2), padding (1, 1), bias False) (1): BatchNorm2d(16, eps 0.001, momentum 0.01, affine True, track_running_stats True) (2): Hardswish() ) (1): InvertedResidual( (block): Sequential( (0): ConvNormActivation( (0): Conv2d(16, 16, kernel_size (3, 3), stride (2, 2), padding (1, 1), groups 16, bias False) (1): BatchNorm2d(16, eps 0.001, momentum 0.01, affine True, track_running_stats True) (2): ReLU(inplace True) ) (1): SqueezeExcitation( (avgpool): AdaptiveAvgPool2d(output_size 1) (fc1): Conv2d(16, 8, kernel_size (1, 1), stride (1, 1)) (fc2): Conv2d(8, 16, kernel_size (1, 1), stride (1, 1)) (activation): ReLU() (scale_activation): Hardsigmoid() ) (2): ConvNormActivation( (0): Conv2d(16, 16, kernel_size (1, 1), stride (1, 1), bias False) (1): BatchNorm2d(16, eps 0.001, momentum 0.01, affine True, track_running_stats True) ) ) ) \t\t... \t\t ) (avgpool): AdaptiveAvgPool2d(output_size 1) (classifier): Sequential( (0): Linear(in_features 576, out_features 1024, bias True) (1): Hardswish() (2): Dropout(p 0.2, inplace True) (3): Linear(in_features 1024, out_features 1000, bias True) ) ) \"\"\" ``` åœ¨å®é™…ç§»æ¤çš„æ—¶å€™, ç”±äºä¹‹åéœ€è¦å¯¹æå–å‡ºæ¥çš„ä¸åŒå¤§å°ç‰¹å¾åˆå¹¶, æ‰€ä»¥éœ€è¦å¯¹ä¸åŒå±‚çš„è¾“å‡ºè¿›è¡ŒåŒ¹é…, æ›¿æ¢çš„æ˜¯backboneéƒ¨åˆ†çš„ å¦‚æœæ‰‹åŠ¨è¿›è¡Œæ‰€æœ‰çš„å±‚çš„ç§»æ¤, æ˜¯ä¸€ä¸ªå¾ˆéº»çƒ¦çš„, è¿™é‡Œçš„moduleä½¿ç”¨ä¸€ä¸ªSequentialç±»å‹çš„, æ‰€ä»¥å¯ä»¥ä½¿ç”¨æ•°ç»„çš„æ–¹å¼æå–å…¶ä¸­ä¸€éƒ¨åˆ†çš„æ¨¡å—`model.features[:4]`, æ‰€ä»¥å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸ªæ–¹å¼è¿›è¡Œåˆ†å‰² ```python from torch import nn class MobileNetV3(nn.Module): def __init__(self, slice): super(MobileNetV3, self).__init__() self.model None if slice 1: self.model models.mobilenet_v3_small(pretrained True ,progress True).features[:4] elif slice 2: self.model models.mobilenet_v3_small(pretrained True ,progress True).features[4:9] elif slice 3: self.model models.mobilenet_v3_small(pretrained True ,progress True).features[9:] def forward(self, x): x self.model(x) return x ``` ```yaml backbone: # [from, number, module, args] # è¿™é‡Œçš„24, 48, 576æ˜¯è¾“å‡ºçš„é€šé“æ•°, ä½¿ç”¨ä¹‹å‰æ‰“å°çš„æ•°æ®å³å¯è·å– [ \t\t[ 1, 1, MobileNetV3, [24, 1]], \t\t[ 1, 1, MobileNetV3, [48, 2]], \t\t[ 1, 1, MobileNetV3, [576, 1]] ] ``` ```python elif m is MobileNetV3: c2 args[0] # è®°å½•è¾“å‡ºé€šé“ args args[1:] # å®é™…ä½¿ç”¨çš„å‚æ•° ```"},"/note/æœºå™¨å­¦ä¹ /index.html":{"title":"","content":"# æœºå™¨å­¦ä¹ "},"/note/æœºå™¨å­¦ä¹ /å…·èº«æ™ºèƒ½/2026-2-2-åŸºç¡€æ¦‚å¿µ.html":{"title":"åŸºç¡€æ¦‚å¿µ","content":"# åŸºç¡€æ¦‚å¿µ ## ç”µæœº + æ­¥è¿›ç”µæœº: ä½¿ç”¨ç”µç£é“è½¬åŠ¨ç£é“çš„æ–¹å¼è¿›è¡Œè½¬åŠ¨, ä¸èƒ½è·å–åˆ°å®é™…çš„æ—‹è½¬æƒ…å†µ + æ— åˆ·ç”µæœº: ç”µç£é“ + ç£åœºé‡‡é›†, å¯ä»¥ç²¾ç¡®çš„è·å–å½“å‰çš„ ### ä½ç½®è·å– + ç”µä½å™¨: ä½¿ç”¨æ»‘åŠ¨ç”µé˜»å™¨çš„åŸç†, ç²¾åº¦ä¸é«˜, ä¼šç£¨æŸ + ç£ç¼–ç å™¨: æ­é…ä¸€ä¸ªç£é“, èŠ¯ç‰‡æ„ŸçŸ¥ç£é“çš„æ—‹è½¬, ç²¾åº¦æ¯”è¾ƒé«˜, ä½†æ˜¯ä»·æ ¼æ˜‚è´µ"},"/note/æœºå™¨å­¦ä¹ /å…·èº«æ™ºèƒ½/2026-2-3-02-ä»¿çœŸ.html":{"title":"ä»¿çœŸ","content":"# ä»¿çœŸ å¸¸è§çš„ä»¿çœŸè½¯ä»¶æœ‰NVIDIA Issac Simè‹±ä¼Ÿè¾¾çš„ä»¿çœŸ, ä½†æ˜¯ç¡¬ä»¶æˆæœ¬å¾ˆé«˜ MuloCo, ä»¥åŠThree.js/Webä»¿çœŸ åŸºç¡€ä½¿ç”¨çš„è¯­è¨€éƒ½æ˜¯urdfè¿›è¡Œæè¿° ```xml <?xml version '1.0' encoding 'utf 8'?> <robot name \"so_arm100_simplified_core\"> <! ä¿ç•™æœºå™¨äººåç§° > <! Base Link: æœºå™¨äººçš„åŸºç¡€è¿æ† > <link name \"Base\"> <! visual: ä¿ç•™åŸºç¡€è¿æ†çš„å¤–è§‚ï¼Œmeshæ–‡ä»¶æŒ‡å‘å…¶å‡ ä½•å½¢çŠ¶ > <visual> <geometry> <mesh filename \"meshes/AAA.stl\" /> <! æ³¨æ„: filenameéœ€è¦åŒ…è·¯å¾„ > <! å¦‚æœä½ çš„STLå•ä½æ˜¯æ¯«ç±³(mm), éœ€è¦æ·»åŠ  scale \"0.001 0.001 0.001\" > </geometry> <! origin: å¦‚æœSTLæ–‡ä»¶çš„åŸç‚¹ä¸æ˜¯ä½ æœŸæœ›çš„è¿æ†åæ ‡ç³»åŸç‚¹ï¼Œéœ€è¦åœ¨è¿™é‡Œè°ƒæ•´ > <! <origin xyz \"0 0 0\" rpy \"0 0 0\"/> > </visual> <! ä¿ç•™ç¬¬äºŒä¸ªvisualï¼Œå› ä¸ºå®ƒä»£è¡¨ä¸åŒçš„éƒ¨åˆ† (å¯é€‰ï¼Œå¦‚æœä¸€ä¸ªmeshå°±å¤Ÿäº†å¯ä»¥åˆ æ‰) > </link> <! Rotation_Pitch Link: ç¬¬ä¸€ä¸ªæ´»åŠ¨è¿æ† > <link name \"yao\"> <visual> <geometry> <mesh filename \"meshes/BBB.stl\" /> \t\t <origin xyz \"0 0 0\" rpy \"0 0 0\"/> </geometry> </visual> </link> <! Rotation_Pitch Link: ç¬¬ä¸€ä¸ªæ´»åŠ¨è¿æ† > <link name \"jian1\"> <visual> <geometry> <mesh filename \"meshes/CCC.stl\" /> \t\t <origin xyz \"0 0 0\" rpy \"0 0 0\"/> </geometry> </visual> </link> <! Rotation_Pitch Link: ç¬¬ä¸€ä¸ªæ´»åŠ¨è¿æ† > <link name \"jian2\"> <visual> <geometry> <mesh filename \"meshes/CCC2.stl\" /> \t\t <origin xyz \"0 0 0\" rpy \"0 0 0\"/> </geometry> </visual> </link> <link name \"wan\"> <visual> <geometry> <mesh filename \"meshes/DDD.stl\" /> \t\t <origin xyz \"0 0 0\" rpy \"0 0 0\"/> </geometry> </visual> </link> <link name \"wan2\"> <visual> <geometry> <mesh filename \"meshes/EEE.stl\" /> \t\t <origin xyz \"0 0 0\" rpy \"0 0 0\"/> </geometry> </visual> </link> <link name \"zhua\"> <visual> <geometry> <mesh filename \"meshes/FFF.stl\" /> \t\t <origin xyz \"0 0 0\" rpy \"0 0 0\"/> </geometry> </visual> </link> <! Joint: è¿æ¥ Base å’Œ yao > <joint name \"Rotation\" type \"revolute\"> <! å…³èŠ‚åç§°å’Œç±»å‹ï¼ˆæ—‹è½¬ï¼‰ > <parent link \"Base\"/> <! çˆ¶è¿æ† > <child link \"yao\"/> <! å­è¿æ† > <! origin: å®šä¹‰å­è¿æ†åæ ‡ç³»åŸç‚¹ç›¸å¯¹äºçˆ¶è¿æ†åæ ‡ç³»åŸç‚¹çš„å˜æ¢ > <origin xyz \" 0.013 0 0.0265\" rpy \"0 1.57 0\"/> <! å®šä¹‰è¿æ¥çš„ä½ç½® > <! axis: å®šä¹‰æ—‹è½¬è½´ï¼ˆåœ¨å…³èŠ‚åæ ‡ç³»ä¸‹ï¼‰ > <axis xyz \"1 0 0\"/> <! è¿™æ˜¯è¿åŠ¨çš„å…³é”®, å›´ç»•æ¨¡å‹åæ ‡ç³»ä¸­çš„xè½´æ—‹è½¬ > <! limit: å®šä¹‰å…³èŠ‚è¿åŠ¨é™åˆ¶ (å¯¹åŠŸèƒ½æè¿°å¾ˆé‡è¦) > <limit lower \" 1.57\" upper \"1.57\" effort \"35\" velocity \"1\"/> </joint> <! Joint: è¿æ¥ yao å’Œ jian1 > <joint name \"Rotation2\" type \"revolute\"> <! å…³èŠ‚åç§°å’Œç±»å‹ï¼ˆæ—‹è½¬ï¼‰ > <parent link \"yao\"/> <! çˆ¶è¿æ† > <child link \"jian1\"/> <! å­è¿æ† > <! origin: å®šä¹‰å­è¿æ†åæ ‡ç³»åŸç‚¹ç›¸å¯¹äºçˆ¶è¿æ†åæ ‡ç³»åŸç‚¹çš„å˜æ¢ > <origin xyz \"0.081 0 0.0\" rpy \"0 1.57 0\"/> <! è¿™æ˜¯è¿æ¥çš„å…³é”® > <! axis: å®šä¹‰æ—‹è½¬è½´ï¼ˆåœ¨å…³èŠ‚åæ ‡ç³»ä¸‹ï¼‰ > <axis xyz \"0 1 0\"/> <! è¿™æ˜¯è¿åŠ¨çš„å…³é”® > <! limit: å®šä¹‰å…³èŠ‚è¿åŠ¨é™åˆ¶ (å¯¹åŠŸèƒ½æè¿°å¾ˆé‡è¦) > <limit lower \" 1.57\" upper \"1.57\" effort \"35\" velocity \"1\"/> </joint> <! Joint: è¿æ¥ jian1 å’Œ jian2 > <joint name \"Rotation3\" type \"revolute\"> <! å…³èŠ‚åç§°å’Œç±»å‹ï¼ˆæ—‹è½¬ï¼‰ > <parent link \"jian1\"/> <! çˆ¶è¿æ† > <child link \"jian2\"/> <! å­è¿æ† > <! origin: å®šä¹‰å­è¿æ†åæ ‡ç³»åŸç‚¹ç›¸å¯¹äºçˆ¶è¿æ†åæ ‡ç³»åŸç‚¹çš„å˜æ¢ > <origin xyz \"0 0 0.118\" rpy \"0 0 0\"/> <! è¿™æ˜¯è¿æ¥çš„å…³é”® > <! axis: å®šä¹‰æ—‹è½¬è½´ï¼ˆåœ¨å…³èŠ‚åæ ‡ç³»ä¸‹ï¼‰ > <axis xyz \"0 1 0\"/> <! è¿™æ˜¯è¿åŠ¨çš„å…³é”® > <! limit: å®šä¹‰å…³èŠ‚è¿åŠ¨é™åˆ¶ (å¯¹åŠŸèƒ½æè¿°å¾ˆé‡è¦) > <limit lower \" 1.57\" upper \"1.57\" effort \"35\" velocity \"1\"/> </joint> <! Joint: è¿æ¥ jian2 å’Œ wan > <joint name \"Rotation4\" type \"revolute\"> <! å…³èŠ‚åç§°å’Œç±»å‹ï¼ˆæ—‹è½¬ï¼‰ > <parent link \"jian2\"/> <! çˆ¶è¿æ† > <child link \"wan\"/> <! å­è¿æ† > <! origin: å®šä¹‰å­è¿æ†åæ ‡ç³»åŸç‚¹ç›¸å¯¹äºçˆ¶è¿æ†åæ ‡ç³»åŸç‚¹çš„å˜æ¢ > <origin xyz \"0 0 0.118\" rpy \"0 0 0\"/> <! è¿™æ˜¯è¿æ¥çš„å…³é”® > <! axis: å®šä¹‰æ—‹è½¬è½´ï¼ˆåœ¨å…³èŠ‚åæ ‡ç³»ä¸‹ï¼‰ > <axis xyz \"0 1 0\"/> <! è¿™æ˜¯è¿åŠ¨çš„å…³é”® > <! limit: å®šä¹‰å…³èŠ‚è¿åŠ¨é™åˆ¶ (å¯¹åŠŸèƒ½æè¿°å¾ˆé‡è¦) > <limit lower \" 1.57\" upper \"1.57\" effort \"35\" velocity \"1\"/> </joint> <! Joint: è¿æ¥ wan å’Œ wan2 > <joint name \"Rotation5\" type \"revolute\"> <! å…³èŠ‚åç§°å’Œç±»å‹ï¼ˆæ—‹è½¬ï¼‰ > <parent link \"wan\"/> <! çˆ¶è¿æ† > <child link \"wan2\"/> <! å­è¿æ† > <! origin: å®šä¹‰å­è¿æ†åæ ‡ç³»åŸç‚¹ç›¸å¯¹äºçˆ¶è¿æ†åæ ‡ç³»åŸç‚¹çš„å˜æ¢ > <origin xyz \"0 0 0.0635\" rpy \"0 0 0\"/> <! è¿™æ˜¯è¿æ¥çš„å…³é”® > <! axis: å®šä¹‰æ—‹è½¬è½´ï¼ˆåœ¨å…³èŠ‚åæ ‡ç³»ä¸‹ï¼‰ > <axis xyz \"0 0 1\"/> <! è¿™æ˜¯è¿åŠ¨çš„å…³é”® > <! limit: å®šä¹‰å…³èŠ‚è¿åŠ¨é™åˆ¶ (å¯¹åŠŸèƒ½æè¿°å¾ˆé‡è¦) > <limit lower \" 1.57\" upper \"1.57\" effort \"35\" velocity \"1\"/> </joint> <! Joint: è¿æ¥ wan2 å’Œ zhua > <joint name \"Rotation6\" type \"revolute\"> <! å…³èŠ‚åç§°å’Œç±»å‹ï¼ˆæ—‹è½¬ï¼‰ > <parent link \"wan2\"/> <! çˆ¶è¿æ† > <child link \"zhua\"/> <! å­è¿æ† > <! origin: å®šä¹‰å­è¿æ†åæ ‡ç³»åŸç‚¹ç›¸å¯¹äºçˆ¶è¿æ†åæ ‡ç³»åŸç‚¹çš„å˜æ¢ > <origin xyz \"0 0.0132 0.021\" rpy \"0 0 0\"/> <! è¿™æ˜¯è¿æ¥çš„å…³é”® > <! axis: å®šä¹‰æ—‹è½¬è½´ï¼ˆåœ¨å…³èŠ‚åæ ‡ç³»ä¸‹ï¼‰ > <axis xyz \"1 0 0\"/> <! è¿™æ˜¯è¿åŠ¨çš„å…³é”® > <! limit: å®šä¹‰å…³èŠ‚è¿åŠ¨é™åˆ¶ (å¯¹åŠŸèƒ½æè¿°å¾ˆé‡è¦) > <limit lower \"0\" upper \"1.57\" effort \"35\" velocity \"1\"/> </joint> </robot> ```"},"/note/æœºå™¨å­¦ä¹ /å…·èº«æ™ºèƒ½/2026-2-3-03-å§¿æ€è§£ç®—.html":{"title":"å§¿æ€è§£ç®—","content":"# å§¿æ€è§£ç®— äºŒç»´çš„æœºæ¢°è‡‚çš„å§¿æ€è§£ç®—å®é™…å¯ä»¥ç†è§£ä¸ºåæ ‡ç³»çš„æ—‹è½¬, æ—‹è½¬ä»¥ååœ¨xè½´ä¸Šé¢è¿›è¡Œå¹³ç§», è¿™ä¸ªå˜åŒ–å¯ä»¥ä½¿ç”¨ä¸€ä¸ªæ—‹è½¬å¹³ç§»çŸ©é˜µå®ç° ```bash [cos(x), sin(x), x] [sin(x), cos(x), y] [ 0, 0, 1] ``` è¿™é‡Œçš„xæŒ‡çš„æ˜¯å½“å‰çš„è¿™ä¸ªæ†ç›¸å¯¹äºå‰ä¸€ä¸ªæ†çš„è§’åº¦, ä»¥åŠåœ¨ä¹‹å‰çš„é‚£ä¸ªæ†ç›¸åŒè§’åº¦å’Œå‚ç›´è§’åº¦çš„å¹³ç§» ä¸‰ç»´çš„å˜åŒ–èµ·å§‹ä¹Ÿæ˜¯å·®ä¸å¤šçš„, ä½¿ç”¨ä¸‰ä¸ªäºŒç»´çš„çŸ©é˜µåˆèµ·æ¥å¯ä»¥è·å–ä¸€ä¸ªä¸‰ç»´çš„å˜åŒ–çŸ©é˜µ + é€†è¿ç®— å®é™…ä½¿ç”¨å¤§éƒ¨åˆ†éœ€è¦æ˜¯é€†è¿ç®—, å·²çŸ¥ä¸€ä¸ªä½ç½®, å¦‚ä½•åˆ°è¾¾å¯¹åº”ä½ç½® å¯èƒ½æ²¡æœ‰è§£, å¤šä¸ªè§£, ä¸€ä¸ªè§£ç­‰, å®é™…è¿ç®—çš„æ—¶å€™, å¯ä»¥ç”»åœ†å»è§£ > å®é™…è¿åŠ¨çš„æ—¶å€™ä¼šå‡ºç°å¥‡å¼‚ç‚¹, ä¸€èˆ¬æ˜¯åœ¨è¾¹ç•Œçš„ä½ç½®, åœ¨æŸä¸ªä½ç½®çš„æ—¶å€™, æŸä¸ªè½´çš„ç§»åŠ¨æ˜¯ä¸å¯èƒ½çš„, æ¯”å¦‚èƒ³è†Šä¼¸ç›´çš„æ—¶å€™, ä¸èƒ½å†å»¶é•¿, åœ¨è®¡ç®—çš„æ—¶å€™ä¼šå‡ºé—®é¢˜, ç«™ç›´çš„æœºå™¨äººä¸€èˆ¬è…¿ä¹Ÿä¸æ˜¯ç›´çš„ ä¸€èˆ¬çš„è¿ç®—æ–¹æ³•æœ‰ä¸¤ç§, è§£ææ³•ä½¿ç”¨ä¸‰è§’å‡½æ•°å»è¿ç®—, å¦ä¸€ç§æ˜¯æ•°å€¼æ³•, å‡å®šä¸€ä¸ªåˆå§‹çš„è§’åº¦, ç®—å‡ºæ¥æœ«å°¾çš„ä½ç½®, ä¹‹åé€šè¿‡å¾®è°ƒçš„æ–¹å¼è¿­ä»£æˆ–è€…ä½¿ç”¨ç©·ä¸¾çš„å½¢å¼ æ¯”è¾ƒå¸¸ç”¨çš„æ˜¯æ¢¯åº¦ä¸‹é™çš„æ–¹å¼, åœ¨å¥‡å¼‚ç‚¹ä¼šå‡ºé”™"},"/note/æœºå™¨å­¦ä¹ /å…·èº«æ™ºèƒ½/2026-2-4-04-SO-ARM101.html":{"title":"","content":""},"/note/æœºå™¨å­¦ä¹ /åµŒå…¥å¼ç§»æ¤/00ç»†èŠ.html":{"title":"","content":"[ã€åµŒå…¥å¼AIå¼€å‘ã€‘ç¯‡ä¸€ç†è®ºç¯‡ï¼šSTM32ä¸Šéƒ¨ç½²ç¥ç»ç½‘ç»œä¹‹ç†è®ºç¯‡](https://mp.weixin.qq.com/s?__biz Mzg2NTY1OTA3Nw &mid 2247484170&idx 1&sn e6692903c377c3b2c1c53f17d4047adb&chksm ce57f2a0f9207bb69f0e09b07bd0dd127bc04e99a80d3a49ea013734e24adc9f7c931571b30c&scene 21#wechat_redirect)"},"/note/æœºå™¨å­¦ä¹ /åµŒå…¥å¼ç§»æ¤/2025-12-18-01-æ¨¡å‹é‡åŒ–.html":{"title":"æ¨¡å‹é‡åŒ–","content":"# æ¨¡å‹é‡åŒ– [(83 å°ç§ä¿¡ / 80 æ¡æ¶ˆæ¯) ç»ˆäºæœ‰äººæŠŠæ¨¡å‹è½¬æ¢ä¸è®­ç»ƒåé‡åŒ–éƒ¨ç½²è®²æ˜ç™½äº† çŸ¥ä¹](https://zhuanlan.zhihu.com/p/673488601)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-10-33é•¿çŸ­æœŸè®°å¿†LSTM.html":{"title":"é•¿çŸ­æœŸè®°å¿†LSTM","content":"# é•¿çŸ­æœŸè®°å¿†LSTM + å¿˜è®°é—¨: å€¼å‘0å‡å°‘ + è¾“å…¥é—¨: çœ‹æ˜¯ä¸æ˜¯å¿½ç•¥è¾“å…¥ + è¾“å‡ºé—¨: å†³å®šæ˜¯ä¸æ˜¯ä½¿ç”¨éšçŠ¶æ€ ![image 20250210164218122](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502101642218.png) > è¿™ä¸‰ä¸ªé—¨çš„å€¼éƒ½åœ¨(0,1)çš„èŒƒå›´å†… ![image 20250210164306755](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502101643807.png) > ç”±äºè¿˜æ²¡æœ‰æŒ‡å®šå„ç§é—¨çš„æ“ä½œï¼Œæ‰€ä»¥å…ˆä»‹ç»å€™é€‰è®°å¿†å…ƒï¼ˆcandidatememorycellï¼‰Ëœ C~t~ âˆˆRnÃ— hã€‚å®ƒçš„è®¡ç®—ä¸ ä¸Šé¢æè¿°çš„ä¸‰ä¸ªé—¨çš„è®¡ç®—ç±»ä¼¼ï¼Œä½†æ˜¯ä½¿ç”¨tanhå‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå‡½æ•°çš„å€¼èŒƒå›´ä¸º(âˆ’1,1)ã€‚ ![image 20250210164451051](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502101644121.png) > å®é™…å®ç°çš„æœ‰ä¸¤ä¸ªçŠ¶æ€, ä¸€ä¸ªæ˜¯Cå¦ä¸€ä¸ªæ˜¯H > > ![image 20250210164758777](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502101647819.png) ![image 20250210164903487](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502101649527.png) > è¿™é‡Œä½¿ç”¨tanhçš„ä½œç”¨æ˜¯æŠŠæ•°å€¼å›å½’åˆ°(+1 ~ 1)ä¹‹é—´ > > ![image 20250210164910398](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502101649436.png) ![image 20250210165517848](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502101655903.png) Cå¯ä»¥ç†è§£ä¸ºä¸€ä¸ªæ²¡æœ‰è¢«normalizeçš„ä¸€ä¸ªæ¯”è¾ƒå¤§çš„æ•°å€¼, ç”¨äºè¾…åŠ©è®°å¿†, åŒæ—¶è¾“å‡ºé—¨å¯ä»¥æ§åˆ¶æ˜¯ä¸æ˜¯ä½¿ç”¨è¿™ä¸€éƒ¨åˆ†çš„æ•°æ® ## ä»£ç å®ç° ```python import torch from torch import nn from d2l import torch as d2l batch_size, num_steps 32, 35 train_iter, vocab d2l.load_data_time_machine(batch_size, num_steps) ``` åˆå§‹åŒ–å‚æ•° ```python def get_lstm_params(vocab_size, num_hiddens, device): num_inputs num_outputs vocab_size def normal(shape): return torch.randn(size shape, device device)*0.01 def three(): return (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device device)) W_xi, W_hi, b_i three() # è¾“å…¥é—¨å‚æ•° W_xf, W_hf, b_f three() # é—å¿˜é—¨å‚æ•° W_xo, W_ho, b_o three() # è¾“å‡ºé—¨å‚æ•° W_xc, W_hc, b_c three() # å€™é€‰è®°å¿†å…ƒå‚æ•° # è¾“å‡ºå±‚å‚æ•° W_hq normal((num_hiddens, num_outputs)) b_q torch.zeros(num_outputs, device device) # é™„åŠ æ¢¯åº¦ params [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] for param in params: param.requires_grad_(True) return params ``` åˆå§‹åŒ–çŠ¶æ€ ```python # åˆå§‹åŒ–çš„æ—¶å€™éœ€è¦åˆå§‹åŒ–Hå’ŒC def init_lstm_state(batch_size, num_hiddens, device): return (torch.zeros((batch_size, num_hiddens), device device), torch.zeros((batch_size, num_hiddens), device device)) ``` å¼€å§‹è®¡ç®— ![image 20250210183947804](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502101839950.png) ```python def lstm(inputs, state, params): [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] params (H, C) state outputs [] for X in inputs: I torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i) F torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f) O torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o) C_tilda torch.tanh((X @ W_xc) + (H @ W_hc) + b_c) C F * C + I * C_tilda H O * torch.tanh(C) Y (H @ W_hq) + b_q outputs.append(Y) return torch.cat(outputs, dim 0), (H, C) ``` å¼€å§‹è®­ç»ƒ ```python vocab_size, num_hiddens, device len(vocab), 256, d2l.try_gpu() num_epochs, lr 500, 1 model d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_lstm_params, init_lstm_state, lstm) d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) ``` ![image 20250210195400592](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502101954663.png) ç®€å•å®ç° ```python num_inputs vocab_size lstm_layer nn.LSTM(num_inputs, num_hiddens) model d2l.RNNModel(lstm_layer, len(vocab)) model model.to(device) d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) ``` ![image 20250210185404160](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502101854248.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-16-èŠ¯ç‰‡.html":{"title":"èŠ¯ç‰‡","content":"# èŠ¯ç‰‡ ## DSPæ•°å­—ä¿¡å·å¤„ç† å¤„ç†æ•°å­—ä¿¡å·, ç‚¹ç§¯, å·ç§¯, FFT ä½åŠŸè€—, é«˜æ€§èƒ½, æ¯”ç§»åŠ¨GPUçš„åŠŸè€—ä»¥åŠæ€§èƒ½éƒ½è¦å¿«, ä½¿ç”¨Very long instruction word, ä¸€æ¡æŒ‡ä»¤å¯ä»¥å¤„å‡ ç™¾ä¸ªåŠ æ³• ä½†æ˜¯è°ƒè¯•ä»¥åŠç¼–ç¨‹æ¯”è¾ƒå›°éš¾, ç¼–è¯‘å™¨è‰¯è ä¸é½ ## FPGAå¯ç¼–ç¨‹é˜µåˆ— å¤§é‡çš„è¿æ¥ä»¥åŠé€»è¾‘å•å…ƒæ˜¯å¯ä»¥æ”¹å˜çš„ å¯ä»¥è®¾è®¡ä¸ºè®¡ç®—å¤æ‚çš„å‡½æ•°, é€šå¸¸æ¯”é€šç”¨çš„ç¡¬ä»¶æ›´åŠ é«˜æ•ˆ, ä½†æ˜¯å·¥å…·é“¾è‰¯è ä¸é½ä»¥åŠç¼–è¯‘çš„æ—¶é—´é•¿ é€šå¸¸ä½¿ç”¨ä½œä¸ºæ¨¡æ‹Ÿ ## AI ASIC ç”¨äºAIçš„å•ç‹¬çš„èŠ¯ç‰‡, æ¯”è¾ƒçƒ­é—¨çš„æ˜¯Goole TPU, åœ¨Googleé‡Œé¢å¤§éƒ¨åˆ†ä½¿ç”¨, æ ¸å¿ƒä½¿ç”¨çš„æ˜¯systolic arrayç”¨äºåšçŸ©é˜µè¿ç®— systolic arrayæ˜¯PE(è®¡ç®—å•å…ƒ)çš„é˜µåˆ—(äºŒç»´), ç‰¹åˆ«æ—¶å€™çŸ©é˜µä¹˜æ³•, è®¾è®¡ä»¥åŠåˆ¶é€ æ¯”è¾ƒç®€å•"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-14-19GoogLeNet.html":{"title":"GoogLeNetå«å¹¶è¡Œè¿ç»“çš„ç½‘ç»œ","content":"# GoogLeNetå«å¹¶è¡Œè¿ç»“çš„ç½‘ç»œ ![image 20250114174431978](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141744148.png) ä¸»è¦ä½¿ç”¨çš„æ˜¯Inceptionå—, ä»ä¸åŒçš„å±‚æ¬¡é‡Œé¢æŠ½å–ä¿¡æ¯, ä¹‹ååœ¨è¾“å‡ºçš„é€šé“é‡Œé¢è¿›è¡Œåˆå¹¶ ![image 20250114174725817](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141747878.png) è¾“å…¥è¢«å¤åˆ¶ä¸º4ä»½, é€šè¿‡å››æ¡è·¯åœ¨è¾“å‡ºçš„é€šé“è¿›è¡Œåˆå¹¶ ![image 20250114175114862](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141751965.png) > ä¸­é—´ä¸¤ä¸ªä¸ºäº†åŠ å¿«å·ç§¯çš„è¿ç®—, ä»¥åŠå‡å°‘å‚æ•°, æ‰€ä»¥æå‰é™ä½ç»´åº¦(ç™½è‰²çš„ç”¨äºæ”¹å˜é€šé“æ•°, è“è‰²çš„ç”¨äºæŠ½å–æ•°æ®) > > å®é™…åšçš„æ˜¯ä¸€ä¸ªæŠŠ196å˜ä¸º256ç»´, åŒæ—¶ä¸åŒçš„è·¯å¾„ä»£è¡¨æƒé‡ > > å¤šç»´çš„å¯ä»¥çœ‹ç©ºé—´ä¿¡æ¯, ä¸€ç»´çš„åªå…³æ³¨é€šé“ä¿¡æ¯ å’Œåªä½¿ç”¨3x3æˆ–5x5åšåˆ°æ‰©å¤§ç»´åº¦, è¿™ä¸€ä¸ªä½¿ç”¨çš„å‚æ•°æ›´å°‘ ![image 20250114175703265](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141757345.png) ![image 20250114180005688](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141800753.png) > æ¯ä¸€ä¸ªæ¡†é«˜å’Œå®½å‡åŠ, æœ€åä½¿ç”¨ä¸€ä¸ªå…¨è¿æ¥å±‚è¿›è¡Œæ˜ å°„(æ›´åŠ çµæ´»çš„è¾“å‡ºä¸ªæ•°) å’ŒAlexNetå¯¹æ¯” ![image 20250114181454110](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141814211.png) ![image 20250114181704816](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141817925.png) ![image 20250114181916180](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141819289.png) > ä»¥ä¸ŠInceptionçš„æ˜¯V1, ä¹‹åæœ‰å¾ˆå¤šçš„å˜ç§ > > v2ä½¿ç”¨batch normalization > > v3æ”¹äº†Inceptionå— > > + 5x5æ”¹ä¸ºå¤šä¸ª3x3å·ç§¯å±‚ > + 5x5æ”¹ä¸º1x7å’Œ7x1å·ç§¯å±‚ > + 3x3æ”¹ä¸º1x3å’Œ3x1å·ç§¯å±‚ > + æ›´æ·± > > ![image 20250114182750524](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141827603.png) > > ![image 20250114182846345](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141828455.png) > > ![image 20250114182919797](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141829903.png) > > v4ä½¿ç”¨æ®‹å·®é“¾æ¥ ## ä»£ç å®ç° ```python import torch from torch import nn from d2l import torch as d2l from torch.nn import functional as F ``` + å®ç°ä¸€ä¸ªInception, å¯ä»¥ä½¿ç”¨å‡½æ•°çš„è¾“å‡ºåå‚æ•°è®¾ç½®æ¯ä¸€çº¿è·¯çš„è¾“å‡º ```python class Inception(nn.Module): def __init__(self, in_channels, c1, c2, c3, c4): super(Inception, self).__init__() self.p1_1 nn.Conv2d(in_channels, c1, kernel_size 1) self.p2_1 nn.Conv2d(in_channels, c2[0], kernel_size 1) self.p2_2 nn.Conv2d(c2[0], c2[1], kernel_size 3, padding 1) self.p3_1 nn.Conv2d(in_channels, c3[0], kernel_size 1) self.p3_2 nn.Conv2d(c3[0], c3[1], kernel_size 5, padding 2) self.p4_1 nn.MaxPool2d(kernel_size 3, stride 1, padding 1) self.p4_2 nn.Conv2d(in_channels, c4, kernel_size 1) def forward(self, x): p1 F.relu(self.p1_1(x)) p2 F.relu(self.p2_2(F.relu(self.p2_1(x)))) p3 F.relu(self.p3_2(F.relu(self.p3_1(x)))) p4 F.relu(self.p4_2(self.p4_1(x))) return torch.cat((p1, p2, p3, p4), dim 1) ``` + å®ç°ä»¥ä¸‹GooLeNet ```python b1 nn.Sequential(nn.Conv2d(1, 64, kernel_size 7, stride 2, padding 3), nn.ReLU(), nn.MaxPool2d(kernel_size 3, stride 2, padding 1)) b2 nn.Sequential(nn.Conv2d(64, 64, kernel_size 1), nn.ReLU(), nn.Conv2d(64, 192, kernel_size 3, padding 1), nn.MaxPool2d(kernel_size 3, stride 2, padding 1)) b3 nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32), Inception(256, 128, (128, 192), (32, 96), 64), nn.MaxPool2d(kernel_size 3, stride 2, padding 1)) b4 nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64), Inception(512, 160, (112, 224), (24, 64), 64), Inception(512, 128, (128, 256), (24, 64), 64), Inception(512, 112, (144, 288), (32, 64), 64), Inception(528, 256, (160, 320), (32, 128), 128), nn.MaxPool2d(kernel_size 3, stride 2, padding 1)) b5 nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128), Inception(832, 384, (192, 384), (48, 128), 128), nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten()) net nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10)) ``` + å®é™…çš„æµ‹è¯•, è®¡ç®—é‡å¤ªå¤§äº†æ‰€ä»¥è¿™é‡Œä½¿ç”¨96çš„å›¾åƒ ```python X torch.rand(size (1, 1, 96, 96)) for layer in net: X layer(X) print(layer.__class__.__name__, 'output shape:\\t', X.shape) \"\"\" Sequential output shape:\t torch.Size([1, 64, 24, 24]) Sequential output shape:\t torch.Size([1, 192, 12, 12]) Sequential output shape:\t torch.Size([1, 480, 6, 6]) Sequential output shape:\t torch.Size([1, 832, 3, 3]) Sequential output shape:\t torch.Size([1, 1024]) Linear output shape:\t torch.Size([1, 10]) \"\"\" ``` + æ•°æ®é›†æµ‹è¯• ```python lr, num_epochs, batch_size 0.1, 10, 128 train_iter, test_iter d2l.load_data_fashion_mnist(batch_size, resize 96) d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) ``` ![image 20250114191552129](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141915209.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-15-43Transformer.html":{"title":"Transformer","content":"# Transformer å®é™…æ˜¯ä¸€ä¸ªSequence to sequence, è¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯ä¸€ä¸ªsequence, è¾“å‡ºçš„é•¿åº¦æ˜¯ä¸ä¸€å®šçš„, ä½¿ç”¨çº¯æ³¨æ„åŠ›æœºåˆ¶ å¦‚æœæŠŠä¸€ä¸ªæ ‘çŠ¶çš„åºåˆ—ä½¿ç”¨å¤šä¸ªæ‹¬å·è¿›è¡Œåˆ†å±‚ç”šè‡³å¯ä»¥ä½¿ç”¨ç”¨è¿™ç§æ–¹å¼è¿›è¡Œæ ‘çŠ¶çš„å¤„ç† Transformerå®é™…ä½¿ç”¨çš„è¿˜æ˜¯encoderå’Œdecoderä¸¤ä¸ªçš„æ¶æ„ ## encoder ![image 20250215162322779](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151623907.png) transformeré‡Œé¢Attentionä»¥åè¿˜è®°å½•æœ‰åŸæ•°æ®, ä¹‹åè¿›è¡Œä¸€ä¸‹norm(Layer Normè®¡ç®—å¹³å‡å€¼å’Œæ ‡å‡†å·®ä¹‹åæ ‡å‡†åŒ–) ![image 20250215162748331](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151627428.png) ![image 20250215163015346](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151630389.png) å‰é¦ˆå…¨è¿æ¥å±‚ï¼ˆfeed forward linear layerï¼‰åŸºæœ¬ä¸Šå°±æ˜¯ä¸€å †ç¥ç»å…ƒï¼Œæ¯ä¸ªç¥ç»å…ƒéƒ½ä¸å…¶ä»–ç¥ç»å…ƒç›¸è¿æ¥ã€‚ä½†æ˜¯è¾“å…¥æ˜¯(b, n, d)çš„ä¸€ä¸ªç½‘ç»œ, è¾“å…¥æ—¶å€™éœ€è¦å˜åŒ–ä¸º(bn, d)ç„¶åä½¿ç”¨ä¸¤ä¸ªå…¨è¿æ¥å±‚, è¾“å‡ºçš„å½¢çŠ¶å†å˜å›(b, n, d), è¿™ä¹ˆåšæ˜¯ä¸ºäº†å·ç§¯å¯ä»¥å¤„ç† ![image 20250215163758449](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151637562.png) å‰é¦ˆå…¨è¿æ¥å±‚çš„è¾“å…¥æ•°æ®åªå‘å‰ä¼ æ’­ï¼Œæ²¡æœ‰åå‘ä¼ æ’­ã€‚æ¯ä¸ªç¥ç»å…ƒçš„è¾“å‡ºæ˜¯å‰ä¸€å±‚æ‰€æœ‰ç¥ç»å…ƒçš„è¾“å…¥ç»è¿‡æƒé‡åŠ æƒæ±‚å’Œåå†åŠ ä¸Šåç½®é¡¹ï¼Œç„¶åç»è¿‡æ¿€æ´»å‡½æ•°å¾—åˆ°çš„ç»“æœã€‚ å‰é¦ˆå…¨è¿æ¥å±‚å’Œå…¨è¿æ¥å±‚çš„ä¸»è¦åŒºåˆ«åœ¨äºå‰è€…æ˜¯ä¸€ç§ç‰¹æ®Šçš„å…¨è¿æ¥ç»“æ„ï¼Œæ¯ä¸ªç¥ç»å…ƒçš„è¾“å…¥åªæ¥è‡ªä¸Šä¸€å±‚çš„ç¥ç»å…ƒï¼Œä¸åŒ…æ‹¬ç½‘ç»œå†…éƒ¨çš„åé¦ˆè¿æ¥ã€‚è€Œå…¨è¿æ¥å±‚æ˜¯ä¸€ç§é€šç”¨çš„è¿æ¥ç»“æ„ï¼Œæ¯ä¸ªç¥ç»å…ƒéƒ½ä¸ä¸Šä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒæœ‰è¿æ¥ï¼Œå¯ä»¥åŒ…æ‹¬åé¦ˆè¿æ¥ã€‚ ```python #@save class PositionWiseFFN(nn.Module): \"\"\"åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ\"\"\" def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs): super(PositionWiseFFN, self).__init__(**kwargs) self.dense1 nn.Linear(ffn_num_input, ffn_num_hiddens) self.relu nn.ReLU() self.dense2 nn.Linear(ffn_num_hiddens, ffn_num_outputs) def forward(self, X): return self.dense2(self.relu(self.dense1(X))) ffn PositionWiseFFN(4, 4, 8) ffn.eval() \"\"\" PositionWiseFFN( (dense1): Linear(in_features 4, out_features 4, bias True) (relu): ReLU() (dense2): Linear(in_features 4, out_features 8, bias True) ) \"\"\" # è¾“å…¥æ˜¯4, è¾“å‡ºæ˜¯8, å®é™…æ˜¯å¯¹è¾“å…¥çš„æ¯ä¸ªå…ƒç´ åº”ç”¨äº†ä¸€ä¸ªå…¨è¿æ¥ç½‘ç»œ ffn(torch.ones((2, 3, 4))).shape \"\"\" torch.Size([2, 3, 8]) \"\"\" ``` å½’ä¸€åŒ–å±‚æ˜¯å¯¹æ¯ä¸€ä¸ªç‰¹å¾åšä¸€ä¸ªå½’ä¸€åŒ–, å› ä¸ºéšç€è¾“å…¥çš„å˜åŒ–, è¿™é‡Œçš„å¤§å°ä¼šå˜åŒ– ```python ln nn.LayerNorm(2) bn nn.BatchNorm1d(2) X torch.tensor([[1, 2], [2, 3]], dtype torch.float32) # åœ¨è®­ç»ƒæ¨¡å¼ä¸‹è®¡ç®—Xçš„å‡å€¼å’Œæ–¹å·® print('layer norm:', ln(X), '\\nbatch norm:', bn(X)) \"\"\" layer norm: tensor([[ 1.0000, 1.0000], [ 1.0000, 1.0000]], grad_fn <NativeLayerNormBackward0>) batch norm: tensor([[ 1.0000, 1.0000], [ 1.0000, 1.0000]], grad_fn <NativeBatchNormBackward0>) \"\"\" ``` ```python #@save class AddNorm(nn.Module): \"\"\"æ®‹å·®è¿æ¥åè¿›è¡Œå±‚è§„èŒƒåŒ–\"\"\" def __init__(self, normalized_shape, dropout, **kwargs): super(AddNorm, self).__init__(**kwargs) self.dropout nn.Dropout(dropout) self.ln nn.LayerNorm(normalized_shape) def forward(self, X, Y): return self.ln(self.dropout(Y) + X) add_norm AddNorm([3, 4], 0.5) add_norm.eval() add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape \"\"\" torch.Size([2, 3, 4]) \"\"\" ``` ### å®ç° ```python #@save class EncoderBlock(nn.Module): \"\"\"Transformerç¼–ç å™¨å—\"\"\" def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias False, **kwargs): super(EncoderBlock, self).__init__(**kwargs) self.attention MultiHeadAttention( key_size, query_size, value_size, num_hiddens, num_heads, dropout, use_bias) self.addnorm1 AddNorm(norm_shape, dropout) self.ffn PositionWiseFFN( ffn_num_input, ffn_num_hiddens, num_hiddens) self.addnorm2 AddNorm(norm_shape, dropout) def forward(self, X, valid_lens): # ä½¿ç”¨ä¸‰ä¸ªXæ‰§è¡Œè‡ªæ³¨æ„åŠ› Y self.addnorm1(X, self.attention(X, X, X, valid_lens)) return self.addnorm2(Y, self.ffn(Y)) # batch_size 2, seq_len 100, embed_size 24 # transformerå®é™…ä¸ä¼šæ”¹å˜è¾“å…¥çš„å½¢çŠ¶ X torch.ones((2, 100, 24)) valid_lens torch.tensor([3, 2]) encoder_blk EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5) encoder_blk.eval() encoder_blk(X, valid_lens).shape \"\"\" torch.Size([2, 100, 24]) \"\"\" #@save class TransformerEncoder(d2l.Encoder): \"\"\"Transformerç¼–ç å™¨\"\"\" def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, use_bias False, **kwargs): super(TransformerEncoder, self).__init__(**kwargs) self.num_hiddens num_hiddens self.embedding nn.Embedding(vocab_size, num_hiddens) self.pos_encoding d2l.PositionalEncoding(num_hiddens, dropout) self.blks nn.Sequential() for i in range(num_layers): self.blks.add_module(\"block\"+str(i), EncoderBlock(key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias)) def forward(self, X, valid_lens, *args): # å› ä¸ºä½ç½®ç¼–ç å€¼åœ¨ 1å’Œ1ä¹‹é—´ï¼Œ # å› æ­¤åµŒå…¥å€¼ä¹˜ä»¥åµŒå…¥ç»´åº¦çš„å¹³æ–¹æ ¹è¿›è¡Œç¼©æ”¾ï¼Œ # ç„¶åå†ä¸ä½ç½®ç¼–ç ç›¸åŠ ã€‚ X self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens)) self.attention_weights [None] * len(self.blks) for i, blk in enumerate(self.blks): X blk(X, valid_lens) self.attention_weights[i] blk.attention.attention.attention_weights return X encoder TransformerEncoder( 200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5) encoder.eval() encoder(torch.ones((2, 100), dtype torch.long), valid_lens).shape \"\"\" torch.Size([2, 100, 24]) \"\"\" ``` ## Decoder æ¯”è¾ƒç»å¸¸ä½¿ç”¨çš„æ˜¯Autoregressive, å®é™…çš„å·¥ä½œæ˜¯æ”¶å–encoderçš„è¾“å…¥ä»¥å, æä¾›ç»™ä»–ä¸€ä¸ªå¼€å§‹çš„æç¤º, è®©ä»–è¿›è¡Œè¾“å‡º, å¹¶æŠŠæ¯ä¸€æ¬¡çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€æ¬¡çš„æç¤ºè¯ ![image 20250215165756411](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151657467.png) è¿™é‡Œä½¿ç”¨çš„Masked Multi Head Attentionæ¯ä¸€ä¸ªæ•°æ®åœ¨è®¡ç®—å…³ç³»çš„æ—¶å€™åªå¯ä»¥ä½¿ç”¨ä¹‹å‰çš„æ•°æ® ![image 20250215165937601](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151659722.png) ![image 20250215170116909](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151701966.png) Non autoregressive(NAT) ![image 20250215171659559](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151716642.png) å¯ä»¥ä½¿ç”¨encoderçš„è¾“å‡ºä½¿ç”¨å¦ä¸€ä¸ªç½‘ç»œè®¡ç®—ä¸€ä¸‹ä½¿ç”¨çš„BEGINçš„æ•°é‡, ä¹Ÿå¯ä»¥ç›´æ¥ç»™ä»–å¾ˆå¤šçš„BEGIN, æ‰¾å‡ºæ¥ç¬¬ä¸€ä¸ªç»“æŸç¬¦å·, è¿™ä¸ªæ–¹å¼çš„ä½¿ç”¨éœ€è¦å’ŒSelf Attentionè¿›è¡Œé…åˆ > é€Ÿåº¦æ›´å¿«, ä½†æ˜¯å’ŒATçš„æ¯”å®é™…çš„æ•ˆæœæ¯”è¾ƒå·® + ä¸¤ä¸ªéƒ¨åˆ†ä¼ é€’ä¿¡æ¯ ![image 20250215172221189](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151722253.png) ![image 20250215172442107](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151724196.png) > åŸå§‹çš„paperé‡Œé¢ä½¿ç”¨çš„éƒ½æ˜¯æœ€åä¸€æ¬¡çš„è¾“å‡º, ä½†æ˜¯å®é™…å¯ä»¥ä½¿ç”¨å¤šç§ä¸åŒçš„è¿æ¥æ–¹å¼ ```python class DecoderBlock(nn.Module): \"\"\"è§£ç å™¨ä¸­ç¬¬iä¸ªå—, ç”¨äºè§£ç åºåˆ—\"\"\" def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, i, **kwargs): super(DecoderBlock, self).__init__(**kwargs) self.i i self.attention1 MultiHeadAttention( key_size, query_size, value_size, num_hiddens, num_heads, dropout) self.addnorm1 AddNorm(norm_shape, dropout) self.attention2 MultiHeadAttention( key_size, query_size, value_size, num_hiddens, num_heads, dropout) self.addnorm2 AddNorm(norm_shape, dropout) self.ffn PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens) self.addnorm3 AddNorm(norm_shape, dropout) def forward(self, X, state): enc_outputs, enc_valid_lens state[0], state[1] # è®­ç»ƒé˜¶æ®µï¼Œè¾“å‡ºåºåˆ—çš„æ‰€æœ‰è¯å…ƒéƒ½åœ¨åŒä¸€æ—¶é—´å¤„ç†ï¼Œ # å› æ­¤state[2][self.i]åˆå§‹åŒ–ä¸ºNoneã€‚ # é¢„æµ‹é˜¶æ®µï¼Œè¾“å‡ºåºåˆ—æ˜¯é€šè¿‡è¯å…ƒä¸€ä¸ªæ¥ç€ä¸€ä¸ªè§£ç çš„ï¼Œ # å› æ­¤state[2][self.i]åŒ…å«ç€ç›´åˆ°å½“å‰æ—¶é—´æ­¥ç¬¬iä¸ªå—è§£ç çš„è¾“å‡ºè¡¨ç¤º if state[2][self.i] is None: key_values X # è¿™æ˜¯åœ¨è®­ç»ƒé˜¶æ®µ, ç›´æ¥ä½¿ç”¨X else: # åœ¨é¢„æµ‹é˜¶æ®µï¼Œå°†state[2][self.i]çš„å½¢çŠ¶å˜æ¢ä¸º # (batch_size, i, num_hiddens)ï¼Œå¹¶å°†å…¶æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œ key_values torch.cat((state[2][self.i], X), axis 1) state[2][self.i] key_values if self.training: batch_size, num_steps, _ X.shape # dec_valid_lensçš„å¼€å¤´:(batch_size,num_steps), # å…¶ä¸­æ¯ä¸€è¡Œæ˜¯[1,2,...,num_steps] dec_valid_lens torch.arange( 1, num_steps + 1, device X.device).repeat(batch_size, 1) else: dec_valid_lens None # è‡ªæ³¨æ„åŠ› X2 self.attention1(X, key_values, key_values, dec_valid_lens) Y self.addnorm1(X, X2) # ç¼–ç å™¨ï¼è§£ç å™¨æ³¨æ„åŠ›ã€‚ # enc_outputsçš„å¼€å¤´:(batch_size,num_steps,num_hiddens) Y2 self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens) Z self.addnorm2(Y, Y2) return self.addnorm3(Z, self.ffn(Z)), state decoder_blk DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0) decoder_blk.eval() X torch.ones((2, 100, 24)) state [encoder_blk(X, valid_lens), valid_lens, [None]] decoder_blk(X, state)[0].shape \"\"\" torch.Size([2, 100, 24]) \"\"\" class TransformerDecoder(d2l.AttentionDecoder): def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, **kwargs): super(TransformerDecoder, self).__init__(**kwargs) self.num_hiddens num_hiddens self.num_layers num_layers self.embedding nn.Embedding(vocab_size, num_hiddens) self.pos_encoding d2l.PositionalEncoding(num_hiddens, dropout) self.blks nn.Sequential() for i in range(num_layers): self.blks.add_module(\"block\"+str(i), DecoderBlock(key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, i)) self.dense nn.Linear(num_hiddens, vocab_size) def init_state(self, enc_outputs, enc_valid_lens, *args): return [enc_outputs, enc_valid_lens, [None] * self.num_layers] def forward(self, X, state): X self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens)) self._attention_weights [[None] * len(self.blks) for _ in range (2)] for i, blk in enumerate(self.blks): X, state blk(X, state) # è§£ç å™¨è‡ªæ³¨æ„åŠ›æƒé‡ self._attention_weights[0][i] blk.attention1.attention.attention_weights # â€œç¼–ç å™¨ï¼è§£ç å™¨â€è‡ªæ³¨æ„åŠ›æƒé‡ self._attention_weights[1][i] blk.attention2.attention.attention_weights return self.dense(X), state @property def attention_weights(self): return self._attention_weights ``` + è®­ç»ƒ å®é™…è®­ç»ƒçš„æ—¶å€™Decoderå®é™…çš„è¾“å…¥æ˜¯æ­£ç¡®çš„ç­”æ¡ˆ, Teacher forcing, è·å–è¾“å‡ºçš„æœ€å°çš„minimize cross entropy, ä½†æ˜¯è¿™æ ·å’Œå®é™…çš„ä½¿ç”¨æ˜¯æœ‰åŒºåˆ«çš„ exposure bias, æµ‹è¯•çš„æ—¶å€™è¾“å‡ºæœ‰ä¸€ä¸ªé”™è¯¯çš„è¾“å‡ºå¯èƒ½ä¼šå½±å“åé¢çš„è¾“å‡º, æ‰€ä»¥å®é™…çš„è®­ç»ƒè¾“å…¥ç»™ä¸€éƒ¨åˆ†é”™è¯¯çš„æ•°æ®Scheduled Sampling ```python num_hiddens, num_layers, dropout, batch_size, num_steps 32, 2, 0.1, 64, 10 lr, num_epochs, device 0.005, 200, d2l.try_gpu() ffn_num_input, ffn_num_hiddens, num_heads 32, 64, 4 key_size, query_size, value_size 32, 32, 32 norm_shape [32] train_iter, src_vocab, tgt_vocab d2l.load_data_nmt(batch_size, num_steps) encoder TransformerEncoder( len(src_vocab), key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout) decoder TransformerDecoder( len(tgt_vocab), key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout) net d2l.EncoderDecoder(encoder, decoder) d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device) ``` ![image 20250215234119472](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502152341582.png) æµ‹è¯•ä¸€ä¸‹ ```python engs ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .'] fras ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .'] for eng, fra in zip(engs, fras): translation, dec_attention_weight_seq d2l.predict_seq2seq( net, eng, src_vocab, tgt_vocab, num_steps, device, True) print(f'{eng} > {translation}, ', f'bleu {d2l.bleu(translation, fra, k 2):.3f}') \"\"\" go . > va !, bleu 1.000 i lost . > j'ai perdu ., bleu 1.000 he's calm . > il est calme ., bleu 1.000 i'm home . > je suis chez moi ., bleu 1.000 \"\"\" ``` + Copy Mechanism å®é™…çš„ä½¿ç”¨è¿‡ç¨‹é‡Œé¢å¦‚æœç”¨æˆ·è¾“å…¥ä¸€ä¸ªæ²¡æœ‰å‡ºç°è¿‡çš„åè¯, éœ€è¦æŠŠè¿™ä¸ªåè¯è¿›è¡Œå¤åˆ¶ä½œä¸ºè¾“å‡º(å°¤å…¶æ˜¯åœ¨åšæ–‡ç« çš„æ‘˜è¦) + Guided Attention æœ‰çš„é—®é¢˜åœ¨å¤„ç†çš„æ—¶å€™ä½¿ç”¨çš„Attentionæ˜¯æœ‰ä¸€å®šè§„å¾‹çš„, æ¯”å¦‚è¿›è¡Œè¯­éŸ³åˆæˆ, å°±æ˜¯ä»å·¦åˆ°å³çš„ä¸€ä¸ªå¤„ç†è¿‡ç¨‹, å¯ä»¥åŠ ä¸€ä¸ªé™åˆ¶, å¯ä»¥ä½¿ç”¨Monotonic Attentionå’ŒLocation aware attention"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-13-14æ± åŒ–.html":{"title":"æ± åŒ–Pooling","content":"# æ± åŒ–Pooling å·ç§¯å¯¹äºä½ç½®ååˆ†æ•æ„Ÿ, ä½†æ˜¯å¤„ç†å®é™…é—®é¢˜çš„æ—¶å€™é€šå¸¸è·å–çš„ä¿¡æ¯æ˜¯ä¼šå‘ç”Ÿåç§»çš„, æ‰€ä»¥æœ€å¥½æœ‰ä¸€éƒ¨åˆ†çš„è¾“å‡ºä¸å˜æ€§, åœ¨ä¸€å®šç¨‹åº¦çš„å¹³ç§»ä¸‹é¢è¾“å‡ºæ˜¯ä¸å˜çš„ ## æ± åŒ–å±‚ **æœ€å¤§æ± åŒ–å±‚** ![image 20250113200624428](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501132006495.png) ä½¿ç”¨2x2çš„æ± åŒ–å±‚å¯¹äºä¸€ä¸ªè¾¹ç¼˜æ£€æµ‹çš„ç»“æœè¿›è¡Œå¤„ç†, å¯ä»¥æä¾›ä¸€ä¸ªåƒç´ çš„å®¹å¿åº¦(è¾¹ç¼˜æ˜¾ç¤ºä¸º1, éè¾¹ç¼˜ä¸º0) å‚æ•°ä¹Ÿæ˜¯æœ‰å¡«å……ä»¥åŠæ­¥å¹…, æ²¡æœ‰å¯ä»¥å­¦ä¹ çš„å‚æ•°, ä½œç”¨äºå¤šè¾“å…¥çš„æ—¶å€™, ä¼šå¯¹æ¯ä¸€å±‚åšä¸€æ¬¡æ± åŒ–, è¾“å…¥é€šé“æ•°ç­‰äºè¾“å‡ºé€šé“æ•° ä¹Ÿå¯ä»¥ä½¿ç”¨**å¹³å‡æ± åŒ–å±‚**, è¿”å›æ¯ä¸€ä¸ªæ± åŒ–å±‚é‡Œé¢çš„å¹³å‡æ•°å€¼ ## ä»£ç å®ç° ```python def pool2d(X, pool_size, mode 'max'): p_h, p_w pool_size Y torch.zeros((X.shape[0] p_h + 1, X.shape[1] p_w + 1)) for i in range (Y.shape[0]): for j in range (Y.shape[1]): if mode 'max': Y[i, j] X[i: i + p_h, j: j + p_w].max() elif mode 'avg': Y[i, j] X[i: i + p_h, j: j + p_w].mean() return Y ``` + ä½¿ç”¨å®ç°å¥½çš„ ```python X torch.arange(16, dtype torch.float32).reshape((1, 1, 4, 4)) pool2d nn.MaxPool2d(3) pool2d(X) \"\"\" tensor([[[[10.]]]]) \"\"\" ``` > é»˜è®¤çš„æ­¥é•¿å’Œå·ç§¯æ ¸çš„å¤§å°æ˜¯ä¸€æ ·çš„, å¯ä»¥ä½¿ç”¨å‚æ•°`padding`, æ­¥é•¿`stride`, ç¬¬ä¸€ä¸ªå‚æ•°ä½¿ç”¨å…ƒç»„å¯ä»¥ä½¿ç”¨ä¸ä¸ºæ­£æ–¹å½¢çš„å·ç§¯æ ¸ å¤šé€šé“çš„æ—¶å€™æ˜¯åœ¨æ¯ä¸€ä¸ªé€šé“é‡Œé¢éƒ½é€‚ç”¨åŒæ ·çš„ ```python X torch.cat((X, X + 1), 1) \"\"\" tensor([[[[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.]], [[ 1., 2., 3., 4.], [ 5., 6., 7., 8.], [ 9., 10., 11., 12.], [13., 14., 15., 16.]]]]) \"\"\" pool2d nn.MaxPool2d(3, padding 1, stride 2) pool2d(X) \"\"\" X torch.cat((X, X + 1), 1) pool2d nn.MaxPool2d(3, padding 1, stride 2) pool2d(X) \"\"\" ``` > è¿™ä¸€ä¸ªå®é™…ä½¿ç”¨çš„è¶Šæ¥è¶Šå°‘, å› ä¸ºæ•°æ®åœ¨ä¼ è¿›å»ä¹‹å‰ä¸€èˆ¬ä¼šè¿›è¡Œä¸€ä¸‹å¤„ç†, é¿å…æ•°æ®çš„è¿‡æ‹Ÿåˆ"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-10-35-BPTT.html":{"title":"é€šè¿‡æ—¶é—´åå‘ä¼ æ’­","content":"# é€šè¿‡æ—¶é—´åå‘ä¼ æ’­ ![image 20250210212303113](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102123153.png) åœ¨è®¡ç®—çš„æ—¶å€™æ¯ä¸€æ­¥çš„è¾“å‡ºæ¥è‡ªä¸Šä¸€æ­¥çš„è®¡ç®—ç»“æœ, æœ€åçš„è¯„ä¼°å‡½æ•°å¯ä»¥å†™ä¸º ![image 20250210212344457](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102123495.png) å¯¹äºåå‘ä¼ æ’­ï¼Œé—®é¢˜åˆ™æœ‰ç‚¹æ£˜æ‰‹ï¼Œç‰¹åˆ«æ˜¯å½“æˆ‘ä»¬è®¡ç®—ç›®æ ‡å‡½æ•°Lå…³äºå‚æ•°w~h~çš„æ¢¯åº¦æ—¶ ![image 20250210212518453](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102125490.png) ç¬¬ä¸‰é¡¹âˆ‚ht/âˆ‚whæ˜¯ä½¿äº‹æƒ…å˜å¾—æ£˜æ‰‹çš„åœ°æ–¹ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦ å¾ªç¯åœ°è®¡ç®—å‚æ•°w~h~å¯¹h~t~çš„å½±å“ã€‚htæ—¢ä¾èµ–äºhtâˆ’1åˆä¾èµ–äºwhï¼Œå…¶ä¸­htâˆ’1çš„è®¡ç®—ä¹Ÿ ä¾èµ–äºwhã€‚ ![image 20250210212653974](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102126009.png) ä¸ºäº†å¯¼å‡ºä¸Šè¿°æ¢¯åº¦ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸‰ä¸ªåºåˆ—{at},{bt},{ct}ï¼Œå½“t 1,2,...æ—¶ï¼Œåºåˆ—æ»¡è¶³a0 0ä¸”a~t~ b~t~+c~t~a~tâˆ’1~ã€‚ å¯¹äºtâ‰¥1ï¼Œå°±å¾ˆå®¹æ˜“å¾—å‡º ![image 20250210213818327](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102138373.png) ä½¿ç”¨ä¸‹é¢çš„å˜é‡è¿›è¡Œæ›¿æ¢ ![image 20250210213901956](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102139994.png) ![image 20250210213920189](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102139234.png) ç›´æ¥è®¡ç®—è¿™ä¸€ä¸ªä¼šå¯¼è‡´è®¡ç®—çš„å¾ˆæ…¢åŒæ—¶æœ‰å¯èƒ½å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸, æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨Ï„æ­¥åæˆªæ–­(8.7.7)ä¸­çš„æ±‚å’Œè®¡ç®—ã€‚è¿™æ˜¯æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢ä¸€ç›´åœ¨è®¨è®ºçš„å†…å®¹ï¼Œä¾‹å¦‚åœ¨8.5èŠ‚ä¸­ åˆ†ç¦»æ¢¯åº¦æ—¶ã€‚è¿™ä¼šå¸¦æ¥çœŸå®æ¢¯åº¦çš„è¿‘ä¼¼ï¼Œåªéœ€å°†æ±‚å’Œç»ˆæ­¢ä¸ºâˆ‚h~tâˆ’Ï„~/âˆ‚w~h~ã€‚ æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªéšæœºå˜é‡æ›¿æ¢âˆ‚h~t~/âˆ‚w~h~ï¼Œè¯¥éšæœºå˜é‡åœ¨é¢„æœŸä¸­æ˜¯æ­£ç¡®çš„ï¼Œä½†æ˜¯ä¼šæˆªæ–­åºåˆ—ã€‚è¿™ä¸ªéšæœº å˜é‡æ˜¯é€šè¿‡ä½¿ç”¨åºåˆ—Î¾~t~æ¥å®ç°çš„ ![image 20250210214435824](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102144864.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2024-11-03-02æ•°æ®ç±»å‹.html":{"title":"æ•°æ®ç±»å‹","content":" layout: post title: \"æ•°æ®ç±»å‹\" date: 2024 1 11 15:39:08 +0800 tags: stm32 lvgl # æ•°æ®ç±»å‹ ## Nç»´æ•°ç»„ ### å»ºç«‹ è¿™ä¸€ä¸ªæ•°ç»„æ˜¯æœºå™¨å­¦ä¹ çš„æœ€ä¸»è¦çš„æ•°æ®ç±»å‹, åˆ›å»ºä¸€ä¸ªæ•°ç»„éœ€è¦æ•°ç»„çš„å½¢çŠ¶,æ•°æ®ç±»å‹ä»¥åŠæ•°æ®çš„å€¼ ![image 20241103232548145](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202411032325238.png) > å–åˆ—çš„æ—¶å€™æ˜¯[1:,] å¼ é‡: ä¸€ä¸ªæ•°å€¼ç»„æˆçš„æ•°ç»„ ```python x torch.arange(12) ``` > tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) å¯ä»¥é€šè¿‡`shape`è®¿é—®è¿™ä¸€ä¸ªå‘é‡çš„å¤§å°`torch.Size([12])`ä»£è¡¨ä¸€ä¸ªç»´åº¦é•¿åº¦ä¸º12, å¯ä»¥ä½¿ç”¨`numel()`è·å–è¿™ä¸€ä¸ªé‡Œé¢çš„å…ƒç´ çš„æ€»æ•°, æ˜¯ä¸€ä¸ªæ ‡é‡12 æ”¹å˜å¼ é‡ä½†æ˜¯ä¸æ”¹å˜æ•°é‡å¯ä»¥ä½¿ç”¨`x.reshape(3, 4)`è·å–åˆ° ```bash tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) ``` åŒæ—¶å¯ä»¥ä½¿ç”¨`zeros((2, 3, 4))`è·å–ä¸€ä¸ªå…¨æ˜¯é›¶çš„å‘é‡, ä½¿ç”¨`ones`å¯ä»¥å»ºç«‹ä¸€ä¸ªä¸ºå…¨1çš„tensor å®é™…ä½¿ç”¨çš„æ—¶å€™å¯ä»¥ä½¿ç”¨åµŒå¥—é“¾è¡¨è¿›è¡Œç»„å»º ```python tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) ``` ### è¿ç®— åˆ›å»ºå‡ºæ¥çš„tensoræ˜¯å¯ä»¥ç›´æ¥è¿›è¡Œç®€å•çš„è¿ç®—çš„, è¿ç®—çš„æ—¶å€™æ˜¯æŒ‰ç…§å…ƒç´ è¿›è¡Œçš„`+, , *, /` ä¹Ÿå¯ä»¥ä½¿ç”¨`tensor.exp(x)`å¯¹xé‡Œé¢çš„æ¯ä¸€ä¸ªå…ƒç´ è¿›è¡ŒæŒ‡æ•°è¿ç®— è¿˜å¯ä»¥æŠŠå¤šä¸ªå¼ é‡è¿ç»“åœ¨ä¸€èµ· ```python x torch.arange(12, dtype torch.float32).reshape(3, 4) y torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]], dtype torch.float32) torch.cat((x, y), dim 0), torch.cat((x, y), dim 1) ``` ![image 20241110124345434](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202411101243773.png) > dimä½¿ç”¨0æ˜¯æŒ‰è¡Œè¿›è¡Œåˆå¹¶, 1æ˜¯æŒ‰ç…§åˆ—è¿›è¡Œåˆå¹¶ å¯ä»¥é€šè¿‡` `è¿›è¡Œæ¯”è¾ƒ, è¿™ä¸€ä¸ªæ˜¯æŒ‰ç…§å…ƒç´ è¿›è¡Œæ¯”è¾ƒçš„, è¿”å›çš„æ•°æ®ç»“æœè¿˜æ˜¯ä¸€ä¸ªtensor, æ¯ä¸€ä¸ªçš„æ•°æ®æ˜¯Trueæˆ–è€…False å¯ä»¥ä½¿ç”¨`X.sum()`è¿›è¡Œæ±‚å’Œ, è¿”å›ä¸€ä¸ªåªæœ‰ä¸€ä¸ªå…ƒç´ çš„tensor ä¸¤ä¸ªå¼ é‡å¯ä»¥ä½¿ç”¨`+`è¿›è¡Œè®¡ç®—, å¦‚æœè¿™ä¸¤ä¸ªå¼ é‡çš„å½¢çŠ¶ä¸åŒ, ä¼šé€šè¿‡ä¸€ä¸ªå¹¿æ’­æœºåˆ¶æ‰§è¡Œå…ƒç´ æ“ä½œ, è¿™ä¸€ä¸ªæœºåˆ¶ä¼šæŠŠå¼ é‡è¿›è¡Œå¤åˆ¶, æ‰©å……ä¸ºæ¯ä¸€ç»´åº¦æœ€å¤§çš„ä¸€ä¸ªå€¼ ![image 20250107104047296](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071040401.png) å†å¤šå…ƒç´ èµ‹å€¼çš„æ—¶å€™å¯ä»¥ä½¿ç”¨ ```python X[0:2, :] 12 # å‰ä¸¤è¡Œèµ‹å€¼ä¸º12 ``` ### å†…å­˜ åœ¨pythoné‡Œé¢ç”±äºä¸ä¼šç›´æ¥æ§åˆ¶å†…å­˜, æ‰€ä»¥å¯èƒ½å¯¼è‡´å¤§çš„æ•°ç»„ä¼šé‡å¤å¤åˆ¶, å¯¼è‡´å†…å­˜æµªè´¹ ```python before id(Y) Y Y + X id(Y) before ``` > è¿™æ—¶å€™å‘ç°åœ°å€æ”¹å˜äº†; å¯ä»¥æŠŠ`Y Y + X`æ”¹ä¸º`Y[:] Y + x`, å®é™…æ˜¯å¯¹è¿™é‡Œé¢çš„æ‰€æœ‰å…ƒç´ è¿›è¡Œæ”¹å†™ ### å’ŒNumPyè½¬æ¢ ```python A X.numpy() B torch.tensor(A) ``` å¤§å°ä¸ºä¸€çš„å¼ é‡å¯ä»¥è½¬æ¢ä¸ºpythonçš„æ ‡é‡ ````python a torch.tensor([3.5]) float(a), int(a) ```` ## æ•°æ®é¢„å¤„ç† æœ‰ä¸€ä¸ªåŸå§‹çš„æ•°æ®é›†, å¦‚ä½•å¯¹æ•°æ®è¿›è¡Œè¯»å– ```python # æ•°æ®æ„å»º import os os.makedirs(os.path.join('data'), exist_ok True) data_file os.path.join('data', 'house_thiny.csv') print(data_file) with open(data_file, 'w') as f: f.write('NumberRoom, Alley, Price\\n') f.write('None, None, 213\\n') f.write('2, Paved, 120\\n') f.write('3, Gravel, 240\\n') f.write('None, None, 330\\n') f.write('5, Paved, 400\\n') f.write('6, Gravel, 500\\n') f.write('7, None, 600\\n') # æ•°æ®è¯»å– import pandas as pd import os data pd.read_csv(os.path.join('data', 'house_thiny.csv')) print(data) ``` > ```bash > (transforms) E:\\JHY\\python\\2024 11 3 pytorchLiMu>python ./test.py > data\\house_thiny.csv > > (transforms) E:\\JHY\\python\\2024 11 3 pytorchLiMu>python ./test.py > NumberRoom Alley Price > NumberRoom Alley Price > 0 NaN None 213 > 1 2.0 Paved 120 > 2 3.0 Gravel 240 > 3 NaN None 330 > 4 5.0 Paved 400 > 5 6.0 Gravel 500 > 6 7.0 None 600 > ``` ### å¤„ç†æ•°æ®çš„ç¼ºå¤± å…¸å‹çš„æ•°æ®å¤„ç†æ–¹æ³•æ˜¯åˆ é™¤, æ’å€¼ ```python inputs , outputs data.iloc[:, 0:2], data.iloc[:, 1] # åˆ‡ç‰‡æ“ä½œ inputs['NumberRoom'] inputs['NumberRoom'].fillna(inputs['NumberRoom'].mean()) # ä½¿ç”¨å‡å€¼å¡«å……ç¼ºå¤±å€¼ print(inputs) ''' data\\house_thiny.csv NumberRoom Alley Price 0 NaN NA 213 1 2.0 Paved 120 2 3.0 Gravel 240 3 NaN NA 330 4 5.0 Paved 400 5 6.0 Gravel 500 6 7.0 NA 600 NumberRoom Alley 0 4.6 NA 1 2.0 Paved 2 3.0 Gravel 3 4.6 NA 4 5.0 Paved 5 6.0 Gravel 6 7.0 NA ''' ``` ä¹‹åæ˜¯ä¸ªä¸åŒçš„æ•°æ®æ”¹ä¸ºæ•°å€¼ ```python input pd.get_dummies(inputs,dtype int) # å¯¹åˆ†ç±»å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç , dummy_na Trueè¡¨ç¤ºå¯¹ç¼ºå¤±å€¼ä¹Ÿè¿›è¡Œç‹¬çƒ­ç¼–ç  print(input) ''' NumberRoom Alley_ Gravel Alley_ None Alley_ Paved 0 4.6 0 1 0 1 2.0 0 0 1 2 3.0 1 0 0 3 4.6 0 1 0 4 5.0 0 0 1 5 6.0 1 0 0 6 7.0 0 1 0 ''' ``` è½¬ä¸ºå¼ é‡ ```python import torch X, Y torch.tensor(input.values), torch.tensor(outputs.values) print(X) print(Y) ''' tensor([[4.6000, 0.0000, 1.0000, 0.0000], [2.0000, 0.0000, 0.0000, 1.0000], [3.0000, 1.0000, 0.0000, 0.0000], [4.6000, 0.0000, 1.0000, 0.0000], [5.0000, 0.0000, 0.0000, 1.0000], [6.0000, 1.0000, 0.0000, 0.0000], [7.0000, 0.0000, 1.0000, 0.0000]], dtype torch.float64) tensor([213, 120, 240, 330, 400, 500, 600]) ''' ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-11-38seq2seq.html":{"title":"seq2seqåºåˆ—åˆ°åºåˆ—","content":"# seq2seqåºåˆ—åˆ°åºåˆ— æœ€æ—©çš„åº”ç”¨æ˜¯ä½œä¸ºæœºå™¨ç¿»è¯‘, å®é™…æ˜¯åšä¸€ä¸ªsequence to sequenceçš„è½¬åŒ–, å¯ä»¥ä½¿ç”¨ç¼–ç å™¨è§£ç å™¨çš„æ¶æ„è¿›è¡Œå®ç° å¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨ä½¿ç”¨é•¿åº¦å¯å˜çš„åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œå°†å…¶è½¬æ¢ä¸ºå›ºå®š å½¢çŠ¶çš„éšçŠ¶æ€ã€‚ è¾“å…¥åºåˆ—çš„ä¿¡æ¯è¢«ç¼–ç åˆ°å¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨çš„éšçŠ¶æ€ä¸­ã€‚ä¸ºäº†è¿ç»­ç”Ÿæˆè¾“å‡ºåºåˆ— çš„è¯å…ƒï¼Œç‹¬ç«‹çš„å¾ªç¯ç¥ç»ç½‘ç»œè§£ç å™¨æ˜¯åŸºäºè¾“å…¥åºåˆ—çš„ç¼–ç ä¿¡æ¯å’Œè¾“å‡ºåºåˆ—å·²ç»çœ‹è§çš„æˆ–è€…ç”Ÿæˆçš„è¯å…ƒæ¥é¢„ æµ‹ä¸‹ä¸€ä¸ªè¯å…ƒã€‚ ![image 20250211110109509](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111101558.png) > è¿™ä¸€ä¸ªæ¨¡å‹å¯ä»¥ä½¿ç”¨åŒå‘çš„RNN ç¼–ç å™¨æœ€ç»ˆçš„éšçŠ¶æ€åœ¨æ¯ä¸€ä¸ªæ—¶é—´æ­¥éƒ½ä½œ ä¸ºè§£ç å™¨çš„è¾“å…¥åºåˆ—çš„ä¸€éƒ¨åˆ†ã€‚ ![image 20250211111658630](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111116693.png) ![image 20250211111941474](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111119537.png) > æ¨ç†çš„æ—¶å€™ä½¿ç”¨ä¸Šä¸€æ¬¡çš„è¾“å‡ºä½œä¸ºè¾“å…¥ è¾“å‡ºçš„åºåˆ—éœ€è¦ä½¿ç”¨æ–°çš„æ–¹å¼è¿›è¡Œæ£€æµ‹è´¨é‡, å› ä¸ºåŒä¸€ä¸ªå«ä¹‰å®é™…çš„å¥å­å¯èƒ½æ˜¯ä¸åŒçš„ ![image 20250211112220610](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111122670.png) > æœ€å¥½çš„ç»“æœæ˜¯1, æ•°å­—è¶Šå°è¶Šä¸å¥½ > > n gradæ˜¯ä½¿ç”¨nä¸ªå­—ç¬¦å¯¹è¾“å‡ºè¿›è¡Œåˆ†å‰², çœ‹è¿™ä¸ªåˆ†å‰²æ˜¯ä¸æ˜¯åœ¨ç›®æ ‡çš„é‡Œé¢å‡ºç°(å•æ¬¡åŒ¹é…) > > è®¡ç®—çš„æ—¶å€™, å¦‚æœé¢„æµ‹çš„é•¿åº¦æ¯”å®é™…çš„é•¿åº¦å°çš„æ—¶å€™expä¼šè®¡ç®—ä¸€ä¸ªè´Ÿæ•°(å¾ˆå°) > > åé¢çš„è®¡ç®—çš„æ—¶å€™nè¶Šå¤§, 1 / 2^n^å˜å°, p~n~<1ä¼šå¯¼è‡´å®é™…çš„æ•°å€¼å˜å¤§, æ‰€ä»¥é•¿çš„åŒ¹é…æƒé‡æ›´é«˜ ## åµŒå…¥å±‚ åµŒå…¥å±‚çš„æƒé‡æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œå…¶è¡Œæ•°ç­‰äºè¾“å…¥è¯è¡¨çš„å¤§å°ï¼ˆvocab_sizeï¼‰ï¼Œå…¶åˆ—æ•°ç­‰äºç‰¹å¾ å‘é‡çš„ç»´åº¦ï¼ˆembed_sizeï¼‰ã€‚å¯¹äºä»»æ„è¾“å…¥è¯å…ƒçš„ç´¢å¼•iï¼ŒåµŒå…¥å±‚è·å–æƒé‡çŸ©é˜µçš„ç¬¬iè¡Œï¼ˆä»0å¼€å§‹ï¼‰ä»¥è¿”å›å…¶ ç‰¹å¾å‘é‡ã€‚ ## ä»£ç å®ç°"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-15-20æ‰¹é‡å½’ä¸€åŒ–.html":{"title":"æ‰¹é‡å½’ä¸€åŒ–","content":"# æ‰¹é‡å½’ä¸€åŒ– ä¹‹å‰ä½¿ç”¨çš„æ¨¡å‹å¯¹å‡ºç°é—®é¢˜, æŸå¤±å‡½æ•°åœ¨æœ€åé¢, åé¢çš„è®­ç»ƒæ¯”è¾ƒå¿« æ•°æ®åœ¨è®­ç»ƒçš„å¼€å§‹ä½ç½®, å¼€å§‹ä½ç½®çš„è®­ç»ƒæ¯”è¾ƒæ…¢, ä¸åŒä½ç½®çš„æ”¶æ•›çš„é€Ÿåº¦æ˜¯ä¸åŒçš„(å­¦ä¹ ç‡ç›¸åŒ, ä½†æ˜¯ä¸åŒä½ç½®çš„æ–¹å·®å·®çš„æ¯”è¾ƒå¤§0325) æ•°æ®å˜åŒ–å½±å“å…¨å±€, åº•éƒ¨æ•°æ®å˜åŒ–çš„å¯èƒ½å¯¼è‡´åé¢çš„æ•°æ®é‡æ–°è®­ç»ƒ ç›®æ ‡: æ”¹å˜åº•å±‚çš„æ•°æ®, ä½¿å¾—é¡¶éƒ¨çš„æ•°æ®æ”¶åˆ°çš„å½±å“æ¯”è¾ƒå°‘ ![image 20250115103709061](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501151037215.png) ![image 20250115104024280](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501151040536.png) > å…¶ä»–ä¸¤ä¸ªå‚æ•°æ˜¯å¯ä»¥å­¦ä¹ çš„å‚æ•°, é˜²æ­¢æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„æ•°æ®ä¸å¤ªåˆç†, å­¦ä¹ å‡ºæ¥é€‚åˆçš„åç§»å’Œç¼©æ”¾ è¿™ä¸€å±‚çš„ä½ç½®æ˜¯åœ¨å…¨è¿æ¥ä»¥åŠå·ç§¯å±‚çš„è¾“å‡ºä¸Šé¢, æ¿€æ´»å‡½æ•°çš„å‰é¢, ä»¥åŠå…¨è¿æ¥å’Œå·ç§¯å±‚çš„è¾“å…¥ å…¨è¿æ¥å±‚æ˜¯ä½œç”¨åœ¨ç‰¹å¾ç»´, å·ç§¯å±‚æ˜¯åœ¨é€šé“ç»´, å®é™…ä½¿ç”¨çš„æ—¶å€™å¯èƒ½æ˜¯åŠ å…¥äº†å°æ‰¹é‡çš„å™ªéŸ³, èµ·åˆ°ä¸€éƒ¨åˆ†çš„dropoutå±‚çš„ä½œç”¨(ä¸è¦æ··ç”¨), å¯ä»¥ç”¨äºåŠ é€Ÿæ”¶æ•›ä½†æ˜¯ä¸æ”¹å˜ç²¾åº¦ ## è®¡ç®—æ»‘åŠ¨å¹³å‡ ```python moving_mean (moving_mean * (n 1) + batch_mean) / n (1 1/n) * moving_mean + 1/n * batch_mean moving_var (moving_var * (n 1) + batch_var) / n (1 1/n) * moving_var + 1/n * batch_var ``` > æ­£å¸¸ä½¿ç”¨çš„æ—¶å€™æ˜¯è¿™æ ·çš„, ä½†æ˜¯ï¼Œå½“n é€æ­¥å¢å¤§çš„æ—¶å€™ï¼Œ1/n é€æ¸å‡å°ï¼Œ1/n * batch_mean èµ·çš„å½±å“ä¼šè¶Šæ¥è¶Šå°ï¼Œ(moving_mean, moving_var) ä¼šè¶‹äºä¸å˜ã€‚ è€Œå¯¹äºä¸€ä¸ªå°çš„å¸¸é‡ 1 momentum å€¼ï¼Œèƒ½å¤Ÿè®© (moving_mean, moving_var) åœ¨æ•´ä¸ªè®­ç»ƒé›†çœŸå®çš„å‡å€¼å’Œæ–¹å·®é™„è¿‘æ³¢åŠ¨ï¼Œè¿™å¯¹äºè®­ç»ƒæ¥è¯´ï¼Œèƒ½å¤Ÿå¢åŠ æ¨¡å‹çš„é²æ£’æ€§ï¼Œä¹Ÿä¼šåœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡å°‘è¿‡æ‹Ÿåˆã€‚ä½†è¿™ä¸ªæ³¢åŠ¨ä¸èƒ½å¾ˆå¤§ï¼Œæ‰€ä»¥ 1 momentum éœ€è¦æ˜¯ä¸€ä¸ªæ¯”è¾ƒå°çš„å€¼ã€‚ ```python3 moving_mean moving_mean * momentum + batch_mean * (1 momentum) moving_var moving_var * momentum + batch_var * (1 momentum) ``` ## ä»£ç å®ç° ```python import torch from torch import nn from d2l import torch as d2l ``` + å®ç°ä¸€æ¬¡è®¡ç®—é¢˜ ```python # X:è¿™ä¸€å±‚çš„è¾“å…¥ï¼Œå½¢çŠ¶ä¸ºï¼ˆbatch_sizeï¼Œnum_featuresï¼‰ # gammaï¼šæ‹‰ä¼¸å‚æ•° # betaï¼šåç§»å‚æ•°, ä»¥ä¸Šä¸¤ä¸ªå‚æ•°æ˜¯å¯ä»¥å­¦ä¹ çš„ # moving_meanï¼šå…¨è¿æ¥å±‚çš„å‡å€¼(å…¨å±€çš„å‡å€¼) # moving_varï¼šå…¨è¿æ¥å±‚çš„æ–¹å·® # epsï¼šä¸ºäº†ç»´æŒæ•°å€¼ç¨³å®šæ€§è€Œæ·»åŠ çš„å°å¸¸æ•°, é¿å…åˆ†æ¯ä¸º0 # momentumï¼šåŠ¨é‡è¶…å‚æ•°, ç”¨äºæ›´æ–°å…¨è¿æ¥å±‚çš„å‡å€¼å’Œæ–¹å·®ä¸€èˆ¬æ˜¯0.9 # è¿”å›å€¼ï¼šæ‰¹é‡å½’ä¸€åŒ–çš„è¾“å‡ºå’Œæ›´æ–°çš„å…¨è¿æ¥å±‚çš„å‡å€¼å’Œæ–¹å·® def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum): if not torch.is_grad_enabled(): # å¦‚æœæ˜¯åœ¨é¢„æµ‹æ¨¡å¼ä¸‹ï¼Œç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ç§»åŠ¨å¹³å‡æ‰€å¾—çš„å‡å€¼å’Œæ–¹å·® X_hat (X moving_mean) / torch.sqrt(moving_var + eps) else: assert len(X.shape) in (2, 4) # Xçš„ç»´åº¦åªèƒ½æ˜¯2æˆ–4(å…¨è¿æ¥ä»¥åŠå·ç§¯) if len(X.shape) 2: # å…¨è¿æ¥ mean X.mean(dim 0) # æ²¿ç€batch_sizeç»´åº¦æ±‚å‡å€¼, 0è¡¨ç¤ºç¬¬ä¸€ä¸ªç»´åº¦, å¯¹æ‰€æœ‰batchçš„å¯¹åº”ç‰¹å¾æ±‚å‡å€¼ var ((X mean) ** 2).mean(dim 0) # æ²¿ç€batch_sizeç»´åº¦æ±‚æ–¹å·® else: # dim (0, 2, 3)è¡¨ç¤ºæ²¿ç€é€šé“ç»´åº¦æ±‚å‡å€¼ mean X.mean(dim (0, 2, 3), keepdim True) # æ²¿ç€é€šé“ç»´åº¦æ±‚å‡å€¼ var ((X mean) ** 2).mean(dim (0, 2, 3), keepdim True) # æ²¿ç€é€šé“ç»´åº¦æ±‚æ–¹å·® X_hat (X mean) / torch.sqrt(var + eps) # è®¡ç®—ä¸€ä¸‹ç§»åŠ¨å¹³å‡, è¿™é‡Œçš„meanå’Œvaræ˜¯å½“å‰batchçš„å‡å€¼å’Œæ–¹å·®, è€Œmoving_meanå’Œmoving_varæ˜¯å…¨å±€çš„å‡å€¼å’Œæ–¹å·® moving_mean momentum * moving_mean + (1.0 momentum) * mean moving_var momentum * moving_var + (1.0 momentum) * var Y gamma * X_hat + beta return Y, moving_mean, moving_var ``` + å®ç°ä¸€å±‚ ```python class BatchNorm(nn.Module): def __init__(self, num_features, num_dims): # num_features: å…¨è¿æ¥å±‚çš„è¾“å‡ºä¸ªæ•°æˆ–è€…å·ç§¯å±‚çš„è¾“å‡ºé€šé“æ•° # num_dims: 2è¡¨ç¤ºå…¨è¿æ¥å±‚ï¼Œ4è¡¨ç¤ºå·ç§¯å±‚ super(BatchNorm, self).__init__() if num_dims 2: shape (1, num_features) else: shape (1, num_features, 1, 1) # å‚ä¸æ±‚æ¢¯åº¦å’Œè¿­ä»£çš„æ‹‰ä¼¸å’Œåç§»å‚æ•°ï¼Œåˆ†åˆ«åˆå§‹åŒ–ä¸º0å’Œ1 self.gamma nn.Parameter(torch.ones(shape)) self.beta nn.Parameter(torch.zeros(shape)) # ä¸å‚ä¸æ±‚æ¢¯åº¦å’Œè¿­ä»£çš„å˜é‡ï¼Œå…¨è¿æ¥å±‚çš„å‡å€¼å’Œæ–¹å·® self.moving_mean torch.zeros(shape) self.moving_var torch.zeros(shape) def forward(self, X): if self.moving_mean.device ! X.device: # å¦‚æœmoving_meanå’Œmoving_varä¸åœ¨Xçš„è®¾å¤‡ä¸Š, # å°±å°†å®ƒä»¬å¤åˆ¶åˆ°Xæ‰€åœ¨çš„è®¾å¤‡ä¸Š # å…¶ä»–çš„å‚æ•°gammaå’Œbetaæ˜¯åœ¨net.parameters()ä¸­, ä¼šè‡ªåŠ¨è½¬ç§»åˆ°Xæ‰€åœ¨çš„è®¾å¤‡ä¸Š self.moving_mean self.moving_mean.to(X.device) self.moving_var self.moving_var.to(X.device) # ä¿å­˜æ›´æ–°è¿‡çš„moving_meanå’Œmoving_var Y, self.moving_mean, self.moving_var batch_norm( X, self.gamma, self.beta, self.moving_mean, self.moving_var, eps 1e 5, momentum 0.9) return Y ``` + å¼€å§‹è®­ç»ƒ ```python # æ„é€ ä¸€ä¸ªLeNet net nn.Sequential( nn.Conv2d(1, 6, kernel_size 5), BatchNorm(6, num_dims 4), nn.Sigmoid(), nn.MaxPool2d(kernel_size 2, stride 2), nn.Conv2d(6, 16, kernel_size 5), BatchNorm(16, num_dims 4), # 16æ˜¯å·ç§¯å±‚çš„è¾“å‡ºé€šé“æ•° nn.Sigmoid(), nn.MaxPool2d(kernel_size 2, stride 2), nn.Flatten(), nn.Linear(16*4*4, 120), BatchNorm(120, num_dims 2), nn.Sigmoid(), nn.Linear(120, 84), BatchNorm(84, num_dims 2), nn.Sigmoid(), nn.Linear(84, 10) ) lr, num_epochs, batch_size 0.2, 10, 256 train_iter, test_iter d2l.load_data_fashion_mnist(batch_size) d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) ``` ![image 20250115131131636](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501151311132.png) ### ç®€å•å®ç° ```python net nn.Sequential( nn.Conv2d(1, 6, kernel_size 5), nn.BatchNorm2d(6), nn.Sigmoid(), nn.MaxPool2d(kernel_size 2, stride 2), nn.Conv2d(6, 16, kernel_size 5), nn.BatchNorm2d(16), nn.Sigmoid(), nn.MaxPool2d(kernel_size 2, stride 2), nn.Flatten(), nn.Linear(16*4*4, 120), nn.BatchNorm1d(120), nn.Sigmoid(), nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(), nn.Linear(84, 10) ) ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-08-05æ„ŸçŸ¥æœº.html":{"title":"æ„ŸçŸ¥æœº","content":"# æ„ŸçŸ¥æœº ç»™å®šè¾“å…¥x, æƒé‡wå’Œåç§»b, æ„ŸçŸ¥æœºè¾“å‡º ![image 20250108232238937](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501082322970.png) softmaxè¾“å‡ºçš„æ˜¯ä¸€ä¸ªæ¦‚ç‡, çº¿æ€§å›å½’è¾“å‡ºçš„æ˜¯ä¸€ä¸ªå®æ•° ![image 20250108232610625](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501082326667.png) > y~i~æ˜¯+1æˆ–è€… 1, æ‰€ä»¥åˆ†ç±»æ­£ç¡®çš„æ—¶å€™, ä¸¤ä¸ªçš„ä¹˜ç§¯ä¸€å®šæ˜¯å¤§äº0, å¦‚æœåˆ¤æ–­å¤±è´¥çš„è¯æ›´æ–°ä¸€ä¸‹æƒé‡, ä½¿ç”¨ä»¥ä¸‹çš„å‡½æ•°è¿›è¡Œæ›´æ–° > > ![image 20250108232948834](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501082329864.png) ![image 20250108233508436](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501082335493.png) ![image 20250108233550379](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501082335461.png) ## é—®é¢˜ å¯¹äºä¸€ä¸ªXORçš„æ•°æ®ä¸å¯ä»¥æ‹Ÿåˆ, åªå¯ä»¥äº§ç”Ÿä¸€ä¸ªçº¿æ€§çš„åˆ†å‰²é¢ ![image 20250108233723294](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501082337352.png) ä¸å¯ä»¥ä½¿ç”¨ä¸€æ¡çº¿æŠŠæ•°æ®åˆ†å¼€ > å®é™…æ˜¯ä¸€ä¸ªæ‰¹é‡å¤§å°ä¸ºä¸€çš„æ¢¯åº¦ä¸‹é™, æ˜¯ä¸€ä¸ªäºŒåˆ†ç®—æ³• ## å¤šå±‚æ„ŸçŸ¥æœº ![image 20250109093325058](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090933096.png) ![image 20250109093339684](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090933728.png) > è¿›è¡Œå¤šæ¬¡åˆ†ç±», ä½¿ç”¨å¤šæ¬¡çš„ç»“æœè¿›è¡Œè·å–ç»“æœ ![image 20250109093613244](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090936314.png) > è¾“å…¥å’Œè¾“å‡ºçš„ä¸ªæ•°æ˜¯ä¸å¯ä»¥æ”¹å˜çš„, å”¯ä¸€å¯ä»¥æ”¹å˜çš„æ˜¯éšè—å±‚ ![image 20250109094125299](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090941354.png) > è¿™é‡Œçš„éšè—å±‚æ˜¯ä¸€ä¸ªéçº¿æ€§çš„åŸå› æ˜¯å¦‚æœä½¿ç”¨ä¸¤ä¸ªçº¿æ€§å±‚, å›äº‹çš„å®é™…ä½¿ç”¨çš„åˆ†ç±»å‡½æ•°è¿˜æ˜¯ä¸€ä¸ªçº¿æ€§å‡½æ•°, æ‰€ä»¥æ¿€æ´»å‡½æ•°ä¸å¯ä»¥æ˜¯ä¸€ä¸ªçº¿æ€§å‡½æ•°(é¿å…å•å±‚æ„ŸçŸ¥æœº) ## æ¿€æ´»å‡½æ•° æ¿€æ´»å‡½æ•°æ˜¯ç”¨æ¥åŠ å…¥éçº¿æ€§å› ç´ çš„ï¼Œå› ä¸ºçº¿æ€§æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ä¸å¤Ÿï¼Œå¼•å…¥éçº¿æ€§å‡½æ•°ä½œä¸ºæ¿€åŠ±å‡½æ•°ï¼Œè¿™æ ·æ·±å±‚ç¥ç»ç½‘ç»œè¡¨è¾¾èƒ½åŠ›å°±æ›´åŠ å¼ºå¤§ï¼ˆä¸å†æ˜¯è¾“å…¥çš„çº¿æ€§ç»„åˆï¼Œè€Œæ˜¯å‡ ä¹å¯ä»¥é€¼è¿‘ä»»æ„å‡½æ•°ï¼‰ ### Sigmoidæ¿€æ´»å‡½æ•° ![image 20250109094540829](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090945862.png) ![image 20250109094600852](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090946891.png) æŠŠè¿™ä¸€ä¸ªæ•°æ®å‡åŒ€çš„åˆ†å¸ƒåˆ°0å’Œ1ä¹‹é—´, ç›¸æ¯”äºæœ€åˆçš„äºŒåˆ†ç±»æ¨¡å‹æ›´åŠ å¹³æ»‘ ### Tanhå‡½æ•° æŠŠè¾“å…¥æŠ•å°„åˆ°( 1, 1) ![image 20250109094812835](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090948866.png) ![image 20250109094829575](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090948618.png) ### ReLUå‡½æ•° ReLU(x) max(x, 0), å°äº0çš„æ—¶å€™æ˜¯0, å¤§äºçš„æ—¶å€™æ˜¯x > ä½¿ç”¨è¿™ä¸ªå‡½æ•°çš„è®¡ç®—éå¸¸å¿«, æ‰€ä»¥ä½¿ç”¨æ¯”è¾ƒå¤š ## å¤šç±»åˆ†ç±» ![image 20250109095256125](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090952151.png) è¿™æ˜¯ä¹‹å‰çš„åˆ†ç±»æ–¹æ³• ![image 20250109095405411](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090954466.png) å®é™…æ˜¯åœ¨softmaxåˆ†ç±»é‡Œé¢åŠ å…¥ä¸€å±‚ ![image 20250109095513488](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090955541.png) ![image 20250109095709557](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501090957611.png) > ä¸€èˆ¬æ•°æ®æ¯”è¾ƒå¤æ‚çš„æ—¶å€™, å¯ä»¥ä½¿ç”¨æ¯”è¾ƒå¤§çš„éšè—å±‚æˆ–è€…ä½¿ç”¨å¤šä¸ªéšè—å±‚, ä¸€èˆ¬åœ¨ä½¿ç”¨çš„æ—¶å€™ä¸ä¼šå…ˆè¿›è¡Œå‹ç¼©, é¿å…æ•°æ®çš„ä¸¢å¤± ## å®é™…å®ç° + å¯¼å…¥åŒ…å’Œæ•°æ®é›† ```python import torch from torch import nn from d2l import torch as d2l batch_size 256 train_iter, test_iter d2l.load_data_fashion_mnist(batch_size) ``` + å»ºç«‹å‚æ•°åˆ—è¡¨ ```python # å»ºç«‹ä¸€ä¸ªæœ‰å•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœº num_inputs, num_outputs, num_hiddens 784, 10, 256 # è¾“å…¥å±‚åˆ°éšè—å±‚çš„å‚æ•°, 784 * 256, åˆå§‹åŒ–ä¸ºæ­£æ€åˆ†å¸ƒ, ä½¿ç”¨nn.Parameteræ¥å‘Šè¯‰pytorchè¿™æ˜¯ä¸€ä¸ªå‚æ•°(å¯è®­ç»ƒ) # è¿™é‡Œä¸ä½¿ç”¨åŒæ ·çš„å‚æ•°æ˜¯å› ä¸ºå¦‚æœå‚æ•°ç›¸åŒ, é‚£ä¹ˆåœ¨åå‘ä¼ æ’­æ—¶, ä¸¤ä¸ªå‚æ•°çš„æ¢¯åº¦ä¼šç›¸åŒ, ä»è€Œå¯¼è‡´ä¸¤ä¸ªå‚æ•°çš„æ›´æ–°ç›¸åŒ W1 nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad True) * 0.01) # éšè—å±‚åˆ°è¾“å‡ºå±‚çš„å‚æ•°, 256 * 10, åˆå§‹åŒ–ä¸ºæ­£æ€åˆ†å¸ƒ W2 nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad True) * 0.01) # åç½®å‚æ•° b1 nn.Parameter(torch.zeros(num_hiddens, requires_grad True)) b2 nn.Parameter(torch.zeros(num_outputs, requires_grad True)) params [W1, b1, W2, b2] ``` + åŠ ä¸€ä¸ªæ¿€æ´»å‡½æ•° ```python #Reluæ¿€æ´»å‡½æ•° def relu(X): a torch.zeros_like(X) # è·å–ä¸€ä¸ªå’ŒXç›¸åŒå½¢çŠ¶çš„å…¨0å¼ é‡ return torch.max(X, a) ``` + å»ºç«‹ä¸€ä¸ªå®é™…çš„ç½‘ç»œå‡½æ•°, ä»¥åŠä½¿ç”¨ç°æˆçš„æŸå¤±å‡½æ•° ```python # å®šä¹‰æ¨¡å‹, ä¹‹å‰çš„æ¨¡å‹åªè¿›è¡Œäº†çŸ©é˜µä¹˜æ³•, è¿™é‡ŒåŠ å…¥äº†æ¿€æ´»å‡½æ•° def net(X): X X.reshape(( 1, num_inputs)) # å°†è¾“å…¥è½¬æ¢ä¸º2ç»´å¼ é‡ # @è¡¨ç¤ºçŸ©é˜µä¹˜æ³•, n*784 @ 784*256 n*256 H relu(X @ W1 + b1) # n*256 @ 256*10 n*10 return (H @ W2 + b2) # æŸå¤±å‡½æ•° loss nn.CrossEntropyLoss() ``` + å¼€å§‹è®­ç»ƒ ```python num_epochs, lr 10, 0.1 # ä¼˜åŒ–å‡½æ•° updater torch.optim.SGD(params, lr lr) # å®é™…è®­ç»ƒ d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater) ``` ![image 20250109131803953](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501091318018.png) > å®é™…çš„æ•ˆæœæ¯”ä¹‹å‰è¦å¥½ä¸€ç‚¹ > > ![image 20250108193835446](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081938604.png) ### ç®€å•å®ç° ````python import torch from torch import nn from d2l import torch as d2l ```` + è·å–å‚æ•° ```python net nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(),nn.Linear(256, 10)) def init_weights(m): if type(m) nn.Linear: nn.init.normal_(m.weight, std 0.01) net.apply(init_weights) ``` + è·å–ä½¿ç”¨çš„ç®—æ³•ä»¥åŠå¼€å§‹è®­ç»ƒ ```python betch_size, lr, num_epochs 256, 0.1, 10 loss nn.CrossEntropyLoss() trainer torch.optim.SGD(net.parameters(), lr lr) train_iter, test_iter d2l.load_data_fashion_mnist(betch_size) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) ``` ![image 20250109133045270](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501091330318.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-14-15LeNet.html":{"title":"å·ç§¯ç¥ç»ç½‘ç»œLeNet","content":"# å·ç§¯ç¥ç»ç½‘ç»œLeNet å®ƒæ˜¯æœ€æ—©å‘å¸ƒçš„å·ç§¯ç¥ç»ç½‘ç»œä¹‹ä¸€ï¼Œç”±AT&Tè´å°”å®éªŒå®¤çš„ç ”ç©¶å‘˜Yann LeCunåœ¨1989å¹´æå‡ºçš„ï¼ˆå¹¶ä»¥å…¶å‘½åï¼‰ï¼Œç›®çš„æ˜¯è¯†åˆ«å›¾åƒ ([LeCun *et al.*, 1998](https://zh v2.d2l.ai/chapter_references/zreferences.html#id90))ä¸­çš„æ‰‹å†™æ•°å­—ã€‚ LeNetå–å¾—äº†ä¸æ”¯æŒå‘é‡æœºï¼ˆsupport vector machinesï¼‰æ€§èƒ½ç›¸åª²ç¾çš„æˆæœï¼Œæˆä¸ºç›‘ç£å­¦ä¹ çš„ä¸»æµæ–¹æ³•ã€‚ ä½¿ç”¨æ•°æ®é›†MNISTè¿›è¡Œæ‰‹å†™æ•°å­—çš„è¯†åˆ«50000ä¸ªè®­ç»ƒæ•°æ®é›†, 10000ä¸ªæµ‹è¯•æ•°æ®é›†, å›¾åƒæ˜¯28x28 ![image 20250114112336078](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141123260.png) æ¯ä¸ªå·ç§¯å—ä¸­çš„åŸºæœ¬å•å…ƒæ˜¯ä¸€ä¸ªå·ç§¯å±‚ã€ä¸€ä¸ªsigmoidæ¿€æ´»å‡½æ•°å’Œå¹³å‡æ±‡èšå±‚ã€‚è™½ç„¶ReLUå’Œæœ€å¤§æ±‡èšå±‚æ›´æœ‰æ•ˆï¼Œä½†å®ƒä»¬åœ¨20ä¸–çºª90å¹´ä»£è¿˜æ²¡æœ‰å‡ºç°ã€‚æ¯ä¸ªå·ç§¯å±‚ä½¿ç”¨5Ã—5å·ç§¯æ ¸å’Œä¸€ä¸ªsigmoidæ¿€æ´»å‡½æ•°ã€‚è¿™äº›å±‚å°†è¾“å…¥æ˜ å°„åˆ°å¤šä¸ªäºŒç»´ç‰¹å¾è¾“å‡ºï¼Œé€šå¸¸åŒæ—¶å¢åŠ é€šé“çš„æ•°é‡ã€‚ç¬¬ä¸€å·ç§¯å±‚æœ‰6ä¸ªè¾“å‡ºé€šé“ï¼Œè€Œç¬¬äºŒä¸ªå·ç§¯å±‚æœ‰16ä¸ªè¾“å‡ºé€šé“ã€‚æ¯ä¸ª2Ã—2æ± æ“ä½œï¼ˆæ­¥å¹…2ï¼‰é€šè¿‡ç©ºé—´ä¸‹é‡‡æ ·å°†ç»´æ•°å‡å°‘4å€ã€‚å·ç§¯çš„è¾“å‡ºå½¢çŠ¶ç”±æ‰¹é‡å¤§å°ã€é€šé“æ•°ã€é«˜åº¦ã€å®½åº¦å†³å®šã€‚ ![image 20250114112534101](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141125187.png) ## ä»£ç å®ç° ```python import torch from torch import nn from d2l import torch as d2l # æŠŠæ•°æ®è½¬æ¢ä¸ºä¸€ä¸ªå››ç»´å¼ é‡ï¼Œä»¥é€‚åº”å·ç§¯å±‚çš„è¾“å…¥æ ¼å¼ class Reshape(nn.Module): def forward(self, x): return x.view( 1, 1, 28, 28) # LeNetæ¨¡å‹, æ¯ä¸€ä¸ªå±‚æ˜¯ä¸€ä¸ªå·ç§¯+Sigmoidæ¿€æ´»å‡½æ•°+å¹³å‡æ± åŒ–å±‚ # ç¬¬ä¸€å±‚è¾“å‡ºçš„å¤§å°æ˜¯(1, 6, 28, 28), ç¬¬äºŒå±‚è¾“å‡ºçš„å¤§å°æ˜¯(1, 16, 10, 10) net torch.nn.Sequential(Reshape(), nn.Conv2d(1, 6, kernel_size 5, padding 2), nn.Sigmoid(), # (1, 6, 14, 14) nn.AvgPool2d(kernel_size 2, stride 2), # (1, 16, 10, 10) nn.Conv2d(6, 16, kernel_size 5), nn.Sigmoid(), # (1, 16, 5, 5) >(1, 400) nn.AvgPool2d(kernel_size 2, stride 2), nn.Flatten(), nn.Linear(16*5*5, 120), nn.Sigmoid(), nn.Linear(120, 84), nn.Sigmoid(), nn.Linear(84, 10)) ``` + çœ‹ä¸€ä¸‹å®é™…çš„è¾“å‡º ```python X torch.rand(size (1, 1, 28, 28), dtype torch.float32) for layer in net: X layer(X) print(layer.__class__.__name__, 'output shape:\\t', X.shape) \"\"\" Reshape output shape:\t torch.Size([1, 1, 28, 28]) Conv2d output shape:\t torch.Size([1, 6, 28, 28]) Sigmoid output shape:\t torch.Size([1, 6, 28, 28]) AvgPool2d output shape:\t torch.Size([1, 6, 14, 14]) Conv2d output shape:\t torch.Size([1, 16, 10, 10]) Sigmoid output shape:\t torch.Size([1, 16, 10, 10]) AvgPool2d output shape:\t torch.Size([1, 16, 5, 5]) Flatten output shape:\t torch.Size([1, 400]) Linear output shape:\t torch.Size([1, 120]) Sigmoid output shape:\t torch.Size([1, 120]) Linear output shape:\t torch.Size([1, 84]) Sigmoid output shape:\t torch.Size([1, 84]) Linear output shape:\t torch.Size([1, 10]) \"\"\" ``` + å®é™…ä½¿ç”¨æ•°æ®é›†æµ‹è¯• ```python batch_size 256 train_iter, test_iter d2l.load_data_fashion_mnist(batch_size batch_size) ``` + ä½¿ç”¨GPUæµ‹è¯•æ•°æ®çš„å‡†ç¡®æ€§ ```python def evaluate_accuracy_gpu(net, data_iter, device None): #@save \"\"\"ä½¿ç”¨GPUè®¡ç®—æ¨¡å‹åœ¨æ•°æ®é›†ä¸Šçš„ç²¾åº¦ã€‚\"\"\" # isinstanceå‡½æ•°ç”¨äºæ£€æŸ¥ä¸€ä¸ªå¯¹è±¡æ˜¯å¦æ˜¯æŸç§ç‰¹å®šç±»å‹ if isinstance(net, torch.nn.Module): net.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ if not device: device next(iter(net.parameters())).device # æ­£ç¡®é¢„æµ‹çš„æ•°é‡ï¼Œæ€»é¢„æµ‹çš„æ•°é‡ metric d2l.Accumulator(2) for X, y in data_iter: if isinstance(X, list): # BERTå¾®è°ƒæ‰€éœ€çš„ï¼ˆä¹‹åå°†ä»‹ç»ï¼‰ X [x.to(device) for x in X] else: X X.to(device) y y.to(device) metric.add(d2l.accuracy(net(X), y), y.numel()) return metric[0] / metric[1] ``` + ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ ```python def train_ch6(net, train_iter, test_iter, num_epochs, lr, device): \"\"\"ç”¨GPUè®­ç»ƒæ¨¡å‹(åœ¨ç¬¬å…­ç« å®šä¹‰)ã€‚\"\"\" def init_weights(m): if type(m) nn.Linear or type(m) nn.Conv2d: nn.init.xavier_uniform_(m.weight) net.apply(init_weights) print('training on', device) net.to(device) optimizer torch.optim.SGD(net.parameters(), lr lr) loss nn.CrossEntropyLoss() animator d2l.Animator(xlabel 'epoch', xlim [1, num_epochs], legend ['train loss', 'train acc', 'test acc']) timer, num_batches d2l.Timer(), len(train_iter) for epoch in range(num_epochs): # è®­ç»ƒæŸå¤±ä¹‹å’Œï¼Œè®­ç»ƒå‡†ç¡®ç‡ä¹‹å’Œï¼ŒèŒƒä¾‹æ•° metric d2l.Accumulator(3) net.train() # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ for i, (X, y) in enumerate(train_iter): timer.start() optimizer.zero_grad() X, y X.to(device), y.to(device) y_hat net(X) l loss(y_hat, y) l.backward() optimizer.step() with torch.no_grad(): metric.add(l*X.shape[0], d2l.accuracy(y_hat, y), X.shape[0]) timer.stop() train_l metric[0]/metric[2] train_acc metric[1]/metric[2] if (i+1) % (num_batches // 5) 0 or i num_batches 1: animator.add(epoch + (i+1) / num_batches, (train_l, train_acc, None)) test_acc evaluate_accuracy_gpu(net, test_iter) # æµ‹è¯•å‡†ç¡®ç‡ animator.add(epoch+1, (None, None, test_acc)) print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, ' f'test acc {test_acc:.3f}') print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec ' f'on {str(device)}') ``` + å¼€å§‹è®­ç»ƒ ```python lr, num_epochs 0.9, 50 train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) ``` ![image 20250114122144151](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141221262.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-11-37ç¼–ç å™¨è§£ç å™¨.html":{"title":"ç¼–ç å™¨è§£ç å™¨","content":"# ç¼–ç å™¨è§£ç å™¨ ![image 20250213165001095](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502131650196.png) ç¼–ç å™¨: æŠŠè¾“å…¥ç¼–ç¨‹ä¸ºä¸€ä¸ªä¸­é—´çš„è¡¨è¾¾å½¢å¼(ç‰¹å¾), å®ƒæ¥å—ä¸€ä¸ªé•¿åº¦å¯å˜çš„åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå…·æœ‰å›ºå®šå½¢çŠ¶çš„ç¼–ç çŠ¶æ€ è§£ç å™¨: ä¸­é—´å½¢å¼è¡¨è¾¾ä¸ºè§£ç è¾“å‡º, å®ƒå°†å›ºå®šå½¢çŠ¶çš„ç¼–ç çŠ¶æ€æ˜ å°„åˆ°é•¿åº¦å¯å˜çš„åºåˆ—ã€‚è¿™è¢«ç§°ä¸ºç¼–ç å™¨ è§£ç å™¨ ![image 20250211104131054](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111041121.png) ![image 20250211104258835](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111042888.png) > Encoderéƒ¨åˆ†çš„è´£ä»»å°±æ˜¯å¾—åˆ°å‘é‡ C (è¿™ä¸€éƒ¨åˆ†è¾“å…¥çš„ä¿¡æ¯)ã€‚ ## æ¶æ„ ```python from torch import nn #@save class Encoder(nn.Module): \"\"\"ç¼–ç å™¨ è§£ç å™¨æ¶æ„çš„åŸºæœ¬ç¼–ç å™¨æ¥å£\"\"\" def __init__(self, **kwargs): super(Encoder, self).__init__(**kwargs) # ä½¿ç”¨è¾“å…¥è·å–ä¸€ä¸ªè¾“å‡º def forward(self, X, *args): # æ²¡æœ‰å®ç°çš„é”™è¯¯ raise NotImplementedError ``` ```python #@save class Decoder(nn.Module): \"\"\"ç¼–ç å™¨ è§£ç å™¨æ¶æ„çš„åŸºæœ¬è§£ç å™¨æ¥å£\"\"\" def __init__(self, **kwargs): super(Decoder, self).__init__(**kwargs) # è¿™ä¸ªå‡½æ•°çš„ä¸»è¦ä½œç”¨æ˜¯åœ¨å¼€å§‹è§£ç è¿‡ç¨‹ä¹‹å‰ï¼Œ # ä¸ºè§£ç å™¨æä¾›ä¸€ä¸ªåˆå§‹çŠ¶æ€ï¼Œä»¥ä¾¿è§£ç å™¨å¯ä»¥åŸºäºè¿™ä¸ªçŠ¶æ€ç”Ÿæˆç›®æ ‡åºåˆ—ã€‚ def init_state(self, enc_outputs, *args): # enc_outputs çš„å½¢çŠ¶: (æ‰¹é‡å¤§å°, ç¼–ç å™¨åºåˆ—é•¿åº¦, éšè—å•å…ƒä¸ªæ•°) # ï¼Œç”¨äºå°†ç¼–ç å™¨çš„è¾“å‡ºï¼ˆenc_outputsï¼‰è½¬æ¢ä¸ºç¼–ç åçš„è¾“å…¥ # æ­¤æ­¥éª¤å¯èƒ½éœ€è¦é¢å¤–çš„è¾“å…¥ï¼Œä¾‹å¦‚ï¼šè¾“å…¥åºåˆ—çš„æœ‰æ•ˆé•¿åº¦ raise NotImplementedError def forward(self, X, state): raise NotImplementedError ``` æŠŠè¿™ä¸¤ä¸ªæ•´åˆåœ¨ä¸€èµ· ```python #@save class EncoderDecoder(nn.Module): \"\"\"ç¼–ç å™¨ è§£ç å™¨æ¶æ„çš„åŸºç±»\"\"\" def __init__(self, encoder, decoder, **kwargs): super(EncoderDecoder, self).__init__(**kwargs) self.encoder encoder self.decoder decoder def forward(self, enc_X, dec_X, *args): enc_outputs self.encoder(enc_X, *args) dec_state self.decoder.init_state(enc_outputs, *args) return self.decoder(dec_X, dec_state) ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-10-34æ·±åº¦å¾ªç¯ç½‘ç»œ.html":{"title":"æ·±åº¦å¾ªç¯ç½‘ç»œ","content":"# æ·±åº¦å¾ªç¯ç½‘ç»œ ![image 20250210205237762](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102052820.png) > ä¸€ä¸ªå…·æœ‰Lä¸ªéšè—å±‚çš„æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œï¼Œæ¯ä¸ªéšçŠ¶æ€éƒ½è¿ç»­åœ°ä¼ é€’åˆ°å½“å‰å±‚çš„ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ å’Œä¸‹ä¸€å±‚çš„å½“å‰æ—¶é—´æ­¥ äº‹å®ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å°†å¤šå±‚å¾ªç¯ç¥ç»ç½‘ç»œå †å åœ¨ä¸€èµ·ï¼Œé€šè¿‡å¯¹å‡ ä¸ªç®€å•å±‚çš„ç»„åˆï¼Œäº§ç”Ÿäº†ä¸€ä¸ªçµæ´»çš„æœºåˆ¶ã€‚ç‰¹ åˆ«æ˜¯ï¼Œæ•°æ®å¯èƒ½ä¸ä¸åŒå±‚çš„å †å æœ‰å…³ã€‚ ![image 20250210205451596](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102054642.png) ![image 20250210205732627](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102057682.png) ![image 20250210205743679](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102057726.png) ## ä»£ç å®ç° ````python import torch from torch import nn from d2l import torch as d2l batch_size, num_steps 32, 35 train_iter, vocab d2l.load_data_time_machine(batch_size, num_steps) ```` ç½‘ç»œ, åªæ˜¯å¤šä¸€ä¸ªå‚æ•° ```python vocab_size, num_hiddens, num_layers len(vocab), 256, 2 num_inputs vocab_size device d2l.try_gpu() lstm_layer nn.LSTM(num_inputs, num_hiddens, num_layers) model d2l.RNNModel(lstm_layer, len(vocab)) model model.to(device) ``` å¼€å§‹è®­ç»ƒ ```python num_epochs, lr 500, 2 d2l.train_ch8(model, train_iter, vocab, lr*1.0, num_epochs, device) ``` ![image 20250210210240459](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102102510.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-12-å®æˆ˜æ¯”èµ›.html":{"title":"å®æˆ˜æ¯”èµ›","content":"# å®æˆ˜æ¯”èµ› ## æµ‹è¯•ç¤ºä¾‹ + ä¸‹è½½æ•°æ®ä½¿ç”¨çš„å‡½æ•° ```python import hashlib import os import tarfile import zipfile import requests DATA_HUB dict() DATA_URL 'http://d2l data.s3 accelerate.amazonaws.com/' def download(name, cache_dir os.path.join('..', 'data')): \"\"\"ä¸‹è½½ä¸€ä¸ªDATA_HUBä¸­çš„æ–‡ä»¶ï¼Œè¿”å›æœ¬åœ°æ–‡ä»¶åã€‚\"\"\" assert name in DATA_HUB, f\"{name} ä¸å­˜åœ¨äº {DATA_HUB}.\" url, sha1_hash DATA_HUB[name] os.makedirs(cache_dir, exist_ok True) fname os.path.join(cache_dir, url.split('/')[ 1]) # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ— éœ€é‡æ–°ä¸‹è½½ if os.path.exists(fname): # ä¸ºäº†æ›´å¿«è®¡ç®—sha1ï¼Œä½¿ç”¨4Mçš„ç¼“å†²åŒº # æ£€æµ‹å“ˆå¸Œå€¼ sha1 hashlib.sha1() with open(fname, 'rb') as f: while True: data f.read(1048576) if not data: break sha1.update(data) # æ›´æ–°sha1 if sha1.hexdigest() sha1_hash: # sha1åŒ¹é…åˆ™è¿”å› return fname print(f'æ­£åœ¨ä»{url}ä¸‹è½½{fname}...') r requests.get(url, stream True, verify True) with open(fname, 'wb') as f: f.write(r.content) return fname def download_extract(name, folder None): \"\"\"ä¸‹è½½å¹¶è§£å‹zip/taræ–‡ä»¶ã€‚\"\"\" fname download(name) base_dir os.path.dirname(fname) data_dir, ext os.path.splitext(fname) if ext '.zip': fp zipfile.ZipFile(fname, 'r') elif ext in ('.tar', '.gz'): fp tarfile.open(fname, 'r') else: assert False, 'åªæœ‰zip/taræ–‡ä»¶å¯ä»¥è¢«è§£å‹ç¼©ã€‚' fp.extractall(base_dir) return os.path.join(base_dir, folder) if folder else data_dir def download_all(): \"\"\"ä¸‹è½½DATA_HUBä¸­çš„æ‰€æœ‰æ–‡ä»¶ã€‚\"\"\" for name in DATA_HUB: download(name) ``` + å®é™…ä¸‹è½½æ•°æ® ```python %matplotlib inline import numpy as np import pandas as pd import torch from torch import nn from d2l import torch as d2l DATA_HUB['kaggle_house_train'] ( DATA_URL + 'kaggle_house_pred_train.csv', '585e9cc93e70b39160e7921475f9bcd7d31219ce') DATA_HUB['kaggle_house_test'] ( DATA_URL + 'kaggle_house_pred_test.csv', 'fa19780a7b011d9b009e8bff8e99922a8ee2eb90') train_data pd.read_csv(download('kaggle_house_train')) test_data pd.read_csv(download('kaggle_house_test')) print(train_data.shape) print(test_data.shape) ``` + è·å–çš„æ•°æ®å¤„ç†ä¸€ä¸‹, ä½¿å¾—æ•°å€¼æ­£æ€åˆ†å¸ƒ ```python # åœ¨æ ‡å‡†åŒ–æ•°æ®ä¹‹åï¼Œæ‰€æœ‰æ•°æ®éƒ½æ„å‘³ç€å¹³å‡å€¼ä¸º0ä¸”æ ‡å‡†å·®ä¸º1 # é¦–å…ˆä½¿ç”¨.dtypeè·å–æ‰€æœ‰æ•°å€¼ç‰¹å¾çš„ç´¢å¼•, ç„¶åè·å–ä¸ºæ•°å€¼çš„åˆ—, å¹¶ä¸”å°†æ‰€æœ‰ç¼ºå¤±å€¼æ›¿æ¢ä¸º0 numeric_features all_features.dtypes[all_features.dtypes ! 'object'].index all_features[numeric_features] all_features[numeric_features].apply( lambda x: (x x.mean()) / (x.std())) # åœ¨æ ‡å‡†åŒ–æ•°æ®ä¹‹åï¼Œç¼ºå¤±å€¼è¢«è®¾ç½®ä¸º0, å‡å€¼å·²ç»æ˜¯0äº† all_features[numeric_features] all_features[numeric_features].fillna(0) ``` + å¤„ç†ä¸€ä¸‹å­—ç¬¦ä¸², æŠŠä¸€åˆ—ä¸­çš„å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ¯ä¸€ä¸ªä¸åŒé¡¹çš„boolæ•°ç»„, ä½¿ç”¨ä¹‹å‰çš„å­—ç¬¦ä¸²ä¸ºåˆ—çš„åå­—, å¯¹åº”çš„é¡¹ä¸ºtrue ```python # `Dummy_na True` å°†â€œnaâ€ï¼ˆç¼ºå¤±å€¼ï¼‰è§†ä¸ºæœ‰æ•ˆçš„ç‰¹å¾å€¼ï¼Œå¹¶ä¸ºå…¶åˆ›å»ºæŒ‡ç¤ºç¬¦ç‰¹å¾ all_features pd.get_dummies(all_features, dummy_na True, dtype np.float32) ``` + è·å–å®é™…çš„æ•°æ® ```python n_train train_data.shape[0] train_features torch.tensor(all_features[:n_train].values, dtype torch.float32) test_features torch.tensor(all_features[n_train:].values, dtype torch.float32) train_labels torch.tensor(train_data.SalePrice.values.reshape( 1, 1), dtype torch.float32) ``` + å»ºç«‹ç½‘ç»œä»¥åŠè¯¯å·®å‡½æ•° ```python loss nn.MSELoss() in_features train_features.shape[1] def get_net(): net nn.Sequential(nn.Linear(in_features, 1)) return net ``` + å¯¹è·å–çš„è¯¯å·®è¿›è¡Œä¸€æ¬¡log, è¿™æ ·æ•°æ®åœ¨æ•°æ®æ¯”è¾ƒå¤§çš„å€¼å’Œæ¯”è¾ƒå°çš„å€¼çš„æ—¶å€™çš„è¯¯å·®ç›¸è¿‘ ```python def log_rmse(net, features, labels): # ä¸ºäº†åœ¨å–å¯¹æ•°æ—¶è¿›ä¸€æ­¥ç¨³å®šè¯¥å€¼ï¼Œå°†å°äº1çš„å€¼è®¾ç½®ä¸º1 # è¿™æ ·å¤§æ•°æ®ä»¥åŠå°æ•°æ®ä¹‹é—´çš„å·®è·ä¸ä¼šå¤ªå¤§ # å°†å°äº1çš„å€¼è®¾ç½®ä¸º1 clipped_preds torch.clamp(net(features), 1, float('inf')) # è®¡ç®—å¯¹æ•°å‡æ–¹æ ¹è¯¯å·® rmse torch.sqrt(2 * loss(clipped_preds.log(), labels.log()).mean()) return rmse.item() ``` + åˆå§‹åŒ–ä¸€ä¸ªè®­ç»ƒå‡½æ•° ```python def train(net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size): train_ls, test_ls [], [] train_iter d2l.load_array((train_features, train_labels), batch_size) # è¿™é‡Œä½¿ç”¨çš„æ˜¯Adamä¼˜åŒ–ç®—æ³•, å¯¹å­¦ä¹ ç‡ä¸å¤ªæ•æ„Ÿ optimizer torch.optim.Adam(net.parameters(), lr learning_rate, weight_decay weight_decay) for epoch in range(num_epochs): for X, y in train_iter: optimizer.zero_grad() l loss(net(X), y) l.backward() optimizer.step() # è®°å½•ä¸€ä¸‹è®­ç»ƒçš„è¯¯å·® train_ls.append(log_rmse(net, train_features, train_labels)) if test_labels is not None: test_ls.append(log_rmse(net, test_features, test_labels)) return train_ls, test_ls ``` + è¿›è¡Œä¸€æ¬¡K åˆ™äº¤å‰éªŒè¯å®ç° ```python # è·å–æ¯ä¸€æ¬¡ä½¿ç”¨çš„æ•°æ®é›† def get_k_fold_data(k, i, X, y): assert k > 1 fold_size X.shape[0] // k # æ¯ä¸€æ¬¡çš„éªŒè¯é›†å¤§å° X_train, y_train None, None for j in range(k): idx slice(j * fold_size, (j + 1) * fold_size) X_part, y_part X[idx, :], y[idx] if j i: X_valid, y_valid X_part, y_part elif X_train is None: X_train, y_train X_part, y_part else: X_train torch.cat([X_train, X_part], 0) # æ²¿ç€0è½´æ‹¼æ¥ y_train torch.cat([y_train, y_part], 0) return X_train, y_train, X_valid, y_valid # å®é™…çš„è®­ç»ƒå‡½æ•° def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size): train_l_sum, valid_l_sum 0, 0 for i in range(k): data get_k_fold_data(k, i, X_train, y_train) net get_net() train_ls, valid_ls train(net, *data, num_epochs, learning_rate, weight_decay, batch_size) train_l_sum + train_ls[ 1] # å–æœ€åä¸€æ¬¡è®­ç»ƒçš„å€¼ valid_l_sum + valid_ls[ 1] if i 0: d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls], xlabel 'epoch', ylabel 'rmse', xlim [1, num_epochs], legend ['train', 'valid'], yscale 'log') print(f'fold {i + 1}, train log rmse {float(train_ls[ 1]):f}, ' f'valid log rmse {float(valid_ls[ 1]):f}') return train_l_sum / k, valid_l_sum / k ``` + å¼€å§‹è®­ç»ƒ ```python k, num_epochs, lr, weight_decay, batch_size 5, 100, 5, 0, 64 train_l, valid_l k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size) print(f'{k} æŠ˜éªŒè¯: å¹³å‡è®­ç»ƒlog rmse: {float(train_l):f}, ' f'å¹³å‡éªŒè¯log rmse: {float(valid_l):f}') ``` + ä½¿ç”¨æµ‹è¯•é›†é¢„æµ‹ä¸€ä¸‹ ```python def train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size): net get_net() train_ls, _ train(net, train_features, train_labels, None, None, num_epochs, lr, weight_decay, batch_size) d2l.plot(np.arange(1, num_epochs + 1), [train_ls], xlabel 'epoch', ylabel 'log rmse', xlim [1, num_epochs], yscale 'log') print(f'train log rmse {float(train_ls[ 1]):f}') # å°†ç½‘ç»œåº”ç”¨äºæµ‹è¯•é›†, detach()å°†å…¶ä»è®¡ç®—å›¾åˆ†ç¦», å¹¶è½¬æ¢ä¸ºnumpyæ ¼å¼ preds net(test_features).detach().numpy() # å°†å…¶é‡æ–°æ ¼å¼åŒ–ä»¥å¯¼å‡ºåˆ°Kaggle test_data['SalePrice'] pd.Series(preds.reshape(1, 1)[0]) submission pd.concat([test_data['Id'], test_data['SalePrice']], axis 1) submission.to_csv('submission.csv', index False) train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size) ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-10-10ä¸¢å¼ƒæ³•.html":{"title":"ä¸¢å¼ƒæ³•Drop out","content":"# ä¸¢å¼ƒæ³•Drop out ä¸€ä¸ªå¥½çš„æ¨¡å‹, å¦‚æœè¾“å…¥çš„æ•°æ®æœ‰ä¸€éƒ¨åˆ†çš„æ‰°åŠ¨ä¹Ÿæ˜¯å¯ä»¥æ­£å¸¸åˆ†æçš„, ä½¿ç”¨æœ‰å™ªéŸ³çš„æ•°æ®ç­‰ä»·äºTikhonovæ­£åˆ™ ä¸¢å¼ƒæ³•: åœ¨å±‚ä¹‹é—´åŠ å…¥å™ªéŸ³ ## æ²¡æœ‰åå·®çš„åŠ å…¥å™ªéŸ³ å¯¹äºxåŠ å…¥å™ªéŸ³x'ä½¿å¾—E[x'] x, æœŸæœ›å€¼ä¸å˜ ![image 20250110233531804](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501102335922.png) é€‚ä¸­çš„ä¸€éƒ¨åˆ†æ•°æ®è¿›è¡Œä¸¢å¼ƒ, å¦ä¸€éƒ¨åˆ†æ•°æ®æ¦‚ç‡æ”¾å¤§ä»¥åæ€»æ¦‚ç‡å˜ä¸º1 è¿™ä¸€å±‚ä¸€èˆ¬ä½¿ç”¨åœ¨éšè—å…¨è¿æ¥å±‚çš„è¾“å‡ºä¸Šé¢ ![image 20250110233809902](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501102338011.png) ![image 20250110233858777](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501102338862.png) > è¿™ä¸€ä¸ªåªåœ¨è®­ç»ƒçš„æ—¶å€™ä½¿ç”¨, æ˜¯ä¸€ä¸ªæ­£åˆ™é¡¹, æ¨ç†çš„æ—¶å€™è¾“å…¥ç­‰äºè¾“å‡º, å®é™…ç›¸å½“äºéšæœºä½¿ç”¨ä¸€éƒ¨åˆ†çš„å°çš„ç½‘ç»œ, è¿™ä¸€éƒ¨åˆ†çš„æ¢¯åº¦ä¹Ÿä¼šé™ä½ä¸º0 > > è¿™ä¸€ä¸ªæ–¹å¼ä¸€èˆ¬æ˜¯å…¨è¿æ¥å±‚åœ¨ä½¿ç”¨, å·ç§¯å±‚ä½¿ç”¨çš„æ˜¯æƒé‡è¡°é€€å¤šä¸€ç‚¹ ### å®é™…å®ç° ```python import torch import torch.nn as nn from d2l import torch as d2l ``` + åˆå§‹åŒ–ä¸€ä¸‹ä½¿ç”¨çš„drop_outå‡½æ•° ```python def dropout_layer(X, dropout): assert 0 < dropout < 1 if dropout 1: return torch.zeros_like(X) if dropout 0: return X # å®é™…çš„è®¡ç®—, ç”Ÿæˆä¸€ä¸ªéšæœºæ•°, è½¬æ¢ä¸º0, 1, ç„¶åå’ŒXç›¸ä¹˜, é™¤ä»¥(1 dropout) mask (torch.randn(X.shape) > dropout).float() return mask * X / (1.0 dropout) # ä½¿ç”¨ä¹˜æ³•çš„è®¡ç®—é€Ÿåº¦æ¯”è¾ƒå¿« ``` + æ‰“å°ä¸€ä¸‹å®éªŒ ```python X torch.arange(16, dtype torch.float32).reshape((2, 8)) print(X) print(dropout_layer(X, 0.)) print(dropout_layer(X, 0.5)) print(dropout_layer(X, 1.)) \"\"\" tensor([[ 0., 1., 2., 3., 4., 5., 6., 7.], [ 8., 9., 10., 11., 12., 13., 14., 15.]]) tensor([[ 0., 1., 2., 3., 4., 5., 6., 7.], [ 8., 9., 10., 11., 12., 13., 14., 15.]]) tensor([[ 0., 0., 0., 0., 0., 10., 0., 14.], [ 0., 0., 0., 0., 24., 26., 0., 0.]]) tensor([[0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0.]]) \"\"\" ``` + å®é™…å»ºç«‹ç½‘ç»œ ```python num_inputs, num_outputs, num_hidden1, num_hidden2 784, 10, 256, 256 dropout1, dropout2 0.2, 0.5 class Net(nn.Module): def __init__(self, num_inputs, num_outputs, num_hidden1, num_hidden2, is_training True): super(Net, self).__init__() self.num_inputs num_inputs self.training is_training self.lin1 nn.Linear(num_inputs, num_hidden1) self.lin2 nn.Linear(num_hidden1, num_hidden2) self.lin3 nn.Linear(num_hidden2, num_outputs) self.relu nn.ReLU() # æ¿€æ´»å‡½æ•°, è¿”å›max(0, x) def forward(self, X): H1 self.relu(self.lin1(X.reshape(( 1, self.num_inputs)))) if self.training: H1 dropout_layer(H1, dropout1) H2 self.relu(self.lin2(H1)) if self.training: H2 dropout_layer(H2, dropout2) out self.lin3(H2) return out net Net(num_inputs, num_outputs, num_hidden1, num_hidden2) ``` + è¿è¡Œ ```python num_epochs, lr, batch_size 10, 0.5, 256 loss nn.CrossEntropyLoss() train_iter, test_iter d2l.load_data_fashion_mnist(batch_size) trainer torch.optim.SGD(net.parameters(), lr lr) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) ``` ![image 20250111105045907](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111050148.png) ### ç®€å•å®ç° ```python net nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(), nn.Dropout(dropout1), nn.Linear(256, 256), nn.ReLU(), nn.Dropout(dropout2), nn.Linear(256, 10)) def init_weights(m): if type(m) nn.Linear: nn.init.normal_(m.weight, std 0.01) net.apply(init_weights) trainer torch.optim.SGD(net.parameters(), lr lr) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) ``` ![image 20250111105135572](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111051656.png) > dropä¸º0çš„æ—¶å€™ > > ![image 20250111105152631](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111051718.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-11-11æ•°å€¼ç¨³å®šæ€§.html":{"title":"æ•°å€¼ç¨³å®šæ€§","content":"# æ•°å€¼ç¨³å®šæ€§ ![image 20250111171922663](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111719115.png) è¿™é‡Œçš„yæ˜¯ç»è¿‡æ‰€æœ‰å±‚ä»¥åè¿˜æœ‰ä¸€ä¸ªæŸå¤±å‡½æ•°ä»¥åå¾—ç»“æœ ![image 20250111172213613](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111722686.png) è¿™æ˜¯è®¡ç®—äº†å¾ˆå¤šæ¬¡çš„çŸ©é˜µä¹˜æ³•, ä¼šå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸ä»¥åŠæ¢¯åº¦æ¶ˆå¤± æ¢¯åº¦çˆ†ç‚¸: è·å–åˆ°ä¸€ä¸ªå¾ˆå¤§çš„æ•°å­— æ¢¯åº¦æ¶ˆå¤±: è·å–çš„æ˜¯ä¸€ä¸ªå¾ˆå°çš„æ•°å­— ![image 20250111172851544](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111728616.png) ![image 20250111173153592](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111731685.png) æ¢¯åº¦çˆ†ç‚¸å¯¼è‡´çš„é—®é¢˜: å°‘å‡ºåŸŸå€¼(infinity)å¯¹äº16ä½çš„æµ®ç‚¹æ•°å°¤å…¶ä¸¥é‡, åŒæ—¶å¯¹äºå­¦ä¹ ç‡å¾ˆæ•æ„Ÿ, å¯¼è‡´å‚æ•°å¾ˆéš¾è°ƒ ![image 20250111173454284](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111734398.png) ä½¿ç”¨è¿™ä¸ªå‡½æ•°çš„æ—¶å€™åœ¨æç«¯çš„æ•°å€¼çš„æ—¶å€™å‡½æ•°çš„æ¢¯åº¦å¾ˆå°, æ±‚å¯¼ä¼šå¯¼è‡´å¾ˆå¤šä¸ªå°æ•°ç›¸ä¹˜ ![image 20250111173740419](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111737468.png) å¦‚æœè¿‡æ•°å€¼è¿‡å°, æ¢¯åº¦å€¼å˜ä¸º0, å¯¼è‡´è®­ç»ƒæ²¡æœ‰è¿›å±•, å¯¹äºåº•éƒ¨çš„å±‚æœ€ä¸ºä¸¥é‡, é¡¶å±‚çš„ç½‘ç»œè®­ç»ƒæ¯”è¾ƒå¥½, ä¸‹é¢çš„å±‚å®é™…æ²¡æœ‰èµ·ä½œç”¨ ## è§£å†³æ–¹æ³• ç›®æ ‡: ä½¿æ¢¯åº¦å€¼åœ¨ä¸€ä¸ªåˆç†çš„åŒºé—´é‡Œé¢ æ–¹æ³•: + ä¹˜æ³•å˜ä¸ºåŠ æ³•ResNet, LSTM + å½’ä¸€åŒ–: æ¢¯åº¦å½’ä¸€åŒ–, æ¢¯åº¦å‰ªè£ + åˆç†çš„æƒé‡åˆå§‹åŒ–ä»¥åŠåˆç†çš„æ¿€æ´»å‡½æ•° å®é™…å®ç°: æ¯ä¸€å±‚çš„è¾“å‡ºä»¥åŠæ¢¯åº¦çœ‹åšä¸€ä¸ªéšæœºå˜é‡, ä½¿ä»–ä»¬çš„è¾“å‡ºä»¥åŠæ–¹å·®ä¿æŒä¸€è‡´ ![image 20250111174634233](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111746501.png) ### æƒé‡åˆå§‹åŒ– åœ¨åˆç†çš„åŒºé—´é‡Œé¢åˆå§‹åŒ–å‚æ•° è®­ç»ƒå¼€å§‹çš„æ—¶å€™å®¹æ˜“æœ‰æ•°æ®çš„ä¸ç¨³å®š, è¿œç¦»æœ€ä¼˜è§£çš„ä½ç½®çš„æ•°å€¼ä¸ç¨³å®š, æŸå¤±å‡½æ•°è¡¨é¢æ¯”è¾ƒå¤æ‚, æœ€ä¼˜è§£é™„è¿‘çš„æ¯”è¾ƒå¹³ ä½¿ç”¨N~(0, 0.01)åœ¨æ¯”è¾ƒå°çš„ç½‘ç»œå¯ä»¥ä½¿ç”¨ #### æ²¡æœ‰æ¿€æ´»å‡½æ•°çš„æ—¶å€™ ![image 20250111175129593](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111751662.png) ![image 20250111175338122](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111753214.png) ![image 20250111175931950](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111759022.png) > æƒ³è¦æ»¡è¶³è¾“å…¥å’Œè¾“å‡ºçš„æ–¹å·®æ˜¯ä¸€æ ·çš„æ—¶å€™, éœ€è¦æ»¡è¶³å³è¾¹çš„å¼å­ <img src \"https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111802764.png\" alt \"image 20250111180224615\" style \"zoom:200%;\" /> æ€»ç»“: è¿™ä¸€ä¸ªç­‰å¼å¾ˆéš¾æ»¡è¶³, é™¤éæŸä¸€å±‚çš„è¾“å…¥å’Œè¾“å‡ºçš„é¡¹æ˜¯ç›¸åŒçš„ ![image 20250111182644081](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111826166.png) #### æœ‰æ¿€æ´»å‡½æ•° ![image 20250111183116734](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111831826.png) ![image 20250111183200544](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111832620.png) å®é™…åœ¨ä½¿ç”¨çš„æ—¶å€™æ¿€æ´»å‡½æ•°è¦åŸºæœ¬æ»¡è¶³`f(x) x` ![image 20250111183339198](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501111833325.png) > åœ¨é›¶ç‚¹çš„é™„è¿‘å…¶ä»–çš„ä¸¤ä¸ªå‡½æ•°æ¯”è¾ƒæ¥è¿‘x #### æ€»ç»“ åˆç†çš„è®¾è®¡æ¿€æ´»å‡½æ•°ä»¥åŠåˆå§‹åŒ–æƒé‡å¯ä»¥æé«˜æ•°å€¼çš„ç¨³å®šæ€§ ### ä»£ç å®ç° [å‚æ•°åˆå§‹åŒ–ä¸å½“å¯¼è‡´è®­ç»ƒä¸ç¨³å®š è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/2469173) ```python import numpy as np # Xavieråˆå§‹åŒ– def xavier_init(shape): in_dim, out_dim shape limit np.sqrt(6 / (in_dim + out_dim)) # é™åˆ¶, sqrtæ˜¯å¼€æ–¹ return np.random.uniform( limit, limit, size shape) # ç”Ÿæˆä¸€ä¸ªå‡åŒ€åˆ†å¸ƒçš„éšæœºæ•° ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-18-24CIFARæ•°æ®é›†.html":{"title":"CIFARæ•°æ®é›†","content":"# CIFARæ•°æ®é›† æ˜¯ä¸€ä¸ªkaggleé‡Œé¢çš„ä¸€ä¸ªæ¯”èµ›, æ˜¯ä¸€ä¸ªæ¯”è¾ƒå¤§çš„æ•°æ®é›†, ä¸‹é¢è®°å½•ä¸€ä¸‹ä½¿ç”¨å›¾ç‰‡ä»¥åŠä¸€ä¸ªcsvåˆ†ç±»çš„æ—¶å€™çš„å‡ ç§å¤„ç†æ–¹å¼ ## åœ¨åŠ è½½çš„æ—¶å€™åˆ†ç±» é¦–å…ˆéœ€è¦æå–å‡ºæ¥ä¸åŒçš„ç±»åˆ« ```python leaves_labels sorted(list(set(labels_dataframe['label']))) n_classes len(leaves_labels) ``` ä½¿ç”¨è¿™ä¸ªäº†åˆ«å¯ä»¥å»ºç«‹ä¸€ä¸ªå¯¹åº”çš„è¡¨, å»ºç«‹ä»¥åè¿˜éœ€è¦ä¸€ä¸ªè¿”å›çš„è¡¨ ```python class_to_num dict(zip(leaves_labels, range(n_classes))) num_to_class {v:k for k,v in class_to_num.items()} \"\"\" {0: 'abies_concolor', 1: 'abies_nordmanniana', 2: 'acer_campestre', 3: 'acer_ginnala', 4: 'acer_griseum', 5: 'acer_negundo', 6: 'acer_palmatum', ... \"\"\" ``` ä¸‹é¢å»ºç«‹ä¸€ä¸ªDatasetçš„å­ç±», å®ç°æ•°æ®çš„åˆå§‹åŒ–ä»¥åŠç»™æ•°æ®çš„æ ‡å·è¿›è¡Œè¿”å›å¯¹åº”çš„æ•°æ® ```python class LeavesData(Dataset): def __init__(self, csv_path, file_path, mode 'train', valid_ratio 0.2, resize_height 256, resize_width 256): \"\"\" Args: csv_path (string): csv æ–‡ä»¶è·¯å¾„ img_path (string): å›¾åƒæ–‡ä»¶æ‰€åœ¨è·¯å¾„ mode (string): è®­ç»ƒæ¨¡å¼è¿˜æ˜¯æµ‹è¯•æ¨¡å¼ valid_ratio (float): éªŒè¯é›†æ¯”ä¾‹ \"\"\" self.file_path file_path self.resize_height resize_height self.resize_width resize_width self.mode mode # è¯»å– csv æ–‡ä»¶ self.data_info pd.read_csv(csv_path) self.data_len len(self.data_info.index) self.train_len int(self.data_len * (1 valid_ratio)) if mode 'train': # è®­ç»ƒé›†, åˆ†å‰²å‡ºæ¥ä¸€éƒ¨åˆ†æ•°æ® self.train_image np.asarray(self.data_info.iloc[0:self.train_len]['image']) self.train_label np.asarray(self.data_info.iloc[0:self.train_len]['label']) self.image_arr self.train_image self.label_arr self.train_label self.data_len len(self.train_image) # è®°å½•æ•°æ®çš„å¤§å° elif mode 'valid': # éªŒè¯é›† self.valid_image np.asarray(self.data_info.iloc[self.train_len:]['image']) self.valid_label np.asarray(self.data_info.iloc[self.train_len:]['label']) self.image_arr self.valid_image self.label_arr self.valid_label self.data_len len(self.valid_image) else: # æµ‹è¯•é›† self.test_image np.asarray(self.data_info.iloc[0:]['image']) self.image_arr self.test_image self.data_len len(self.test_image) print('Finished reading the {} set of Leaves Dataset ({} samples found)'.format(mode, self.data_len)) def __getitem__(self, index): # ä» image_arrä¸­å¾—åˆ°ç´¢å¼•å¯¹åº”çš„æ–‡ä»¶å single_image_name self.image_arr[index] # è¯»å–å›¾åƒæ–‡ä»¶ img_as_img Image.open(self.file_path + single_image_name) # å¦‚æœéœ€è¦å°†ç°åº¦å›¾è½¬æ¢ä¸º RGB å½©è‰²å›¾ if img_as_img.mode ! 'RGB': img_as_img img_as_img.convert('RGB') normalize torchvision.transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) # å¯¹æ•°æ®è¿›è¡Œä¸€æ¬¡é¢„å¤„ç† if self.mode \"train\": train_augs torchvision.transforms.Compose([ torchvision.transforms.RandomResizedCrop(224), torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor(), normalize]) img_as_img train_augs(img_as_img) else: test_augs torchvision.transforms.Compose([ torchvision.transforms.Resize(256), torchvision.transforms.CenterCrop(224), torchvision.transforms.ToTensor(), normalize]) img_as_img test_augs(img_as_img) # å¾—åˆ°å›¾åƒçš„ label if self.mode 'test': label 1 else: label self.label_arr[index] label class_to_num[label] # æŠŠæ ‡å·è½¬ä¸ºæ•°ç»„tensor label torch.tensor(label) return img_as_img, label def __len__(self): return self.data_len ``` æ•°æ®é›†çš„åŠ è½½ ```python train_path \"../data/train.csv\" test_path \"../data/test.csv\" img_path \"../data/\" train_dataset LeavesData(train_path, img_path, mode 'train') valid_dataset LeavesData(train_path, img_path, mode 'valid') test_dataset LeavesData(test_path, img_path, mode 'test') train_loader DataLoader(dataset train_dataset, batch_size 128, shuffle True) valid_loader DataLoader(dataset valid_dataset, batch_size 128) test_loader DataLoader(dataset test_dataset, batch_size 128) for i, data in enumerate(train_loader): inputs, labels data print(inputs.size(), labels) break \"\"\" torch.Size([128, 3, 224, 224]) tensor([164, 69, 118, 25, 116, 40, 130, 50, 153, 133, 94, 76, 58, 3, 104, 5, 126, 2, 0, 125, 25, 51, 141, 14, 36, 77, 107, 10, 59, 101, 59, 81, 123, 95, 30, 61, 40, 162, 174, 110, 145, 58, 31, 164, 45, 107, 28, 159, 11, 67, 22, 131, 57, 78, 86, 123, 155, 130, 83, 14, 108, 108, 161, 147, 108, 28, 69, 106, 75, 144, 80, 128, 111, 32, 96, 84, 59, 23, 53, 107, 14, 135, 42, 2, 68, 7, 71, 4, 37, 65, 126, 57, 77, 145, 24, 52, 71, 37, 0, 99, 32, 70, 173, 147, 144, 71, 64, 92, 12, 28, 162, 68, 20, 145, 115, 65, 45, 132, 69, 111, 39, 130, 17, 157, 130, 142, 99, 30]) \"\"\" ``` ## æŒ‰ç…§æ–‡ä»¶å¤¹è¿›è¡Œè®°å½• ```python def read_csv_file(fname): \"\"\"è¯»å–æ–‡ä»¶ç»™æ–‡ä»¶æ ‡ç­¾è¿”å›ä¸€ä¸ªå­—å…¸\"\"\" with open(fname, 'r') as f: lines f.readlines() # rstrip() æ–¹æ³•ç”¨äºåˆ é™¤å­—ç¬¦ä¸²æœ«å°¾çš„ç©ºç™½å­—ç¬¦, split() æ–¹æ³•ç”¨äºæŠŠä¸€ä¸ªå­—ç¬¦ä¸²åˆ†å‰²æˆå­—ç¬¦ä¸²åˆ—è¡¨ tokens [line.rstrip().split(',') for line in lines] return dict((tokens[0], tokens[1]) for i, tokens in enumerate(tokens)) labels read_csv_file(os.path.join(data_dir, 'train.csv')) ``` > è¯»å–ä¸€ä¸ªcsvæ–‡ä»¶, ä»¥å­—å…¸çš„å½¢å¼è¿›è¡Œè¿”å› + å»ºç«‹ä¸€ä¸ªå¤åˆ¶çš„å‡½æ•°, æŠŠæ–‡ä»¶æŒ‰ç…§csvæ–‡ä»¶é‡Œé¢çš„åˆ†ç±»è¿›è¡ŒæŒ‰æ–‡ä»¶å¤¹å­˜å‚¨ ```python def copyfile(filename, target_dir): \"\"\"å°†æ–‡ä»¶å¤åˆ¶åˆ°ç›®æ ‡ç›®å½•ã€‚\"\"\" os.makedirs(target_dir, exist_ok True) shutil.copy(filename, target_dir) # data_dir: æ•°æ®é›†ç›®å½•, labels: {filename: label}, valid_ratio: éªŒè¯é›†ä¸­çš„æ ·æœ¬å æ¯” def reorg_train_valid(data_dir, labels, valid_ratio): # å°†è¿”å›ä¸€ä¸ªæŒ‰å‡ºç°æ¬¡æ•°ç”±é«˜åˆ°ä½æ’åˆ—çš„å…ƒç»„åˆ—è¡¨ï¼Œ # å…¶ä¸­æ¯ä¸ªå…ƒç»„åŒ…å«ä¸€ä¸ªæ ‡ç­¾å’Œè¯¥æ ‡ç­¾å‡ºç°çš„æ¬¡æ•°ã€‚ # collections.Counterç”¨äºç»Ÿè®¡æ ‡ç­¾çš„ä¸ªæ•°, most_common()æ–¹æ³•è¿”å›æœ€å¸¸è§çš„nä¸ªå…ƒç´  n collections.Counter(labels.values()).most_common()[ 1][1] # è¿”å›å°äºæˆ–ç­‰äºæŒ‡å®šæ•°å€¼çš„æœ€å¤§æ•´æ•°å€¼ n_valid_per_label max(1, math.floor(n * valid_ratio)) label_count {} for file in os.listdir(os.path.join(data_dir, 'images')): # è¯»å–æ–‡ä»¶æ ‡ç­¾ file os.path.join('images', file) file file.replace('\\\\', '/') label labels[file] fname os.path.join(data_dir, file) # å°†æ–‡ä»¶å¤åˆ¶åˆ°ç›®æ ‡ç›®å½• copyfile( fname, os.path.join(data_dir, 'train_valid_test', 'train_valid', label)) # å¦‚æœæ ‡ç­¾ä¸åœ¨label_countä¸­æˆ–è€…label_count[label] < n_valid_per_label if label not in label_count or label_count[label] < n_valid_per_label: copyfile( fname, os.path.join(data_dir, 'train_valid_test', 'valid', label)) # è¿”å›æŒ‡å®šé”®çš„å€¼, å¦‚æœå€¼ä¸åœ¨å­—å…¸ä¸­è¿”å›é»˜è®¤å€¼0, å¯¹è®°å½•çš„æ ‡ç­¾æ•°åŠ 1 label_count[label] label_count.get(label, 0) + 1 else: copyfile( fname, os.path.join(data_dir, 'train_valid_test', 'train', label)) return n_valid_per_label ``` + è¯»å–æ•°æ®é›† ```python def reorg_test(data_dir): for file in os.listdir(os.path.join(data_dir, 'images_test')): # è¯»å–æ–‡ä»¶æ ‡ç­¾ file os.path.join('images_test', file) file file.replace('\\\\', '/') copyfile( os.path.join(data_dir, file), os.path.join(data_dir, 'train_valid_test', 'test', 'unknown')) ``` > è®°å½•æµ‹è¯•æ–‡ä»¶ä¸ºunknowç±»å‹ + å®é™…çš„å»ºç«‹å‡½æ•° ```python def reorg_leave_data(data_dir,valid_ratio): labels read_csv_file(os.path.join(data_dir, 'train.csv')) reorg_train_valid(data_dir, labels, valid_ratio) reorg_test(data_dir) valid_ratio 0.1 reorg_leave_data(data_dir, valid_ratio) ``` + æ•°æ®é¢„å¤„ç† ```python transform_train torchvision.transforms.Compose([ # åœ¨é«˜åº¦å’Œå®½åº¦ä¸Šå°†å›¾åƒæ”¾å¤§åˆ°244åƒç´ çš„å¤§å° torchvision.transforms.RandomResizedCrop(224, scale (0.64, 1.0), ratio (1.0, 1.0)), torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor(), # å¯¹å›¾åƒçš„æ¯ä¸ªé€šé“åšæ ‡å‡†åŒ– torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) transform_test torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) ``` + åº”ç”¨ ```python train_ds, train_valid_ds [ torchvision.datasets.ImageFolder( os.path.join(data_dir, 'train_valid_test', folder), transform transform_train) for folder in ['train', 'train_valid']] valid_ds, test_ds [ torchvision.datasets.ImageFolder( os.path.join(data_dir, 'train_valid_test', folder), transform transform_test) for folder in ['valid', 'test']] ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-11-39æŸæœç´¢.html":{"title":"æŸæœç´¢","content":"# æŸæœç´¢ > æˆ‘ä»¬ä½¿ç”¨æ•°å­¦ç¬¦å·å®šä¹‰æœç´¢é—®é¢˜ã€‚åœ¨ä»»æ„æ—¶é—´æ­¥tâ€²ï¼Œè§£ç å™¨è¾“ å‡ºytâ€²çš„æ¦‚ç‡å–å†³äºæ—¶é—´y~tâ€²~ä¹‹å‰çš„è¾“å‡ºå­åºåˆ—y~1~,...,y~tâ€²âˆ’1~ å’Œå¯¹è¾“å…¥åºåˆ—çš„ä¿¡æ¯è¿›è¡Œç¼–ç å¾—åˆ°çš„ä¸Šä¸‹æ–‡å˜ é‡cã€‚ä¸ºäº†é‡åŒ–è®¡ç®—ä»£ä»·ï¼Œç”¨Yè¡¨ç¤ºè¾“å‡ºè¯è¡¨ï¼Œå…¶ä¸­åŒ…å«â€œ\\<eos\\>â€ï¼Œæ‰€ä»¥è¿™ä¸ªè¯æ±‡é›†åˆçš„åŸºæ•°Yå°±æ˜¯è¯è¡¨ çš„å¤§å°ã€‚æˆ‘ä»¬è¿˜å°†è¾“å‡ºåºåˆ—çš„æœ€å¤§è¯å…ƒæ•°æŒ‡å®šä¸ºTâ€²ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä»æ‰€æœ‰O(Y^Tâ€²^)ä¸ªå¯èƒ½çš„è¾“å‡ºåºåˆ— ä¸­å¯»æ‰¾ç†æƒ³çš„è¾“å‡ºã€‚å½“ç„¶ï¼Œå¯¹äºæ‰€æœ‰è¾“å‡ºåºåˆ—ï¼Œåœ¨â€œ\\<eos\\>â€ä¹‹åçš„éƒ¨åˆ†ï¼ˆéæœ¬å¥ï¼‰å°†åœ¨å®é™…è¾“å‡ºä¸­ä¸¢å¼ƒã€‚ ## è´ªå¿ƒæœç´¢ åœ¨ä¹‹å‰çš„è®¡ç®—é‡Œé¢ä½¿ç”¨çš„æ˜¯è´ªå¿ƒæœç´¢, ä½¿ç”¨ä¸Šä¸€ä¸ªè¾“å‡ºé‡Œé¢æ¦‚ç‡æœ€å¤§çš„è¯è¿›è¡Œè¾“å‡º, ä½†æ˜¯è´ªå¿ƒç®—æ³•ä¸€èˆ¬ä¸æ˜¯æœ€ä¼˜çš„(å½“å‰æœ€ä¼˜ä¸ä¸€å®šæ˜¯æ•´ä¸ªå¥å­æœ€ä¼˜çš„) ![image 20250211150622335](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111506401.png) ![image 20250211151035616](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111510677.png) > ç”±äºæ—¶é—´æ­¥3æ‰€åŸºäºçš„æ—¶é—´æ­¥1å’Œ2å¤„çš„è¾“å‡ºå­åºåˆ—å·²ä»â€œAâ€å’Œâ€œBâ€æ”¹å˜ä¸ºâ€œAâ€å’Œâ€œCâ€ï¼Œå› æ­¤æ—¶é—´æ­¥3å¤„çš„æ¯ä¸ªè¯å…ƒçš„æ¡ä»¶æ¦‚ç‡ä¹Ÿæ”¹å˜ ## ç©·ä¸¾æœç´¢ å¦‚æœç›®æ ‡æ˜¯è·å¾—æœ€ä¼˜åºåˆ—ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘ä½¿ç”¨ç©·ä¸¾æœç´¢ï¼ˆexhaustivesearchï¼‰ï¼šç©·ä¸¾åœ°åˆ—ä¸¾æ‰€æœ‰å¯èƒ½çš„è¾“å‡ºåº åˆ—åŠå…¶æ¡ä»¶æ¦‚ç‡ï¼Œç„¶åè®¡ç®—è¾“å‡ºæ¡ä»¶æ¦‚ç‡æœ€é«˜çš„ä¸€ä¸ªã€‚ è™½ç„¶æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç©·ä¸¾æœç´¢æ¥è·å¾—æœ€ä¼˜åºåˆ—ï¼Œä½†å…¶è®¡ç®—é‡O(Y^Tâ€²^)å¯èƒ½é«˜çš„æƒŠäººã€‚ä¾‹å¦‚ï¼Œå½“Y 10000å’ŒTâ€² 10æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è¯„ä¼°10000^10^ 10^40^åºåˆ— ## æŸæœç´¢ æŸæœç´¢ï¼ˆbeamsearchï¼‰æ˜¯è´ªå¿ƒæœç´¢çš„ä¸€ä¸ªæ”¹è¿›ç‰ˆæœ¬ã€‚å®ƒæœ‰ä¸€ä¸ªè¶…å‚æ•°ï¼Œåä¸ºæŸå®½ï¼ˆbeamsizeï¼‰kã€‚åœ¨æ—¶é—´ æ­¥1ï¼Œæˆ‘ä»¬é€‰æ‹©å…·æœ‰æœ€é«˜æ¡ä»¶æ¦‚ç‡çš„kä¸ªè¯å…ƒã€‚åœ¨åé¢çš„è®¡ç®—é‡Œé¢ä¿ç•™æœ€å¥½çš„Kä¸ªå€™é€‰, æ¯ä¸€ä¸ªæ—¶åˆ»çš„æ¯ä¸€ä¸ªå€™é€‰æ·»åŠ ä¸€é¡¹(nä¸ªå¯èƒ½), åœ¨kné‡Œé¢é€‰å–æœ€å¥½çš„kä¸ª ![image 20250211151505510](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111515558.png) > æŸæœç´¢è¿‡ç¨‹ï¼ˆæŸå®½ï¼š2ï¼Œè¾“å‡ºåºåˆ—çš„æœ€å¤§é•¿åº¦ï¼š3ï¼‰ã€‚å€™é€‰è¾“å‡ºåºåˆ—æ˜¯Aã€Cã€ABã€CEã€ABDå’ŒCED æ—¶é—´å¤æ‚åº¦æ˜¯O(knT) ![image 20250211152638110](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111526160.png) > è¿™é‡Œçš„Læ˜¯åœ¨æ¯”è¾ƒé•¿çš„å¥å­è®¡ç®—çš„æ—¶å€™ç»™ä¸€ä¸ªè¡¥å¿, è¿™é‡Œçš„è®¡ç®—ç»“æœæ˜¯ä¸€ä¸ªè´Ÿæ•°"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-23-26åŒºåŸŸå·ç§¯ç¥ç»ç½‘ç»œ.html":{"title":"åŒºåŸŸå·ç§¯ç¥ç»ç½‘ç»œ","content":"# åŒºåŸŸå·ç§¯ç¥ç»ç½‘ç»œ ## R CNN ä½¿ç”¨å¯å‘å¼æœç´¢ç®—æ³•é€‰æ‹©é”šæ¡†, é¢„è®­ç»ƒæ¨¡å‹å¯¹æ¯ä¸€ä¸ªé”šæ¡†æŠ½å–ç‰¹å¾ è®­ç»ƒä¸€ä¸ªSVMå¯¹ç±»åˆ«åˆ†ç±», å†è®­ç»ƒä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹é¢„æµ‹è¾¹ç¼˜æ¡†åç§» ### Rolå…´è¶£åŒºåŸŸæ± åŒ–å±‚ å…¶ç›®çš„æ˜¯å¯¹éå‡åŒ€å°ºå¯¸çš„è¾“å…¥æ‰§è¡Œæœ€å¤§æ± åŒ–ä»¥è·å¾—å›ºå®šå°ºå¯¸çš„ç‰¹å¾å›¾ ç»™å®šä¸€ä¸ªé”šæ¡†, å‡åŒ€çš„è¿›è¡Œåˆ†å‰²ä¸ºn x må—, è¾“å‡ºæ¯ä¸€ä¸ªå—é‡Œé¢çš„æœ€å¤§å€¼(æœ€å¤§æ± åŒ–) ä¸ç®¡è¿™ä¸€ä¸ªé”šæ¡†å¤šå¤§, æ€»è¾“å‡ºä¸€ä¸ªnmçš„å€¼ ![image 20250123224349974](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501232243010.png) ## Fast RCNN ä½¿ç”¨CNNå¯¹å›¾åƒè¿›è¡ŒæŠ½å–ç‰¹å¾, ä¹‹åä½¿ç”¨æ¯”è¾ƒå¥½çš„é”šæ¡†è¿›è¡Œæ‹Ÿåˆ, è€Œä¸æ˜¯ä½¿ç”¨æ‰€æœ‰çš„é”šæ¡†, é€‰æ‹©é”šæ¡†çš„ç®—æ³•æ˜¯å›¾åƒè¯†åˆ«é‡Œé¢çš„ç®—æ³• ![image 20250123224313652](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501232243728.png) ## Faster RCNN å›¾åƒè¯†åˆ«çš„ç®—æ³•é€Ÿåº¦æ¯”è¾ƒæ…¢, æ‰€ä»¥ä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œè¿›è¡Œé€‰æ‹© ![image 20250123224558588](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501232245636.png) ## Mask RCNN ![image 20250123224720530](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501232247571.png) è¿›è¡Œåƒç´ çº§åˆ«çš„é¢„æµ‹, æé«˜ä¸€ä¸ªå›¾ç‰‡è¾¹ç¼˜çš„è´¨é‡, å› ä¸ºä¹‹å‰ä½¿ç”¨çš„Rol poolä¼šä½¿å¾—è¾“å‡ºæœ‰åç§»(ä¸èƒ½æ•´é™¤çš„æ—¶å€™å‘ä¸€ä¾§å–æ•´) ## å•å‘å¤šæ¡†æ£€æµ‹SSD ### å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹ å¦‚æœä¸ºæ¯ä¸ªåƒç´ éƒ½ç”Ÿæˆçš„é”šæ¡†ï¼Œæˆ‘ä»¬æœ€ç»ˆå¯èƒ½ä¼šå¾—åˆ°å¤ªå¤šéœ€è¦è®¡ç®—çš„é”šæ¡†ã€‚æˆ‘ä»¬å¯ä»¥åœ¨è¾“å…¥å›¾åƒä¸­å‡åŒ€é‡‡æ ·ä¸€å°éƒ¨åˆ†åƒç´ ï¼Œå¹¶ä»¥å®ƒä»¬ä¸ºä¸­å¿ƒç”Ÿæˆé”šæ¡†ã€‚ ```python def display_anchors(fmap_w, fmap_h, s): d2l.set_figsize() # å‰ä¸¤ä¸ªç»´åº¦ä¸Šçš„å€¼ä¸å½±å“è¾“å‡º fmap torch.zeros((1, 10, fmap_h, fmap_w)) anchors multibox_prior(fmap, sizes s, ratios [1, 2, 0.5]) bbox_scale torch.tensor((w, h, w, h)) show_bboxes(d2l.plt.imshow(img).axes, anchors[0] * bbox_scale) # æ˜¾ç¤ºä¸€ä¸‹ display_anchors(fmap_w 4, fmap_h 4, s [0.15]) # æŒ‰ç…§4*4çš„ç”Ÿæˆ ``` ![image 20250124225408398](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501242254605.png) ```python display_anchors(fmap_w 2, fmap_h 2, s [0.4]) ``` ![image 20250124225737928](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501242257099.png) ### å®ç°åŸç† å¯¹æ¯ä¸€ä¸ªåƒç´ ç”Ÿæˆå¤šä¸ªé”šæ¡†, å¯¹é”šæ¡†è¿›è¡Œè®¡ç®— æ­¤æ¨¡å‹ä¸»è¦ç”±åŸºç¡€ç½‘ç»œç»„æˆï¼Œå…¶åæ˜¯å‡ ä¸ªå¤šå°ºåº¦ç‰¹å¾å—ã€‚åŸºæœ¬ç½‘ ç»œç”¨äºä»è¾“å…¥å›¾åƒä¸­æå–ç‰¹å¾ï¼Œå› æ­¤å®ƒå¯ä»¥ä½¿ç”¨æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œã€‚ æ¯ä¸ªå¤šå°ºåº¦ç‰¹å¾å— å°†ä¸Šä¸€å±‚æä¾›çš„ç‰¹å¾å›¾çš„é«˜å’Œå®½ç¼©å°ï¼ˆå¦‚å‡åŠï¼‰ï¼Œå¹¶ä½¿ç‰¹å¾å›¾ä¸­æ¯ä¸ªå•å…ƒåœ¨è¾“å…¥å›¾åƒä¸Šçš„æ„Ÿå—é‡å˜å¾—æ›´å¹¿é˜”ã€‚ ![image 20250124230844742](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501242308903.png) ### ç±»åˆ«é¢„æµ‹å±‚ è®¾ç›®æ ‡ç±»åˆ«çš„æ•°é‡ä¸ºqã€‚è¿™æ ·ä¸€æ¥ï¼Œé”šæ¡†æœ‰q + 1ä¸ªç±»åˆ«ï¼Œå…¶ä¸­0ç±»æ˜¯èƒŒæ™¯ã€‚ è®¾ç‰¹å¾å›¾çš„é«˜å’Œå®½ åˆ†åˆ«ä¸ºhå’Œwã€‚å¦‚æœä»¥å…¶ä¸­æ¯ä¸ªå•å…ƒä¸ºä¸­å¿ƒç”Ÿæˆaä¸ªé”šæ¡†ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦å¯¹hwaä¸ªé”šæ¡†è¿›è¡Œåˆ†ç±»ã€‚å¦‚æœä½¿ç”¨å…¨ è¿æ¥å±‚ä½œä¸ºè¾“å‡ºï¼Œå¾ˆå®¹æ˜“å¯¼è‡´æ¨¡å‹å‚æ•°è¿‡å¤šã€‚ ç±»åˆ«é¢„æµ‹å±‚ä½¿ç”¨ä¸€ä¸ªä¿æŒè¾“å…¥é«˜å’Œå®½çš„å·ç§¯å±‚ã€‚è¿™æ ·ä¸€æ¥ï¼Œè¾“å‡ºå’Œè¾“å…¥åœ¨ç‰¹å¾å›¾å®½å’Œé«˜ä¸Šçš„ç©ºé—´ åæ ‡ä¸€ä¸€å¯¹åº”ã€‚è€ƒè™‘è¾“å‡ºå’Œè¾“å…¥åŒä¸€ç©ºé—´åæ ‡ï¼ˆã€ï¼‰ï¼ˆğ‘¥ã€ğ‘¦ï¼‰ï¼šè¾“å‡ºç‰¹å¾å›¾ä¸Šï¼ˆxã€yï¼‰åæ ‡çš„é€šé“é‡ŒåŒ…å«äº†ä»¥è¾“å…¥ç‰¹å¾å›¾ï¼ˆã€ï¼‰ï¼ˆğ‘¥ã€ğ‘¦ï¼‰åæ ‡ä¸ºä¸­å¿ƒç”Ÿæˆçš„æ‰€æœ‰é”šæ¡†çš„ç±»åˆ«é¢„æµ‹ã€‚å› æ­¤è¾“å‡ºé€šé“æ•°ä¸ºğ‘(ğ‘+1)ï¼Œå…¶ä¸­ç´¢å¼•ä¸ºï¼ˆï¼‰ğ‘–(ğ‘+1)+ğ‘—ï¼ˆ0â‰¤ğ‘—â‰¤ğ‘ï¼‰çš„é€šé“ä»£è¡¨äº†ç´¢å¼•ä¸ºiçš„é”šæ¡†æœ‰å…³ç±»åˆ«ç´¢å¼•ä¸ºjçš„é¢„æµ‹ã€‚ ```python def cls_predictor(num_inputs, num_anchors, num_classes): return nn.Conv2d(num_inputs, num_anchors * (num_classes + 1),kernel_size 3, padding 1) ``` ### è¾¹æ¡†é¢„æµ‹å±‚ å’Œä¸Šé¢çš„æ¯”è¾ƒç±»ä¼¼, ä½†æ˜¯ä¸ºæ¯ä¸€ä¸ªé”šæ¡†é¢„æµ‹å‡ºå››ä¸ªåç§»é‡ ```python def bbox_predictor(num_inputs, num_anchors): return nn.Conv2d(num_inputs, num_anchors * 4, kernel_size 3, padding 1) ``` ### è¿ç»“å¤šå°ºåº¦çš„é¢„æµ‹ å®é™…çš„è¾“å‡ºå¤§å°å’Œæ¯ä¸€ä¸ªå›¾ç‰‡çš„é”šæ¡†æ•°, æ‰¹é‡å¤§å°, ç±»åˆ«æ•°, å›¾ç‰‡çš„å¤§å°, æœ‰å…³ ```python def forward(x, block): \treturn block(x) Y1 forward(torch.zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10)) Y2 forward(torch.zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10)) Y1.shape, Y2.shape \"\"\" (torch.Size([2, 55, 20, 20]), torch.Size([2, 33, 10, 10])) ç¬¬äºŒç»´çš„å¤§å°æ˜¯è¾“å‡ºçš„(ç§ç±»+1)*é”šæ¡†çš„å¤§å°, åé¢çš„æ˜¯å›¾ç‰‡çš„å¤§å° \"\"\" ``` åˆ°è¿™ä¸€æ­¥çš„æ—¶å€™, ç”±äºå›¾ç‰‡çš„å¤§å°ä¸åŒçš„åŸå› , æ‰€ä»¥æŠŠå›¾ç‰‡è¿›è¡Œå±•å¹³ ```python def flatten_pred(pred): # permuteå˜åŒ–æŠŠè¾“å‡ºçš„é€šé“æ•°æ”¾åœ¨æœ€å, å±•å¹³ä»¥åå®é™…çš„ç›¸åŒä½ç½®çš„ä¸åŒé€šé“æ˜¯åœ¨ä¸€èµ·çš„ return torch.flatten(pred.permute(0, 2, 3, 1), start_dim 1) def concat_preds(preds): # æŠŠç¬¬äºŒç»´æ‹¼æ¥èµ·æ¥ return torch.cat([flatten_pred(p) for p in preds], dim 1) ``` ### é«˜å®½å‡åŠå— æ¯ä¸ªé«˜å’Œå®½å‡ åŠå—ç”±ä¸¤ä¸ªå¡«å……ä¸º1çš„3 Ã— 3çš„å·ç§¯å±‚ã€ä»¥åŠæ­¥å¹…ä¸º2çš„2 Ã— 2æœ€å¤§æ±‡èšå±‚ç»„æˆã€‚é«˜å’Œå®½å‡åŠå—ä¼šæ‰©å¤§æ¯ä¸ªå•å…ƒåœ¨å…¶è¾“å‡ºç‰¹å¾å›¾ä¸­çš„æ„Ÿå—é‡ã€‚ ```python def down_sample_blk(in_channels, out_channels): blk [] for _ in range(2): blk.append(nn.Conv2d(in_channels, out_channels, kernel_size 3, padding 1)) blk.append(nn.BatchNorm2d(out_channels)) // å½’ä¸€åŒ– blk.append(nn.ReLU()) in_channels out_channels blk.append(nn.MaxPool2d(2)) return nn.Sequential(*blk) ``` ### åŸºæœ¬ç½‘ç»œå¿« ç”¨äºä»å›¾åƒé‡Œé¢æŠ½å–ç‰¹å¾, è¯¥ç½‘ç»œä¸²è”3ä¸ªé«˜å’Œ å®½å‡åŠå—ï¼Œå¹¶é€æ­¥å°†é€šé“æ•°ç¿»å€ã€‚ç»™å®šè¾“å…¥å›¾åƒçš„å½¢çŠ¶ä¸º256Ã—256ï¼Œæ­¤åŸºæœ¬ç½‘ç»œå—è¾“å‡ºçš„ç‰¹å¾å›¾å½¢çŠ¶ä¸º32Ã—32 ï¼ˆ256/23 32ï¼‰ã€‚ ```python def base_net(): blk [] num_filters [3, 16, 32, 64] for i in range(len(num_filters) 1): blk.append(down_sample_blk(num_filters[i], num_filters[i+1])) return nn.Sequential(*blk) forward(torch.zeros((2, 3, 256, 256)), base_net()).shape ``` ### å®Œæ•´çš„æ¨¡å‹ å®Œæ•´çš„å•å‘å¤šæ¡†æ£€æµ‹æ¨¡å‹ç”±äº”ä¸ªæ¨¡å—ç»„æˆã€‚æ¯ä¸ªå—ç”Ÿæˆçš„ç‰¹å¾å›¾æ—¢ç”¨äºç”Ÿæˆé”šæ¡†ï¼Œåˆç”¨äºé¢„æµ‹è¿™äº›é”šæ¡†çš„ç±» åˆ«å’Œåç§»é‡ã€‚åœ¨è¿™äº”ä¸ªæ¨¡å—ä¸­ï¼Œç¬¬ä¸€ä¸ªæ˜¯åŸºæœ¬ç½‘ç»œå—ï¼Œç¬¬äºŒä¸ªåˆ°ç¬¬å››ä¸ªæ˜¯é«˜å’Œå®½å‡åŠå—ï¼Œæœ€åä¸€ä¸ªæ¨¡å—ä½¿ç”¨ å…¨å±€æœ€å¤§æ± å°†é«˜åº¦å’Œå®½åº¦éƒ½é™åˆ°1ã€‚ ```python def get_blk(i): if i 0: blk base_net() elif i 1: blk down_sample_blk(64, 128) elif i 4: blk nn.AdaptiveMaxPool2d((1,1)) else: blk down_sample_blk(128, 128) return blk ``` ç°åœ¨æˆ‘ä»¬ä¸ºæ¯ä¸ªå—å®šä¹‰å‰å‘ä¼ æ’­ã€‚ä¸å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸åŒï¼Œæ­¤å¤„çš„è¾“å‡ºåŒ…æ‹¬ï¼šCNNç‰¹å¾å›¾Yï¼›åœ¨å½“å‰å°ºåº¦ä¸‹æ ¹ æ®Yç”Ÿæˆçš„é”šæ¡†ï¼›é¢„æµ‹çš„è¿™äº›é”šæ¡†çš„ç±»åˆ«å’Œåç§»é‡ï¼ˆåŸºäºYï¼‰ã€‚ ```python def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor): Y blk(X) # ç”Ÿæˆå¤šä¸ªé”šæ¡† anchors d2l.multibox_prior(Y, sizes size, ratios ratio) cls_preds cls_predictor(Y) # å·ç§¯é¢„æµ‹æ¯ä¸€ä¸ªæ¡†çš„è¾“å‡ºç§ç±» bbox_preds bbox_predictor(Y) # é¢„æµ‹ä¸€ä¸‹åç§» return (Y, anchors, cls_preds, bbox_preds) ``` ä¸€ä¸ªè¾ƒæ¥è¿‘é¡¶éƒ¨çš„å¤šå°ºåº¦ç‰¹å¾å—æ˜¯ç”¨äºæ£€æµ‹è¾ƒå¤§ç›®æ ‡çš„ï¼Œå› æ­¤éœ€è¦ç”Ÿæˆæ›´å¤§çš„é”šæ¡†ã€‚ åœ¨ä¸Šé¢çš„å‰å‘ä¼ æ’­ä¸­ï¼Œåœ¨æ¯ä¸ªå¤šå°ºåº¦ç‰¹å¾å—ä¸Šï¼Œæˆ‘ä»¬é€šè¿‡è°ƒç”¨çš„multibox_priorå‡½æ•°çš„sizeså‚ æ•°ä¼ é€’ä¸¤ä¸ªæ¯”ä¾‹å€¼çš„åˆ—è¡¨ã€‚ åœ¨ä¸‹é¢ï¼Œ0.2å’Œ1.05ä¹‹é—´çš„åŒºé—´è¢«å‡åŒ€åˆ†æˆäº”ä¸ªéƒ¨åˆ†ï¼Œä»¥ç¡®å®šäº”ä¸ªæ¨¡å—çš„åœ¨ä¸åŒå°ºåº¦ ä¸‹çš„è¾ƒå°å€¼ï¼š0.2ã€0.37ã€0.54ã€0.71å’Œ0.88ã€‚ä¹‹åï¼Œä»–ä»¬è¾ƒå¤§çš„å€¼ç”±âˆš 0.2 Ã— 0.37 0.272ã€ âˆš 0.37 Ã— 0.54 0.447ç­‰ ç»™å‡ºã€‚ ```python sizes [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79], [0.88, 0.961]] ratios [[1, 2, 0.5]] * 5 num_anchors len(sizes[0]) + len(ratios[0]) 1 ``` æ„å»ºæ¨¡å‹, æ¯ä¸€å±‚éƒ½æœ‰ä¸€ä¸ªè¾“å‡º, æœ€åæŠŠè¾“å‡ºåˆå¹¶èµ·æ¥ ```python class TinySSD(nn.Module): def __init__(self, num_classes, **kwargs): super(TinySSD, self).__init__(**kwargs) self.num_classes num_classes idx_to_in_channels [64, 128, 128, 128, 128] for i in range(5): # å³èµ‹å€¼è¯­å¥self.blk_i get_blk(i) setattr(self, f'blk_{i}', get_blk(i)) # äº”ä¸ªä¸åŒçš„å— setattr(self, f'cls_{i}', cls_predictor(idx_to_in_channels[i], num_anchors, num_classes)) # é¢„æµ‹æ¯ä¸€ä¸ªæ¡†çš„è¾“å‡ºç§ç±» setattr(self, f'bbox_{i}', bbox_predictor(idx_to_in_channels[i], num_anchors)) # é¢„æµ‹æ¯ä¸€ä¸ªæ¡†çš„è¾“å‡ºåæ ‡åç§»é‡ def forward(self, X): anchors, cls_preds, bbox_preds [None] * 5, [None] * 5, [None] * 5 for i in range(5): # getattr(self,'blk_%d'%i)å³è®¿é—®self.blk_i X, anchors[i], cls_preds[i], bbox_preds[i] blk_forward( X, getattr(self, f'blk_{i}'), sizes[i], ratios[i], getattr(self, f'cls_{i}'), getattr(self, f'bbox_{i}')) anchors torch.cat(anchors, dim 1) # å°†é”šæ¡†åæ ‡å±•å¹³ cls_preds concat_preds(cls_preds) # è¾¹æ¡†é¢„æµ‹ç§ç±» cls_preds cls_preds.reshape( cls_preds.shape[0], 1, self.num_classes + 1) # æŠŠç±»çš„æ¯ä¸€ä¸ªé¢„æµ‹ä½œä¸ºä¸€ä¸ªç»´åº¦ bbox_preds concat_preds(bbox_preds) # è¾¹æ¡†é¢„æµ‹åæ ‡ return anchors, cls_preds, bbox_preds ``` ```python net TinySSD(num_classes 1) X torch.zeros((32, 3, 256, 256)) anchors, cls_preds, bbox_preds net(X) print('output anchors:', anchors.shape) print('output class preds:', cls_preds.shape) print('output bbox preds:', bbox_preds.shape) \"\"\" output anchors: torch.Size([1, 5444, 4]) # é”šæ¡†çš„ä½ç½® output class preds: torch.Size([32, 5444, 2]) # é”šæ¡†çš„ç§ç±»é¢„æµ‹, 32æ‰¹é‡å¤§å°, 5444é”šæ¡†æ•°é‡ output bbox preds: torch.Size([32, 21776]) # é¢„æµ‹ä¸€ä¸‹åç§» \"\"\" ``` åŠ è½½æ•°æ®é›† ```python batch_size 32 train_iter, _ d2l.load_data_bananas(batch_size) ``` åŠ è½½æ¨¡å‹ ```python device, net d2l.try_gpu(), TinySSD(num_classes 1) trainer torch.optim.SGD(net.parameters(), lr 0.2, weight_decay 5e 4) ``` æŸå¤±å‡½æ•° ```python cls_loss nn.CrossEntropyLoss(reduction 'none') bbox_loss nn.L1Loss(reduction 'none') # def calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks): batch_size, num_classes cls_preds.shape[0], cls_preds.shape[2] # è®¡ç®—ä¸€ä¸‹åˆ†ç±»çš„åç§» cls cls_loss(cls_preds.reshape( 1, num_classes), cls_labels.reshape( 1)).reshape(batch_size, 1).mean(dim 1) # è®¡ç®—ä¸€ä¸‹è¾¹æ¡†ä½ç½®çš„åç§», ä¹˜ä¸€ä¸ªmaskå»é™¤æ— å…³çš„æ¡† bbox bbox_loss(bbox_preds * bbox_masks, bbox_labels * bbox_masks).mean(dim 1) return cls + bbox # æŠŠä¸¤ä¸ªè¯¯å·®åŠ åœ¨ä¸€èµ· def cls_eval(cls_preds, cls_labels): # ç”±äºç±»åˆ«é¢„æµ‹ç»“æœæ”¾åœ¨æœ€åä¸€ç»´ï¼Œargmaxéœ€è¦æŒ‡å®šæœ€åä¸€ç»´ã€‚ # è®¡ç®—ä¸€ä¸‹ç®—å¯¹çš„ä¸ªæ•° return float((cls_preds.argmax(dim 1).type(cls_labels.dtype) cls_labels).sum()) def bbox_eval(bbox_preds, bbox_labels, bbox_masks): # è®¡ç®—ä¸€ä¸‹åç§» return float((torch.abs((bbox_labels bbox_preds) * bbox_masks)) ``` å¼€å§‹è®­ç»ƒ ```python num_epochs, timer 20, d2l.Timer() animator d2l.Animator(xlabel 'epoch', xlim [1, num_epochs], legend ['class error', 'bbox mae']) net net.to(device) for epoch in range(num_epochs): # è®­ç»ƒç²¾ç¡®åº¦çš„å’Œï¼Œè®­ç»ƒç²¾ç¡®åº¦çš„å’Œä¸­çš„ç¤ºä¾‹æ•° # ç»å¯¹è¯¯å·®çš„å’Œï¼Œç»å¯¹è¯¯å·®çš„å’Œä¸­çš„ç¤ºä¾‹æ•° metric d2l.Accumulator(4) net.train() for features, target in train_iter: timer.start() trainer.zero_grad() X, Y features.to(device), target.to(device) # ç”Ÿæˆå¤šå°ºåº¦çš„é”šæ¡†ï¼Œä¸ºæ¯ä¸ªé”šæ¡†é¢„æµ‹ç±»åˆ«å’Œåç§»é‡ anchors, cls_preds, bbox_preds net(X) # è·å–çœŸå®çš„æ¯ä¸€ä¸ªé”šæ¡†çš„åˆ†ç±»ä»¥åŠåç§» bbox_labels, bbox_masks, cls_labels d2l.multibox_target(anchors, Y) # æ ¹æ®ç±»åˆ«å’Œåç§»é‡çš„é¢„æµ‹å’Œæ ‡æ³¨å€¼è®¡ç®—æŸå¤±å‡½æ•° l calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks) l.mean().backward() trainer.step() metric.add(cls_eval(cls_preds, cls_labels), cls_labels.numel(), bbox_eval(bbox_preds, bbox_labels, bbox_masks), bbox_labels.numel()) cls_err, bbox_mae 1 metric[0] / metric[1], metric[2] / metric[3] animator.add(epoch + 1, (cls_err, bbox_mae)) print(f'class err {cls_err:.2e}, bbox mae {bbox_mae:.2e}') ``` ![image 20250125153326312](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501251533557.png) å®é™…é¢„æµ‹ä¸€ä¸‹ ```python import torchvision # åŠ è½½ä¸€ä¸ªå›¾ç‰‡ X torchvision.io.read_image('E:/JHY/python/2024 11 3 pytorchLiMu/jupyrt/data/bananas/bananas_val/images/1.png').unsqueeze(0).float() img X.squeeze(0).permute(1, 2, 0).long() # åŠ ä¸€ä¸ªæ‰¹é‡ç»´åº¦ import torch.nn.functional as F def predict(X): net.eval() anchors, cls_preds, bbox_preds net(X.to(device)) cls_probs F.softmax(cls_preds, dim 2).permute(0, 2, 1) # ä½¿ç”¨çœŸå®çš„é”šæ¡†ä»¥åŠåç§»è¿›è¡ŒæŠ‘åˆ¶ä»¥åŠè·å–å®é™…çš„è¾“å‡º output multibox_detection(cls_probs, bbox_preds, anchors) idx [i for i, row in enumerate(output[0]) if row[0] ! 1] # è·å–æœ‰æ•ˆçš„ç±» return output[0, idx] output predict(X) output \"\"\" tensor([[ 0.00, 0.99, 0.09, 0.31, 0.30, 0.53], [ 0.00, 0.04, 0.18, 0.18, 1.13, 0.81], [ 0.00, 0.04, 0.12, 0.05, 0.98, 0.96], [ 0.00, 0.03, 0.10, 0.37, 0.26, 0.58], [ 0.00, 0.03, 0.22, 0.52, 0.44, 1.18], [ 0.00, 0.03, 0.08, 0.24, 0.28, 0.45], [ 0.00, 0.02, 0.62, 0.32, 1.14, 1.31], [ 0.00, 0.02, 0.63, 0.32, 1.14, 0.64], [ 0.00, 0.01, 0.11, 0.36, 0.26, 0.45], [ 0.00, 0.01, 0.37, 0.61, 1.36, 1.13], [ 0.00, 0.01, 0.37, 0.17, 1.32, 0.34], [ 0.00, 0.01, 0.03, 0.33, 0.21, 0.52], [ 0.00, 0.01, 0.09, 0.19, 0.30, 0.37]], device 'cuda:0', grad_fn <IndexBackward0>) \"\"\" def display(img, output, threshold): d2l.set_figsize((5, 5)) fig d2l.plt.imshow(img) for row in output: score float(row[1]) if score < threshold: continue h, w img.shape[0:2] bbox [row[2:6] * torch.tensor((w, h, w, h), device row.device)] d2l.show_bboxes(fig.axes, bbox, '%.2f' % score, 'w') display(img, output.cpu(), threshold 0.9) ``` ![image 20250125153705020](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501251537278.png) ## YOLO SSDæ¡†é‡Œé¢é”šæ¡†å¤§é‡çš„é‡å , æµªè´¹å¾ˆå¤šçš„è®¡ç®—, YOLOæŠŠå›¾ç‰‡å‡åŒ€çš„åˆ†å‰²ä¸ºSxSä¸ªé”šæ¡†, æ¯ä¸ªé”šæ¡†é¢„æµ‹Bä¸ªè¾¹ç¼˜æ¡†(æœ‰Bä¸ªç‰©ä½“å’Œè¿™ä¸€ä¸ªè¾¹ç¼˜æ¡†æ¯”è¾ƒç›¸è¿‘) æ‰€æœ‰çš„é”šæ¡†ä¹‹é—´ä¸ä¼šé‡åˆ"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-15-42è‡ªæ³¨æ„åŠ›.html":{"title":"è‡ªæ³¨æ„åŠ›","content":"# è‡ªæ³¨æ„åŠ› Self attention ç»™å®šä¸€ä¸ªåºåˆ—, æ¯ä¸€ä¸ªx~i~æ˜¯ä¸€ä¸ªé•¿åº¦ä¸ºdçš„åºåˆ—, è‡ªæ³¨æ„åŠ›æŠŠx~i~å½“åškey, value, queryæ¥å¯¹åºåˆ—æŠ½å–ç‰¹å¾å¾—åˆ°y~1~ ... y~n~ ![image 20250215132122542](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151321689.png) è¾“å‡ºä¹Ÿæ˜¯ä¸€ä¸ªé•¿åºåˆ—, æ˜¯è€ƒè™‘åˆ°æ¯ä¸€ä¸ªè¾“å…¥ä»¥åå¯¹ç€ä¸€ä¸ªè¾“å…¥çš„ä¸€ä¸ªè¾“å‡º ![image 20250215133841094](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151338231.png) è¾“å…¥çš„é•¿åº¦æ˜¯ä¸ä¸€å®šçš„, éœ€è¦è®¡ç®—å‡ºæ¥ä¸€ä¸ªè¾“å…¥å’Œå…¶ä»–çš„è¾“å…¥ä¹‹é—´çš„å…³è”åº¦ ![image 20250215134413932](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151344118.png) æœ€ç»å¸¸ä½¿ç”¨çš„æ˜¯å·¦è¾¹çš„é‚£ä¸€ç§å¤„ç†æ–¹å¼, ä¹Ÿæ˜¯transformeré‡Œé¢æ˜¯ä½¿ç”¨çš„æ–¹æ³•, è®¡ç®—å‡ºä¸€ä¸ªå…³è”åº¦ è‡ªæ³¨æ„åŠ›éœ€è¦æŠŠæ¯ä¸€ä¸ªè¾“å…¥å’Œå…¶ä»–çš„è¾“å…¥è®¡ç®—å‡ºæ¥ä¸€ä¸ªå…³è”åº¦(åŠ æƒ) ![image 20250215134828912](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151348981.png) > è®¡ç®—çš„æ—¶å€™è¿˜ä¼šå’Œè‡ªå·±è®¡ç®—å…³è”æ€§, æ‰€æœ‰è®¡ç®—å‡ºæ¥ä»¥åå†åšä¸€ä¸ªsoftmax(å½’ä¸€åŒ–, å¯ä»¥ä½¿ç”¨å…¶ä»–å‡½æ•°æ¯”å¦‚reluè¿›è¡Œæ¿€æ´») ![image 20250215134944381](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151349470.png) ç°åœ¨å·²ç»è·å–å…³è”åº¦, å¯ä»¥ä½¿ç”¨è¿™ä¸ªå…³è”åº¦è®¡ç®—æœ€åçš„è¾“å‡º ![image 20250215135320682](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151353783.png) ![image 20250215133841094](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151338231.png) å®é™…è®¡ç®—çš„æ—¶å€™æƒé‡çš„è®¡ç®—å¯ä»¥åœ¨ä¸€èµ·è¿›è¡Œ ![image 20250215135808710](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151358802.png) ![image 20250215140001314](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151400401.png) ![image 20250215140058540](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151400602.png) ![image 20250215140303152](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151403236.png) æœ‰ä¸€ä¸ªè¿›é˜¶çš„ç‰ˆæœ¬, Multi head Self attention, è®¡ç®—å‡ºæ¥æ›´å¤šçš„a hat, åœ¨è®¡ç®—å‡ºæ¥q^1^, k^1^ä¹‹ç±»ä»¥å, ä¹˜ä»¥å¤šä¸ªæƒé‡è·å–åˆ°q^i,1^, q^i,2^ç­‰ ![image 20250215140914218](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151409306.png) ![image 20250215140951023](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151409071.png) ![image 20250215220342259](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502152203424.png) ä½¿ç”¨ä¸¤ä¸ªå‡½æ•°æŠŠéšè—å±‚åˆ†ä¸ºå¤šä¸ªä¸åŒçš„å¤´ ```python #@save def transpose_qkv(X, num_heads): \"\"\"ä¸ºäº†å¤šæ³¨æ„åŠ›å¤´çš„å¹¶è¡Œè®¡ç®—è€Œå˜æ¢å½¢çŠ¶, æŠŠéšè—å±‚åˆ†ä¸ºå¤šä¸ªå¤´\"\"\" # è¾“å…¥Xçš„å½¢çŠ¶:(batch_sizeï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_hiddens) # è¾“å‡ºXçš„å½¢çŠ¶:(batch_sizeï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_headsï¼Œ # num_hiddens/num_heads) X X.reshape(X.shape[0], X.shape[1], num_heads, 1) # è¾“å‡ºXçš„å½¢çŠ¶:(batch_sizeï¼Œnum_headsï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°, # num_hiddens/num_heads) X X.permute(0, 2, 1, 3) # æœ€ç»ˆè¾“å‡ºçš„å½¢çŠ¶:(batch_size*num_heads,æŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°, # num_hiddens/num_heads) return X.reshape( 1, X.shape[2], X.shape[3]) #@save def transpose_output(X, num_heads): \"\"\"é€†è½¬transpose_qkvå‡½æ•°çš„æ“ä½œ\"\"\" X X.reshape( 1, num_heads, X.shape[1], X.shape[2]) X X.permute(0, 2, 1, 3) return X.reshape(X.shape[0], X.shape[1], 1) ``` å®é™…çš„å®ç° ```python #@save class MultiHeadAttention(nn.Module): \"\"\" å¤šå¤´æ³¨æ„åŠ›, num_headsä¸ªå¹¶è¡Œçš„æ³¨æ„åŠ›å¤´ æŠŠnumber_hiddensä¸ªå¤´çš„åˆ†å‰², å¾—åˆ°num_hiddens/num_heads \"\"\" def __init__(self, key_size, query_size, value_size, num_hiddens, num_heads, dropout, bias False, **kwargs): # è¿™é‡Œçš„num_hiddensæ˜¯äºŒç»´çš„ super(MultiHeadAttention, self).__init__(**kwargs) self.num_heads num_heads self.attention d2l.DotProductAttention(dropout) self.W_q nn.Linear(query_size, num_hiddens, bias bias) self.W_k nn.Linear(key_size, num_hiddens, bias bias) self.W_v nn.Linear(value_size, num_hiddens, bias bias) self.W_o nn.Linear(num_hiddens, num_hiddens, bias bias) def forward(self, queries, keys, values, valid_lens): # queriesï¼Œkeysï¼Œvaluesçš„å½¢çŠ¶: # (batch_sizeï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_hiddens) # valid_lensã€€çš„å½¢çŠ¶: # (batch_sizeï¼Œ)æˆ–(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°) # ç»è¿‡å˜æ¢åï¼Œè¾“å‡ºçš„queriesï¼Œkeysï¼Œvaluesã€€çš„å½¢çŠ¶: # (batch_size*num_headsï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œ # num_hiddens/num_heads) # è¿™ä¹ˆåšçš„åŸå› æ˜¯ä¸ºäº†ä½¿ç”¨batch_dotå‡½æ•° queries transpose_qkv(self.W_q(queries), self.num_heads) keys transpose_qkv(self.W_k(keys), self.num_heads) values transpose_qkv(self.W_v(values), self.num_heads) if valid_lens is not None: # åœ¨è½´0ï¼Œå°†ç¬¬ä¸€é¡¹ï¼ˆæ ‡é‡æˆ–è€…çŸ¢é‡ï¼‰å¤åˆ¶num_headsæ¬¡ï¼Œ # ç„¶åå¦‚æ­¤å¤åˆ¶ç¬¬äºŒé¡¹ï¼Œç„¶åè¯¸å¦‚æ­¤ç±»ã€‚ valid_lens torch.repeat_interleave( valid_lens, repeats self.num_heads, dim 0) # outputçš„å½¢çŠ¶:(batch_size*num_headsï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œ # num_hiddens/num_heads) output self.attention(queries, keys, values, valid_lens) # output_concatçš„å½¢çŠ¶:(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œnum_hiddens) output_concat transpose_output(output, self.num_heads) return self.W_o(output_concat) ``` ```python num_hiddens, num_heads 100, 5 attention MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, 0.5) attention.eval() \"\"\" MultiHeadAttention( (attention): DotProductAttention( (dropout): Dropout(p 0.5, inplace False) ) (W_q): Linear(in_features 100, out_features 100, bias False) (W_k): Linear(in_features 100, out_features 100, bias False) (W_v): Linear(in_features 100, out_features 100, bias False) (W_o): Linear(in_features 100, out_features 100, bias False) ) \"\"\" ``` æµ‹è¯•ä¸€ä¸‹, è¿™ä¸ªä¸ä¼šæ”¹å˜è¾“å…¥çš„å½¢çŠ¶ ```python batch_size, num_queries 2, 4 num_kvpairs, valid_lens 6, torch.tensor([3, 2]) X torch.ones((batch_size, num_queries, num_hiddens)) Y torch.ones((batch_size, num_kvpairs, num_hiddens)) attention(X, Y, Y, valid_lens).shape ``` ## ä½ç½®ä¿¡æ¯ ![image 20250215141334285](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151413386.png) + ä¸‰è§’å‡½æ•° åªä½¿ç”¨è¿™éƒ¨åˆ†çš„æ—¶å€™æ²¡æœ‰ä½ç½®çš„å…³ç³», å¯ä»¥ä½¿ç”¨Positional Encoding, å¯ä»¥ä¸ºæ¯ä¸€ä¸ªä½ç½®æ·»åŠ ä¸€ä¸ªç‹¬ç‰¹çš„Vector e^i^ , æœ€å¼€å§‹çš„e^i^æ˜¯äººè®¾ç½®çš„, å¯ä»¥é€šè¿‡å­¦ä¹ å¾—åˆ°ä¹Ÿå¯ä»¥ç›´æ¥å›ºå®šå¾—åˆ°, æ¥ä¸‹æ¥æè¿°çš„æ˜¯åŸºäºæ­£å¼¦å‡½æ•°å’Œä½™å¼¦å‡½æ•° çš„å›ºå®šä½ç½®ç¼–ç  ![image 20250215184118243](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151841293.png) ![image 20250215185242796](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151852855.png) ```python #@save class PositionalEncoding(nn.Module): \"\"\"ä½ç½®ç¼–ç \"\"\" def __init__(self, num_hiddens, dropout, max_len 1000): super(PositionalEncoding, self).__init__() self.dropout nn.Dropout(dropout) # åˆ›å»ºä¸€ä¸ªè¶³å¤Ÿé•¿çš„P self.P torch.zeros((1, max_len, num_hiddens)) X torch.arange(max_len, dtype torch.float32).reshape( 1, 1) / torch.pow(10000, torch.arange( 0, num_hiddens, 2, dtype torch.float32) / num_hiddens) self.P[:, :, 0::2] torch.sin(X) self.P[:, :, 1::2] torch.cos(X) def forward(self, X): X X + self.P[:, :X.shape[1], :].to(X.device) return self.dropout(X) ``` > å‡è®¾è¾“å…¥è¡¨ç¤ºX âˆˆ R^nÃ—d^ åŒ…å«ä¸€ä¸ªåºåˆ—ä¸­nä¸ªè¯å…ƒçš„dç»´åµŒå…¥è¡¨ç¤ºã€‚ä½ç½®ç¼–ç ä½¿ç”¨ç›¸åŒå½¢çŠ¶çš„ä½ç½®åµŒå…¥çŸ©é˜µ P âˆˆR^nÃ—d^è¾“å‡ºX+Pï¼ŒçŸ©é˜µç¬¬iè¡Œã€ç¬¬2jåˆ—å’Œ2j+1åˆ—ä¸Šçš„å…ƒç´ (ä¸åŒçš„åˆ—çš„å‘¨æœŸæ˜¯ä¸ä¸€æ ·çš„) + ç»å¯¹ä½ç½® ä¹Ÿå¯ä»¥ä½¿ç”¨ç»å¯¹ä½ç½®ä¿¡æ¯, åœ¨äºŒè¿›åˆ¶è¡¨ç¤ºä¸­ï¼Œè¾ƒé«˜æ¯”ç‰¹ä½çš„äº¤æ›¿é¢‘ç‡ä½äºè¾ƒä½æ¯”ç‰¹ä½ï¼Œä¸ä¸‹é¢çš„çƒ­å›¾æ‰€ç¤ºç›¸ä¼¼ï¼Œåªæ˜¯ä½ç½®ç¼–ç é€šè¿‡ä½¿ç”¨ ä¸‰è§’å‡½æ•°åœ¨ç¼–ç ç»´åº¦ä¸Šé™ä½é¢‘ç‡ã€‚ç”±äºè¾“å‡ºæ˜¯æµ®ç‚¹æ•°ï¼Œå› æ­¤æ­¤ç±»è¿ç»­è¡¨ç¤ºæ¯”äºŒè¿›åˆ¶è¡¨ç¤ºæ³•æ›´èŠ‚çœç©ºé—´ ![image 20250215185212150](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151852209.png) + ç›¸å¯¹ä½ç½® æ¨¡å‹å­¦ä¹ å¾—åˆ°è¾“å…¥åºåˆ—ä¸­ç›¸å¯¹ä½ç½®ä¿¡æ¯, ã€‚è¿™æ˜¯å› ä¸ºå¯¹äº ä»»ä½•ç¡®å®šçš„ä½ç½®åç§»Î´ï¼Œä½ç½®i+Î´å¤„çš„ä½ç½®ç¼–ç å¯ä»¥çº¿æ€§æŠ•å½±ä½ç½®iå¤„çš„ä½ç½®ç¼–ç æ¥è¡¨ç¤º(å¯ä»¥ä¸ç”¨é™å®šäºå‡ºç°åœ¨å¥å­çš„æŸä¸€ä¸ªä½ç½®) ![image 20250215190007919](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151900966.png) > è¿™éƒ¨åˆ†çš„åº”ç”¨ä¸»è¦æ˜¯åœ¨transformerå’ŒBERTé‡Œé¢ ## å¯¹æ¯” åœ¨å¤„ç†æ•°æ®çš„æ—¶å€™, å¦‚æœä½¿ç”¨çš„æ•°æ®çš„æ•°é‡æ¯”è¾ƒå¤§, ä½¿å¾—è®¡ç®—æ•°é‡éå¸¸å¤§, æ‰€ä»¥æœ‰ä¸€ç§Truncated Self attentionçš„æœºåˆ¶, Self attentionåªæ³¨æ„ä»–é™„è¿‘çš„æ•°æ® åœ¨å¤„ç†å›¾åƒçš„æ—¶å€™ä¹Ÿå¯ä»¥ä½¿ç”¨, Self Attention GANå’ŒDEtection Transformer ä¹‹å‰ä½¿ç”¨CNNè¿›è¡Œè®¡ç®—çš„æ—¶å€™, èŒƒå›´æ˜¯åˆ’å®šçš„, ä½†æ˜¯ä½¿ç”¨Self Attentionè¿›è¡Œå¤„ç†å¯ä»¥è‡ªè¡Œè®¡ç®—ä½¿ç”¨çš„èŒƒå›´, èµ„æ–™é‡éå¸¸å¤§çš„æ—¶å€™å®é™…çš„æ•ˆæœå¯ä»¥è¶…è¿‡CNN ![image 20250215151555326](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151515414.png) ç›¸æ¯”äºRNNçš„æ•°æ®å¿…é¡»æ¥è‡ªäºå‰é¢çš„æ•°æ®, è®¡ç®—çš„æ—¶é—´æ¯”è¾ƒé•¿, ä»¥æ­¤è®¡ç®—è€Œä½¿ç”¨Self Attentionå¯ä»¥æŸ¥æ‰¾å…¨å±€, å¹¶ä¸”å¯ä»¥åŒæ—¶è®¡ç®—, æ‰€ä»¥å®é™…ä½¿ç”¨çš„æ—¶é—´æ¯”è¾ƒå°‘ ä¸¤ä¸ªæ•°æ®çš„å…³ç³»å¦‚æœå¯ä»¥ä½¿ç”¨å›¾è¡¨ç¤º, è®¡ç®—çš„æ—¶å€™æ— å…³çš„æ•°æ®ç›´æ¥è®¾ç½®ä¸º0, è¿™æ ·çš„è®¡ç®—æ–¹å¼æ˜¯GNN ![](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151515414.png) ![image 20250215183124520](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151831582.png) ![image 20250215183337456](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151833516.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-08-03åŸºç¡€å‡½æ•°.html":{"title":"","content":"## çº¿ä»£ ```python import torch tensor torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) tensor ''' tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) ''' tensor.T #è½¬ç½® ''' tensor([[1, 4, 7], [2, 5, 8], [3, 6, 9]]) ''' ``` åœ¨ä½¿ç”¨sumè¿›è¡Œæ±‚å’Œçš„æ—¶å€™, å¯ä»¥ä½¿ç”¨axisæŒ‡å®šå®é™…æ±‚å’Œä½¿ç”¨çš„è½´, ç­‰äº0 çš„æ—¶å€™ä½¿ç”¨çš„æ˜¯ç»´åº¦æœ€é«˜çš„è½´ ![image 20250107124555762](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071245846.png) åŒæ ·å¯ä»¥ä½¿ç”¨mean(average)å‡½æ•°è®¡ç®—å‡å€¼, ä½¿ç”¨axisæŒ‡å®šç»´åº¦ å¯ä»¥åœ¨è®¡ç®—çš„æ—¶å€™ä¸ä¸¢å¼ƒè¿™ä¸€ä¸ªç»´åº¦ ```python tensor3 tensor2.sum(axis [1, 2], keepdim True) # ä¿æŒç»´åº¦ tensor3, tensor3.shape ''' (tensor([[[ 45]], [[145]]]), torch.Size([2, 1, 1])) ''' ``` > ä½¿ç”¨è¿™ä¸€ä¸ªæ–¹æ¡ˆçš„æ—¶å€™, å¯ä»¥æ–¹ä¾¿çš„ä½¿ç”¨å¹¿æ’­æœºåˆ¶ > > ```python > tensor2 / tensor3 > \"\"\" > tensor([[[0.0000, 0.0222, 0.0444, 0.0667, 0.0889], > [0.1111, 0.1333, 0.1556, 0.1778, 0.2000]], > > [[0.0690, 0.0759, 0.0828, 0.0897, 0.0966], > [0.1034, 0.1103, 0.1172, 0.1241, 0.1310]]]) > \"\"\" > ``` ```python # ç´¯åŠ æ±‚å’Œ tensor, tensor.cumsum(axis 0) # ç´¯åŠ  (tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), tensor([[ 1, 2, 3], [ 5, 7, 9], [12, 15, 18]])) ``` ```python x torch.arange(4, dtype torch.float32) #ç‚¹ä¹˜ y torch.ones(4, dtype torch.float32) x, y, torch.dot(x, y) \"\"\" (tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.)) \"\"\" ``` ```python #å‘é‡ç§¯ x torch.arange(20, dtype torch.float32).reshape(5, 4) y torch.ones(4, dtype torch.float32) x, y, torch.mv(x, y) # çŸ©é˜µå‘é‡ä¹˜æ³• \"\"\" (tensor([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.], [12., 13., 14., 15.], [16., 17., 18., 19.]]), tensor([1., 1., 1., 1.]), tensor([ 6., 22., 38., 54., 70.])) \"\"\" ``` ```python # L2èŒƒæ•°/é•¿åº¦, å‘é‡å¹³æ–¹å’Œæ ¹å· u torch.tensor([1, 0, 1], dtype torch.float32) torch.norm(u) # èŒƒæ•° \"\"\" tensor(1.4142) \"\"\" ``` ```python #L1å‡½æ•°èŒƒæ•°, ç´ æœ‰å…ƒç´ çš„ç»å¯¹å€¼æ±‚å’Œ torch.abs(u).sum() # L1èŒƒæ•° \"\"\" torch.abs(u).sum() # L1èŒƒæ•° \"\"\" ``` ## å¤šç»´çŸ©é˜µä¹˜æ³• åœ¨çŸ©é˜µè¿ç®—çš„æ—¶å€™ï¼Œå…¶å®æœ€åéƒ½å¯ä»¥è½¬æˆæˆ‘ä»¬å¸¸è§çš„äºŒç»´çŸ©é˜µè¿ç®—ï¼Œéµå¾ªçš„åŸåˆ™æ˜¯ï¼šåœ¨å¤šç»´çŸ©é˜µç›¸ä¹˜ä¸­ï¼Œéœ€æœ€åä¸¤ç»´æ»¡è¶³shapeåŒ¹é…åŸåˆ™ï¼Œæœ€åä¸¤ç»´æ‰æ˜¯æœ‰æ•°æ®çš„çŸ©é˜µï¼Œå‰é¢çš„ç»´åº¦åªæ˜¯çŸ©é˜µçš„æ’åˆ—è€Œå·² [ã€å…¨é¢ç†è§£å¤šç»´çŸ©é˜µè¿ç®—ã€‘å¤šç»´ï¼ˆä¸‰ç»´å››ç»´ï¼‰çŸ©é˜µå‘é‡è¿ç®— è¶…å¼ºå¯è§†åŒ– çŸ¥ä¹](https://zhuanlan.zhihu.com/p/337829793) ç¤ºä¾‹: ```python a [[[ 1. 2. 3.] [ 4. 5. 6.]] [[ 7. 8. 9.] [10. 11. 12.]]] b [[[ 1. 2.] [ 3. 4.] [ 5. 6.]] [[ 7. 8.] [ 9. 10.] [11. 12.]]] ``` ä¸Šé¢ä¸¤ä»½çŸ©é˜µè¿›è¡Œä¹˜æ³•, å®é™…è®¡ç®—çš„æ—¶å€™å…ˆè®¡ç®—å•ä¸ªçš„äºŒç»´å‘é‡, ä¹‹åäºŒç»´å‘é‡ç›¸åŠ  ![image 20250113105145616](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131051152.png)+![image 20250113105205304](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131052413.png) ç»“æœæ˜¯ ```python [[[ 22. 28.] [ 49. 64.]] [[220. 244.] [301. 334.]]] ``` å®é™…çœ‹ç»´åº¦çš„æ—¶å€™åä¸¤ä¸ªæŒ‰ç…§äºŒç»´çš„å˜åŒ–, å‰é¢çš„å–æœ€å¤§å€¼ **å–å€¼**: ä¸ä¸‰ç»´ä¹˜ä¸‰ç»´ç±»ä¼¼ï¼Œå¯ä¹˜æ¡ä»¶2æ”¹ä¸ºï¼šé™¤æœ€åä¸¤ç»´å¤–ï¼Œæ¯ä¸€ç»´çš„åˆ†é‡æ•°å¿…é¡»**å¯¹åº”ç›¸ç­‰**ï¼ˆæ¯ä¸ªåˆ†é‡å¯¹åº”ç›¸ä¹˜ï¼‰ æˆ– **æœ‰ä¸€æ–¹ä¸º1**ï¼ˆbroadcast å¹¿æ’­æœºåˆ¶ï¼‰ ## å¯¼æ•° æ™®é€šçš„å¯¼æ•°çš„è®¡ç®—å’Œæ•°å­¦çš„æ˜¯ä¸€æ ·çš„, ä½†æ˜¯åœ¨è®¡ç®—ä¸å¯å¾®çš„å‡½æ•°çš„æ—¶å€™, æ¯”å¦‚xçš„ç»å¯¹å€¼åœ¨ä½äº0çš„ä½ç½®çš„æ—¶å€™, é€‰å–ä¸¤ä¾§çš„æ•°æ®çš„ä¸­é—´çš„éšä¾¿ä¸€ä¸ªæ•°æ® æ¢¯åº¦: å¯¹æ¯ä¸€ä¸ªå˜é‡è¿›è¡Œæ±‚å¯¼, å¸¦å…¥åæ ‡, è¿™ä¸€ä¸ªæ•°å­—å‘é‡æ˜¯å˜åŒ–æœ€å¿«çš„æ–¹å‘ ![image 20250107141801446](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071418555.png) ![image 20250107142031708](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071420786.png) ![image 20250107142045847](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071420916.png) ![image 20250107142305152](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071423273.png) ### è®¡ç®—å›¾ æŠŠå®é™…çš„è®¡ç®—åˆ†ä¸ºå¾ˆå¤šå±‚, å¯¹æ¯ä¸€å±‚æ±‚å¯¼ç›¸ä¹˜, å®é™…çš„è®¡ç®—æ˜¯ä¸€ä¸ªæ— ç¯å›¾ ![image 20250107143355624](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071433716.png) ![image 20250107143752147](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071437231.png) ![image 20250107143731575](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071437667.png) > å®é™…è®¡ç®—çš„å¤æ‚åº¦éƒ½æ˜¯O(n), ä½†æ˜¯å†…å­˜çš„å¤æ‚åº¦ä¸åŒ, åå‘è®¡ç®—çš„å¤æ‚åº¦æ˜¯O(1) ### è‡ªåŠ¨æ±‚å¯¼ å®é™…è®¡ç®—å®ä¾‹ ![image 20250107144133289](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071441378.png) è®¡ç®—ä¸Šé¢çš„å¼å­ ```python x torch.arange(4.0) x.requires_grad_(True) # è®¾ç½®æ¢¯åº¦, å®é™…æ˜¯æœ‰ä¸€ä¸ªåœ°æ–¹å¯ä»¥è®°å½•æ¢¯åº¦ x.grad # é»˜è®¤çš„æ—¶å€™æ˜¯None y 2 * torch.dot(x, x) y # æ¯”æ²¡æœ‰åŠ gradçš„æ—¶å€™å¤šäº†ä¸€ä¸ªå‡½æ•° \"\"\" tensor(28., grad_fn <MulBackward0>) \"\"\" ``` ```python y.backward() # è®¡ç®—æ¢¯åº¦ x.grad # æ¢¯åº¦, è¿™é‡Œçš„æ¢¯åº¦æ˜¯yå¯¹xçš„æ¢¯åº¦, y 4 * x1 , 4 * x2 , 4 * x3 , 4 * x4 \"\"\" tensor([ 0., 4., 8., 12.]) \"\"\" ``` > é»˜è®¤çš„æ—¶å€™è¿™ä¸€ä¸ªä¸æ¸…é›¶, è®¡ç®—ä¸‹ä¸€ä¸ªä¹‹å‰éœ€è¦æŠŠç»“æœæ¸…é›¶ ```python x.grad.zero_() # æ¢¯åº¦æ¸…é›¶ y x.sum() y.backward() x.grad \"\"\" tensor([1., 1., 1., 1.]) \"\"\" ``` > åœ¨æ·±åº¦å­¦ä¹ é‡Œé¢, ä¸æ˜¯ä¸ºäº†è®¡ç®—å¾®åˆ†çŸ©é˜µ, è€Œæ˜¯ä¸ºäº†æ‰¹é‡è®¡ç®—æ¯ä¸€ä¸ªæ ·æœ¬çš„å•ç‹¬è®¡ç®—çš„åå¯¼æ•°ä¹‹å’Œ ```python x.grad.zero_() y x * x y.sum().backward() x.grad \"\"\" tensor([0., 2., 4., 6.]) \"\"\" ``` å¯ä»¥å®ç°æŠŠæŸäº›è®¡ç®—ç§»åŠ¨åˆ°è®¡ç®—å›¾å¤–é¢ ```python x.grad.zero_() y x * x u y.detach() # åˆ†ç¦»å‡ºæ¥, ä¸éœ€è¦æ¢¯åº¦ u x * x z u * x z.sum().backward() x.grad, x.grad u \"\"\" (tensor([0., 1., 4., 9.]), tensor([True, True, True, True])) \"\"\" ``` å®é™…è¿™ä¸€ä¸ªå›¾çš„æ„å»ºå¯ä»¥ç»è¿‡å‡½æ•°ä»¥åŠå¾ªç¯ ```python def f(a): b a * 2 while b.norm() < 1000: # èŒƒæ•° b b * 2 if b.sum() > 0: c b else: c 100 * b return c a torch.randn(size (), requires_grad True) d f(a) d.backward() a.grad d / a \"\"\" tensor(True) \"\"\" ``` ## çº¿æ€§æ¨¡å‹ ç»™å®šä¸€ä¸ªnç»´çš„è¾“å…¥, x [x1, x2, x3, ...]^T^ è¿™ä¸€ä¸ªæ¨¡å‹æœ‰ä¸€ä¸ªnç»´åº¦æƒé‡ä»¥åŠä¸€ä¸ªæ ‡å‡†çš„åå·®, è¾“å‡ºæ˜¯ä¸€ä¸ªåŠ æƒçš„æ±‚å’Œå‡½æ•° çº¿æ€§æ¨¡å¼å¯ä»¥æ˜¯å•å±‚çš„ç¥ç»ç½‘ç»œæ¨¡å‹ > é¢„ä¼°çš„æ•°æ®éœ€è¦é¢„æµ‹ä¸€ä¸‹æ•°æ®çš„è´¨é‡, å¯ä»¥ä½¿ç”¨å¹³æ–¹æŸå¤± > > ![image 20250107154914804](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071549901.png) ![image 20250107155230777](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071552868.png) ![image 20250107155301749](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071553834.png) > é€šè¿‡è°ƒæ•´å‚æ•°ä½¿å¾—æ‹Ÿåˆçš„ç¨‹åº¦æœ€é«˜ > > **æ³¨: **è¿™é‡Œçš„wåœ¨åˆå§‹åŒ–çš„æ—¶å€™ä¸è¦è®¾ç½®ä¸ºä¸€æ ·çš„, å¦åˆ™æ¢¯åº¦ç›¸åŒä¼šå¯¼è‡´å®é™…ä¸ªæ›´æ–°ä¹Ÿæ˜¯ç›¸åŒçš„ ![image 20250107155507277](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071555375.png) ![image 20250107155518653](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071555747.png) ### ä¼˜åŒ–æ–¹æ³• #### æ¢¯åº¦ä¸‹é™ ![image 20250107155925193](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071559294.png) è¿™ä¸€ä¸ªä½¿ç”¨çš„æ—¶å€™ä¸€èˆ¬æ˜¯ä¸€ä¸ªå°æ‰¹é‡çš„, åœ¨æ•´ä¸ªæ•°æ®é›†å¤„ç†å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿç”šè‡³å‡ ä¸ªå°æ—¶, æˆ‘ä»¬å¯ä»¥é€‰å–å…¶ä¸­ä¸€ä¸ªæ ·æœ¬æ¥è¿›è¡Œè®¡ç®—, æ ·æœ¬çš„å¤§å°æ˜¯å¾ˆé‡è¦çš„å‚æ•°(æ‰¹é‡å¤§å°) ### å®é™…å®ç° ä½¿ç”¨w [2, 3, 4]å’Œb 4.2ä»¥åŠå™ªå£°æ„å»ºä¸€ä¸ªæ•°æ®é›† + å¯¼å…¥å„ç§åŒ… ```python %matplotlib inline import torch import random from d2l import torch as d2l ``` + å»ºç«‹æ•°æ®é›†, xæ˜¯ä¸€ä¸ªæ ‡å‡†çš„æ­£æ€åˆ†å¸ƒ, yæ˜¯æ¯ä¸€ä¸ªxå®é™…çš„yåšçš„ä¸€ä¸ªæ ‡å‡†å·®ä¸º0.01çš„æ­£æ€åˆ†å¸ƒ ```python # ä½¿ç”¨æƒé‡ä»¥åŠåç½®å»ºç«‹ä¸€ä¸ªæ•°æ®é›† def synthetic_data(w, b, num_examples): \"\"\"Generate y Xw + b + noise.\"\"\" # å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1çš„éšæœºæ•°, ç”Ÿæˆnum_examplesè¡Œï¼Œlen(w)åˆ—çš„çŸ©é˜µ X torch.normal(0, 1, (num_examples, len(w))) y torch.matmul(X, w) + b # çŸ©é˜µä¹˜æ³•, è·å–æ­£ç¡®çš„ç»“æœ y + torch.normal(0, 0.01, y.shape) # åŠ ä¸Šå™ªå£° return X, y.reshape(( 1, 1)) # yå˜æˆåˆ—å‘é‡ true_w torch.tensor([2, 3.4]) # è®°å½•ä¸€ä¸‹å®é™…çš„ç»“æœ true_b 4.2\t\t\t\t\t# å¦ä¸€ä¸ªç»“æœ features, labels synthetic_data(true_w, true_b, 1000) #è·å–å®é™…çš„æ•°æ® ``` + ä½¿ç”¨å›¾å½¢åŒ–ç•Œé¢çœ‹ä¸€ä¸‹ç»“æœ ```python d2l.set_figsize() # è®¾ç½®å›¾çš„å°ºå¯¸, 3.5*2.5 d2l.plt.scatter(features[:, 1].detach().numpy(), labels.detach().numpy(), 1) # ç”»æ•£ç‚¹å›¾ ``` > ![image 20250108123403113](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081234205.png) + ç”±äºæ•°æ®çš„æ•°é‡æ¯”è¾ƒå¤§, æ‰€ä»¥æ¯ä¸€æ¬¡åªéšæœºå–å‡ºæ¥ä¸€éƒ¨åˆ† ```python # è¯»å–æ•°æ®, bach_size: æ‰¹é‡å¤§å°, features: ç‰¹å¾, labels: æ ‡ç­¾ # é¦–å…ˆå»ºç«‹ä»¥åŠéšæœºçš„ç´¢å¼•åˆ—è¡¨, ç„¶åæ¯æ¬¡å–å‡ºbatch_sizeä¸ªæ ·æœ¬ def data_iter(batch_size, features, labels): num_examples len(features) # æ ·æœ¬æ•° indices list(range(num_examples)) # ç”Ÿæˆä¸€ä¸ªæ ·æœ¬æ•°çš„åˆ—è¡¨, rangeç”¨äºç”Ÿæˆä¸€ä¸ªæ•°åˆ— random.shuffle(indices) # éšæœºæ‰“ä¹± for i in range(0, num_examples, batch_size): # æ¯æ¬¡å–batch_sizeä¸ªæ ·æœ¬ batch_indices torch.tensor(indices[i:min(i + batch_size, num_examples)]) yield features[batch_indices], labels[batch_indices] bach_size 10 for X, y in data_iter(bach_size, features, labels): print(X, '\\n', y) break ``` + å»ºç«‹åˆå§‹çš„æ•°æ® ```python # éšæœºåˆå§‹åŒ–w, requires_grad Trueè¡¨ç¤ºéœ€è¦æ±‚æ¢¯åº¦ w torch.normal(0, 0.01, size (2, 1), requires_grad True) # åˆå§‹åŒ–bä¸º0, requires_grad Trueè¡¨ç¤ºéœ€è¦æ±‚æ¢¯åº¦ b torch.zeros(1, requires_grad True) ``` + å»ºç«‹è®¡ç®—çš„å‡½æ•°, ä½¿ç”¨ç°åœ¨çš„æ•°æ®è®¡ç®—å‡ºä¸€ä¸ªç»“æœ ```python def linreg(X, w, b): # çº¿æ€§å›å½’æ¨¡å‹ return torch.matmul(X, w) + b ``` + ä½¿ç”¨è·å–çš„ç»“æœç®—ä¸€ä¸‹å®é™…çš„åå·®, ä¹‹åéœ€è¦ä½¿ç”¨è®¡ç®—çš„æ–¹æ³•ä½¿è¿™ä¸€ä¸ªå€¼ä¸‹é™ ```python def squared_loss(y_hat, y): # æŸå¤±å‡½æ•°, è¿”å›çš„æ˜¯å‘é‡ return (y_hat y.reshape(y_hat.shape)) ** 2 / 2 ``` + ä½¿ç”¨è·å–çš„æ¢¯åº¦è¿›è¡Œä¸€æ¬¡æ•°æ®çš„ä¼˜åŒ–è¿­ä»£, è¿™é‡Œçš„æ¢¯åº¦é™¤ä»¥nå¯ä»¥ä½¿å¾—æ­¥é•¿ä¸ä¼šå—æ•°æ®å¤§å°çš„å½±å“ ```python # ä¼˜åŒ–ç®—æ³•, params: å‚æ•°, lr: å­¦ä¹ ç‡, batch_size: æ‰¹é‡å¤§å° def sgd(params, lr, batch_size): with torch.no_grad(): # ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ for param in params: # æ›´æ–°å‚æ•°, æ¯ä¸€ä¸ªå‚æ•°éƒ½éœ€è¦å‡å»æ¢¯åº¦çš„å¹³å‡å€¼ param lr * param.grad / batch_size param.grad.zero_() # æ¢¯åº¦æ¸…é›¶ ``` + å®é™…çš„è®­ç»ƒ ```python lr 0.01 num_epochs 10 # è¿­ä»£æ¬¡æ•° net linreg # ç½‘ç»œ loss squared_loss # æŸå¤±å‡½æ•° for epoch in range(num_epochs): for X, y in data_iter(bach_size, features, labels): l loss(net(X, w, b), y) # è®¡ç®—æŸå¤± l.sum().backward() # æ±‚æ¢¯åº¦, ä½¿å¾—lå˜æˆæ ‡é‡ sgd([w, b], lr, bach_size) # æ›´æ–°å‚æ•° with torch.no_grad(): train_l loss(net(features, w, b), labels) print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}') ``` + çœ‹ä¸€ä¸‹è¯¯å·® ```python print(f'wçš„ä¼°è®¡è¯¯å·®: {true_w w.reshape(true_w.shape)}') print(f'bçš„ä¼°è®¡è¯¯å·®: {true_b b}') ``` ### å®é™…å®ç° + å¯¼å…¥å„ç§æ•°æ®åŒ… ```python import numpy as np import torch from torch.utils import data from d2l import torch as d2l ``` + è·å–ä¸€ä¸ªæ•°æ®é›† ```python true_w torch.tensor([2, 3.4]) true_b 4.2 features, labels d2l.synthetic_data(true_w, true_b, 1000) ``` + ä½¿ç”¨æ•°æ®å»ºç«‹ä¸€ä¸ªæ•°æ®è¿­ä»£å™¨ ```python def load_array(data_arrays, batch_size, is_train True): dataset data.TensorDataset(*data_arrays) # è·å–æ•°æ®é›† # è¿”å›æ•°æ®è¿­ä»£å™¨, shuffle Trueè¡¨ç¤ºæ‰“ä¹±æ•°æ® return data.DataLoader(dataset, batch_size, shuffle is_train) batch_size 10 data_iter load_array((features, labels), batch_size) next(iter(data_iter)) ``` + å»ºç«‹ä¸€ä¸ªçº¿æ€§å±‚ ```python from torch import nn # 2ä¸ªè¾“å…¥ï¼Œ1ä¸ªè¾“å‡º, çº¿æ€§å›å½’æ¨¡å‹, sequentialæ˜¯ä¸€ä¸ªå®¹å™¨ï¼Œå¯ä»¥å°†å¤šä¸ªå±‚ä¸²è”èµ·æ¥ net nn.Sequential(nn.Linear(2, 1)) ``` + è®¾ç½®ä¸€ä¸‹åˆå§‹å‚æ•° ```python net[0].weight.data.normal_(0, 0.01) # åˆå§‹åŒ–æƒé‡ net[0].bias.data.fill_(0) # åˆå§‹åŒ–åç½® ``` + æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ ```python loss nn.MSELoss() # å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•° # éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨ trainer torch.optim.SGD(net.parameters(), lr 0.03) ``` > è¿˜æœ‰å‚æ•°momentumæ˜¯åœ¨ä¼˜åŒ–ç®—æ³•ä¸­çš„ä¸€ç§åŠ é€Ÿå› å­ï¼Œç”¨äºåŠ é€Ÿæ¢¯åº¦ä¸‹é™çš„æ”¶æ•›è¿‡ç¨‹ã€‚å…·ä½“æ¥è¯´ï¼Œå½“æ¢¯åº¦æ–¹å‘ä¿æŒä¸å˜çš„æ—¶å€™ï¼Œåˆ©ç”¨momentumå¯ä»¥åŠ é€Ÿå‚æ•°çš„æ›´æ–°ï¼›å½“æ¢¯åº¦æ–¹å‘å‘ç”Ÿå˜åŒ–çš„æ—¶å€™ï¼Œåˆ©ç”¨momentumå¯ä»¥å‡å°æ›´æ–°çš„å¹…åº¦ï¼Œé¿å…å‚æ•°åœ¨å±€éƒ¨æå°å€¼ç‚¹é™„è¿‘éœ‡è¡ã€‚ > > åœ¨SGDä¼˜åŒ–ç®—æ³•ä¸­ï¼Œmomentumå‚æ•°é€šå¸¸è®¾ç½®ä¸ºä¸€ä¸ªä»‹äº0åˆ°1ä¹‹é—´çš„å€¼ï¼Œä¾‹å¦‚0.9ã€‚è¿™æ„å‘³ç€æ¯æ¬¡å‚æ•°æ›´æ–°æ—¶ï¼Œä¸Šä¸€æ¬¡æ›´æ–°çš„æ–¹å‘å’Œå¤§å°å°†ä»¥0.9çš„æ¯”ä¾‹è¢«ä¿ç•™ï¼Œå¹¶ä¸å½“å‰çš„æ¢¯åº¦ä¸€èµ·è®¡ç®—æ–°çš„æ›´æ–°æ–¹å‘å’Œå¤§å°ã€‚è¿™æ ·å¯ä»¥åœ¨æœ€ç»ˆæ”¶æ•›æ—¶æŠ‘åˆ¶éœ‡è¡ï¼ŒåŠ é€Ÿæ”¶æ•›é€Ÿåº¦ã€‚ + å®é™…è®­ç»ƒ ```python num_epochs 3 for epoch in range(num_epochs): for X, y in data_iter: # è·å–å°æ‰¹é‡æ•°æ® l loss(net(X), y) trainer.zero_grad() # æ¢¯åº¦æ¸…é›¶ l.backward() # è®¡ç®—æ¢¯åº¦ trainer.step() # æ›´æ–°å‚æ•° l loss(net(features), labels) print(f'epoch {epoch + 1}, loss {l:f}') ``` ## åˆ†ç±»å’Œå›å½’ å›å½’æ˜¯ä¸€ä¸ªè¿ç»­å€¼, åˆ†ç±»æ˜¯ä¸€ä¸ªç¦»æ•£çš„ç±»åˆ«, å¯ä»¥å®ç°æ–‡å­—è¯„è®º, æ‰‹å†™æ•°å­— å›å½’: æ˜¯ä¸€ä¸ªå•è¿ç»­çš„æ•°å€¼è¾“å‡º, åœ¨è‡ªç„¶åŒºé—´R, å’ŒçœŸå®çš„æ•°å­—ä¹‹é—´çš„åŒºåˆ«ä½œä¸ºæŸå¤± åˆ†ç±»: é€šå¸¸æœ‰å¤šä¸ªè¾“å‡º, è¾“å‡ºçš„ç¬¬iä¸ªæ˜¯ç¬¬iç±»çš„å¯ä¿¡åº¦, å®é™…çš„ç»“æœæ˜¯y~i~ 1 æˆ– 0, é¢„æµ‹ç»“æœæ˜¯è¾“å‡ºçš„æœ€å¤§å€¼, åŒæ—¶è¿™ä¸€ä¸ªæ•°å€¼æœ€å¥½å¯ä»¥å¤§äºå…¶ä»–çš„è¾“å‡ºä¸€ä¸ªé˜ˆå€¼ ### Softmaxå›å½’ä»¥åŠäº¤å‰ç†µ ![image 20250108135945070](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081359202.png) ä½¿ç”¨æŒ‡æ•°å¯ä»¥ä½¿å¾—æ‰€æœ‰çš„æ•°æ®éƒ½æ˜¯ä¸€ä¸ªéè´Ÿçš„å€¼, åŒæ—¶æ‰€æœ‰çš„æ•°å­—çš„å’Œä¸º1, å¯ä»¥ä½œä¸ºæ¦‚ç‡ ![image 20250108140258973](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081402079.png) ![image 20250108140321684](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081403791.png) > æŸå¤±è®¡ç®—çš„æ—¶å€™, ç”±äºçœŸå®åªæœ‰ä¸€ä¸ªæ•°æ®çš„è¾“å‡º, æ¦‚ç‡ä¸º1, æ‰€ä»¥å®é™…è®¡ç®—çš„æ—¶å€™åªæœ‰ä¸€é¡¹, å¦‚æœå®Œå…¨é¢„æµ‹åˆ°ç»“æœ, log1 0 ### å®é™…å®ç° ```python import torch from IPython import display from d2l import torch as d2l batch_size 256 # è¿™ä¸€ä¸ªå‡½æ•°åœ¨æ•°æ®é›†æ–‡ä»¶é‡Œé¢å®ç°è¿‡äº† train_iter, test_iter d2l.load_data_fashion_mnist(batch_size) ``` ```python num_input 784 # 28 * 28çš„å›¾åƒ num_output 10 # 10ä¸ªç±»åˆ« # åˆå§‹åŒ–å‚æ•° W torch.normal(0, 0.01, size (num_input, num_output), requires_grad True) b torch.zeros(num_output, requires_grad True) ``` + è®¡ç®—ä¸€ä¸‹softmaxçš„é¢‘ç‡ ```python def softmax(X): X_exp torch.exp(X) # è¿™é‡Œæ˜¯å¯¹æ¯ä¸€ä¸ªå…ƒç´ æ±‚æŒ‡æ•° e^x # è¿™é‡Œæ˜¯å¯¹æ¯ä¸€è¡Œæ±‚å’Œ, è·å–åˆ†æ¯ partition X_exp.sum(1, keepdim True) return X_exp / partition # è¿™é‡Œåº”ç”¨äº†å¹¿æ’­æœºåˆ¶ ``` + è®¡ç®—ä¸€è½®çš„ç»“æœ ```python def net(X): # è¿™é‡Œçš„reshapeæ˜¯ä¸ºäº†å°†å›¾åƒå±•å¹³, ä¹‹åå†è¿›è¡ŒçŸ©é˜µä¹˜æ³•, # ä¹‹åå†åŠ ä¸Šåç½®, æœ€åå†è¿›è¡Œsoftmax return softmax(torch.matmul(X.reshape(( 1, W.shape[0])), W) + b) ``` + å»ºç«‹ä¸€ä¸ªç±»ç´¯åŠ å™¨, ä¼šå¯¹ä¹ˆä¸€æ¬¡ä¼ è¿›æ¥çš„æ•°æ®è¿›è¡Œè®°å½• ```python class Accumulator: #@save \"\"\"For accumulating sums over `n` variables.\"\"\" def __init__(self, n): self.data [0.0] * n def add(self, *args): self.data [a + float(b) for a, b in zip(self.data, args)]# è¿™é‡Œæ˜¯å°†ä¸¤ä¸ªlistå¯¹åº”å…ƒç´ ç›¸åŠ  def reset(self): self.data [0.0] * len(self.data) def __getitem__(self, idx):# è¿™ä¸ªå‡½æ•°æ˜¯ä¸ºäº†èƒ½å¤Ÿé€šè¿‡ä¸‹æ ‡è®¿é—®æ•°æ® return self.data[idx] ``` + è®¡ç®—äº¤å‰ç†µ ```python # è¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥è¯„ä¼°æ¨¡å‹çš„æŸå¤± def cross_entropy(y_hat, y): # è¿™é‡Œçš„range(len(y_hat))æ˜¯ä¸ºäº†å–å‡ºæ¯ä¸€è¡Œçš„å¯¹åº”çš„å€¼, # æ˜¯å®é™…çš„æ•°æ®å¯¹åº”çš„æ¦‚ç‡ return torch.log(y_hat[range(len(y_hat)), y]) ``` + ä½¿ç”¨é¢„æµ‹çš„ç»“æœä»¥åŠå®é™…çš„ç»“æœè®¡ç®—ä¸€ä¸‹æ­£ç¡®çš„ä¸ªæ•° ```python # è¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥è¯„ä¼°æ¨¡å‹çš„æŸå¤±, è¿”å›çš„æ˜¯æˆåŠŸçš„ä¸ªæ•° # y_hatæ˜¯é¢„æµ‹çš„æ¦‚ç‡, yæ˜¯å®é™…çš„æ•°æ® def accuracy(y_hat, y): # è¿™é‡Œçš„argmax(1)æ˜¯å–å‡ºæ¯ä¸€è¡Œæœ€å¤§çš„å€¼çš„ç´¢å¼•, è¿™ä¸ªç´¢å¼•å°±æ˜¯é¢„æµ‹çš„ç±»åˆ« if len(y_hat.shape) > 1 and y_hat.shape[1] > 1: y_hat y_hat.argmax(axis 1) cmp y_hat.type(y.dtype) y # è·å–ä¸€ä¸ªboolç±»å‹çš„tensor # å°†boolç±»å‹çš„tensorè½¬æ¢ä¸ºfloatç±»å‹çš„tensor # ç„¶åæ±‚å’Œ, è·å–æ­£ç¡®çš„æ•°é‡ return float(cmp.type(y.dtype).sum()) ``` + è®¡ç®—ä¸€ä¸‹æ­£ç¡®ç‡ ```python # è¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥è¯„ä¼°æ¨¡å‹çš„å‡†ç¡®ç‡ # netæ˜¯æ¨¡å‹, data_iteræ˜¯æ•°æ®é›† def evaluate_accuracy(net, data_iter): if isinstance(net, torch.nn.Module): net.eval() metric Accumulator(2) # è¿™é‡Œçš„2æ˜¯å› ä¸ºæ­£ç¡®çš„æ•°é‡å’Œæ€»çš„æ•°é‡ for X, y in data_iter: # y.numel()æ˜¯è·å–yçš„å…ƒç´ æ•°é‡ metric.add(accuracy(net(X), y), y.numel()) return metric[0] / metric[1] # è¿”å›æ­£ç¡®çš„æ•°é‡é™¤ä»¥æ€»çš„æ•°é‡ ``` + å»ºç«‹å®é™…çš„è®­ç»ƒä¸€æ¬¡çš„å‡½æ•°ï¼Œ å¯ä»¥å…¼å®¹ä½¿ç”¨torchçš„æ¨¡å¼ ```python # è¿™é‡Œæ˜¯è®­ç»ƒå‡½æ•°, è¿™é‡Œçš„updateræ˜¯ä¸€ä¸ªå‡½æ•°, è¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥æ›´æ–°å‚æ•°çš„ def train_epoch_ch3(net, train_iter, loss, updater): #@save if isinstance(net, torch.nn.Module): # è¿™é‡Œæ˜¯ä¸ºäº†åˆ¤æ–­netæ˜¯ä¸æ˜¯torch.nn.Moduleçš„å­ç±» net.train() metric Accumulator(3) # è®­ç»ƒæŸå¤±æ€»å’Œ, è®­ç»ƒå‡†ç¡®åº¦æ€»å’Œ, æ ·æœ¬æ•° for X, y in train_iter: y_hat net(X) l loss(y_hat, y) # è®¡ç®—æŸå¤±, è¿™é‡Œä½¿ç”¨äº¤å‰ç†µæŸå¤± if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.backward() updater.step() metric.add(float(l) * len(y), accuracy(y_hat, y), y.numel()) else: l.sum().backward() # è¿™é‡Œæ˜¯æ±‚å’Œ updater(X.shape[0]) # ä½¿ç”¨çš„æ˜¯ä¹‹å‰å†™çš„æ¢¯åº¦ä¸‹é™ metric.add(float(l.sum()), accuracy(y_hat, y), y.numel()) # è¿”å›æŸå¤±å’Œå‡†ç¡®åº¦ return metric[0] / metric[2], metric[1] / metric[2] ``` + å»ºç«‹ä¸€ä¸ªæ˜¾ç¤ºå›¾åƒçš„ç±» ```python class Animator: #@save \"\"\"For plotting data in animation.\"\"\" def __init__(self, xlabel None, ylabel None, legend None, xlim None, ylim None, xscale 'linear', yscale 'linear', fmts (' ', 'm ', 'g .', 'r:'), nrows 1, ncols 1, figsize (3.5, 2.5)): # Incrementally plot multiple lines if legend is None: legend [] d2l.use_svg_display() self.fig, self.axes d2l.plt.subplots(nrows, ncols, figsize figsize) if nrows * ncols 1: self.axes [self.axes,] # Use a lambda function to capture arguments self.config_axes lambda: d2l.set_axes(self.axes[ 0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend) self.X, self.Y, self.fmts None, None, fmts def add(self, x, y): # Add multiple data points into the figure if not hasattr(y, \"__len__\"): y [y] n len(y) if not hasattr(x, \"__len__\"): x [x] * n if not self.X: self.X [[] for _ in range(n)] if not self.Y: self.Y [[] for _ in range(n)] for i, (a, b) in enumerate(zip(x, y)): if a is not None and b is not None: self.X[i].append(a) self.Y[i].append(b) self.axes[0].cla() for x, y, fmt in zip(self.X, self.Y, self.fmts): self.axes[0].plot(x, y, fmt) self.config_axes() display.display(self.fig) display.clear_output(wait True) ``` + å»ºç«‹è®­ç»ƒå‡½æ•° ```python # è¿™ä¸ªå‡½æ•°æ˜¯ä¸ºäº†è®­ç»ƒæ¨¡å‹ # netæ˜¯æ¨¡å‹, train_iteræ˜¯è®­ç»ƒæ•°æ®, test_iteræ˜¯æµ‹è¯•æ•°æ®, lossæ˜¯æŸå¤±å‡½æ•° # num_epochsæ˜¯è®­ç»ƒçš„è½®æ•°, updateræ˜¯æ›´æ–°å‚æ•°çš„å‡½æ•° def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): #@save animator Animator(xlabel 'epoch', xlim [1, num_epochs], ylim [0.3, 0.9], legend ['train loss', 'train acc', 'test acc']) for epoch in range(num_epochs): train_metrics train_epoch_ch3(net, train_iter, loss, updater) # è®­ç»ƒä¸€ä¸ªepoch test_acc evaluate_accuracy(net, test_iter) # æµ‹è¯•æ¨¡å‹ animator.add(epoch + 1, train_metrics + (test_acc,)) # æ·»åŠ æ•°æ®åˆ°åŠ¨ç”» train_loss, train_acc train_metrics # è·å–è®­ç»ƒçš„æŸå¤±å’Œå‡†ç¡®åº¦ assert train_loss < 0.5, train_loss # æŸå¤±æ¯”è¾ƒå° # å‡†ç¡®ç‡æ¯”è¾ƒé«˜ assert train_acc < 1 and train_acc > 0.7, train_acc assert test_acc < 1 and test_acc > 0.7, test_acc ``` + å¼€å§‹è®­ç»ƒ ```python num_epochs 10 # è®­ç»ƒæ¨¡å‹ train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater) ``` ![image 20250108193835446](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081938604.png) + é¢„æµ‹ ```python def predict_ch3(net, test_iter, n 6): #@save for X, y in test_iter: break trues d2l.get_fashion_mnist_labels(y) preds d2l.get_fashion_mnist_labels(net(X).argmax(axis 1)) titles [true + '\\n' + pred for true, pred in zip(trues, preds)] d2l.show_images(X[0:n].reshape((n, 28, 28)), 1, n, titles titles[0:n]) predict_ch3(net, test_iter) # é¢„æµ‹æ¨¡å‹ ``` ![image 20250108193848764](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081938854.png) ### å®é™…å®ç°ç®€å• ```python import torch from torch import nn from d2l import torch as d2l batch_size 256 train_iter, test_iter d2l.load_data_fashion_mnist(batch_size) ``` + å»ºç«‹æ¨¡å‹ ```python # åˆå§‹åŒ–ä¸€ä¸ªçº¿æ€§æ¨¡å‹, 784ä¸ªè¾“å…¥ç‰¹å¾ï¼Œ10ä¸ªè¾“å‡ºç‰¹å¾, åŒæ—¶å¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œå±•å¹³ net nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) def init_weights(m): if type(m) nn.Linear: nn.init.normal_(m.weight, std 0.01) # å¯¹æ¨¡å‹è¿›è¡Œåˆå§‹åŒ–, å®é™…æ˜¯å¯¹æ¨¡å‹ä¸­çš„æ¯ä¸ªçº¿æ€§å±‚è¿›è¡Œåˆå§‹åŒ– net.apply(init_weights) ``` + è·å–æ›´æ–°ä»¥åŠæŸå¤±å‡½æ•° ```python loss nn.CrossEntropyLoss() # è·å–äº¤å‰ç†µæŸå¤±å‡½æ•° trainer torch.optim.SGD(net.parameters(), lr 0.1) # ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨ ``` + å®é™…çš„è®­ç»ƒ, ä½¿ç”¨ä¹‹å‰å®ç°çš„è®­ç»ƒå‡½æ•° ```python num_epochs 10 d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) ``` ![image 20250108195441237](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081954335.png) ## æŸå¤±å‡½æ•° ç”¨äºè®¡ç®—å®é™…çš„å€¼å’Œé¢„æµ‹å€¼ä¹‹é—´çš„åŒºåˆ« ### L2 Loss ![image 20250108141723229](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081417328.png) é™¤ä»¥2æ˜¯ä¸ºäº†æ±‚å¯¼çš„æ—¶å€™å¯ä»¥æŠµæ¶ˆ, å®é™…ä½¿ç”¨çš„æ—¶å€™å¦‚æœè¿™ä¸€ä¸ªæ•°å­—ç¦»åŸç‚¹æ¯”è¾ƒè¿œçš„æ—¶å€™å¯èƒ½å¯¼è‡´æ­¥é•¿å¤ªå¤§ ![image 20250108142015545](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081420679.png) è“è‰²çš„æ˜¯å‡½æ•°, é»„è‰²çš„æ˜¯å¯¼æ•°, ç»¿è‰²ä¼¼ç„¶å‡½æ•°, å®é™…ä½¿ç”¨çš„æ˜¯å¯¼æ•°è¿›è¡Œæ›´æ–° ### L1 Loss ![image 20250108142139059](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081421153.png) ![image 20250108142156891](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081421023.png) æ‰€æœ‰çš„ä½ç½®çš„æ¢¯åº¦éƒ½æ˜¯å®šå€¼, ä½†æ˜¯é›¶ç‚¹çš„æ—¶å€™ä¸å¯å¯¼, ä¼šå‘ç”Ÿå‰§çƒˆå˜åŒ–, ä¼˜åŒ–çš„æœ«æœŸä¸å¤ªç¨³å®š ### Huber's Robust Loss ![image 20250108142357172](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501081423309.png) ä½¿ç”¨ä»¥ä¸Šçš„ä¸¤ä¸ªå‡½æ•°åšæˆåˆ†å¸ƒå‡½æ•° ## å­¦ä¹ ç‡ä¸‹é™ ```python # å»ºç«‹ä¸€ä¸ªæ—¶é—´è°ƒåº¦å™¨, æ¯lr_periodé™ä½çš„æ¯”ä¾‹ä¸ºlr_decay scheduler torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay) # è®­ç»ƒçš„æ—¶å€™æ¯ä¸€è½®ä½¿ç”¨ä¸€æ¬¡ scheduler.step() # æ›´æ–°å­¦ä¹ ç‡ ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/0000-0-0-00åŸºç¡€pandas.html":{"title":"pandas","content":"# pandas é€šå¸¸ä½¿ç”¨`import pandas as pd`, è¿™æ˜¯ä¸€ä¸ªæ ‡ç­¾åº“, åœ¨numpyçš„åŸºç¡€ä¸Šç»™äºˆè¡Œåˆ—æ ‡ç­¾, åœ¨è¿™é‡Œé¢æ‰€æœ‰æ•°ç»„çš„ç‰¹æ€§ä¾æ—§å­˜åœ¨, æ•°æ®ä»¥numPyçš„æ ¼å¼å­˜å‚¨ ## ä¸€ç»´å¯¹è±¡å»ºç«‹ å¯ä»¥é€šè¿‡`pd.Series`æŠŠå­—å…¸è½¬æ¢ä¸ºä¸€ä¸ªSerieså¯¹è±¡, è¿™é‡Œçš„å¯¹è±¡æ˜¯ä¸€ä¸ªåˆ—å¯¹è±¡ ```python dict_v {'a': 0, 'b': 1, 'c': 2, 'd': 3} sr pandas.Series(dict_v) \"\"\" a 0 b 1 c 2 d 3 dtype: int64 \"\"\" ``` ä¹Ÿå¯ä»¥ä½¿ç”¨æ•°ç»„çš„æ–¹å¼è¿›è¡Œå»ºç«‹, ä½¿ç”¨ä¸¤ä¸ªæ•°ç»„, ç¬¬ä¸€ä¸ªæ•°ç»„æ˜¯ä¸€ä¸ªåˆ—è¡¨/æ•°ç»„/å¼ é‡, ç¬¬äºŒä¸ªæ˜¯indexç´¢å¼• ```python v [0, 0.25, 0.5, 0.75] k ['a', 'b', 'c', 'd'] sr pd.Series(v, index k) \"\"\" a 0.00 b 0.25 c 0.50 d 0.75 dtype: float64 \"\"\" ``` > indexå¯ä»¥çœç•¥, çœç•¥ä»¥åè¿™ä¸€ä¸ªå‚æ•°æ˜¯ä»0å¼€å§‹çš„ä¸€ç³»åˆ—æ•°å­— ## Serieså±æ€§ æœ‰ä¸¤ä¸ªå±æ€§, ä¸€ä¸ªæ˜¯values, å¦ä¸€ä¸ªæ˜¯index, æœ€ç»ˆçš„valuséƒ½æ˜¯ä¸€ä¸ªnumPyçš„æ•°ç»„ ## å»ºç«‹äºŒç»´ æœ‰è¡Œæ ‡ç­¾indexä»¥åŠåˆ—æ ‡ç­¾columns ### å­—å…¸å»ºç«‹ ä½¿ç”¨å­—å…¸å»ºç«‹çš„æ—¶å€™, å¿…é¡»åŸºäºå¤šä¸ªSerieså¯¹è±¡, æ¯ä¸€ä¸ªSerieså°±æ˜¯ä¸€ä¸ªåˆ—å¯¹è±¡ å»ºç«‹Seriesçš„æ—¶å€™é”®æ˜¯index, ç«–å‘å»¶å±•, å»ºç«‹DataFrameçš„æ—¶å€™é”®æ˜¯columns, æ°´å¹³å»¶ä¼¸ ```python v1 [53, 64, 75, 86] i ['1å·', '2å·', '3å·', '4å·'] sr1 pd.Series(v1, index i) v2 ['ç”·', 'å¥³', 'ç”·', 'å¥³'] sr2 pd.Series(v2, index i) df pd.DataFrame({'åˆ†æ•°': sr1, 'æ€§åˆ«': sr2}) \"\"\" åˆ†æ•° æ€§åˆ« 1å·\t53\tç”· 2å·\t64\tå¥³ 3å·\t75\tç”· 4å·\t86\tå¥³ \"\"\" ``` å¦‚æœä¸¤ä¸ªsrçš„æ ‡ç­¾æ˜¯ä¸ä¸€æ ·çš„, å®é™…ä¼šä½¿ç”¨ä¸¤ä¸ªçš„äº¤é›†å¹¶äº§ç”Ÿä¸€å®šæ•°é‡çš„NaN ### æ•°ç»„å»ºç«‹ ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯values(æ•°ç»„), ç¬¬äºŒä¸ªæ˜¯è¡Œæ ‡ç­¾index, ç¬¬ä¸‰ä¸ªæ˜¯åˆ—æ ‡ç­¾columns, indexå’Œcolumnså¯ä»¥çœç•¥ ```python import numpy as np v np.array([[53, 'å¥³'], [64, 'ç”·'], [75, å¥³], [86, 'ç”·']]) i ['1å·', '2å·', '3å·', '4å·'] c ['åˆ†æ•°', 'æ€§åˆ«'] df pd.DataFrame(v, index i, columns c) \"\"\" åˆ†æ•° æ€§åˆ« 1å·\t53\tå¥³ 2å·\t64\tç”· 3å·\t75\tå¥³ 4å·\t86\tç”· \"\"\" ``` > è¿™é‡Œçš„æ•°å­—ä¼šè¢«è½¬åŒ–ä¸ºå­—ç¬¦ä¸² ### å±æ€§ æœ‰ä¸‰ä¸ªå±æ€§, values, indexå’Œcolumns ```python df.index, df.columns, df.values \"\"\" (Index(['1å·', '2å·', '3å·', '4å·'], dtype 'object'), Index(['åˆ†æ•°', 'æ€§åˆ«'], dtype 'object'), array([['53', 'å¥³'], ['64', 'ç”·'], ['75', 'å¥³'], ['86', 'ç”·']], dtype object)) \"\"\" ``` > åªæå–valuesçš„æ—¶å€™è¿™ä¸€ä¸ªä¼šé€€åŒ–ä¸ºæ•°ç»„, å¯ä»¥æå–å‡ºæ¥ä¸€åˆ—ç„¶åæ”¹å˜ç±»å‹, è¿›è¡Œæ•°å­—æ“ä½œ > > ```python > df.values[:, 0].astype(np.int32) > \"\"\" > df.values[:, 0].astype(np.int32) > \"\"\" > ``` ## å¯¹è±¡ç´¢å¼• å¯ä»¥ä½¿ç”¨æ˜¾å¼çš„ä»¥åŠéšå¼çš„ç´¢å¼•, æ˜¾å¼çš„æ˜¯pandasæä¾›çš„ç´¢å¼•, éšå¼çš„æ˜¯ä½¿ç”¨æ•°ç»„çš„ç´¢å¼•, å¦‚æœä¸€ä¸ªæ˜¾ç¤ºçš„ç´¢å¼•æ˜¯intä¼šå‡ºç°å†²çª, æ‰€ä»¥Pandasä½¿ç”¨ç´¢å¼•å™¨loc(æ˜¾å¼)ä»¥åŠiloc(éšå¼)æ‰‹åŠ¨é€‰æ‹© ### ä¸€ç»´ ```python v [53, 64, 75, 86] k ['1å·', '2å·', '3å·', '4å·'] sr pd.Series(v, index k) sr['1å·'], sr[0], sr.loc['1å·'], sr.iloc[0] \"\"\" (53, 53, 53, 53) \"\"\" ``` + åˆ‡ç‰‡ ```python sr['1å·':'3å·'], sr[0:2], sr.loc['1å·':'3å·'], sr.iloc[0:2] \"\"\" (1å· 53 2å· 64 3å· 75 dtype: int64, 1å· 53 2å· 64 dtype: int64, 1å· 53 2å· 64 3å· 75 dtype: int64, 1å· 53 2å· 64 dtype: int64) \"\"\" ``` > ä½¿ç”¨æ˜¾å¼åˆ‡ç‰‡çš„æ—¶å€™ç´¢å¼•åŒ…å«æœ€åä¸€ä¸ª ### äºŒç»´ åœ¨äºŒç»´é‡Œé¢, ç´¢å¼•å™¨æ˜¯ä¸å¯ä»¥å»æ‰çš„ ```python df.loc['1å·'], df.iloc[0] \"\"\" (åˆ†æ•° 53 æ€§åˆ« å¥³ Name: 1å·, dtype: object, åˆ†æ•° 53 æ€§åˆ« å¥³ Name: 1å·, dtype: object) \"\"\" ``` ```python df.loc['1å·', 'åˆ†æ•°'], df.iloc[0, 0] \"\"\" ('53', '53') \"\"\" ``` ```python df.loc[['1å·', '3å·'], ['æ€§åˆ«', 'åˆ†æ•°']] \"\"\" \tæ€§åˆ«\tåˆ†æ•° 1å·\tå¥³\t53 3å·\tå¥³\t75 \"\"\" ``` > åœ¨Pandasé‡Œé¢èŠ±å¼ç´¢å¼•è¾“å‡ºçš„æ˜¯ä¸€ä¸ªå‘é‡, åœ¨Pandasé‡Œé¢è¡Œåˆ—æ ‡ç­¾çš„ä¿¡æ¯ä¸å¯ä»¥ä¸¢å¤±, åªè¾“å‡ºä¸€ä¸ªå‘é‡ä¸å¯ä»¥, æ‰€ä»¥å®é™…è¾“å‡ºçš„æ˜¯ä¸€ä¸ªäºŒç»´å¯¹è±¡ å®é™…æå–çš„æ—¶å€™å¦‚æœæå–ä¸€è¡Œå¯ä»¥ä½¿ç”¨`df.loc['3å·']`ä¸€åˆ—å¯ä»¥åªä½¿ç”¨`df[å¹´é¾„]`, å› ä¸ºåœ¨Pandasé‡Œé¢åˆ—æ ‡ç­¾å®é™…å°±æ˜¯äºŒç»´å­—å…¸çš„é”® ## å¯¹è±¡å˜å½¢ å®é™…ä½¿ç”¨æ—¶å€™æœ‰çš„éœ€è¦å¯¹è¡Œåˆ—è¿›è¡Œè½¬ç½® ```python v np.array([[53, 64, 75, 86], ['ç”·', 'å¥³', 'ç”·', 'å¥³']]) c ['1å·', '2å·', '3å·', '4å·'] i ['åˆ†æ•°', 'æ€§åˆ«'] df pd.DataFrame(v, index i, columns c) df \"\"\" \t1å·\t2å·\t3å·\t4å· åˆ†æ•°\t53\t64\t75\t86 æ€§åˆ«\tç”·\tå¥³\tç”·\tå¥³ \"\"\" df.T \"\"\" \tåˆ†æ•°\tæ€§åˆ« 1å·\t53\tç”· 2å·\t64\tå¥³ 3å·\t75\tç”· 4å·\t86\tå¥³ \"\"\" ``` + å·¦å³ç¿»è½¬ ```python df.iloc[:, :: 1] \"\"\" 4å·\t3å·\t2å·\t1å· åˆ†æ•°\t86\t75\t64\t53 æ€§åˆ«\tå¥³\tç”·\tå¥³\tç”· \"\"\" ``` ```python df.iloc[:: 1, :] \"\"\" \tæ€§åˆ«\tåˆ†æ•° 4å·\tå¥³\t86 3å·\tç”·\t75 2å·\tå¥³\t64 1å·\tç”·\t53 \"\"\" ``` ### é‡å¡‘ ä¸å¯ä»¥ç›´æ¥ä½¿ç”¨reshape, ä½†æ˜¯å¯ä»¥ä½¿ç”¨æŠŠsræ’å…¥dfä»¥åŠä»dfé‡Œé¢å‰²å‡ºæ¥sr ```python i ['1å·', '2å·', '3å·', '4å·'] v1 [53, 64, 75, 86] v2 ['ç”·', 'å¥³', 'ç”·', 'å¥³'] v3 [1, 2, 3, 4] sr1 pd.Series(v1, index i) sr2 pd.Series(v2, index i) sr3 pd.Series(v3, index i) sr1, sr2, sr3 \"\"\" (1å· 53 2å· 64 3å· 75 4å· 86 dtype: int64, 1å· ç”· 2å· å¥³ 3å· ç”· 4å· å¥³ dtype: object, 1å· 1 2å· 2 3å· 3 4å· 4 dtype: int64) \"\"\" df pd.DataFrame({'åˆ†æ•°': sr1, 'æ€§åˆ«': sr2}) df['å¹´çº§'] sr3 df \"\"\" \tåˆ†æ•°\tæ€§åˆ«\tå¹´çº§ 1å·\t53\tç”·\t1 2å·\t64\tå¥³\t2 3å·\t75\tç”·\t3 4å·\t86\tå¥³\t4 \"\"\" sr4 df['åˆ†æ•°'] \"\"\" 1å· 53 2å· 64 3å· 75 4å· 86 Name: åˆ†æ•°, dtype: int64 \"\"\" ``` ### åˆå¹¶ ```python v1 [10, 20, 30, 40] v2 [50, 60, 70] k1 ['a', 'b', 'c', 'd'] k2 ['e', 'e', 'f'] sr1 pd.Series(v1, index k1) sr2 pd.Series(v2, index k2) pd.concat([sr1, sr2]) \"\"\" a 10 b 20 c 30 d 40 e 50 e 60 f 70 dtype: int64 \"\"\" ``` > è¿™ä¸€ä¸ªå˜é‡çš„keyå¯ä»¥æ˜¯é‡å¤çš„, å‡ºç°é‡å¤çš„æ—¶å€™å¯ä»¥ä½¿ç”¨å±æ€§`.index`æˆ–`.columns`ä½¿ç”¨`.is_unique`æ£€æŸ¥ > > ```python > sr3.index.is_unique > ``` ### ä¸€ç»´äºŒç»´çš„åˆå¹¶ å¯ä»¥ç†è§£ä¸ºç»™äºŒç»´çš„å¯¹è±¡æ·»åŠ ä¸€ä¸ªè¡Œæˆ–è€…åˆ— ```python v1 [10, 20, 30] v2 ['ç”·', 'å¥³', 'ç”·'] sr1 pd.Series(v1, index ['a', 'b', 'c']) sr2 pd.Series(v2, index ['a', 'b', 'c']) df pd.DataFrame({'åˆ†æ•°': sr1, 'æ€§åˆ«': sr2}) # åŠ ä¸€åˆ— df['åå­—'] ['å¼ ä¸‰', 'æå››', 'ç‹äº”'] \"\"\" \tåˆ†æ•°\tæ€§åˆ«\tåå­— a\t10\tç”·\tå¼ ä¸‰ b\t20\tå¥³\tæå›› c\t30\tç”·\tç‹äº” \"\"\" # åŠ ä¸€åˆ— df.loc['4å·'] [40, 'å¥³', 'èµµå…­'] \"\"\" \tåˆ†æ•°\tæ€§åˆ«\tåå­— a\t10\tç”·\tå¼ ä¸‰ b\t20\tå¥³\tæå›› c\t30\tç”·\tç‹äº” 4å·\t40\tå¥³\tèµµå…­ \"\"\" ``` ```python v1 [[10, 'ç”·'], [20, 'å¥³'], [30, 'ç”·']] v2 [[1, 'å¼ ä¸‰'], [2, 'æå››'], [3, 'ç‹äº”']] v3 [[10, 'ç”·', 4, 'å¼ ä¸‰'], [20, 'å¥³', 5,'æå››'], [30, 'ç”·', 6, 'ç‹äº”']] i1 ['1å·', '2å·', '3å·'] i2 ['1å·', '2å·', '3å·'] i3 ['4å·', '5å·', '6å·'] c1 ['åˆ†æ•°', 'æ€§åˆ«'] c2 ['å¹´çº§', 'åå­—'] c3 ['åˆ†æ•°', 'æ€§åˆ«', 'å¹´çº§', 'åå­—'] df1 pd.DataFrame(v1, index i1, columns c1) df2 pd.DataFrame(v2, index i2, columns c2) df3 pd.DataFrame(v3, index i3, columns c3) \"\"\" åˆ†æ•° æ€§åˆ« 1å· 10 ç”· 2å· 20 å¥³ 3å· 30 ç”· å¹´çº§ åå­— 1å· 1 å¼ ä¸‰ 2å· 2 æå›› 3å· 3 ç‹äº” åˆ†æ•° æ€§åˆ« å¹´çº§ åå­— 7å· 10 ç”· 4 å¼ ä¸‰ 8å· 20 å¥³ 5 æå›› 9å· 30 ç”· 6 ç‹äº” \"\"\" df pd.concat([df1, df2], axis 1) \"\"\" \tåˆ†æ•°\tæ€§åˆ«\tå¹´çº§\tåå­— 1å·\t10\tç”·\t1\tå¼ ä¸‰ 2å·\t20\tå¥³\t2\tæå›› 3å·\t30\tç”·\t3\tç‹äº” \"\"\" df pd.concat([df, df3]) \"\"\" \tåˆ†æ•°\tæ€§åˆ«\tå¹´çº§\tåå­— 1å·\t10\tç”·\t1\tå¼ ä¸‰ 2å·\t20\tå¥³\t2\tæå›› 3å·\t30\tç”·\t3\tç‹äº” 4å·\t10\tç”·\t4\tå¼ ä¸‰ 5å·\t20\tå¥³\t5\tæå›› 6å·\t30\tç”·\t6\tç‹äº” \"\"\" ``` ## è¿ç®— ä¸€ç»´çš„å¯¹è±¡å¯ä»¥ç›´æ¥ä½¿ç”¨åŸºç¡€çš„è¿ç®—, å®é™…è¿›è¡Œå’Œæ•°ç»„æ˜¯ä¸€æ ·çš„, åœ¨å®é™…å¤„ç†çš„æ—¶å€™, å¦‚æœæ•°ç»„é‡Œé¢æœ‰å¤šç§ä¸åŒçš„ç±»å‹, ä¼šæŒ‰ç…§objectè¿›è¡Œå­˜å‚¨, ä½†æ˜¯æ¯ä¸€åˆ—çš„å­˜å‚¨æ˜¯ç‹¬ç«‹çš„, æ‰€ä»¥å¯ä»¥è¾¾åˆ°æ•°å€¼å’Œå­—ç¬¦ä¸²åŒæ—¶æˆç«‹çš„æ•ˆæœ ```python v1 [10, 20, 30] v2 ['ç”·', 'å¥³', 'ç”·'] sr1 pd.Series(v1, index ['a', 'b', 'c']) sr2 pd.Series(v2, index ['a', 'b', 'c']) df pd.DataFrame({'åˆ†æ•°': sr1, 'æ€§åˆ«': sr2}) df['åˆ†æ•°'].values, df.values \"\"\" array([10, 20, 30], dtype int64), array([[10, 'ç”·'], [20, 'å¥³'], [30, 'ç”·']], dtype object) \"\"\" ``` ä¸¤ä¸ªå¯¹è±¡ä¹‹é—´çš„è¿ç®—å¿…é¡»éƒ½æ˜¯æ•°å­—ç±»å‹ä¹‹é—´çš„è¿ç®—, ä¸¤ä¸ªå¯¹è±¡çš„ä¸ªæ•°å¯ä»¥ä¸åŒ ```python v1 [10, 20, 30, 40] k1 ['a', 'b', 'c', 'd'] sr1 pd.Series(v1, index k1) v2 [1, 2, 3] k2 ['a', 'b', 'c'] sr2 pd.Series(v2, index k2) \"\"\" a 10 b 20 c 30 d 40 dtype: int64, a 1 b 2 c 3 dtype: int64 \"\"\" sr1+sr2, sr1 sr2, sr1*sr2, sr1/sr2 \"\"\" a 11.0 b 22.0 c 33.0 d NaN dtype: float64, a 9.0 b 18.0 c 27.0 d NaN dtype: float64, a 10.0 b 40.0 c 90.0 d NaN dtype: float64, a 10.0 b 10.0 c 10.0 d NaN dtype: float64 \"\"\" ``` + äºŒç»´çš„è®¡ç®— ```python v1 [[10, 'ç”·'], [20, 'å¥³'], [30, 'ç”·'], [40, 'å¥³']] v2 [1, 2, 3, 6] i1 ['a', 'b', 'c', 'd'] i2 ['a', 'b', 'c', 'e'] c1 ['åˆ†æ•°', 'æ€§åˆ«'] c2 ['å¹´çº§'] df1 pd.DataFrame(v1, index i1, columns c1) df2 pd.DataFrame(v2, index i2, columns c2) \"\"\" åˆ†æ•° æ€§åˆ« a 10 ç”· b 20 å¥³ c 30 ç”· d 40 å¥³, å¹´çº§ a 1 b 2 c 3 e 6 \"\"\" df1['åŠ æ³•'] df1['åˆ†æ•°'] + df2['å¹´çº§'] df1['å‡æ³•'] df1['åˆ†æ•°'] df2['å¹´çº§'] df1['ä¹˜æ³•'] df1['åˆ†æ•°'] * df2['å¹´çº§'] df1['é™¤æ³•'] df1['åˆ†æ•°'] / df2['å¹´çº§'] \"\"\" \tåˆ†æ•°\tæ€§åˆ«\tåŠ æ³•\tå‡æ³•\tä¹˜æ³•\té™¤æ³• a\t10\tç”·\t11.0\t9.0\t10.0\t10.0 b\t20\tå¥³\t22.0\t18.0\t40.0\t10.0 c\t30\tç”·\t33.0\t27.0\t90.0\t10.0 d\t40\tå¥³\tNaN\tNaN\tNaN\tNaN \"\"\" ``` å¯ä»¥å¯¹æ¯ä¸€åˆ—ä½¿ç”¨`np.abs()`, `np.cos()`ä¹‹ç±»çš„å‡½æ•°, ä¼šä¿ç•™ç´¢å¼•, åŒæ—¶å¯ä»¥ä½¿ç”¨æ¯”è¾ƒç¬¦å·è·å–ä¸€ä¸ªboolçš„æ•°ç»„, å¯ä»¥ç”¨äºä½œä¸ºæ©ç  ```python v [[53, 'å¥³'], [64, 'ç”·'], [75, 'å¥³'], [86, 'ç”·']] i ['1å·', '2å·', '3å·', '4å·'] c ['åˆ†æ•°', 'æ€§åˆ«'] df pd.DataFrame(v, index i, columns c) df['åˆ†æ•°'] > 60 \"\"\" 1å· False 2å· True 3å· True 4å· True Name: åˆ†æ•°, dtype: bool \"\"\" (df['åˆ†æ•°'] > 30) & (df['åˆ†æ•°'] < 80) # å¯ä»¥ä½¿ç”¨sumå‡½æ•°è·å–æ€»æ•° \"\"\" 1å· True 2å· True 3å· True 4å· False Name: åˆ†æ•°, dtype: bool \"\"\" df[df['åˆ†æ•°'] > 60] \"\"\" \tåˆ†æ•°\tæ€§åˆ« 2å·\t64\tç”· 3å·\t75\tå¥³ 4å·\t86\tç”· \"\"\" df['æ€§åˆ«'][df['åˆ†æ•°'] > 60] \"\"\" 2å· ç”· 3å· å¥³ 4å· ç”· Name: æ€§åˆ«, dtype: object \"\"\" ``` ## ç¼ºå¤±å€¼ ### ä¸€ç»´ ```python v [53, None, 75, 86] i ['1å·', '2å·', '3å·', '4å·'] sr pd.Series(v, index i) \"\"\" 1å· 53.0 2å· NaN 3å· 75.0 4å· 86.0 dtype: float64 \"\"\" ``` å¯ä»¥ä½¿ç”¨å‡½æ•°`isnull()`è¿›è¡Œå¯»æ‰¾, ä¹Ÿå¯ä»¥ä½¿ç”¨`notnull()` ```python sr.isnull() \"\"\" 1å· False 2å· True 3å· False 4å· False dtype: bool \"\"\" ``` å¯ä»¥å¯¹ç¼ºå¤±çš„å€¼è¿›è¡Œå‰”é™¤, ä¸€ç»´çš„æ—¶å€™å¯ä»¥ç›´æ¥å‰”é™¤, äºŒç»´çš„æ—¶å€™éœ€è¦å†³å®šå‰”é™¤çš„æ˜¯è¡Œè¿˜æ˜¯åˆ—`dropna()`, ä½¿ç”¨å‚æ•°`axis 'cloumns'`å‰”é™¤åˆ—, å»ºè®®ä¸è¦ä½¿ç”¨, ä½¿ç”¨å‚æ•°`how 'all'`åªæœ‰æ‰€æœ‰çš„æ•°æ®éƒ½æ˜¯Nançš„æ—¶å€™å‰”é™¤, ä¹Ÿå¯ä»¥ä¼ å…¥ä¸€ä¸ªæ•°å­—, å¤§äºè¿™ä¸€ä¸ªé˜ˆå€¼çš„è¾“å‡ºåè¿›è¡Œå‰”é™¤ å¯ä»¥ä½¿ç”¨`fillna()`è¿›è¡Œå¡«å……, å®é™…ä½¿æ²¡æœ‰ç»Ÿä¸€çš„æ–¹æ³•, é‡Œé¢çš„å‚æ•°æ˜¯å¡«å……å€¼, å¯ä»¥ä½¿ç”¨`method 'ffill'`ä½¿ç”¨å‰ä¸€ä¸ªæ•°å­—è¿›è¡Œå¡«å……, ä»¥åŠä½¿ç”¨`method 'bfill'`è¿›è¡Œå¡«å…… ### äºŒç»´ ```python v [[None, 1], [64, None], [75, 3], [86, 4]] i ['1å·', '2å·', '3å·', '4å·'] c ['åˆ†æ•°', 'å¹´çº§'] df pd.DataFrame(v, index i, columns c) \"\"\" \tåˆ†æ•°\tå¹´çº§ 1å·\tNaN\t1.0 2å·\t64.0\tNaN 3å·\t75.0\t3.0 4å·\t86.0\t4.0 \"\"\" df.isnull() ``` ## å¯¼å…¥Excel ç¬¬ä¸€åˆ—æ˜¯index, ç¬¬ä¸€è¡Œæ˜¯columns, å¦‚æœæ²¡æœ‰è¿™ä¸¤ä¸ª, åªæƒ³ä½¿ç”¨ä¸€ä¸ªæ•°ç»„, ä¹ŸåŠ ä¸Šè¿™ä¸¤åˆ—, ä¹‹åä½¿ç”¨`.values`å±æ€§å¯ä»¥è·å–å®é™…çš„æ•°æ®, å­˜ä¸ºcsvæ–‡ä»¶ ```python df pd.read_csv('../data/house_thiny.csv', index_col 0) ``` å¯ä»¥ä½¿ç”¨å‡½æ•°`.head(n)`æŸ¥çœ‹å‰nè¡Œ numPyçš„æ‰€æœ‰èšåˆå‡½æ•°å¯¹è¿™ä¸€ä¸ªéƒ½é€‚ç”¨, å¯ä»¥ç›´æ¥`.`å³å¯ä½¿ç”¨, æ¯”å¦‚`.max() .mean()`è¿™ä¸€éƒ¨åˆ†çš„æ–¹æ³•åœ¨ä½¿ç”¨çš„æ—¶å€™é»˜è®¤çœç•¥ç¼ºå¤±å€¼ > å¯ä»¥ä½¿ç”¨`.describe()`æŸ¥çœ‹æ‰€æœ‰çš„èšåˆå‡½æ•°çš„ä¿¡æ¯ > > ```python > df.describe() > \"\"\" > > \tNumberRoom\tPrice > count\t5.000000\t7.000000 > mean\t4.600000\t343.285714 > std\t2.073644\t168.993801 > min\t2.000000\t120.000000 > 25%\t3.000000\t226.500000 > 50%\t5.000000\t330.000000 > 75%\t6.000000\t450.000000 > max\t7.000000\t600.000000\t > \"\"\" > ``` ### æ•°æ®é€è§† ä½¿ç”¨`.pivot_table('', index '', columns '')`å¯ä»¥æŸ¥çœ‹ç¬¬äºŒä¸ªé¡¹å¯¹äºç¬¬ä¸€ä¸ªçš„å½±å“, é»˜è®¤ä½¿ç”¨çš„æ˜¯meanæ±‚å‡å€¼, è·å–indexé‡Œé¢æ¯ä¸€ä¸ªå±æ€§çš„å®é™…å‡å€¼, ä½¿ç”¨aggfuncå¯ä»¥æ”¹å˜é»˜è®¤çš„å‡½æ•°, é»˜è®¤`mean` å¦‚æœä¸€ä¸ªæ•°æ®çš„åˆ†ç±»å¾ˆå¤šä¸ä¾¿äºè§‚çœ‹å¯ä»¥ä½¿ç”¨`pd.cut()`ä»¥åŠ`pd.qcut(n)`è¿›è¡Œåˆ†ç±», å‰ä¸€ä¸ªæ‰‹åŠ¨çš„, ç¬¬äºŒä¸ªè‡ªåŠ¨çš„æŠŠæ•°æ®åˆ†ä¸ºnä¸ª ```python pd.cut(df['å¹´é¾„'], [0, 25, 120]) df.pivot_table('æ˜¯å¦ç”Ÿè¿˜', index [age, 'æ€§åˆ«'], columns 'èˆ¹èˆ±ç­‰çº§') ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-14-17VGG.html":{"title":"ä½¿ç”¨å—çš„ç½‘ç»œVGG","content":"# ä½¿ç”¨å—çš„ç½‘ç»œVGG æ¨¡å‹çš„æ·±åº¦æ›´å¤š, å¦‚ä½•é€‰æ‹©æ–°çš„å±‚ ç»å…¸å·ç§¯ç¥ç»ç½‘ç»œçš„åŸºæœ¬ç»„æˆéƒ¨åˆ†æ˜¯ä¸‹é¢çš„è¿™ä¸ªåºåˆ—ï¼š 1. å¸¦å¡«å……ä»¥ä¿æŒåˆ†è¾¨ç‡çš„å·ç§¯å±‚ï¼› 2. éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œå¦‚ReLUï¼› 3. æ±‡èšå±‚ï¼Œå¦‚æœ€å¤§æ±‡èšå±‚ã€‚ è€Œä¸€ä¸ªVGGå—ä¸ä¹‹ç±»ä¼¼ï¼Œç”±ä¸€ç³»åˆ—å·ç§¯å±‚ç»„æˆï¼Œåé¢å†åŠ ä¸Šç”¨äºç©ºé—´ä¸‹é‡‡æ ·çš„æœ€å¤§æ±‡èšå±‚ã€‚ ![image 20250114145057288](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141450380.png) > åŒæ ·çš„è®¡ç®—é‡çš„æ—¶å€™, å †å èµ·æ¥çš„3x3æ¯”5x5å¥½, å¤šä¸ªVGGå—è¿æ¥ä»¥åæ¥å…¨è¿æ¥å±‚ > > ä¸åŒæ¬¡æ•°çš„VGGå—å¯ä»¥å¾—åˆ°ä¸åŒçš„æ¶æ„VGG 16, VGG 19 ![image 20250114145439195](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141454252.png) å…¶ä¸­æœ‰è¶…å‚æ•°å˜é‡`conv_arch`ã€‚è¯¥å˜é‡æŒ‡å®šäº†æ¯ä¸ªVGGå—é‡Œå·ç§¯å±‚ä¸ªæ•°å’Œè¾“å‡ºé€šé“æ•°ã€‚ VGG 11ä½¿ç”¨å¯å¤ç”¨çš„å·ç§¯å—æ„é€ ç½‘ç»œã€‚ä¸åŒçš„VGGæ¨¡å‹å¯é€šè¿‡æ¯ä¸ªå—ä¸­å·ç§¯å±‚æ•°é‡å’Œè¾“å‡ºé€šé“æ•°é‡çš„å·®å¼‚æ¥å®šä¹‰ã€‚ å—çš„ä½¿ç”¨å¯¼è‡´ç½‘ç»œå®šä¹‰çš„éå¸¸ç®€æ´ã€‚ä½¿ç”¨å—å¯ä»¥æœ‰æ•ˆåœ°è®¾è®¡å¤æ‚çš„ç½‘ç»œã€‚ åœ¨VGGè®ºæ–‡ä¸­ï¼ŒSimonyanå’ŒZisermanå°è¯•äº†å„ç§æ¶æ„ã€‚ç‰¹åˆ«æ˜¯ä»–ä»¬å‘ç°æ·±å±‚ä¸”çª„çš„å·ç§¯ï¼ˆå³3Ã—3ï¼‰æ¯”è¾ƒæµ…å±‚ä¸”å®½çš„å·ç§¯æ›´æœ‰æ•ˆã€‚ ## ä»£ç å®ç° + å®ç°VGGå— ```python import torch from torch import nn from d2l import torch as d2l def vgg_block(num_convs, in_channels, out_channels): \"\"\"vggå—çš„å®ç° num_convs : å—çš„å·ç§¯å±‚æ•° in_channels : å—çš„è¾“å…¥é€šé“æ•° out_channels : å—çš„è¾“å‡ºé€šé“æ•° \"\"\" layers [] for _ in range(num_convs): layers.append(nn.Conv2d(in_channels, out_channels, kernel_size 3, padding 1)) layers.append(nn.ReLU()) in_channels out_channels # ä¸‹ä¸€ä¸ªå·ç§¯å±‚çš„è¾“å…¥é€šé“æ•°, åœ¨ç¬¬ä¸€æ¬¡å¾ªç¯åå°±æ˜¯out_channels layers.append(nn.MaxPool2d(kernel_size 2, stride 2)) # æ¯ä¸ªå—çš„æœ€åæ·»åŠ ä¸€ä¸ªæœ€å¤§æ± åŒ–å±‚ return nn.Sequential(*layers) ``` + å®ç°ä¸€ä¸ªVGG11, åœ¨æ¯ä¸€å±‚çš„é€šé“ç¿»å€, é•¿å®½å‡åŠ ```python conv_arch ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512)) # 5ä¸ªå—, æ¯ä¸ªå—çš„å·ç§¯å±‚æ•°å’Œè¾“å‡ºé€šé“æ•° # VGG 11, å¯ä»¥å¤„ç†224x224çš„å›¾åƒ def vgg(conv_arch): conv_blks [] in_channels 1 # è¾“å…¥é€šé“æ•° for (num_convs, out_channels) in conv_arch: conv_blks.append(vgg_block(num_convs, in_channels, out_channels)) in_channels out_channels # ä¸‹ä¸€ä¸ªå—çš„è¾“å…¥é€šé“æ•° return nn.Sequential( *conv_blks, nn.Flatten(), nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 10) ) ``` + çœ‹ä¸€ä¸‹å®ç°çš„ç»“æœ ```python X torch.randn(1, 1, 224, 224) net vgg(conv_arch) for layer in net: X layer(X) print(layer.__class__.__name__, 'output shape:\\t', X.shape) \"\"\" Sequential output shape:\t torch.Size([1, 64, 112, 112]) Sequential output shape:\t torch.Size([1, 128, 56, 56]) Sequential output shape:\t torch.Size([1, 256, 28, 28]) Sequential output shape:\t torch.Size([1, 512, 14, 14]) Sequential output shape:\t torch.Size([1, 512, 7, 7]) Flatten output shape:\t torch.Size([1, 25088]) Linear output shape:\t torch.Size([1, 4096]) ReLU output shape:\t torch.Size([1, 4096]) Dropout output shape:\t torch.Size([1, 4096]) Linear output shape:\t torch.Size([1, 4096]) ReLU output shape:\t torch.Size([1, 4096]) Dropout output shape:\t torch.Size([1, 4096]) Linear output shape:\t torch.Size([1, 10]) \"\"\" ``` + å®é™…çš„ä½¿ç”¨ ```python lr, num_epochs, batch_size 0.05, 10, 128 train_iter, test_iter d2l.load_data_fashion_mnist(batch_size, resize 224) d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) ``` ![image 20250114153853446](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141538632.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-13-41æ³¨æ„åŠ›seq2seq.html":{"title":"æ³¨æ„åŠ›æœºåˆ¶Seq2Seq","content":"# æ³¨æ„åŠ›æœºåˆ¶Seq2Seq Bahdanauæ³¨æ„åŠ› [ã€è®ºæ–‡è§£è¯»ã€‘Bahdanau Attention çŸ¥ä¹](https://zhuanlan.zhihu.com/p/272662664) å¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨å°†é•¿åº¦å¯å˜çš„åºåˆ—è½¬æ¢ä¸ºå›ºå®šå½¢çŠ¶çš„ä¸Šä¸‹æ–‡å˜é‡ï¼Œç„¶åå¾ªç¯ç¥ç»ç½‘ç»œ è§£ç å™¨æ ¹æ®ç”Ÿæˆçš„è¯å…ƒå’Œä¸Šä¸‹æ–‡å˜é‡æŒ‰è¯å…ƒç”Ÿæˆè¾“å‡ºï¼ˆç›®æ ‡ï¼‰åºåˆ—è¯å…ƒã€‚ç„¶è€Œï¼Œå³ä½¿å¹¶éæ‰€æœ‰è¾“å…¥ï¼ˆæºï¼‰è¯ å…ƒéƒ½å¯¹è§£ç æŸä¸ªè¯å…ƒéƒ½æœ‰ç”¨ æœºå™¨ç¿»è¯‘ä¸ªæ—¶å€™, ä¸åŒçš„ç”Ÿæˆçš„è¯è¯­æ¥æºäºä¸åŒçš„è¯, ä½†æ˜¯seq2seqä¼ è¿‡å»çš„è¯è¯­æ˜¯æœ€åä¸€ä¸ªè¯è¯­è®¡ç®—ä»¥åå¾—çŠ¶æ€ ä¸Šä¸‹æ–‡å˜é‡cåœ¨ä»»ä½•è§£ç æ—¶é—´æ­¥tâ€²éƒ½ä¼šè¢«ctâ€²æ›¿æ¢ ![image 20250213152919308](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502131529353.png) ![image 20250213151825288](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502131518717.png) æŠŠç¼–ç å™¨çš„è¾“å‡ºä½œä¸ºkeyå’Œvalue, è§£ç å™¨çš„ä¸Šä¸€ä¸ªè¾“å‡ºæ˜¯query, æ³¨æ„åŠ›çš„è¾“å‡ºå’Œä¸‹ä¸€ä¸ªè¯åµŒå…¥åˆå¹¶è¿›å…¥RNN ## ä»£ç å®ç° ```python import torch from torch import nn from d2l import torch as d2l ``` ```python #@save class AttentionDecoder(d2l.Decoder): \"\"\"å¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶è§£ç å™¨çš„åŸºæœ¬æ¥å£\"\"\" def __init__(self, **kwargs): super(AttentionDecoder, self).__init__(**kwargs) @property def attention_weights(self): raise NotImplementedError ``` > åœ¨è¿™é‡Œé¢ä¼šè®°å½•æ¯ä¸€æ­¥çš„attention_weights, å¯ä»¥ä½¿ç”¨è¿™ä¸ªå‡½æ•°è¿›è¡Œè¿”å› å®é™…çš„ä»£ç å®ç°, åœ¨é‡Œé¢åŠ å…¥ä¸€å±‚attentionå±‚, ä½¿ç”¨è¿™ä¸€å±‚å¤„ç†ä¸€ä¸‹encoderçš„è¾“å‡ºå’Œæ–°è¿›æ¥çš„æ•°æ® encodeçš„æ—¶å€™ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ¯ä¸€æ¬¡è®°å½•å¤„ç†çš„å½“å‰çŠ¶æ€, ç¬¬äºŒä¸ªè¾“å‡ºæ˜¯æœ€åé¢çš„çŠ¶æ€ å®é™…ä½¿ç”¨çš„æ—¶å€™æ³¨æ„åŠ›è·å–çš„ä¿¡æ¯æ˜¯ä½œä¸ºGRUçš„è¾“å…¥å‚æ•°è¿›è¡Œä¼ é€’çš„, ä¸æ˜¯ç›´æ¥ä½œç”¨äºæ•°æ® > æ¯ä¸ªè§£ç æ—¶é—´æ­¥éª¤ä¸­ï¼Œè§£ç å™¨ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„æœ€ç»ˆå±‚éšçŠ¶æ€å°†ç”¨ä½œæŸ¥è¯¢ã€‚å› æ­¤ï¼Œæ³¨æ„åŠ›è¾“å‡ºå’Œè¾“å…¥åµŒå…¥éƒ½ è¿ç»“ä¸ºå¾ªç¯ç¥ç»ç½‘ç»œè§£ç å™¨çš„è¾“å…¥ã€‚ ```python class Seq2SeqAttentionDecoder(AttentionDecoder): def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout 0, **kwargs): super(Seq2SeqAttentionDecoder, self).__init__(**kwargs) # åŠ å…¥ä¸€ä¸ªåµŒå…¥å±‚ self.attention d2l.AdditiveAttention( num_hiddens, num_hiddens, num_hiddens, dropout) self.embedding nn.Embedding(vocab_size, embed_size) self.rnn nn.GRU( embed_size + num_hiddens, num_hiddens, num_layers, dropout dropout) self.dense nn.Linear(num_hiddens, vocab_size) def init_state(self, enc_outputs, enc_valid_lens, *args): # outputsçš„å½¢çŠ¶ä¸º(batch_sizeï¼Œnum_stepsï¼Œnum_hiddens). # hidden_stateçš„å½¢çŠ¶ä¸º(num_layersï¼Œbatch_sizeï¼Œnum_hiddens) outputs, hidden_state enc_outputs return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens) def forward(self, X, state): # enc_outputsçš„å½¢çŠ¶ä¸º(batch_size,num_steps,num_hiddens). # hidden_stateçš„å½¢çŠ¶ä¸º(num_layers,batch_size,num_hiddens) enc_outputs, hidden_state, enc_valid_lens state # è¾“å‡ºXçš„å½¢çŠ¶ä¸º(num_steps,batch_size,embed_size) X self.embedding(X).permute(1, 0, 2) outputs, self._attention_weights [], [] for x in X: # xçš„å½¢çŠ¶ä¸º(batch_size,embed_size) # æ¯æ¬¡æå–å‡ºæ¥ä¸€ä¸ªæ—¶é—´æ­¥çš„è¯å‘é‡ä½œä¸ºè¾“å…¥ # queryçš„å½¢çŠ¶ä¸º(batch_size,1,num_hiddens) query torch.unsqueeze(hidden_state[ 1], dim 1) # contextçš„å½¢çŠ¶ä¸º(batch_size, æŸ¥è¯¢çš„ä¸ªæ•° 1, å€¼çš„ç»´åº¦), è¿™é‡Œçš„keyå’Œvalueæ˜¯ä¸€æ ·çš„ context self.attention( query, enc_outputs, enc_outputs, enc_valid_lens) # åœ¨ç‰¹å¾ç»´åº¦ä¸Šè¿ç»“, è¾“å‡ºæ˜¯(batch_size,1,num_hiddens+embed_size) x torch.cat((context, torch.unsqueeze(x, dim 1)), dim 1) # å°†xå˜å½¢ä¸º(1,batch_size,embed_size+num_hiddens) out, hidden_state self.rnn(x.permute(1, 0, 2), hidden_state) outputs.append(out) self._attention_weights.append(self.attention.attention_weights) # å…¨è¿æ¥å±‚å˜æ¢åï¼Œoutputsçš„å½¢çŠ¶ä¸º # (num_steps,batch_size,vocab_size) outputs self.dense(torch.cat(outputs, dim 0)) return outputs.permute(1, 0, 2), [enc_outputs, hidden_state, enc_valid_lens] @property def attention_weights(self): return self._attention_weights ``` æµ‹è¯•ä¸€ä¸‹ç»“æœ ```python encoder d2l.Seq2SeqEncoder(vocab_size 10, embed_size 8, num_hiddens 16, num_layers 2) encoder.eval() decoder Seq2SeqAttentionDecoder(vocab_size 10, embed_size 8, num_hiddens 16, num_layers 2) decoder.eval() X torch.zeros((4, 7), dtype torch.long) # (batch_size,num_steps) state decoder.init_state(encoder(X), None) output, state decoder(X, state) # è¾“å‡ºçš„å½¢çŠ¶ä¸º(num_steps,batch_size,vocab_size) # éšè—çŠ¶æ€status[1]çš„å½¢çŠ¶æ˜¯(num_layers,batch_size,num_hiddens) (2, 4, 16) # encoderçš„æƒé‡æ˜¯ä¸€ä¸ªé•¿åº¦ä¸ºbatch_sizeçš„åˆ—è¡¨ï¼Œæ¯ä¸€ä¸ªå…ƒç´ æ˜¯(num_step ,num_hidden)(7, 16) output.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape \"\"\" (torch.Size([4, 7, 10]), 3, torch.Size([4, 7, 16]), 2, torch.Size([4, 16])) \"\"\" ``` å¼€å§‹è®­ç»ƒ ```python embed_size, num_hiddens, num_layers, dropout 32, 32, 2, 0.1 batch_size, num_steps 64, 10 lr, num_epochs, device 0.005, 250, d2l.try_gpu() train_iter, src_vocab, tgt_vocab d2l.load_data_nmt(batch_size, num_steps) encoder d2l.Seq2SeqEncoder( len(src_vocab), embed_size, num_hiddens, num_layers, dropout) decoder Seq2SeqAttentionDecoder( len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout) net d2l.EncoderDecoder(encoder, decoder) d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device) ``` ![image 20250215121020855](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151210089.png) æµ‹è¯•ç»“æœ ```python engs ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .'] fras ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .'] for eng, fra in zip(engs, fras): translation, dec_attention_weight_seq d2l.predict_seq2seq( net, eng, src_vocab, tgt_vocab, num_steps, device, True) print(f'{eng} > {translation}, ', f'bleu {d2l.bleu(translation, fra, k 2):.3f}') \"\"\" go . > va !, bleu 1.000 i lost . > j'ai perdu ., bleu 1.000 he's calm . > il est paresseux ., bleu 0.658 i'm home . > je suis chez moi ., bleu 1.000 \"\"\" ``` ```python attention_weights torch.cat([step[0][0][0] for step in dec_attention_weight_seq], 0).reshape(( 1, 1, 1, num_steps)) # åŠ ä¸Šä¸€ä¸ªåŒ…å«åºåˆ—ç»“æŸè¯å…ƒ d2l.show_heatmaps( attention_weights[:, :, :, :len(engs[ 1].split()) + 1].cpu(), xlabel 'Key positions', ylabel 'Query positions') ``` ![image 20250215122205839](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151222913.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-14-18NiN.html":{"title":"NiNç½‘ç»œä¸­çš„ç½‘ç»œ","content":"# NiNç½‘ç»œä¸­çš„ç½‘ç»œ **å®é™…ä½¿ç”¨æ¯”è¾ƒå°‘** å·ç§¯å±‚ä½¿ç”¨çš„å‚æ•°æ¯”è¾ƒå°‘c~i~ x c~o~ x k^2^, ä½†æ˜¯å·ç§¯å±‚åé¢çš„ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚å‚æ•°æ˜¯å…¨éƒ¨çš„é€šé“ä¹˜é•¿å’Œå®½åœ¨ä¹˜ä¸€ä¸ªè¾“å‡ºçš„ç»´åº¦, è¿™ä¸€ä¸ªæ•°å€¼éå¸¸å¤§ + LetNet 48K + AlexNet 256\\*5\\*5\\*4096 26M + VGG 512\\*7\\*7\\*4096 102M æ‰€ä»¥éœ€è¦æƒ³åŠæ³•æ›¿ä»£ä¸€ä¸‹ ## NiNå— ä¸€ä¸ªå·ç§¯åé¢æœ‰ä¸¤ä¸ªå…¨è¿æ¥å±‚ä½¿ç”¨æ­¥å¹…ä¸º1, æ— å¡«å……, è¾“å‡ºçš„å½¢çŠ¶å’Œå·ç§¯æ˜¯ç›¸åŒçš„1x1å·ç§¯ èµ·åˆ°ä¸€ä¸ªå…¨è¿æ¥çš„ä½œç”¨ ![image 20250114154247207](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141542318.png) > è¿™ä¸¤ä¸ª1Ã—1å·ç§¯å±‚å……å½“å¸¦æœ‰ReLUæ¿€æ´»å‡½æ•°çš„é€åƒç´ å…¨è¿æ¥å±‚, ç¬¬ä¸€å±‚çš„å·ç§¯çª—å£å½¢çŠ¶é€šå¸¸ç”±ç”¨æˆ·è®¾ç½®ã€‚ éšåçš„å·ç§¯çª—å£å½¢çŠ¶å›ºå®šä¸º1Ã—1ã€‚ ![image 20250114154327323](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141543371.png) å®é™…ä½¿ç”¨çš„æ—¶å€™äº¤æ›¿ä½¿ç”¨NiNå—ä»¥åŠæ­¥å¹…ä¸º2çš„æœ€å¤§æ± åŒ–å±‚é€æ­¥å‡å°é«˜å’Œå®½ä»¥åŠå¢å¤§é€šé“æ•°, æœ€åä½¿ç”¨å…¨å±€å¹³å‡æ± åŒ–å¾—åˆ°è¾“å‡º ![image 20250114154707656](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141547719.png) NiNä½¿ç”¨ç”±ä¸€ä¸ªå·ç§¯å±‚å’Œå¤šä¸ª1Ã—1å·ç§¯å±‚ç»„æˆçš„å—ã€‚è¯¥å—å¯ä»¥åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨ï¼Œä»¥å…è®¸æ›´å¤šçš„æ¯åƒç´ éçº¿æ€§ã€‚ NiNå»é™¤äº†å®¹æ˜“é€ æˆè¿‡æ‹Ÿåˆçš„å…¨è¿æ¥å±‚ï¼Œå°†å®ƒä»¬æ›¿æ¢ä¸ºå…¨å±€å¹³å‡æ±‡èšå±‚ï¼ˆå³åœ¨æ‰€æœ‰ä½ç½®ä¸Šè¿›è¡Œæ±‚å’Œï¼‰ã€‚è¯¥æ±‡èšå±‚é€šé“æ•°é‡ä¸ºæ‰€éœ€çš„è¾“å‡ºæ•°é‡ï¼ˆä¾‹å¦‚ï¼ŒFashion MNISTçš„è¾“å‡ºä¸º10ï¼‰ã€‚ ç§»é™¤å…¨è¿æ¥å±‚å¯å‡å°‘è¿‡æ‹Ÿåˆï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘NiNçš„å‚æ•°ã€‚ NiNçš„è®¾è®¡å½±å“äº†è®¸å¤šåç»­å·ç§¯ç¥ç»ç½‘ç»œçš„è®¾è®¡ã€‚ ## å®é™…å®ç° ```python import torch from torch import nn from d2l import torch as d2l def nin_block(in_channels, out_channels, kernel_size, strides, padding): return nn.Sequential( nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size 1), nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size 1), nn.ReLU() ) ``` ```python net nn.Sequential( nin_block(1, 96, kernel_size 11, strides 4, padding 0), nn.MaxPool2d(3, stride 2), nin_block(96, 256, kernel_size 5, strides 1, padding 2), nn.MaxPool2d(3, stride 2), nin_block(256, 384, kernel_size 3, strides 1, padding 1), nn.MaxPool2d(3, stride 2), nn.Dropout(0.5), nin_block(384, 10, kernel_size 3, strides 1, padding 1), nn.AdaptiveAvgPool2d((1, 1)), # ä¸€ä¸ªæŒ‡å®šè¾“å‡ºå¤§å°çš„å…¨å±€å¹³å‡æ± åŒ–å±‚ nn.Flatten() ) ``` + çœ‹ä¸€ä¸‹å½¢çŠ¶ ```python X torch.rand(size (1, 1, 224, 224)) for layer in net: X layer(X) print(layer.__class__.__name__, 'output shape:\\t', X.shape) \"\"\" Sequential output shape:\t torch.Size([1, 96, 54, 54]) MaxPool2d output shape:\t torch.Size([1, 96, 26, 26]) Sequential output shape:\t torch.Size([1, 256, 26, 26]) MaxPool2d output shape:\t torch.Size([1, 256, 12, 12]) Sequential output shape:\t torch.Size([1, 384, 12, 12]) MaxPool2d output shape:\t torch.Size([1, 384, 5, 5]) Dropout output shape:\t torch.Size([1, 384, 5, 5]) Sequential output shape:\t torch.Size([1, 10, 5, 5]) AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1]) Flatten output shape:\t torch.Size([1, 10]) \"\"\" ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-11-40æ³¨æ„åŠ›æœºåˆ¶.html":{"title":"Attention","content":"# Attention å¹¶éæ‰€æœ‰åˆºæ¿€çš„å½±å“éƒ½æ˜¯ç›¸ç­‰çš„ã€‚æ„è¯†çš„èšé›†å’Œä¸“æ³¨ä½¿çµé•¿ç±»åŠ¨ç‰©èƒ½å¤Ÿåœ¨å¤æ‚çš„è§†è§‰ç¯å¢ƒä¸­å°†æ³¨æ„åŠ›å¼•å‘æ„Ÿ å…´è¶£çš„ç‰©ä½“ï¼Œä¾‹å¦‚çŒç‰©å’Œå¤©æ•Œã€‚ å·ç§¯, å…¨è¿æ¥å’Œæ± åŒ–è€ƒè™‘çš„éƒ½æ˜¯ä¸éšæ„çš„çº¿ç´¢ + éšæ„çš„çº¿ç´¢ç§°ä¹‹ä¸ºæŸ¥è¯¢(query) æˆ‘ + æ¯ä¸ªè¾“å…¥æ˜¯ä¸€ä¸ªå€¼(value)å’Œä¸éšæ„çš„çº¿ç´¢(key)çš„å¯¹ è¢«æŸ¥çš„å¯¹è±¡ + é€šè¿‡æ³¨æ„åŠ›æ± åŒ–å±‚æœ‰åå‘çš„é€‰æ‹©ä¸€éƒ¨åˆ†è¾“å…¥ é€šè¿‡query(éšæ„çº¿ç´¢)å’Œkey(ä¸éšæ„çº¿ç´¢)æœ‰åå‘çš„è¿›è¡Œé€‰æ‹©(è®¡ç®—ä¸åŒæ•°æ®æ³•çš„é‡è¦åº¦, Qå’ŒVçš„è®¡ç®—ä¸€èˆ¬ä½¿ç”¨çš„æ˜¯ç‚¹ä¹˜, è·å–Qå’Œæ¯ä¸€ä¸ªKçš„ç›¸ä¼¼åº¦) ![image 20250211154357334](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111543382.png) > æ³¨æ„åŠ›æœºåˆ¶é€šè¿‡æ³¨æ„åŠ›æ±‡èšå°†æŸ¥è¯¢ï¼ˆè‡ªä¸»æ€§æç¤ºï¼‰å’Œé”®ï¼ˆéè‡ªä¸»æ€§æç¤ºï¼‰ç»“åˆåœ¨ä¸€èµ·ï¼Œå®ç°å¯¹å€¼ï¼ˆæ„Ÿå®˜è¾“å…¥ï¼‰çš„é€‰æ‹©å€¾å‘ ## éå‚æ³¨æ„åŠ›æ± åŒ–å±‚ ç»™å®šä¸€ç³»åˆ—å‚æ•°, æœ€ç®€å•çš„æ˜¯å¹³å‡æ± åŒ–, ä½†æ˜¯æ›´å¥½çš„æ˜¯Nadaraya Watsonæ ¸å›å½’ ![image 20250211155915168](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111559226.png) å¦‚æœä¸€ä¸ªé”®xiè¶Šæ˜¯æ¥è¿‘ç»™å®šçš„æŸ¥è¯¢xï¼Œé‚£ä¹ˆåˆ†é…ç»™è¿™ä¸ªé”®å¯¹åº”å€¼yiçš„æ³¨æ„åŠ›æƒé‡å°±ä¼šè¶Šå¤§ï¼Œä¹Ÿ å°±â€œè·å¾—äº†æ›´å¤šçš„æ³¨æ„åŠ›â€ ![image 20250211160109731](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111601789.png) åœ¨ä¹‹å‰çš„å‡½æ•°é‡ŒåŠ å…¥ä¸€ä¸ªå¯ä»¥å­¦ä¹ çš„å‚æ•° ![image 20250211160253179](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111602225.png) ### ä»£ç å®ç° ```python import torch from torch import nn from d2l import torch as d2l ``` åˆå§‹åŒ–ä¸€ä¸ªè®­ç»ƒçš„æ•°æ®æ ·æœ¬ ```python n_train 50 # è®­ç»ƒæ ·æœ¬æ•° x_train, _ torch.sort(torch.rand(n_train) * 5) # æ’åºåçš„è®­ç»ƒæ ·æœ¬ def f(x): return 2 * torch.sin(x) + x**0.8 y_train f(x_train) + torch.normal(0.0, 0.5, (n_train,)) # è®­ç»ƒæ ·æœ¬çš„è¾“å‡º x_test torch.arange(0, 5, 0.1) # æµ‹è¯•æ ·æœ¬ y_truth f(x_test) # æµ‹è¯•æ ·æœ¬çš„çœŸå®è¾“å‡º n_test len(x_test) # æµ‹è¯•æ ·æœ¬æ•° n_test \"\"\" 50 \"\"\" ``` å¦‚æœä½¿ç”¨çš„æ˜¯å¹³å‡çš„è®¡ç®—æ–¹å¼ ```python def plot_kernel_reg(y_hat): d2l.plot(x_test, [y_truth, y_hat], 'x', 'y', legend ['Truth', 'Pred'], xlim [0, 5], ylim [ 1, 5]) d2l.plt.plot(x_train, y_train, 'o', alpha 0.5) y_hat torch.repeat_interleave(y_train.mean(), n_test) # å¹³å‡é¢„æµ‹ plot_kernel_reg(y_hat) ``` ![image 20250211162021432](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111620484.png) > åå·®è¿˜æ˜¯æ¯”è¾ƒå¤§çš„ ```python # X_repeatçš„å½¢çŠ¶:(n_test,n_train), # æ¯ä¸€è¡Œéƒ½åŒ…å«ç€ç›¸åŒçš„æµ‹è¯•è¾“å…¥ï¼ˆä¾‹å¦‚ï¼šåŒæ ·çš„æŸ¥è¯¢ï¼‰ X_repeat x_test.repeat_interleave(n_train).reshape(( 1, n_train)) # x_trainåŒ…å«ç€é”®ã€‚attention_weightsçš„å½¢çŠ¶ï¼š(n_test,n_train), # æ¯ä¸€è¡Œéƒ½åŒ…å«ç€è¦åœ¨ç»™å®šçš„æ¯ä¸ªæŸ¥è¯¢çš„å€¼ï¼ˆy_trainï¼‰ä¹‹é—´åˆ†é…çš„æ³¨æ„åŠ›æƒé‡ attention_weights nn.functional.softmax( (X_repeat x_train)**2 / 2, dim 1) # y_hatçš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯å€¼çš„åŠ æƒå¹³å‡å€¼ï¼Œå…¶ä¸­çš„æƒé‡æ˜¯æ³¨æ„åŠ›æƒé‡ y_hat torch.matmul(attention_weights, y_train) plot_kernel_reg(y_hat) ``` ![image 20250211162047267](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111620357.png) è¿™æ ·çœ‹èµ·æ¥å¥½å¾ˆå¤šäº†, ç†è®ºä¸Šæ•°æ®å±‚ è¶³å¤Ÿçš„å¯ä»¥å®Œå…¨æ‹Ÿåˆ ```python d2l.show_heatmaps(attention_weights.unsqueeze(0).unsqueeze(0), xlabel 'Sorted training inputs', ylabel 'Sorted testing inputs') ``` ![image 20250211162158380](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111621449.png) çœ‹ä¸€ä¸‹æƒé‡åˆ†å¸ƒ, è¿™é‡Œæµ‹è¯•æ•°æ®çš„è¾“å…¥ç›¸å½“äºæŸ¥è¯¢ï¼Œè€Œè®­ç»ƒæ•°æ®çš„è¾“å…¥ç›¸å½“äºé”®ã€‚å› ä¸ºä¸¤ä¸ªè¾“å…¥éƒ½ æ˜¯ç»è¿‡æ’åºçš„ï¼Œå› æ­¤ç”±è§‚å¯Ÿå¯çŸ¥â€œæŸ¥è¯¢â€é”®â€å¯¹è¶Šæ¥è¿‘ï¼Œæ³¨æ„åŠ›æ±‡èšçš„æ³¨æ„åŠ›æƒé‡å°±è¶Šé«˜ + åŠ å…¥å‚æ•° ![image 20250211162436721](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111624775.png) ä¸ºäº†æ›´æœ‰æ•ˆåœ°è®¡ç®—å°æ‰¹é‡æ•°æ®çš„æ³¨æ„åŠ›ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨æ·±åº¦å­¦ä¹ å¼€å‘æ¡†æ¶ä¸­æä¾›çš„æ‰¹é‡çŸ©é˜µä¹˜æ³• ```python X torch.ones((2, 1, 4)) Y torch.ones((2, 4, 6)) torch.bmm(X, Y).shape \"\"\" torch.Size([2, 1, 6]) \"\"\" ``` å®é™…ä½¿ç”¨å¯ä»¥é€šè¿‡å¢åŠ ä¸€ä¸ªç»´åº¦çš„æ–¹å¼å®ç° ```python weights torch.ones((2, 10)) * 0.1 values torch.arange(20.0).reshape((2, 10)) torch.bmm(weights.unsqueeze(1), values.unsqueeze( 1)), weights.unsqueeze(1).shape, values.unsqueeze( 1).shape \"\"\" (tensor([[[ 4.5000]], [[14.5000]]]), torch.Size([2, 1, 10]), torch.Size([2, 10, 1])) \"\"\" ``` è®­ç»ƒç½‘ç»œ ```python class NWKernelRegression(nn.Module): def __init__(self, **kwargs): super().__init__(**kwargs) self.w nn.Parameter(torch.rand((1,), requires_grad True)) # æ³¨æ„åŠ›æ¨¡å‹å‚æ•° def forward(self, queries, keys, values): # querieså’Œattention_weightsçš„å½¢çŠ¶ä¸º(æŸ¥è¯¢ä¸ªæ•°ï¼Œâ€œé”®ï¼å€¼â€å¯¹ä¸ªæ•°) queries queries.repeat_interleave(keys.shape[1]).reshape(( 1, keys.shape[1])) self.attention_weights nn.functional.softmax( ((queries keys) * self.w)**2 / 2, dim 1) # valuesçš„å½¢çŠ¶ä¸º(æŸ¥è¯¢ä¸ªæ•°ï¼Œâ€œé”®ï¼å€¼â€å¯¹ä¸ªæ•°) return torch.bmm(self.attention_weights.unsqueeze(1), values.unsqueeze( 1)).reshape( 1) ``` åˆå§‹åŒ–å‚å‚æ•° ````python # X_tileçš„å½¢çŠ¶:(n_trainï¼Œn_train)ï¼Œæ¯ä¸€è¡Œéƒ½åŒ…å«ç€ç›¸åŒçš„è®­ç»ƒè¾“å…¥ X_tile x_train.repeat((n_train, 1)) # Y_tileçš„å½¢çŠ¶:(n_trainï¼Œn_train)ï¼Œæ¯ä¸€è¡Œéƒ½åŒ…å«ç€ç›¸åŒçš„è®­ç»ƒè¾“å‡º Y_tile y_train.repeat((n_train, 1)) # keysçš„å½¢çŠ¶:('n_train'ï¼Œ'n_train' 1) keys X_tile[(1 torch.eye(n_train)).type(torch.bool)].reshape((n_train, 1)) # valuesçš„å½¢çŠ¶:('n_train'ï¼Œ'n_train' 1) values Y_tile[(1 torch.eye(n_train)).type(torch.bool)].reshape((n_train, 1)) ```` ```python net NWKernelRegression() loss nn.MSELoss(reduction 'none') trainer torch.optim.SGD(net.parameters(), lr 0.5) animator d2l.Animator(xlabel 'epoch', ylabel 'loss', xlim [1, 5]) for epoch in range(5): trainer.zero_grad() l loss(net(x_train, keys, values), y_train) l.sum().backward() trainer.step() print(f'epoch {epoch + 1}, loss {float(l.sum()):.6f}') animator.add(epoch + 1, float(l.sum())) ``` ![image 20250211163454536](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111634605.png) ```python # keysçš„å½¢çŠ¶:(n_testï¼Œn_train)ï¼Œæ¯ä¸€è¡ŒåŒ…å«ç€ç›¸åŒçš„è®­ç»ƒè¾“å…¥ï¼ˆä¾‹å¦‚ï¼Œç›¸åŒçš„é”®ï¼‰ keys x_train.repeat((n_test, 1)) # valueçš„å½¢çŠ¶:(n_testï¼Œn_train) values y_train.repeat((n_test, 1)) y_hat net(x_test, keys, values).unsqueeze(1).detach() plot_kernel_reg(y_hat) ``` ![image 20250211163512767](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111635868.png) ```python d2l.show_heatmaps(net.attention_weights.unsqueeze(0).unsqueeze(0), xlabel 'Sorted training inputs', ylabel 'Sorted testing inputs') ``` ![image 20250211163528692](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111635780.png) ## æ³¨æ„åŠ›åˆ†æ•° æ³¨æ„åŠ›åˆ†æ•°: queryå’Œkeyçš„ç›¸ä¼¼åº¦ æ³¨æ„åŠ›æƒé‡: å¯¹åˆ†æ•°è¿›è¡Œè®¡ç®—softmax æœ€å¸¸è§çš„ + ä¸¤ä¸ªåˆèµ·æ¥è¿›å…¥ä¸€ä¸ªå•è¾“å‡ºçš„ä½†éšè—å±‚MLP + ç›´æ¥å†…ç§¯ ![image 20250211164124996](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111641079.png) é«˜æ–¯æ ¸æŒ‡æ•°éƒ¨åˆ†å¯ä»¥è§†ä¸ºæ³¨æ„åŠ›è¯„åˆ†å‡½æ•° ï¼ˆattention scoring functionï¼‰ï¼Œç®€ç§°è¯„åˆ†å‡½æ•°ï¼ˆscoring functionï¼‰ï¼Œç„¶åæŠŠè¿™ä¸ªå‡½æ•°çš„è¾“å‡ºç»“æœè¾“å…¥åˆ°softmaxå‡½ æ•°ä¸­è¿›è¡Œè¿ç®—ã€‚ é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œå°†å¾—åˆ°ä¸é”®å¯¹åº”çš„å€¼çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆå³æ³¨æ„åŠ›æƒé‡ï¼‰ã€‚æœ€åï¼Œæ³¨æ„åŠ›æ±‡èšçš„è¾“å‡º å°±æ˜¯åŸºäºè¿™äº›æ³¨æ„åŠ›æƒé‡çš„å€¼çš„åŠ æƒå’Œ å‡è®¾æœ‰ä¸€ä¸ªæŸ¥è¯¢qâˆˆRqå’Œmä¸ªâ€œé”®ï¼å€¼â€å¯¹(k~1~,v~1~),...,(k~m~,v~m~)ï¼Œå…¶ä¸­k~i~ âˆˆR^k^ï¼Œv~i~ âˆˆR^v^ã€‚ æ³¨æ„åŠ›æ±‡èšå‡½æ•°få°±è¢«è¡¨ç¤ºæˆå€¼çš„åŠ æƒå’Œ ![image 20250211170412337](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111704410.png) ![image 20250211170536433](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111705506.png) å…¶ä¸­æŸ¥è¯¢qå’Œé”®kiçš„æ³¨æ„åŠ›æƒé‡ï¼ˆæ ‡é‡ï¼‰æ˜¯é€šè¿‡æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°aå°†ä¸¤ä¸ªå‘é‡æ˜ å°„æˆæ ‡é‡ï¼Œå†ç»è¿‡softmaxè¿ç®—å¾—åˆ°çš„ > è®¡ç®—å‡ºæ¥æ¯ä¸€ä¸ªKçš„é‡è¦åº¦, ä¹‹åä½¿ç”¨Kè·å–V ![image 20250215134413932](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502151344118.png) ### åŠ æ€§æ³¨æ„åŠ› additive attention å¦ä¸€ç§å®ç°açš„æ–¹å¼ ![image 20250211183242728](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111832819.png) W~q~âˆˆR^hÃ—q^ã€W~k~ âˆˆR^hÃ—k^å’Œw~v~ âˆˆR^h^, æœ€åçš„è¾“å‡ºæ˜¯æ¯ä¸€ä¸ªqå’Œkå¯¹åº”ä¸€ä¸ªå€¼, å°†æŸ¥è¯¢å’Œé”®è¿ç»“èµ·æ¥åè¾“å…¥åˆ°ä¸€ ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ä¸­ï¼Œæ„ŸçŸ¥æœºåŒ…å«ä¸€ä¸ªéšè—å±‚ï¼Œå…¶éšè—å•å…ƒæ•°æ˜¯ä¸€ä¸ªè¶…å‚æ•°hã€‚é€šè¿‡ä½¿ç”¨tanhä½œä¸ºæ¿€æ´»å‡½ æ•°ï¼Œå¹¶ä¸”ç¦ç”¨åç½®é¡¹ã€‚ > è¿™æ—¶å€™çš„kå’Œvå¯ä»¥æ˜¯ä»»æ„é•¿åº¦ ```python #@save class AdditiveAttention(nn.Module): \"\"\"åŠ æ€§æ³¨æ„åŠ›\"\"\" def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs): super(AdditiveAttention, self).__init__(**kwargs) self.W_k nn.Linear(key_size, num_hiddens, bias False) self.W_q nn.Linear(query_size, num_hiddens, bias False) self.w_v nn.Linear(num_hiddens, 1, bias False) self.dropout nn.Dropout(dropout) # åœ¨è®­ç»ƒæœŸé—´éšæœºä¸¢å¼ƒï¼ˆå³è®¾ç½®ä¸ºé›¶ï¼‰ä¸€éƒ¨åˆ†ç¥ç»å…ƒçš„è¾“å‡º def forward(self, queries, keys, values, valid_lens): # `queries`çš„å½¢çŠ¶ï¼š(`batch_size`, æŸ¥è¯¢çš„ä¸ªæ•°, `num_hidden`) # `keys`çš„å½¢çŠ¶ï¼š(`batch_size`, â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°, `num_hidden`) queries, keys self.W_q(queries), self.W_k(keys) # åœ¨ç»´åº¦æ‰©å±•åï¼Œ # queriesçš„å½¢çŠ¶ï¼š(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œ1ï¼Œnum_hidden) # keyçš„å½¢çŠ¶ï¼š(batch_sizeï¼Œ1ï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_hiddens) # ä½¿ç”¨å¹¿æ’­æ–¹å¼è¿›è¡Œæ±‚å’Œ # åŠ äº†ä»¥åï¼Œå½¢çŠ¶ä¸º(batch_size, æŸ¥è¯¢çš„ä¸ªæ•°, â€œé”® å€¼â€å¯¹çš„ä¸ªæ•°, num_hiddens) features queries.unsqueeze(2) + keys.unsqueeze(1) features torch.tanh(features) # self.w_vä»…æœ‰ä¸€ä¸ªè¾“å‡ºï¼Œå› æ­¤ä»å½¢çŠ¶ä¸­ç§»é™¤æœ€åé‚£ä¸ªç»´åº¦ã€‚ # scoresçš„å½¢çŠ¶ï¼š(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œâ€œé”® å€¼â€å¯¹çš„ä¸ªæ•°) scores self.w_v(features).squeeze( 1) self.attention_weights masked_softmax(scores, valid_lens) # valuesçš„å½¢çŠ¶ï¼š(batch_sizeï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œå€¼çš„ç»´åº¦) return torch.bmm(self.dropout(self.attention_weights), values) queries, keys torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2)) # valuesçš„å°æ‰¹é‡ï¼Œä¸¤ä¸ªå€¼çŸ©é˜µæ˜¯ç›¸åŒçš„ # repeatå‡½æ•°å°†å¼ é‡å¤åˆ¶å¤šä»½ï¼Œç„¶åå†æ‹¼æ¥èµ·æ¥, æ˜¯ä¸€ä¸ª(2, 10, 4)çš„å¼ é‡ values torch.arange(40, dtype torch.float32).reshape(1, 10, 4).repeat( 2, 1, 1) valid_lens torch.tensor([2, 6]) attention AdditiveAttention(key_size 2, query_size 20, num_hiddens 8, dropout 0.1) attention.eval() attention(queries, keys, values, valid_lens) # è¾“å‡ºçš„å½¢çŠ¶ï¼š(2, 1, 4) \"\"\"tensor([[[ 2.0000, 3.0000, 4.0000, 5.0000]], [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn <BmmBackward0>) \"\"\" ``` ```python # ç¬¬ä¸€ä¸ªåªå…³å¿ƒå‰ä¸¤ä¸ªé”®ï¼å€¼å¯¹ï¼Œå› æ­¤æ³¨æ„åŠ›æƒé‡æ˜¯[0.5, 0.5, 0, 0, 0, 0, 0, 0, 0, 0] # ç¬¬äºŒä¸ªå…³å¿ƒ6ä¸ª d2l.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)), xlabel 'Keys', ylabel 'Queries') ``` ![image 20250211195848514](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111958621.png) ### ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ› scaled dotâ€product attention ![image 20250211184318218](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111843303.png) è¦æ±‚æŸ¥è¯¢å’Œé”®å…·æœ‰ç›¸åŒçš„é•¿åº¦d ![image 20250211184420850](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502111844938.png) > æŸ¥è¯¢QâˆˆR^nÃ—d^ã€é”®KâˆˆR^mÃ—d^å’Œå€¼VâˆˆR^mÃ—v^çš„ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›, è¾“å‡ºæ˜¯ä¸€ä¸ªn * mçš„æƒé‡ ## å®ç° ```python #@save class DotProductAttention(nn.Module): \"\"\"ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›\"\"\" def __init__(self, dropout, **kwargs): super(DotProductAttention, self).__init__(**kwargs) self.dropout nn.Dropout(dropout) # queries çš„å½¢çŠ¶ï¼š(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œd) # keys çš„å½¢çŠ¶ï¼š(batch_sizeï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œd) # values çš„å½¢çŠ¶ï¼š(batch_sizeï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œå€¼çš„ç»´åº¦) # valid_lens çš„å½¢çŠ¶:(batch_sizeï¼Œ)æˆ–è€…(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°) def forward(self, queries, keys, values, valid_lens None): d queries.shape[ 1] # è®¾ç½®transpose_b Trueä¸ºäº†äº¤æ¢keysçš„æœ€åä¸¤ä¸ªç»´åº¦ scores torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d) self.attention_weights masked_softmax(scores, valid_lens) return torch.bmm(self.dropout(self.attention_weights), values) ``` ```python queries torch.normal(0, 1, (2, 1, 2)) attention DotProductAttention(dropout 0.5) attention.eval() attention(queries, keys, values, valid_lens) \"\"\" tensor([[[ 2.0000, 3.0000, 4.0000, 5.0000]], [[10.0000, 11.0000, 12.0000, 13.0000]]]) \"\"\" ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-09æ¨¡å‹é€‰æ‹©.html":{"title":"æ¨¡å‹é€‰æ‹©","content":"# æ¨¡å‹é€‰æ‹© ## è®­ç»ƒè¯¯å·®ä»¥åŠæ³›åŒ–è¯¯å·® åˆ†åˆ«åœ¨æ•°æ®ä»¥åŠè®­ç»ƒé›†ä¸Šé¢çš„è¯¯å·®, ä¸€èˆ¬å…³æ³¨ç¬¬äºŒä¸ª ## éªŒè¯æ•°æ®é›†ä»¥åŠæµ‹è¯•æ•°æ®é›† éªŒè¯æ•°æ®é›†: è¿™ä¸€ä¸ªæ•°æ®é›†å¯ä»¥ç”¨äºè¯„ä¼°æ¨¡å‹çš„å¥½å æµ‹è¯•æ•°æ®é›†: è¿™ä¸ªæ•°æ®é›†åªä½¿ç”¨ä¸€æ¬¡, ç”¨äºæœ€åçš„æµ‹è¯• å®é™…ä½¿ç”¨çš„æ—¶å€™å¯èƒ½å‡ºç°æ•°æ®çš„æ•°é‡æ¯”è¾ƒå°, è¿™æ—¶å€™å¯ä»¥ä½¿ç”¨K åˆ™äº¤å‰éªŒè¯ ### K åˆ™äº¤å‰éªŒè¯ æŠŠæ•°æ®é›†åˆ†å‰²ä¸ºKå—, å…¶ä¸­ä¸€ä¸ªä½œä¸ºéªŒè¯æ•°æ®é›†, å…¶ä»–çš„æ•°æ®ä½œä¸ºè®­ç»ƒæ•°æ®é›†, ä¾æ¬¡éå†æ‰€æœ‰çš„æ•°æ®é›†, è·å–æ‰€æœ‰è¯¯å·®çš„å‡å€¼ #### ä»£ç å®ç° ```python # è¿›è¡Œ def get_k_fold_data(k, i, X, y): assert k > 1 fold_size X.shape[0] // k # æ¯ä¸€æ¬¡çš„éªŒè¯é›†å¤§å° X_train, y_train None, None for j in range(k): idx slice(j * fold_size, (j + 1) * fold_size) X_part, y_part X[idx, :], y[idx] if j i: X_valid, y_valid X_part, y_part elif X_train is None: X_train, y_train X_part, y_part else: X_train torch.cat([X_train, X_part], 0) # æ²¿ç€0è½´æ‹¼æ¥ y_train torch.cat([y_train, y_part], 0) return X_train, y_train, X_valid, y_valid def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size): train_l_sum, valid_l_sum 0, 0 for i in range(k): data get_k_fold_data(k, i, X_train, y_train) net get_net() train_ls, valid_ls train(net, *data, num_epochs, learning_rate, weight_decay, batch_size) train_l_sum + train_ls[ 1] # å–æœ€åä¸€æ¬¡è®­ç»ƒçš„å€¼ valid_l_sum + valid_ls[ 1] if i 0: d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls], xlabel 'epoch', ylabel 'rmse', xlim [1, num_epochs], legend ['train', 'valid'], yscale 'log') print(f'fold {i + 1}, train log rmse {float(train_ls[ 1]):f}, ' f'valid log rmse {float(valid_ls[ 1]):f}') return train_l_sum / k, valid_l_sum / k ``` ## æ¬ æ‹Ÿåˆè¿‡æ‹Ÿåˆ ![image 20250109161219268](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501091612338.png) > æ¨¡å‹è¿‡äºå¤æ‚çš„æ—¶å€™å¯ä»¥è®°å½•æ‰€æœ‰çš„æ•°æ®, æ³›åŒ–æ€§æ¯”è¾ƒå·® ![image 20250109161233734](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501091612787.png) > æ¨¡å‹çš„å¤æ‚åº¦ ![image 20250109161302322](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501091613379.png) æ¨¡å‹çš„å®¹é‡éš¾ä»¥ä¼°è®¡, ä¸åŒç§ç±»çš„æ¨¡å‹ä¹‹é—´æ›´éš¾ä»¥æ¯”è¾ƒ ç»™å®šä¸€ä¸ªæ¨¡å‹çš„ç§ç±», ä¸€èˆ¬å…³æ³¨ä¸¤ä¸ªç‚¹ + å‚æ•°çš„ä¸ªæ•° + å‚æ•°çš„å€¼çš„èŒƒå›´ ### VCç»´ å¯¹äºä¸€ä¸ªåˆ†ç±»æ¨¡å‹, VCç­‰äºä¸€ä¸ªæœ€å¤§çš„æ•°æ®é›†, ä¸ç®¡å¦‚ä½•ç»™å®šæ ‡å·, éƒ½å­˜åœ¨ä¸€ä¸ªæ¨¡å‹å¯¹ä»–å®Œæ•´åˆ†ç±» ![image 20250109161326218](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501091613280.png) å®é™…è¿™ä¸€ä¸ªçš„åº”ç”¨å¾ˆéš¾ ### æ•°æ®å¤æ‚åº¦ + æ ·æœ¬çš„æ•°é‡ + æ¯ä¸ªæ ·æœ¬çš„å…ƒç´ ä¸ªæ•° + æ—¶é—´ç©ºé—´ç»“æ„ + å¤šæ ·æ€§ ### å®é™…æµ‹è¯• è¯•ç”¨ä»¥ä¸‹çš„å‡½æ•°è¿›è¡Œæµ‹è¯•, ç»™ä¸åŒæ•°é‡çš„è¾“å…¥å‚æ•°é¢„æµ‹æƒé‡ ![image 20250109162108727](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501091621764.png) ```python # æ¬ æ‹Ÿåˆè¿‡æ‹Ÿåˆ import math import numpy as np import torch from torch import nn from d2l import torch as d2l ``` + ä»£ç å®ç°ä¸Šé¢çš„è¡¨è¾¾å¼, è®°å½•ä¸€ä¸‹åˆå§‹çš„xåœ¨features, ä¸­é—´æ¯ä¸€é¡¹çš„å€¼x^n^/n!åœ¨poly_features, ç”¨äºä¹‹åçš„è®­ç»ƒè¾“å…¥, ä»¥åŠå®é™…çš„è¾“å‡ºyåœ¨labels ````python max_degree 20 n_train, n_test 100, 100 true_w np.zeros(max_degree) true_w[0:4] np.array([5, 1.2, 3.4, 5.6]) # è·å–ä¸€ä¸ªéšæœºçš„ç‰¹å¾, [2n, 1]çš„xæ•°ç»„ features np.random.normal(size (n_train + n_test, 1)) np.random.shuffle(features) # è¿›è¡ŒæŒ‡æ•°å˜æ¢, è·å–ä¸€ä¸ª[2n, max_degree]æ•°ç»„, æ¯ä¸€è¡Œä¾æ¬¡æ˜¯x^0, x^1, x^2, ..., x^(max_degree 1) poly_features np.power(features, np.arange(max_degree).reshape(1, 1)) for i in range(max_degree): # å¯¹æ¯ä¸€è¡Œçš„æ•°å­—ä¾æ¬¡é™¤ä»¥i!, ä¹Ÿå°±æ˜¯gamma(i+1) poly_features[:, i] / math.gamma(i + 1) # è¿›è¡Œä¸€æ¬¡çº¿æ€§å˜æ¢, ä¹˜ä»¥æƒé‡, åŠ ä¸Šå™ªå£°, å¾—åˆ°y labels np.dot(poly_features, true_w) labels + np.random.normal(scale 0.1, size labels.shape) ```` + è½¬ä¸ºtensor ```python # å°†æ•°æ®è½¬æ¢ä¸ºtensor true_w, features, poly_features, labels [ torch.tensor(x, dtype torch.float32) for x in [true_w, features, poly_features, labels]] # ç¬¬ä¸€ä¸ªæ—¶è¾“å…¥å‚æ•°, ç¬¬äºŒä¸ªæ˜¯å¹³æ–¹é™¤ä»¥é˜¶ä¹˜, ç¬¬ä¸‰ä¸ªæ˜¯ä¹˜ä»¥æƒé‡çš„è¾“å‡º features[:2], poly_features[:2], labels[:2] ``` + è·å–ä¸€ä¸ªå¹³å‡lossçš„è¯„ä¼°å‡½æ•° ```python def evaluate_loss(net, data_iter, loss): #@save \"\"\"è¯„ä¼°ç»™å®šæ•°æ®é›†ä¸Šæ¨¡å‹çš„æŸå¤±ã€‚\"\"\" metric d2l.Accumulator(2) # æŸå¤±çš„æ€»å’Œ, æ ·æœ¬æ•°é‡ for X, y in data_iter: l loss(net(X), y) metric.add(l.sum(), l.numel()) return metric[0] / metric[1] ``` + å®é™…çš„è®­ç»ƒå‡½æ•° ```python def train(train_features, test_features, train_labels, test_labels, num_epochs 400): loss nn.MSELoss() # æŸå¤±å‡½æ•°å‡æ–¹å·® input_shape train_features.shape[ 1] # çº¿æ€§å›å½’æ¨¡å‹,biasæ˜¯False, å› ä¸ºæˆ‘ä»¬å·²ç»åœ¨ç‰¹å¾ä¸­åŠ å…¥äº†åç½® net nn.Sequential(nn.Linear(input_shape, 1, bias False)) batch_size min(10, train_labels.shape[0]) # å°†æ•°æ®é›†è½¬æ¢ä¸ºè¿­ä»£å™¨ train_iter d2l.load_array((train_features, train_labels.reshape( 1, 1)), batch_size) test_iter d2l.load_array((test_features, test_labels.reshape( 1, 1)), batch_size, is_train False) trainer torch.optim.SGD(net.parameters(), lr 0.01) # å›¾ç¤ºæ˜¾ç¤º animator d2l.Animator(xlabel 'epoch', ylabel 'loss', yscale 'log', xlim [1, num_epochs], ylim [1e 3, 1e2], legend ['train', 'test']) for epoch in range(num_epochs): d2l.train_epoch_ch3(net, train_iter, loss, trainer) if epoch 0 or (epoch + 1) % 20 0: animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss), evaluate_loss(net, test_iter, loss))) print('weight:', net[0].weight.data.numpy()) ``` + å¼€å§‹æµ‹è¯• + æ­£å¸¸çš„æ‹Ÿåˆ, ä½¿ç”¨å››ä¸ªæƒé‡, æ‰€ä»¥ç»™å››ä¸ªé¢„æµ‹ ```python train(poly_features[:n_train, :4], poly_features[n_train:, :4], labels[:n_train], labels[n_train:]) \"\"\" weight: [[ 5.0277095 1.287504 3.4781575 5.320093 ]] \"\"\" ``` ![image 20250109162927882](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501091629930.png) + ç»™çš„è¾“å…¥æ•°æ®æ¯”è¾ƒå°, é¢„æµ‹çš„ç»´åº¦æ¯”è¾ƒä½ ```python # æ¬ æ‹Ÿåˆ, å®é™…çš„æ•°æ®æ•°é‡æ¯”è¾ƒä½, ä½†æ˜¯æ¨¡å‹çš„å¤æ‚åº¦æ¯”è¾ƒé«˜ train(poly_features[:n_train, :2], poly_features[n_train:, :2], labels[:n_train], labels[n_train:]) \"\"\" weight: [[3.604659 3.4564216]] \"\"\" ``` ![image 20250109163015513](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501091630562.png) + ç»™çš„è¾“å…¥è¿‡å¤š ```python train(poly_features[:n_train, :], poly_features[n_train:, :], labels[:n_train], labels[n_train:]) \"\"\" weight: [[ 4.94952154e+00 1.40046442e+00 3.01533484e+00 4.69035625e+00 1.56668198e+00 1.22568822e+00 4.53702867e 01 2.31323943e 01 1.18733019e 01 1.92391336e 01 2.90535507e 03 3.65933515e 02 1.56559631e 01 1.77428693e 01 2.16690585e 01 1.79554939e 01 1.89996302e 01 1.67450756e 01 1.12046316e 01 1.59917325e 02]] \"\"\" ``` ![image 20250109163047561](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501091630613.png) ## æƒé‡è¡°é€€weight_decay [æƒé‡è¡°å‡weight_decayå‚æ•°ä»å…¥é—¨åˆ°ç²¾é€š_weight decay CSDNåšå®¢](https://blog.csdn.net/zhaohongfei_358/article/details/129625803) ä¸€ç§ç”¨äºå¤„ç†è¿‡æ‹Ÿåˆçš„æ–¹æ³•, åœ¨æ§åˆ¶æ¨¡å‹çš„å®¹é‡çš„æ—¶å€™, å¯ä»¥æ§åˆ¶æ¨¡å‹çš„å‚æ•°ä¸ªæ•°ä»¥åŠæ§åˆ¶å‚æ•°çš„èŒƒå›´ ![image 20250109220937109](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501092209180.png) å¯ä»¥é€šè¿‡æ˜¾ç¤ºwçš„å¤§å°æ¥è¿›è¡Œå®ç°, é€šå¸¸é™åˆ¶bçš„ä½œç”¨ä¸å¤§, é€šè¿‡è®¡ç®—ä½¿å¾—è¯¯å·®å‡½æ•°æœ€å° ![image 20250109221417939](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501092214005.png) ![image 20250109221451957](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501092214017.png) ![image 20250109222032740](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501092220823.png) è¿™ä¸ªç»¿è‰²çš„æ¤­åœ†è¡¨ç¤ºï¼Œå½“W1å’ŒW2å–ç»¿è‰²æ¤­åœ†ä¸Šçš„ç‚¹æ—¶ï¼ŒLosséƒ½æ˜¯2ã€‚æ‰€ä»¥ï¼Œå½“æˆ‘ä»¬æ²¡æœ‰æƒ©ç½šé¡¹æ—¶ï¼Œå¯¹äºLoss 2ï¼Œå–æ¤­åœ†ä¸Šçš„è¿™äº›ç‚¹éƒ½å¯ä»¥ã€‚è‹¥å–åˆ°å³ä¸Šè§’çš„ç‚¹ï¼Œé‚£ä¹ˆ W1å’ŒW2 çš„å€¼å°±ä¼šæ¯”è¾ƒå¤§ï¼Œæ‰€ä»¥æˆ‘ä»¬å¸Œæœ›W1å’ŒW2å°½é‡å¾€å·¦ä¸‹é ã€‚ > ![image 20250109223058788](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501092230841.png) > > å½“wç¦»åŸç‚¹æ¯”è¾ƒè¿œçš„æ—¶å€™, ä¼šåœ¨ä¸‹é™å‡½æ•°é‡Œé¢å æ¯”æ¯”è¾ƒå¤§, æ‰€ä»¥æŠŠå®é™…çš„å€¼æ‹‰å‘åŸç‚¹ > > 1. æ¨¡å‹çš„æƒé‡è¶Šå¤§ï¼ŒLosså°±ä¼šè¶Šå¤§ã€‚ > 2. Î»è¶Šå¤§ï¼Œæƒé‡è¡°å‡çš„å°±è¶Šå‰å®³ > 3. è‹¥ Î»è¿‡å¤§ï¼Œé‚£ä¹ˆåŸæœ¬Lossçš„å æ¯”å°±ä¼šè¾ƒä½ï¼Œæœ€åæ¨¡å‹å°±å…‰é¡¾ç€è®©æ¨¡å‹æƒé‡å˜å°äº†ï¼Œæœ€ç»ˆæ¨¡å‹æ•ˆæœå°±ä¼šå˜ > > **æ³¨:** å®é™…ä½¿ç”¨çš„æ•°å€¼ä¸€èˆ¬æ˜¯0.001 0.0001 ![image 20250109222448554](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501092224623.png) æ¯”å®é™…çš„æ›´æ–°å‡½æ•°å¤šå‡å»ä¸€é¡¹, è¿™ä¸€ä¸ªæ–¹å¼ä½¿å¾—é€šè¿‡L2çš„æ­£åˆ™é¡¹æ˜¯çš„æ¨¡å‹çš„å‚æ•°ä¸ä¼šå¤ªå¤§, æ§åˆ¶æ¨¡å‹çš„å¤æ‚åº¦, æ­£åˆ™é¡¹æƒé‡æ˜¯æ§åˆ¶æ¨¡å‹å¤æ‚åº¦çš„è¶…å‚æ•° ### å®é™…å®ç° ![image 20250110184540176](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501101845421.png) ```python %matplotlib inline import torch from torch import nn from d2l import torch as d2l ``` + åˆå§‹åŒ–æ•°æ®é›† ```python # ç”Ÿæˆæ•°æ®é›†, ä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†å®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆ n_train, n_test, num_inputs, batch_size 20, 100, 200, 5 # true_w å®é™…æ˜¯ä¸€ä¸ª200ç»´çš„å‘é‡ï¼Œæ¯ä¸ªå…ƒç´ éƒ½æ˜¯0.01, true_bæ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå€¼ä¸º0.05 true_w, true_b torch.ones((num_inputs, 1)) * 0.01, 0.05 # ç”Ÿæˆæ•°æ®é›†ä¸€ä¸ª20*200çš„xçŸ©é˜µï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ª200ç»´çš„å‘é‡ï¼Œå…±20è¡Œ, å’Œä¸€ä¸ª20*1çš„yå‘é‡ train_data d2l.synthetic_data(true_w, true_b, n_train) train_iter d2l.load_array(train_data, batch_size) # x 100 * 200 Ã— w 200 * 1 y 100 * 1 test_data d2l.synthetic_data(true_w, true_b, n_test) test_iter d2l.load_array(test_data, batch_size, is_train False) ``` + åˆå§‹åŒ–ä¸€ä¸‹ä½¿ç”¨çš„å‚æ•° ```python def init_params(): w torch.normal(0, 1, size (num_inputs, 1), requires_grad True) b torch.zeros(1, requires_grad True) return [w, b] ``` + ä¸€ä¸ªè®¡ç®—æƒ©ç½šå‡½æ•° ```python def l2_penalty(w): # è¿™é‡Œåªæƒ©ç½šwï¼Œä¸æƒ©ç½šb, å¯¹wè¿›è¡Œå¹³æ–¹æ±‚å’Œå†é™¤ä»¥2, wåªæœ‰ä¸€ç»´ return torch.sum(w.pow(2)) / 2 ``` + å®é™…çš„è®­ç»ƒå‡½æ•° ```python def train(lambd): # è·å–å®é™…ä½¿ç”¨çš„è®­ç»ƒåˆå§‹å‚æ•° w, b init_params() # åˆå§‹åŒ–ä¸¤ä¸ªå‡½æ•° net, loss lambda X: d2l.linreg(X, w, b), d2l.squared_loss num_epochs, lr 200, 0.003 # ç”¨äºæ˜¾ç¤ºå›¾åƒ animator d2l.Animator(xlabel 'epochs', ylabel 'loss', yscale 'log', xlim [5, num_epochs], legend ['train', 'test']) for epoch in range(num_epochs): for X, y in train_iter: with torch.enable_grad(): l loss(net(X), y) + l2_penalty(w) * lambd # æ·»åŠ äº†L2èŒƒæ•°æƒ©ç½šé¡¹ l.sum().backward() d2l.sgd([w, b], lr, batch_size) if (epoch + 1) % 5 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) print('L2 norm of w:', torch.norm(w).item()) ``` + å®éªŒ ```python train(lambd 0) # æ²¡æœ‰æƒ©ç½šé¡¹ ``` ![image 20250110230824685](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501102308830.png) > ç›´æ¥å‘ç”Ÿè¿‡æ‹Ÿåˆ ```python train(lambd 3) # æƒ©ç½šé¡¹ä¸º3 ``` ![image 20250110230856371](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501102308466.png) ### ç®€å•å®ç° ```python def train_concise(wd): net nn.Sequential(nn.Linear(num_inputs, 1)) for param in net.parameters(): param.data.normal_() loss nn.MSELoss() num_epochs, lr 100, 0.003 # å¸¦æœ‰æƒé‡è¡°å‡çš„ä¼˜åŒ–å™¨, paramsæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œæ¯ä¸ªå‚æ•°éƒ½æœ‰è‡ªå·±çš„æƒé‡è¡°å‡ # è¿™é‡Œçš„net[0].weightå’Œnet[0].biaséƒ½æ˜¯å‚æ•°, ä½œç”¨äºæƒé‡è¡°å‡çš„åªæœ‰net[0].weight trainer torch.optim.SGD([{ \"params\": net[0].weight, 'weight_decay': wd}, { \"params\" : net[0].bias}], lr lr) # å¯¹æƒé‡è¿›è¡Œè¡°å‡ animator d2l.Animator(xlabel 'epochs', ylabel 'loss', yscale 'log', xlim [5, num_epochs], legend ['train', 'test']) for epoch in range(num_epochs): for X, y in train_iter: with torch.enable_grad(): trainer.zero_grad() l loss(net(X), y) l.backward() trainer.step() if (epoch + 1) % 5 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) print('L2 norm of w:', net[0].weight.norm().item()) ``` å®é™…çš„ç»“æœå’Œä¸Šé¢å·®ä¸å¤š ![image 20250110232140913](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501102321005.png) ![image 20250110232147856](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501102321938.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-17-22æ•°æ®å¢å¹¿.html":{"title":"æ•°æ®å¢å¹¿","content":"# æ•°æ®å¢å¹¿ åœ¨å›¾ç‰‡å¤„ç†çš„æ—¶å€™, å›¾ç‰‡çš„è‰²æ¸©ä»¥åŠèƒŒæ™¯ä¹‹ç±»çš„ä¼šå½±å“æ•°æ®çš„å¤„ç†, å¯¼è‡´å®é™…éƒ¨ç½²çš„æ—¶å€™ä¼šå‡ºç°é—®é¢˜ æ•°æ®å¢å¼ºå®é™…åšçš„æ˜¯åœ¨ä¸€ä¸ªå·²ç»æœ‰çš„æ•°æ®é›†é‡Œé¢, å¯¹æ•°æ®è¿›è¡Œå¤„ç†, ä½¿å¾—æ•°æ®æœ‰æ›´å¤šæ ·æ€§, æ”¹å˜æ•°æ®çš„å¤§å°, äº®åº¦, è‰²æ¸©ç­‰, ä¸€èˆ¬çš„ç”Ÿæˆæ˜¯éšæœºçš„åœ¨çº¿ç”Ÿæˆ + ç¿»è½¬ å¯ä»¥å¯¹æ•°æ®è¿›è¡Œç¿»è½¬, ä½†æ˜¯ä¸Šä¸‹çš„ç¿»è½¬ä¸æ€»æ˜¯æœ‰æ•ˆçš„, æ¯”å¦‚å»ºç­‘ç‰©çš„ç¿»è½¬ä¹‹ç±»çš„ä¼šå¯¼è‡´å¾ˆå¥‡æ€ª + åˆ‡å‰² å‡ºæ•°æ®é›†é‡Œé¢å–å‡ºæ¥ä¸€éƒ¨åˆ†, å¯ä»¥è®¾ç½®ä¸€ä¸ªéšæœºçš„é«˜å®½ä»¥åŠéšæœºçš„å¤§å°, ä½ç½® + é¢œè‰² è‰²è°ƒ, é¥±å’Œåº¦, æ˜äº®åº¦ > å®é™…çš„ä½¿ç”¨éœ€è¦æ ¹æ®ä½ çš„æ•°æ®é›†è¿›è¡Œé€‰æ‹©å®é™…çš„å¤„ç†æ–¹å¼ ## å®é™…ä½¿ç”¨ + å¯¼å…¥å›¾ç‰‡ ```python %matplotlib inline import torch from torch import nn import torchvision from d2l import torch as d2l d2l.set_figsize() # è®¾ç½®å›¾çš„å°ºå¯¸ img d2l.plt.imread('../img/3.jpg') d2l.plt.imshow(img) from PIL import Image # Convert numpy array to PIL Image img_pil Image.fromarray(img) ``` + è®¾ç½®ä¸€ä¸ªå¤„ç†å‡½æ•° ```python # ä½¿ç”¨augå‡½æ•°æ¥åº”ç”¨å›¾åƒå¢å¹¿ def apply(img, aug, num_rows 2, num_cols 4, scale 1.5): Y [aug(img) for _ in range(num_rows * num_cols)] d2l.show_images(Y, num_rows, num_cols, scale scale) ``` + ç¿»è½¬ ```python apply(img_pil, torchvision.transforms.RandomHorizontalFlip()) ``` ![image 20250117164737573](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501171647677.png) ```python apply(img_pil, torchvision.transforms.RandomVerticalFlip()) ``` ![image 20250117164756591](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501171647688.png) + è£å‰ª ```python # éšæœºè£å‰ª, scaleæ˜¯è£å‰ªçš„é¢ç§¯æ¯”ä¾‹ï¼Œratioæ˜¯è£å‰ªçš„é•¿å®½æ¯”, è¿™ä¸¤ä¸ªå‚æ•°æ˜¯ä¸€ä¸ªèŒƒå›´ apply(img_pil, torchvision.transforms.RandomResizedCrop(200, scale (0.1, 1), ratio (0.5, 2))) ``` ![image 20250117164838779](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501171648868.png) > `200`: æŒ‡å®šè£å‰ªåçš„è¾“å‡ºå›¾åƒçš„å¤§å°ä¸º 200x200 åƒç´ ã€‚è¿™æ˜¯è£å‰ªåçš„è¾“å‡ºå›¾åƒçš„å¤§å°ã€‚ > `scale (0.1, 1)`: æŒ‡å®šè£å‰ªæ¡†çš„é¢ç§¯æ¯”ä¾‹èŒƒå›´ã€‚åœ¨éšæœºè£å‰ªè¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆè®¡ç®—å‡ºè£å‰ªæ¡†çš„é¢ç§¯ä¸ºåŸå§‹å›¾åƒé¢ç§¯çš„ä¸€éƒ¨åˆ†ï¼Œè¿™ä¸ªæ¯”ä¾‹èŒƒå›´åœ¨0.1åˆ°1ä¹‹é—´ã€‚ > `ratio (0.5, 2)`: æŒ‡å®šè£å‰ªæ¡†çš„é«˜å®½æ¯”èŒƒå›´ã€‚åœ¨éšæœºè£å‰ªè¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆä¼šæ ¹æ®æ­¤å‚æ•°éšæœºé€‰æ‹©ä¸€ä¸ªé«˜å®½æ¯”ï¼Œè¿™ä¸ªæ¯”ä¾‹èŒƒå›´åœ¨0.5åˆ°2ä¹‹é—´ï¼Œè¡¨ç¤ºé«˜å®½æ¯”ä¸º0.5åˆ°2ä¹‹é—´çš„ä¸€ä¸ªéšæœºå€¼ + é¢œè‰² ```python # éšæœºäº®åº¦, brightnessæ˜¯äº®åº¦çš„èŒƒå›´, contrastæ˜¯å¯¹æ¯”åº¦çš„èŒƒå›´, saturationæ˜¯é¥±å’Œåº¦çš„èŒƒå›´, hueæ˜¯è‰²è°ƒçš„èŒƒå›´ # è¿™é‡Œçš„èŒƒå›´æ˜¯ä¸€ä¸ªæ¯”ä¾‹ï¼Œæ¯”å¦‚brightness 0.5ï¼Œè¡¨ç¤ºäº®åº¦çš„èŒƒå›´æ˜¯[1 0.5, 1+0.5] apply(img_pil, torchvision.transforms.ColorJitter(brightness 0.5, contrast 0, saturation 0, hue 0)) ``` ![image 20250117164858049](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501171648138.png) ```python # éšæœºäº®åº¦, brightnessæ˜¯äº®åº¦çš„èŒƒå›´, contrastæ˜¯å¯¹æ¯”åº¦çš„èŒƒå›´, saturationæ˜¯é¥±å’Œåº¦çš„èŒƒå›´, hueæ˜¯è‰²è°ƒçš„èŒƒå›´ # è¿™é‡Œçš„èŒƒå›´æ˜¯ä¸€ä¸ªæ¯”ä¾‹ï¼Œæ¯”å¦‚brightness 0.5ï¼Œè¡¨ç¤ºäº®åº¦çš„èŒƒå›´æ˜¯[1 0.5, 1+0.5] apply(img_pil, torchvision.transforms.ColorJitter(brightness 0, contrast 0, saturation 0, hue 0.5)) ``` ![image 20250117164913854](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501171649985.png) + ä¸€èµ·ä½¿ç”¨ ```python hflip torchvision.transforms.RandomHorizontalFlip() vflip torchvision.transforms.RandomVerticalFlip() color_jitter torchvision.transforms.ColorJitter(brightness 0.5, contrast 0, saturation 0, hue 0.5) augs torchvision.transforms.Compose([ hflip, vflip, color_jitter ]) apply(img_pil, augs) ``` ![image 20250117164933360](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501171649461.png) ### å®é™…ä½¿ç”¨ + è·å–æ•°æ®é›† ```python def load_cifar10(is_train, augs, batch_size): dataset torchvision.datasets.CIFAR10(root \"../data\", train is_train, transform augs, download True) return torch.utils.data.DataLoader(dataset, batch_size batch_size, shuffle is_train, num_workers d2l.get_dataloader_workers()) ``` + åˆå§‹åŒ–ä¸¤ä¸ªå¤„ç†å›¾ç‰‡çš„æ–¹å¼ ```python train_augs torchvision.transforms.Compose([ torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor() ]) test_augs torchvision.transforms.Compose([ torchvision.transforms.ToTensor() ]) ``` + åˆå§‹åŒ–ä¸€ä¸ªè®­ç»ƒçš„å•æ¬¡å‡½æ•° ```python def train_batch_ch13(net, X, y, loss, trainer, devices): if isinstance(X, list): X [x.to(devices[0]) for x in X] else: X X.to(devices[0]) y y.to(devices[0]) net.train() # è®­ç»ƒä¸€æ¬¡ trainer.zero_grad() pred net(X) l loss(pred, y) # è®¡ç®—ä¸€æ¬¡æŸå¤± l.sum().backward() trainer.step() # è°ƒæ•´ä¸€æ¬¡å‚æ•° train_loss_sum l.sum() train_acc_sum d2l.accuracy(pred, y) # è®¡ç®—å‡†ç¡®çš„ä¸ªæ•° return train_loss_sum, train_acc_sum ``` + å®é™…çš„è®­ç»ƒå‡½æ•° ```python def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices d2l.try_all_gpus()): timer, num_batches d2l.Timer(), len(train_iter) animator d2l.Animator(xlabel 'epoch', xlim [1, num_epochs], ylim [0, 1], legend ['train loss', 'train acc', 'test acc']) net nn.DataParallel(net, device_ids devices).to(devices[0]) for epoch in range(num_epochs): metric d2l.Accumulator(4) for i, (features, labels) in enumerate(train_iter): timer.start() l, acc train_batch_ch13(net, features, labels, loss, trainer, devices) metric.add(l, acc, labels.shape[0], labels.numel()) timer.stop() if (i + 1) % (num_batches // 5) 0 or i num_batches 1: animator.add(epoch + (i + 1) / num_batches, (metric[0] / metric[2], metric[1] / metric[3], None)) test_acc d2l.evaluate_accuracy_gpu(net, test_iter) animator.add(epoch + 1, (None, None, test_acc)) print(f'loss {metric[0] / metric[2]:.3f}, train acc {metric[1] / metric[3]:.3f}, ' f'test acc {test_acc:.3f}') print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec ' f'on {str(devices)}') ``` + å®é™…çš„å¼€å§‹å‡½æ•° ```python batch_size, devices, net 256, d2l.try_all_gpus(), d2l.resnet18(10, 3) def init_weights(m): if type(m) in [nn.Linear, nn.Conv2d]: nn.init.xavier_uniform_(m.weight) net.apply(init_weights) def train_with_data_aug(train_augs, test_augs, net, lr 0.001): train_iter load_cifar10(True, train_augs, batch_size) # è·å–è®­ç»ƒé›† test_iter load_cifar10(False, test_augs, batch_size) # è·å–æµ‹è¯•é›† loss nn.CrossEntropyLoss(reduction 'none') # è·å–æŸå¤±å‡½æ•° trainer torch.optim.Adam(net.parameters(), lr lr) train_ch13(net, train_iter, test_iter, loss, trainer, 10, devices) train_with_data_aug(train_augs, test_augs, net) ``` ![image 20250117190212529](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501171902733.png) ä¸ä½¿ç”¨å¢å¼ºçš„æ—¶å€™çš„æµ‹è¯• ![image 20250117193040544](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501171930640.png) > å¯ä»¥å‘ç°è¿‡æ‹Ÿåˆçš„ç¨‹åº¦æ¯”è¾ƒé«˜ ## è·¨å›¾ç‰‡å¢å¼º Mixup:å°†éšæœºçš„ä¸¤å¼ æ ·æœ¬æŒ‰æ¯”ä¾‹æ··åˆï¼Œåˆ†ç±»çš„ç»“æœæŒ‰æ¯”ä¾‹åˆ†é…ï¼› Cutout:éšæœºçš„å°†æ ·æœ¬ä¸­çš„éƒ¨åˆ†åŒºåŸŸcutæ‰ï¼Œå¹¶ä¸”å¡«å……0åƒç´ å€¼ï¼Œåˆ†ç±»çš„ç»“æœä¸å˜ï¼› CutMix:å°±æ˜¯å°†ä¸€éƒ¨åˆ†åŒºåŸŸcutæ‰ä½†ä¸å¡«å……0åƒç´ è€Œæ˜¯éšæœºå¡«å……è®­ç»ƒé›†ä¸­çš„å…¶ä»–æ•°æ®çš„åŒºåŸŸåƒç´ å€¼ï¼Œåˆ†ç±»ç»“æœæŒ‰ä¸€å®šçš„æ¯”ä¾‹åˆ†é… mixupå¯¹ä¸¤ä¸ªæ ·æœ¬ æ ‡ç­¾æ•°æ®å¯¹æŒ‰æ¯”ä¾‹ç›¸åŠ åç”Ÿæˆæ–°çš„æ ·æœ¬ æ ‡ç­¾æ•°æ®ï¼š â€ƒâ€ƒ$\\tilde{x} \\lambda x_{i} + (1 \\lambda) x_{j}$ , å…¶ä¸­x xxä¸ºè¾“å…¥å‘é‡ â€ƒâ€ƒ$\\tilde{y} \\lambda y_{i} + (1 \\lambda) y_{j}$ , å…¶ä¸­y yyä¸ºæ ‡ç­¾çš„one hotç¼–ç  â€ƒâ€ƒÎ» âˆˆ [ 0 , 1 ]æ˜¯æ¦‚ç‡å€¼ï¼ŒÎ» âˆ¼ B e t a ( Î± , Î± ) å³ Î» æœ ä» å‚ æ•° éƒ½ ä¸º Î± çš„ B e t a åˆ† å¸ƒ"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-12-12å±‚å’Œå—.html":{"title":"å±‚å’Œå—","content":"# å±‚å’Œå— ## è‡ªå®šä¹‰æ¨¡å‹ ä¹‹å‰ä½¿ç”¨çš„æ˜¯nn.Sequentialå®šä¹‰çš„ä¸€ç§ç‰¹æ®Šçš„Module ```python net nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10)) X torch.rand(2, 20) net(X) ``` ä»»æ„çš„ä¸€ä¸ªå±‚ä»¥åŠç¥ç»ç½‘ç»œéƒ½æ˜¯Moduleçš„ä¸€ä¸ªå­ç±» ä½¿ç”¨torchæä¾›çš„ç±» ```python class MLP(nn.Module): # åˆå§‹åŒ–å‡½æ•°ã€‚ def __init__(self): super(MLP, self).__init__() # å®šä¹‰ä¸¤ä¸ªå…¨è¿æ¥å±‚ self.hidden nn.Linear(20, 256) self.out nn.Linear(256, 10) # å®šä¹‰æ¨¡å‹çš„å‰å‘è®¡ç®—ï¼Œå³å¦‚ä½•æ ¹æ®è¾“å…¥Xè®¡ç®—è¿”å›æ‰€éœ€è¦çš„æ¨¡å‹è¾“å‡º def forward(self, X): return self.out(F.relu(self.hidden(X))) net MLP() net(X) ``` ä½¿ç”¨ä»¥ä¸Šçš„æ¨¡å¼å¯ä»¥å®ç°ä¸€æ ·çš„åŠŸèƒ½ ä¹‹å‰ä½¿ç”¨çš„Sequentialä¹Ÿå¯ä»¥å®ç° ```python class MySequential(nn.Module): def __init__(self, *args): super(MySequential, self).__init__() for block in args: # è¿™é‡Œï¼Œ`block`æ˜¯`Module`å­ç±»çš„ä¸€ä¸ªå®ä¾‹ã€‚æˆ‘ä»¬æŠŠå®ƒä¿å­˜åœ¨'Module'ç±»çš„æˆå‘˜å˜é‡ # `_modules` ä¸­ã€‚'_modules' æ˜¯ä¸€ä¸ªä»å­—ç¬¦ä¸²å±æ€§åæ˜ å°„åˆ°Moduleçš„å­—å…¸ã€‚ self._modules[block] block def forward(self, X): # OrderedDictä¿è¯äº†æŒ‰ç…§æˆå‘˜æ·»åŠ çš„é¡ºåºéå†å®ƒä»¬ for block in self._modules.values(): X block(X) return X net MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10)) net(X) ``` åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™, å¯ä»¥åœ¨Moduleé‡Œé¢ä½¿ç”¨Sequential, ä¹Ÿå¯ä»¥åœ¨Sequentialçš„å‚æ•°é‡Œé¢ç›´æ¥ä½¿ç”¨ä¸€ä¸ªModule ### å‚æ•°ç®¡ç† åœ¨å®é™…è®­ç»ƒçš„æ—¶å€™å¯ä»¥ä½¿ç”¨æ–¹æ³•`.state_dict()`è·å–ä¸€ä¸ªå‚æ•°çš„å­—å…¸ ```python net nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1)) X torch.rand(size (2, 4)) net(X) print(net[2].state_dict()) \"\"\" OrderedDict([('weight', tensor([[ 0.2906, 0.0455, 0.0842, 0.2922, 0.2123, 0.0884, 0.2132, 0.2961]])), ('bias', tensor([0.1226]))]) \"\"\" net.state_dict()['2.bias'].data \"\"\" net.state_dict()['2.bias'].data \"\"\" ``` + å¯ä»¥å•ç‹¬çš„è®¿é—®æŸä¸€ä¸ªå‚æ•° ```python print(type(net[2].bias)) print(net[2].bias) print(net[2].bias.data) \"\"\" <class 'torch.nn.parameter.Parameter'> Parameter containing: tensor([0.1226], requires_grad True) tensor([0.1226]) \"\"\" ``` + ä¹Ÿå¯ä»¥çœ‹å‚æ•°çš„æ¢¯åº¦ ```python net[2].bias.grad None #è¿˜æ²¡æœ‰è®¡ç®— ``` + éå†å‚æ•° ```python print(*[(name, param.shape) for name, param in net[0].named_parameters()]) print(*[(name, param.shape) for name, param in net.named_parameters()]) \"\"\" ('weight', torch.Size([8, 4])) ('bias', torch.Size([8])) ('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1])) \"\"\" ``` + åµŒå¥—çš„è·å–å‚æ•° ```python def block1(): return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU()) def block2(): net nn.Sequential() for i in range(4): net.add_module(f'block {i}', block1()) return net rgnet nn.Sequential(block2(), nn.Linear(4, 1)) rgnet(X) ``` > å¯ä»¥é€šè¿‡ç›´æ¥æ‰“å°çš„æ–¹å¼è·å–ä¸€ä¸‹è¿™ä¸€ä¸ªçš„å®é™…æ¨¡å‹æ ·å¼ > > ```python > print(rgnet) > \"\"\" > Sequential( > (0): Sequential( > (block 0): Sequential( > (0): Linear(in_features 4, out_features 8, bias True) > (1): ReLU() > (2): Linear(in_features 8, out_features 4, bias True) > (3): ReLU() > ) > (block 1): Sequential( > (0): Linear(in_features 4, out_features 8, bias True) > (1): ReLU() > (2): Linear(in_features 8, out_features 4, bias True) > (3): ReLU() > ) > (block 2): Sequential( > (0): Linear(in_features 4, out_features 8, bias True) > (1): ReLU() > (2): Linear(in_features 8, out_features 4, bias True) > (3): ReLU() > ) > (block 3): Sequential( > (0): Linear(in_features 4, out_features 8, bias True) > (1): ReLU() > (2): Linear(in_features 8, out_features 4, bias True) > (3): ReLU() > ) > ) > (1): Linear(in_features 4, out_features 1, bias True) > ) > \"\"\" > # è·å– æ¨¡å‹å‚æ•° > print(rgnet[0][1][0].bias.data) > \"\"\" > tensor([ 0.2361, 0.1758, 0.4468, 0.2908, 0.0806, 0.0225, 0.1792, 0.0419]) > \"\"\" > ``` ### åˆå§‹åŒ–å‚æ•° ```python def init_normal(m): if type(m) nn.Linear: nn.init.normal_(m.weight, mean 0, std 0.01) nn.init.zeros_(m.bias) net.apply(init_normal) net[0].weight.data[0], net[0].bias.data[0] ``` å¯ä»¥åœ¨ä¸åŒçš„å±‚ä½¿ç”¨ä¸åŒçš„åˆå§‹åŒ–å‚æ•° ```python def xavier(m): if type(m) nn.Linear: nn.init.xavier_uniform_(m.weight) # ä½¿ç”¨å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–, uniformæ˜¯å‡åŒ€åˆ†å¸ƒ, axvieræ˜¯æ­£æ€åˆ†å¸ƒ def init_42(m): if type(m) nn.Linear: nn.init.constant_(m.weight, 42) net[0].apply(xavier) net[2].apply(init_42) print(net[0].weight.data[0]) print(net[2].weight.data) \"\"\" tensor([ 0.1802, 0.4651, 0.5505, 0.2359]) tensor([[42., 42., 42., 42., 42., 42., 42., 42.]]) \"\"\" ``` å¯ä»¥ç›´æ¥è®¾ç½®å¯¹åº”çš„ä½ç½® ```python net[0].weight.data[0] + 1 ``` ### å‚æ•°ç»‘å®š ä¸¤ä¸ªå±‚ä½¿ç”¨åŒæ ·çš„å‚æ•°, åšä¸€ä¸ªå‚æ•°çš„ç»‘å®š ```python shared nn.Linear(8, 8) net nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared, nn.ReLU(), nn.Linear(8, 1)) net(X) ``` ä½¿ç”¨è¿™ä¸€ç§çš„æ—¶å€™, ç¬¬äºŒå±‚ä»¥åŠç¬¬å››å±‚çš„å‚æ•°çš„æ›´æ–°æ˜¯ç›¸åŒçš„ ## è‡ªå®šä¹‰å±‚ ```python class CenteredLayer(nn.Module): def __init__(self): super(CenteredLayer, self).__init__() def forward(self, X): return X X.mean() net nn.Sequential(nn.Linear(8, 128), CenteredLayer()) Y net(torch.rand(4, 8)) ``` æœ‰å‚æ•°çš„, å‚æ•°éœ€è¦ä½¿ç”¨nn.Parameterè¿›è¡Œåˆå§‹åŒ– ```python class MyLinear(nn.Module): def __init__(self, in_units, units): super(MyLinear, self).__init__() # Parameteré»˜è®¤è®°å½•æ¢¯åº¦ self.weight nn.Parameter(torch.randn(in_units, units)) self.bias nn.Parameter(torch.randn(units,)) def forward(self, X): linear torch.matmul(X, self.weight.data) + self.bias.data return F.relu(linear) linear MyLinear(5, 3) linear.weight ``` > ä½¿ç”¨Parameterç±»è¿›è¡Œåˆå§‹åŒ–å‚æ•°, è¿™ä¸€ä¸ªå‚æ•°ä¼šè¢«è®°å½•åœ¨Moduleé‡Œé¢, åœ¨è¿­ä»£çš„æ—¶å€™ä½¿ç”¨ ## è¯»å†™æ–‡ä»¶ ä½¿ç”¨`torch.save`è®°å½•ä¸€ä¸ªå¯¹è±¡ ```python x torch.arange(10) torch.save(x, 'x file') x2 torch.load('x file') ``` å®é™…å­˜å‚¨çš„æ˜¯å¯ä»¥è®°å½•çš„æ˜¯ä¸€ä¸ªlist ```python y torch.zeros(4) torch.save([x, y], 'x files') x2, y2 torch.load('x files') ``` ä¹Ÿå¯ä»¥è®°å½•ä¸€ä¸ªå­—å…¸ ```python mydict {'x': x, 'y': y} torch.save(mydict, 'mydict') mydict2 torch.load('mydict') ``` åœ¨è®°å½•ä¸€ä¸ªæ¨¡å‹çš„æ—¶å€™, åªéœ€è¦è®°å½•æ¨¡å‹çš„æƒé‡, å®é™…è®°å½•çš„æ—¶å€™å¯ä»¥ä½¿ç”¨`.state_dict`å‚æ•°è¿›è¡Œå­˜å‚¨ ```python class MLP(nn.Module): def __init__(self): super(MLP, self).__init__() self.hidden nn.Linear(20, 256) self.out nn.Linear(256, 10) def forward(self, X): return self.out(F.relu(self.hidden(X))) net MLP() X torch.randn(size (2, 20)) Y net(X) torch.save(net.state_dict(), 'mlp.params') # åŠ è½½, åŠ è½½çš„æ—¶å€™éœ€è¦ä½¿ç”¨åŸæœ‰çš„æ¨¡å‹ clone MLP() clone.load_state_dict(torch.load('mlp.params')) clone.eval() # è¯„ä¼°æ¨¡å¼, ä¸ä½¿ç”¨dropout Y_clone clone(X) Y_clone Y ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-19-25ç›®æ ‡æ£€æµ‹.html":{"title":"ç›®æ ‡æ£€æµ‹","content":"# ç›®æ ‡æ£€æµ‹ æ£€æµ‹ä¸€ä¸ªå›¾åƒé‡Œé¢å‡ºç°çš„å†…å®¹ä»¥åŠä»–çš„ä½ç½® å®é™…ä½¿ç”¨çš„æœ‰ä¸€ä¸ªè¾¹ç¼˜æ¡†, æŠŠå®é™…çš„ä½ç½®æ¡†èµ·æ¥, ä½¿ç”¨å››ä¸ªæ•°å­—è¿›è¡Œå®šä¹‰, åŸç‚¹çš„åæ ‡æ˜¯åœ¨å·¦ä¸Šè§’, è¿™ç§çš„æ•°æ®é›†ä¸€èˆ¬æ¯”è¾ƒå° å¯ä»¥ä½¿ç”¨æ•°æ®é›†[cocoæ•°æ®é›†](cocodataset.org) ## å¦‚ä½•æ ‡ä¸€ä¸ªæ¡† ```python d2l.set_figsize() img d2l.plt.imread('../data/catdog.jpg') d2l.plt.imshow(img) ``` > åŠ è½½ä¸€ä¸ªå›¾ç‰‡å¹¶è¿›è¡Œæ£€æµ‹ å®é™…çš„è¡¨ç¤ºæœ‰å››ä¸ªè§’è¡¨ç¤ºä»¥åŠä¸­å¿ƒç‚¹è¡¨ç¤º, å†™ä¸€ä¸ªè½¬æ¢å‡½æ•° ```python # ä¸¤ç§è¡¨ç¤ºæ–¹å¼çš„è½¬æ¢ def box_corner_to_center(boxes): \"\"\"Convert from (upper left, lower right) to (center, width, height)\"\"\" x1, y1, x2, y2 boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3] cx (x1 + x2) / 2 cy (y1 + y2) / 2 w x2 x1 h y2 y1 # stackç”¨äºåˆå¹¶å¼ é‡, axis 1è¡¨ç¤ºæ²¿ç€æœ€åä¸€ä¸ªç»´åº¦åˆå¹¶ boxes torch.stack((cx, cy, w, h), axis 1) return boxes def box_center_to_corner(boxes): \"\"\"Convert from (center, width, height) to (upper left, lower right)\"\"\" cx, cy, w, h boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3] x1 cx 0.5 * w y1 cy 0.5 * h x2 cx + 0.5 * w y2 cy + 0.5 * h boxes torch.stack((x1, y1, x2, y2), axis 1) return boxes ``` > æµ‹è¯•ä¸€ä¸‹ > > ```python > dog_bbox, cat_bbox [60.0, 45.0, 378.0, 516.0], [400.0, 112.0, 655.0, 493.0] > boxes torch.tensor((dog_bbox, cat_bbox)) > box_center_to_corner(box_corner_to_center(boxes)) boxes > ``` å®é™…ç»˜åˆ¶ä¸€ä¸‹ ```python def bbox_to_rect(bbox, color): # Convert the bounding box (top left x, top left y, bottom right x, # bottom right y) format to matplotlib format: ((upper left x, upper left y), # width, height) return d2l.plt.Rectangle( xy (bbox[0], bbox[1]), width bbox[2] bbox[0], height bbox[3] bbox[1], fill False, edgecolor color, linewidth 2) fig d2l.plt.imshow(img) fig.axes.add_patch(bbox_to_rect(dog_bbox, 'blue')) fig.axes.add_patch(bbox_to_rect(cat_bbox, 'red')) ``` ![image 20250119204810105](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501192048311.png) ## æ„å»ºæ•°æ®é›† ```python import os import pandas as pd import torchvision ``` + è¯»å–ä¸€ä¸‹æ•°æ®é›† ```python def read_data_bananas(is_train True): data_dir \"../data/bananas\" csv_fname os.path.join(data_dir, 'bananas_train' if is_train else 'bananas_val',\\ 'label.csv') csv_data pd.read_csv(csv_fname) csv_data csv_data.set_index('img_name') images, targets [], [] # iterrows()è¿”å›ä¸€ä¸ªè¿­ä»£å™¨ï¼Œæ¯æ¬¡è¿­ä»£è¿”å›ä¸€ä¸ªå…ƒç»„ï¼Œ # å…ƒç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯è¡Œç´¢å¼•ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯è¯¥è¡Œçš„æ•°æ® for img_name, target in csv_data.iterrows(): # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°æ®åŠ è½½å›¾ç‰‡ images.append(torchvision.io.read_image( os.path.join(data_dir, 'bananas_train' if is_train else 'bananas_val', \"images\", img_name))) targets.append(list(target)) # unsqueeze(1)è¡¨ç¤ºåœ¨ç¬¬äºŒä¸ªç»´åº¦ä¸Šå¢åŠ ä¸€ä¸ªç»´åº¦, ç”¨äºè®°å½•ä¸åŒçš„æ£€æµ‹ç»“æœ # / 256è¡¨ç¤ºå°†åƒç´ å€¼ç¼©æ”¾åˆ°0åˆ°1ä¹‹é—´ return images, torch.tensor(targets).unsqueeze(1) / 256 ``` çœ‹ä¸€ä¸‹è¿™ä¸€ä¸ªåˆ°åº•è¯»å–çš„ä»€ä¹ˆæ•°æ® ```python data_dir \"../data/bananas\" csv_fname os.path.join(data_dir, 'bananas_train', 'label.csv') csv_data pd.read_csv(csv_fname) csv_data csv_data.set_index('img_name') images, targets [], [] # iterrows()è¿”å›ä¸€ä¸ªè¿­ä»£å™¨ï¼Œæ¯æ¬¡è¿­ä»£è¿”å›ä¸€ä¸ªå…ƒç»„ï¼Œå…ƒç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯è¡Œç´¢å¼•ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯è¯¥è¡Œçš„æ•°æ® for img_name, target in csv_data.iterrows(): images.append(torchvision.io.read_image(os.path.join(data_dir, 'bananas_train', \"images\", img_name))) targets.append(list(target)) print(images[0].shape, targets[1]) \"\"\" torch.Size([3, 256, 256]) [0, 68, 175, 118, 223] \"\"\" ``` > å‰é¢çš„æ˜¯å›¾ç‰‡ä¿¡æ¯, åé¢çš„æ˜¯å›¾ç‰‡çš„ç±»åˆ«åŠ ä½ç½®, ä½¿ç”¨åˆ—è¡¨è¿›è¡Œå­˜å‚¨ ```python class BananasDataset(torch.utils.data.Dataset): def __init__(self, is_train): self.features, self.labels read_data_bananas(is_train) print('read ' + str(len(self.features)) + (f' training examples' if is_train else f' validation examples')) def __getitem__(self, idx): return (self.features[idx].float(), self.labels[idx]) def __len__(self): return len(self.features) ``` > ä¸€ä¸ªæ•°æ®é›†ç±» + åŠ è½½è¿­ä»£å™¨ ```python def load_data_bananas(batch_size): train_iter torch.utils.data.DataLoader(BananasDataset(is_train True), batch_size, shuffle True) val_iter torch.utils.data.DataLoader(BananasDataset(is_train False), batch_size) return train_iter, val_iter ``` æµ‹è¯•ä¸€ä¸‹æ•ˆæœ ```python batch_size, edge_size 32, 256 train_iter, _ load_data_bananas(batch_size) batch next(iter(train_iter)) # æ ‡å·çš„1è¡¨ç¤ºæ¯ä¸ªæœ‰ä¸€ä¸ªæ ·æœ¬, 5è¡¨ç¤ºæ¯ä¸ªæ ·æœ¬æœ‰å››ä¸ªä½ç½®å’Œä¸€ä¸ªç±»åˆ« batch[0].shape, batch[1].shape \"\"\" read 1000 training examples read 100 validation examples (torch.Size([32, 3, 256, 256]), torch.Size([32, 1, 5])) \"\"\" ``` æ˜¾ç¤ºä¸€ä¸‹æ•ˆæœ ````python # permute(0, 2, 3, 1)è¡¨ç¤ºå°†ç¬¬0ç»´å’Œç¬¬3ç»´äº¤æ¢ä½ç½® imgs (batch[0][0:10].permute(0, 2, 3, 1)) / 256 axes d2l.show_images(imgs, 2, 5, scale 2) for ax, label in zip(axes, batch[1][0:10]): d2l.show_bboxes(ax, [label[0][1:5] * edge_size], colors ['w']) ```` ![image 20250120112533660](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501201125770.png) ## é”šæ¡† é¦–å…ˆæå‡ºå¤šä¸ªé”šæ¡†åŒºåŸŸ, é¦–å…ˆé¢„æµ‹ä¸€ä¸‹æ¯ä¸€ä¸ªé”šæ¡†é‡Œé¢æ˜¯å¦æœ‰å…³æ³¨çš„ç‰©ä½“, å¦‚æœæ˜¯é¢„æµ‹ä»è¿™ä¸€ä¸ªé”šæ¡†å‘ç‰©ä½“è¾¹ç¼˜åç§» ### IoUäº¤å¹¶æ¯” è®¡ç®—ä¸¤ä¸ªæ¡†ä¹‹é—´çš„é‡åˆä½ç½®çš„å¤§å° ![image 20250120113042966](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501201130044.png) å®é™…è®­ç»ƒçš„æ—¶å€™æ¯ä¸€ä¸ªé”šæ¡†æ˜¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬, å®é™…æ ‡æ³¨çš„æ˜¯èƒŒæ™¯æˆ–è€…ä¸€ä¸ªçœŸå®çš„è¾¹ç¼˜æ¡†(å’ŒæŸä¸€ä¸ªç‰©ä½“å…³è”) > å®é™…ä½¿ç”¨çš„æ—¶å€™æ£€æµ‹æ‰€æœ‰å€¼é‡Œé¢IoUæœ€å¤§çš„ä¸€ä¸ªæ•°å€¼, å–å‡ºæ¥, ä¹‹åè¿™ä¸€ä¸ªå€¼å¯¹åº”çš„é”šæ¡†ä»¥åŠå¯¹åº”çš„å±æ€§ä¸å†å‚ä¸æ¯”è¾ƒ, ä¾æ¬¡å–å‡ºæ¦‚ç‡æœ€å¤§çš„ä¸ºé¢„æµ‹å€¼ ## ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶NMS æ¯ä¸€ä¸ªé”šæ¡†æ˜¯é¢„æµ‹ä¸€ä¸ªè¾¹ç¼˜æ¡†, NMSå¯ä»¥åˆå¹¶ç›¸ä¼¼çš„é¢„æµ‹ å®é™…é€‰ä¸­çš„æ˜¯éèƒŒæ™¯ç±»é‡Œé¢çš„æœ€å¤§é¢„æµ‹å€¼, å»æ‰æ‰€æœ‰å’Œä»–çš„IoUå€¼å¤§äº$\\theta$çš„é¢„æµ‹, é‡å¤ä¸Šé¢çš„è¿‡ç¨‹ç›´åˆ°æ‰€æœ‰çš„é¢„æµ‹è¦ä¸è¢«é€‰æ‹©, è¦ä¸è¢«å»æ‰ ## å®é™…ä½¿ç”¨ ![image 20250120170524887](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501201705996.png) > wæ˜¯å›¾ç‰‡å®½, hæ˜¯å›¾ç‰‡é«˜, sæ˜¯å¤§å°å æ€»å›¾ç‰‡æ¯”é‡, ræ˜¯å®½é«˜æ¯”, åªè€ƒè™‘è¿™ä¸€ä¸ªç»„åˆæ˜¯ä¸ºäº†é¿å…äº§ç”Ÿçš„æ•°é‡è¿‡å¤§, è¿™é‡Œçš„s1å’Œr1æ˜¯å®é™…æœ€é€‚åˆçš„, å®é™…çš„æ¯ä¸€ä¸ªåƒç´ çš„ç”Ÿæˆçš„é”šæ¡†æ•°é‡æ˜¯$nums\\_size + nums\\_ration 1$ + ä¸ºæ¯ä¸€ä¸ªåƒç´ ç”Ÿæˆè‹¥å¹²ä¸ªé”šç‚¹ è¿™ä¸€ä¸ªè¿”å›çš„æ˜¯æ¯”ä¾‹, æ‰€ä»¥å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå°çš„æ•°ç»„, ä¹‹åä¹˜å›¾ç‰‡çš„é•¿å®½, è·å–æŒ‰æ¯”ä¾‹ç”Ÿæˆ ```python def multibox_prior(data, sizes, ratios): \"\"\"ç”Ÿæˆä»¥æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒå…·æœ‰ä¸åŒå½¢çŠ¶çš„é”šæ¡†ã€‚\"\"\" in_height, in_width data.shape[ 2:] # è¾“å…¥æ•°æ®çš„é«˜å’Œå®½ device, num_sizes, num_ratios data.device, len(sizes), len(ratios) # æ¯ä¸ªåƒç´ ç”Ÿæˆçš„é”šæ¡†æ•°é‡ boxes_per_pixel (num_sizes + num_ratios 1) size_tensor torch.tensor(sizes, device device) ratio_tensor torch.tensor(ratios, device device) offset_h, offset_w 0.5, 0.5 # ä¸­å¿ƒåƒç´ çš„åç§»é‡, ä½œç”¨æ˜¯å°†é”šæ¡†çš„ä¸­å¿ƒç‚¹æ”¾åœ¨åƒç´ çš„ä¸­å¿ƒ steps_h 1.0 / in_height steps_w 1.0 / in_width # é«˜å’Œå®½çš„æ­¥å¹… # ç”Ÿæˆé”šæ¡†çš„ä¸­å¿ƒç‚¹ center_h (torch.arange(in_height, device device) + offset_h) * steps_h center_w (torch.arange(in_width, device device) + offset_w) * steps_w # ç”Ÿæˆä»¥æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒå…·æœ‰ä¸åŒå½¢çŠ¶çš„é”šæ¡†, meshgridå‡½æ•°ç”Ÿæˆä¸¤ä¸ªçŸ©é˜µ, # ä¸€ä¸ªæ˜¯ä»¥center_hä¸ºè¡Œ, ä¸€ä¸ªæ˜¯ä»¥center_wä¸ºåˆ— shift_y, shift_x torch.meshgrid(center_h, center_w) # å°†shift_yå’Œshift_xæ‹‰å¹³, ä½œä¸ºé”šæ¡†çš„ä¸­å¿ƒç‚¹ shift_y, shift_x shift_y.reshape( 1), shift_x.reshape( 1) w torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]), sizes[0] * torch.sqrt(ratio_tensor[1:])))\\ * in_height / in_width h torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]), sizes[0] / torch.sqrt(ratio_tensor[1:]))) anchor_manipulations torch.stack( ( w, h, w, h)).T.repeat(in_height * in_width, 1) / 2 out_grid torch.stack([shift_x, shift_y, shift_x, shift_y], dim 1).repeat_interleave(boxes_per_pixel, dim 0) output out_grid + anchor_manipulations return output.unsqueeze(0) ``` å®é™…çš„æ•ˆæœ ```python img d2l.plt.imread('../data/catdog.jpg') h, w img.shape[:2] print(h, w) X torch.rand(size (1, 3, h, w)) Y multibox_prior(X, sizes [0.75, 0.5, 0.25], ratios [1, 2, 0.5]) Y.shape \"\"\" 560 728 torch.Size([1, 2038400, 4]) \"\"\" ``` > è¾“å‡ºçš„æ˜¯å›¾ç‰‡çš„å¤§å°ä»¥åŠå®é™…çš„ç”Ÿæˆçš„é”šæ¡†çš„æ•°é‡ åšä¸€ä¸ªæ˜¾ç¤ºé”šæ¡†çš„å‡½æ•°, å¯ä»¥æŒ‡å®šé”šæ¡†æ˜¾ç¤ºçš„å›¾ç‰‡, ä½ç½®, æ ‡ç­¾ä»¥åŠé¢œè‰² ```python def show_bboxes(axes, bboxes, labels None, colors None): # bboxes: n * 4, næ˜¯é”šæ¡†çš„æ•°é‡ def _make_list(obj, default_values None): # å¦‚æœobjæ˜¯None, è¿”å›default_values, å¦åˆ™è¿”å›obj if obj is None: obj default_values elif not isinstance(obj, (list, tuple)): # isinstanceå‡½æ•°ç”¨äºåˆ¤æ–­objæ˜¯å¦æ˜¯listæˆ–è€…tupleç±»å‹ obj [obj] return obj labels _make_list(labels) colors _make_list(colors, ['b', 'g', 'r', 'm', 'c']) for i, bbox in enumerate(bboxes): color colors[i % len(colors)] rect d2l.bbox_to_rect(bbox.detach().numpy(), color) axes.add_patch(rect) if labels and len(labels) > i: text_color 'k' if color 'w' else 'w' # å°†é”šæ¡†è¡¨ç¤ºæˆmatplotlibæ ¼å¼é•¿æ–¹å½¢ axes.text(rect.xy[0], rect.xy[1], labels[i], va 'center', ha 'center', fontsize 9, color text_color, bbox dict(facecolor color, lw 0)) d2l.set_figsize() bbox_scale torch.tensor((w, h, w, h)) fig d2l.plt.imshow(img) show_bboxes(fig.axes, boxes[250, 250, :, :] * bbox_scale, [ 's 0.75, r 1', 's 0.5, r 1', 's 0.25, r 1', 's 0.75, r 2', 's 0.75, r 0.5' ]) ``` + è®¡ç®—ä¸¤ä¸ªå›¾ç‰‡çš„ç›¸å…³æ€§ ```python def box_iou(boxes1, boxes2): \"\"\"è®¡ç®—ä¸¤ä¸ªé”šæ¡†æˆ–è¾¹ç•Œæ¡†åˆ—è¡¨ä¸­æˆå¯¹çš„äº¤å¹¶æ¯”ã€‚\"\"\" box_area lambda boxes: ((boxes[:, 2] boxes[:, 0]) * (boxes[:, 3] boxes[:, 1])) areas1 box_area(boxes1) areas2 box_area(boxes2) inter_upperlefts torch.max(boxes1[:, None, :2], boxes2[:, :2]) inter_lowerrights torch.min(boxes1[:, None, 2:], boxes2[:, 2:]) # clampå‡½æ•°ç”¨äºå°†å°äº0çš„å€¼è®¾ç½®ä¸º0 inters (inter_lowerrights inter_upperlefts).clamp(min 0) inter_areas inters[:, :, 0] * inters[:, :, 1] union_areas areas1[:, None] + areas2 inter_areas return inter_areas / union_areas ``` + æ‰¾åˆ°æ¯ä¸ªé”šæ¡†ä¸å…¶äº¤å¹¶æ¯”æœ€å¤§çš„çœŸå®è¾¹ç•Œæ¡†ï¼Œå¹¶å°†è¿™äº›é”šæ¡†çš„ç´¢å¼•å­˜å‚¨åœ¨anchors_bbox_map ground_truth: çœŸå®è¾¹ç•Œæ¡†çš„å¼ é‡ã€‚ anchors: é”šæ¡†çš„å¼ é‡ã€‚ iou_threshold: äº¤å¹¶æ¯”é˜ˆå€¼ï¼Œé»˜è®¤å€¼ä¸º 0.5 > æ²¡æœ‰åŒ¹é…åˆ°çš„é”šæ¡†çš„å¯¹åº”è¿”å›å€¼æ˜¯ 1, å¦‚æœæŸä¸ªé”šæ¡†æœ‰å¯¹åº”çš„çœŸå®è¾¹ç•Œæ¡†ï¼Œå…¶å€¼ä¸ºè¯¥çœŸå®è¾¹ç•Œæ¡†åœ¨ ground_truth å¼ é‡ä¸­çš„ç´¢å¼•ã€‚ ```python def assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold 0.5): \"\"\"è·å–æ¯ä¸€ä¸ªåˆ†ç±»é‡Œé¢çš„æœ€æ¥è¿‘çš„é‚£ä¸€é¡¹\"\"\" num_anchors, num_gt_boxes anchors.shape[0], ground_truth.shape[0] jaccard box_iou(anchors, ground_truth) # è®¡ç®—äº¤å¹¶æ¯” anchors_bbox_map torch.full((num_anchors,), 1, dtype torch.long, device device) # å°†è¿”å›é”šæ¡†çš„ç´¢å¼•è®¾ç½®ä¸º 1 max_ious, indices torch.max(jaccard, dim 1) # torch.nonzeroå‡½æ•°ç”¨äºè¿”å›é0å…ƒç´ çš„ç´¢å¼• anc_i torch.nonzero(max_ious > 0.5).reshape( 1) box_j indices[max_ious > 0.5] anchors_bbox_map[anc_i] box_j col_discard torch.full((num_anchors,), 1) # å°†åˆ—è®¾ç½®ä¸º 1 row_discard torch.full((num_gt_boxes,), 1) for _ in range(num_gt_boxes): max_idx torch.argmax(jaccard) box_idx (max_idx % num_gt_boxes).long() # è®¡ç®—æœ€å¤§å€¼çš„åˆ—ç´¢å¼• anc_idx (max_idx / num_gt_boxes).long() # è®¡ç®—æœ€å¤§å€¼çš„è¡Œç´¢å¼• anchors_bbox_map[anc_idx] box_idx # å°†é”šæ¡†çš„è¿™ä¸€ä¸ªå¯¹åº”ç´¢å¼•è®¾ç½®ä¸ºçœŸå®è¾¹ç•Œæ¡†çš„ç´¢å¼• jaccard[:, box_idx] col_discard # å°†åˆ—è®¾ç½®ä¸º 1 jaccard[anc_idx, :] row_discard # å°†è¡Œè®¾ç½®ä¸º 1 return anchors_bbox_map ``` + å¯¹è·å–çš„é”šæ¡†è®¡ç®—ä¸€ä¸‹åç§»çš„å¤§å° ç»™å®šæ¡†Aå’ŒBï¼Œä¸­å¿ƒåæ ‡åˆ†åˆ« ä¸º(xa, ya)å’Œ(xb, yb)ï¼Œå®½åº¦åˆ†åˆ«ä¸ºwaå’Œwbï¼Œé«˜åº¦åˆ†åˆ«ä¸ºhaå’Œhbï¼Œå¯ä»¥å°†Açš„åç§»é‡æ ‡è®°ä¸º ![image 20250120182337742](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501201823821.png) å…¶ä¸­å¸¸é‡çš„é»˜è®¤å€¼ä¸º Âµx Âµy Âµw Âµh 0, Ïƒx Ïƒy 0.1 ï¼ŒÏƒw Ïƒh 0.2ã€‚ ```python def offset_boxes(anchors, assigned_bb, eps 1e 6): \"\"\"å¯¹é”šæ¡†åç§»é‡çš„è½¬æ¢ã€‚\"\"\" c_anc d2l.box_corner_to_center(anchors) c_assigned_bb d2l.box_corner_to_center(assigned_bb) offset_xy 10 * (c_assigned_bb[:, :2] c_anc[:, :2]) / c_anc[:, 2:] offset_wh 5 * torch.log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:]) offset torch.cat([offset_xy, offset_wh], axis 1) return offset ``` + ä½¿ç”¨ä»¥ä¸Šçš„ä¸¤ä¸ªæŠ€æœ¯è·å–åˆ°æ‰€æœ‰é”šæ¡†é‡Œé¢æœ‰æ•ˆçš„æ¡†ä»¥åŠä»–å¯¹åº”çš„ç±»å‹å’Œåç§» ä½¿ç”¨éšæœºçš„è¾¹æ¡†ä»¥åŠç”Ÿæˆçš„è¾¹æ¡†æ¥è¿›è¡Œç”Ÿæˆé¢„æµ‹ç»“æœ, å¯¹éšæœºçš„è¾¹æ¡†è¿›è¡Œè®¡ç®—ç§ç±»ä»¥åŠåç§»å’Œæ©ç  ```python def multibox_target(anchors, labels): \"\"\"ä½¿ç”¨çœŸå®è¾¹ç•Œæ¡†æ ‡è®°é”šæ¡†ã€‚\"\"\" batch_size, anchors labels.shape[0], anchors.squeeze(0) batch_offset, batch_mask, batch_class_labels [], [], [] device, num_anchors anchors.device, anchors.shape[0] for i in range(batch_size): label labels[i, :, :] anchors_bbox_map assign_anchor_to_bbox(label[:, 1:], anchors, device) # å°†æœ€æ¥è¿‘çš„çœŸå®è¾¹ç•Œæ¡†åˆ†é…ç»™é”šæ¡† bbox_mask ((anchors_bbox_map > 0).float().unsqueeze( 1)).repeat( 1, 4) class_labels torch.zeros(num_anchors, dtype torch.long, device device) assigned_bb torch.zeros((num_anchors, 4), dtype torch.float32, device device) indices_true torch.nonzero(anchors_bbox_map > 0) bb_idx anchors_bbox_map[indices_true] class_labels[indices_true] label[bb_idx, 0].long() + 1 assigned_bb[indices_true] label[bb_idx, 1:] offset offset_boxes(anchors, assigned_bb) * bbox_mask batch_offset.append(offset.reshape( 1)) batch_mask.append(bbox_mask.reshape( 1)) batch_class_labels.append(class_labels) bbox_offset torch.stack(batch_offset) bbox_mask torch.stack(batch_mask) class_labels torch.stack(batch_class_labels) # è¿”å›çš„bbox_offset, bbox_mask, class_labelsçš„å½¢çŠ¶æ˜¯(æ‰¹é‡å¤§å°, é”šæ¡†æ•°é‡ * 4), (æ‰¹é‡å¤§å°, é”šæ¡†æ•°é‡ * 1), (æ‰¹é‡å¤§å°, é”šæ¡†æ•°é‡ * 1) # bbox_offsetæ˜¯åç§»é‡, bbox_maskæ˜¯é”šæ¡†çš„æ©ç , class_labelsæ˜¯ç±»åˆ«æ ‡ç­¾ return (bbox_offset, bbox_mask, class_labels) ``` ä¸‹é¢ä½¿ç”¨è¿™ä¸€ä¸ªå‡½æ•°åšä¸€æ¬¡å¤„ç† ```python ground_truth torch.tensor([[0, 0.1, 0.08, 0.52, 0.92], [1, 0.55, 0.2, 0.9, 0.88]]) # ä¸¤ä¸ªçœŸå®è¾¹ç•Œæ¡† anchors torch.tensor([[0, 0.1, 0.2, 0.3], [0.15, 0.2, 0.4, 0.4], [0.63, 0.05, 0.88, 0.98], [0.66, 0.45, 0.8, 0.8], [0.57, 0.3, 0.92, 0.9]]) # 5ä¸ªç”Ÿæˆçš„é”šæ¡† # æ˜¾ç¤ºä¸€ä¸‹åœ¨å›¾ç‰‡é‡Œé¢çš„ä½ç½® fig d2l.plt.imshow(img) show_bboxes(fig.axes, ground_truth[:, 1:] * bbox_scale, ['dog', 'cat'], 'k') show_bboxes(fig.axes, anchors * bbox_scale, ['0', '1', '2', '3', '4']) ``` ![image 20250120193747663](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501201937793.png) ```python labels multibox_target(anchors.unsqueeze(dim 0), ground_truth.unsqueeze(dim 0)) labels[2] # åˆ†ç±»çš„ç»“æœ, 0è¡¨ç¤ºèƒŒæ™¯, 1è¡¨ç¤ºç‹—, 2è¡¨ç¤ºçŒ« \"\"\" tensor([[0, 1, 2, 0, 2]]) \"\"\" labels[1] # æ©ç , ä¸º1çš„è¡¨ç¤ºé”šæ¡†æœ‰æ•ˆ, ä¸º0çš„è¡¨ç¤ºé”šæ¡†æ— æ•ˆ \"\"\" tensor([[0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.]]) \"\"\" labels[0] # åç§»é‡ \"\"\" tensor([[ 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.40e+00, 1.00e+01, 2.59e+00, 7.18e+00, 1.20e+00, 2.69e 01, 1.68e+00, 1.57e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 5.71e 01, 1.00e+00, 4.17e 06, 6.26e 01]]) \"\"\" ``` + è¿™ä¸ªå‡½æ•°çš„ç›®çš„æ˜¯æ ¹æ®é¢„æµ‹çš„åç§»é‡æ¥è°ƒæ•´é”šæ¡†ï¼Œä»è€Œå¾—åˆ°é¢„æµ‹çš„è¾¹ç•Œæ¡†ã€‚ å‡½æ•°é€šè¿‡å°†é”šæ¡†è½¬æ¢ä¸ºä¸­å¿ƒåæ ‡å’Œå®½é«˜ï¼Œç„¶åæ ¹æ®é¢„æµ‹çš„åç§»é‡è°ƒæ•´è¿™äº›å€¼ï¼Œæœ€åå†è½¬æ¢å›å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡ï¼Œä»è€Œå¾—åˆ°é¢„æµ‹çš„è¾¹ç•Œæ¡†ã€‚è¿™ä¸ªè¿‡ç¨‹æ¶‰åŠåˆ°å¤šä¸ªå‡½æ•°çš„è°ƒç”¨ï¼ŒåŒ…æ‹¬åæ ‡è½¬æ¢ã€æŒ‡æ•°è®¡ç®—å’Œå¼ é‡æ‹¼æ¥ã€‚ ```python def offset_inverse(anchors, offset_preds): \"\"\"æ ¹æ®å¸¦æœ‰é¢„æµ‹åç§»é‡çš„é”šæ¡†æ¥é¢„æµ‹è¾¹ç•Œæ¡†ã€‚\"\"\" anc d2l.box_corner_to_center(anchors) pred_bbox_xy (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2] pred_bbox_wh torch.exp(offset_preds[:, 2:] / 5) * anc[:, 2:] pred_bbox torch.cat((pred_bbox_xy, pred_bbox_wh), axis 1) predicted_bbox d2l.box_center_to_corner(pred_bbox) return predicted_bbox ``` + é€šè¿‡æ’åºå’Œ IoU è®¡ç®—ï¼Œé€æ­¥å»é™¤é‡å è¾ƒå¤§çš„é”šæ¡†ï¼Œåªä¿ç•™ç½®ä¿¡åº¦é«˜ä¸”ç‹¬ç«‹çš„é”šæ¡†ã€‚ 1. ä»Lä¸­é€‰å–ç½®ä¿¡åº¦æœ€é«˜çš„é¢„æµ‹è¾¹ç•Œæ¡†B1ä½œä¸ºåŸºå‡†ï¼Œç„¶åå°†æ‰€æœ‰ä¸B1çš„IoUè¶…è¿‡é¢„å®šé˜ˆå€¼Ïµçš„éåŸºå‡†é¢„æµ‹ è¾¹ç•Œæ¡†ä»Lä¸­ç§»é™¤ã€‚è¿™æ—¶ï¼ŒLä¿ç•™äº†ç½®ä¿¡åº¦æœ€é«˜çš„é¢„æµ‹è¾¹ç•Œæ¡†ï¼Œå»é™¤äº†ä¸å…¶å¤ªè¿‡ç›¸ä¼¼çš„å…¶ä»–é¢„æµ‹è¾¹ç•Œæ¡†ã€‚ ç®€è€Œè¨€ä¹‹ï¼Œé‚£äº›å…·æœ‰éæå¤§å€¼ç½®ä¿¡åº¦çš„è¾¹ç•Œæ¡†è¢«æŠ‘åˆ¶äº†ã€‚ 2. ä»Lä¸­é€‰å–ç½®ä¿¡åº¦ç¬¬äºŒé«˜çš„é¢„æµ‹è¾¹ç•Œæ¡†B2ä½œä¸ºåˆä¸€ä¸ªåŸºå‡†ï¼Œç„¶åå°†æ‰€æœ‰ä¸B2çš„IoUå¤§äºÏµçš„éåŸºå‡†é¢„æµ‹ è¾¹ç•Œæ¡†ä»Lä¸­ç§»é™¤ã€‚ 3. é‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œç›´åˆ°Lä¸­çš„æ‰€æœ‰é¢„æµ‹è¾¹ç•Œæ¡†éƒ½æ›¾è¢«ç”¨ä½œåŸºå‡†ã€‚æ­¤æ—¶ï¼ŒLä¸­ä»»æ„ä¸€å¯¹é¢„æµ‹è¾¹ç•Œæ¡†çš„IoUéƒ½å° äºé˜ˆå€¼Ïµï¼›å› æ­¤ï¼Œæ²¡æœ‰ä¸€å¯¹è¾¹ç•Œæ¡†è¿‡äºç›¸ä¼¼ã€‚ 4. è¾“å‡ºåˆ—è¡¨Lä¸­çš„æ‰€æœ‰é¢„æµ‹è¾¹ç•Œæ¡†ã€‚ ```python def nms(boxes, scores, iou_threshold): # å»é™¤ç½®æ¯”è¾ƒåƒçš„é”šæ¡†, ä»¥åŠç½®ä¿¡åº¦è¾ƒä½çš„é”šæ¡† B torch.argsort(scores, dim 1, descending True) # å¯¹ç½®ä¿¡åº¦è¿›è¡Œæ’åº keep [] # è®°å½•ä¿¡æ¯ä½¿ç”¨ while B.numel() > 0: i B[0] keep.append(i) # å–å‡ºå½“å‰ç½®ä¿¡åº¦æœ€é«˜çš„é”šæ¡†ç´¢å¼• if B.numel() 1: break iou box_iou(boxes[i, :].reshape( 1, 4), boxes[B[1:], :].reshape( 1, 4)).reshape( 1) # å°†iouå°äºé˜ˆå€¼çš„é”šæ¡†ç´¢å¼•ä¿ç•™ inds torch.nonzero(iou < iou_threshold).reshape( 1) B B[inds + 1] return torch.tensor(keep, device boxes.device) ``` + ä»ä¸€ç»„å€™é€‰è¾¹ç•Œæ¡†ä¸­é€‰æ‹©æœ€æœ‰å¯èƒ½åŒ…å«ç›®æ ‡çš„è¾¹ç•Œæ¡†ï¼ŒåŒæ—¶æŠ‘åˆ¶é‚£äº›é‡å è¾ƒå¤šçš„å†—ä½™æ¡†ã€‚ å‡½æ•°çš„è¿”å›å€¼æ˜¯ä¸€ä¸ªåŒ…å«é¢„æµ‹è¾¹ç•Œæ¡†ä¿¡æ¯çš„å¼ é‡ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒè¿”å›ä¸€ä¸ªå½¢çŠ¶ä¸º `(batch_size, num_anchors, 6)` çš„å¼ é‡ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š ä½¿ç”¨çš„æ˜¯è¾¹æ¡†ä»¥åŠæ¯ä¸€ä¸ªè¾¹æ¡†å®é™…å¯¹æ¯ä¸€ä¸ªç±»çš„é¢„æµ‹å‡†ç¡®åº¦, å’Œè¾¹æ¡†çš„åç§»ä»¥åŠé˜ˆå€¼ 1. class_idï¼šé¢„æµ‹çš„ç±»åˆ«IDã€‚å¦‚æœè¯¥è¾¹ç•Œæ¡†è¢«æŠ‘åˆ¶æˆ–ç½®ä¿¡åº¦ä½äºé˜ˆå€¼ï¼Œåˆ™ä¸º 1ã€‚ 2. `confidence`ï¼šé¢„æµ‹çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚ 3. predicted_bbï¼šé¢„æµ‹çš„è¾¹ç•Œæ¡†åæ ‡ï¼Œæ ¼å¼ä¸º `[xmin, ymin, xmax, ymax]`ã€‚ ```python def multibox_detection(cls_probs, offset_preds, anchors, nms_threshold 0.5, pos_threshold 0.009999999): \"\"\"ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶æ¥é¢„æµ‹è¾¹ç•Œæ¡†ã€‚\"\"\" # è·å–è®¾å¤‡å’Œæ‰¹é‡å¤§å° device, batch_size cls_probs.device, cls_probs.shape[0] # å‹ç¼© anchors çš„ç¬¬ä¸€ä¸ªç»´åº¦ anchors anchors.squeeze(0) # è·å–ç±»åˆ«æ•°é‡å’Œé”šæ¡†æ•°é‡ num_classes, num_anchors cls_probs.shape[1], cls_probs.shape[2] out [] for i in range(batch_size): # è·å–ç¬¬ i ä¸ªæ ·æœ¬çš„ç±»åˆ«æ¦‚ç‡å’Œåç§»é¢„æµ‹ cls_prob, offset_pred cls_probs[i], offset_preds[i].reshape( 1, 4) # è·å–æœ€å¤§ç±»åˆ«æ¦‚ç‡å’Œå¯¹åº”çš„ç±»åˆ« ID conf, class_id torch.max(cls_prob[1:], 0) # é€šè¿‡åç§»é€†å˜æ¢å¾—åˆ°é¢„æµ‹çš„è¾¹ç•Œæ¡† predicted_bb offset_inverse(anchors, offset_pred) # ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶å¾—åˆ°ä¿ç•™çš„è¾¹ç•Œæ¡†ç´¢å¼• keep nms(predicted_bb, conf, nms_threshold) # åˆ›å»ºæ‰€æœ‰é”šæ¡†çš„ç´¢å¼• all_idx torch.arange(num_anchors, dtype torch.long, device device) # åˆå¹¶ä¿ç•™çš„ç´¢å¼•å’Œæ‰€æœ‰ç´¢å¼• combined torch.cat((keep, all_idx)) # è·å–å”¯ä¸€ç´¢å¼•åŠå…¶è®¡æ•° uniques, counts combined.unique(return_counts True) # æ‰¾åˆ°æœªä¿ç•™çš„ç´¢å¼• non_keep uniques[counts 1] # åˆå¹¶ä¿ç•™å’Œæœªä¿ç•™çš„ç´¢å¼• all_id_sorted torch.cat((keep, non_keep)) # å°†æœªä¿ç•™çš„ç±»åˆ« ID è®¾ä¸º 1 class_id[non_keep] 1 # æ ¹æ®æ’åºåçš„ç´¢å¼•é‡æ–°æ’åºç±»åˆ« ID å’Œç½®ä¿¡åº¦ class_id class_id[all_id_sorted] conf, predicted_bb conf[all_id_sorted], predicted_bb[all_id_sorted] # æ‰¾åˆ°ç½®ä¿¡åº¦ä½äºé˜ˆå€¼çš„ç´¢å¼• below_min_idx (conf < pos_threshold) # å°†è¿™äº›ç´¢å¼•çš„ç±»åˆ« ID è®¾ä¸º 1 class_id[below_min_idx] 1 # è°ƒæ•´ç½®ä¿¡åº¦ conf[below_min_idx] 1 conf[below_min_idx] # å°†ç±»åˆ« IDã€ç½®ä¿¡åº¦å’Œé¢„æµ‹çš„è¾¹ç•Œæ¡†æ‹¼æ¥åœ¨ä¸€èµ· pred_info torch.cat( (class_id.unsqueeze(1), conf.unsqueeze(1), predicted_bb), dim 1) # å°†ç»“æœæ·»åŠ åˆ°è¾“å‡ºåˆ—è¡¨ä¸­ out.append(pred_info) # è¿”å›æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ return torch.stack(out) ``` + ä¸‹é¢å®é™…ä½¿ç”¨ä¸€ä¸‹ ```python anchors torch.tensor([[0.1, 0.08, 0.52, 0.92], [0.08, 0.2, 0.56, 0.95], [0.15, 0.3, 0.62, 0.91], [0.55, 0.2, 0.9, 0.88]]) # 4ä¸ªé”šæ¡† offset_preds torch.tensor([0] * anchors.numel()) # åç§»é‡ cls_probs torch.tensor([[0] * 4, [0.9, 0.8, 0.7, 0.1], [0.1, 0.2, 0.3, 0.9]]) # ç±»åˆ«æ¦‚ç‡, ä¸‰ä¸ªç±», å››ä¸ªæ¡† fig d2l.plt.imshow(img) show_bboxes(fig.axes, anchors * bbox_scale, ['dog 0.9', 'dog 0.8', 'dog 0.7', 'cat 0.9']) ``` ```python output multibox_detection(cls_probs.unsqueeze(dim 0), offset_preds.unsqueeze(dim 0), anchors.unsqueeze(dim 0), nms_threshold 0.5) output \"\"\" tensor([[[ 0.00, 0.90, 0.10, 0.08, 0.52, 0.92], [ 1.00, 0.90, 0.55, 0.20, 0.90, 0.88], [ 1.00, 0.80, 0.08, 0.20, 0.56, 0.95], [ 1.00, 0.70, 0.15, 0.30, 0.62, 0.91]]]) \"\"\" ``` + ç»˜åˆ¶ ```python fig d2l.plt.imshow(img) for i in output[0].detach().numpy(): if i[0] 1: continue label ('dog ', 'cat ')[int(i[0])] + str(i[1]) show_bboxes(fig.axes, [torch.tensor(i[2:]) * bbox_scale], label) ``` ![image 20250120195627246](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202501201956401.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-9-32-é—¨æ§å¾ªç¯å•å…ƒGRU.html":{"title":"é—¨æ§å¾ªç¯å•å…ƒGRU","content":"# é—¨æ§å¾ªç¯å•å…ƒGRU åœ¨è§‚å¯Ÿä¸€ä¸ªäº‹ç‰©çš„æ—¶å€™ä¸æ˜¯æ¯ä¸€ä¸ªå€¼éƒ½æ˜¯åŒç­‰é‡è¦çš„, éœ€è¦è®°å½•æ¯”è¾ƒé‡è¦çš„ æœ‰ä¸¤ä¸ªé—¨æ›´æ–°Updateé—¨å’Œé‡ç½®é—¨Reset, æˆ‘ä»¬æŠŠå®ƒä»¬è®¾è®¡æˆ(0,1)åŒºé—´ä¸­çš„å‘é‡ï¼Œè¿™æ ·æˆ‘ ä»¬å°±å¯ä»¥è¿›è¡Œå‡¸ç»„åˆã€‚é‡ç½®é—¨å…è®¸æˆ‘ä»¬æ§åˆ¶â€œå¯èƒ½è¿˜æƒ³è®°ä½â€çš„è¿‡å»çŠ¶æ€çš„æ•°é‡ï¼›æ›´æ–°é—¨å°†å…è®¸æˆ‘ä»¬æ§åˆ¶æ–° çŠ¶æ€ä¸­æœ‰å¤šå°‘ä¸ªæ˜¯æ—§çŠ¶æ€çš„å‰¯æœ¬ã€‚ ![image 20250209164113034](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091641069.png) ![image 20250209164131093](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091641125.png) + å€™é€‰éšè—çŠ¶æ€ ![image 20250209164514612](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091645643.png) ![image 20250209164713552](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091647591.png) è¿™é‡Œæ²¡æœ‰R~t~çš„è¯å°±å’Œä¹‹å‰çš„RNNä¸€æ ·, è¿™é‡Œçš„R~t~æ˜¯ä¸€ä¸ª0å’Œ1ä¹‹é—´çš„æ•°å­—, å¯ä»¥å¯¹Hè¿›è¡Œä¸€æ¬¡å¤„ç† R~t~å’ŒH~tâˆ’1~ çš„å…ƒç´ ç›¸ä¹˜å¯ä»¥å‡å°‘ä»¥å¾€çŠ¶æ€çš„å½±å“ã€‚æ¯å½“é‡ç½®é—¨Rtä¸­çš„é¡¹æ¥è¿‘1æ—¶ï¼Œæˆ‘ ä»¬æ¢å¤ä¸€ä¸ªå¦‚ä¸­çš„æ™®é€šçš„å¾ªç¯ç¥ç»ç½‘ç»œã€‚å¯¹äºé‡ç½®é—¨R~t~ä¸­æ‰€æœ‰æ¥è¿‘0çš„é¡¹ï¼Œå€™é€‰éšçŠ¶æ€æ˜¯ä»¥X~t~ä½œä¸ºè¾“ å…¥çš„å¤šå±‚æ„ŸçŸ¥æœºçš„ç»“æœã€‚å› æ­¤ï¼Œä»»ä½•é¢„å…ˆå­˜åœ¨çš„éšçŠ¶æ€éƒ½ä¼šè¢«é‡ç½®ä¸ºé»˜è®¤å€¼ã€‚ + éšçŠ¶æ€ ![image 20250209165501288](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091655321.png) æ¯å½“æ›´æ–°é—¨Z~t~æ¥è¿‘1æ—¶ï¼Œæ¨¡å‹å°±å€¾å‘åªä¿ç•™æ—§çŠ¶æ€ã€‚æ­¤æ—¶ï¼Œæ¥è‡ªX~t~çš„ä¿¡æ¯åŸºæœ¬ä¸Šè¢«å¿½ç•¥ï¼Œä»è€Œæœ‰æ•ˆåœ°è·³è¿‡äº†ä¾ èµ–é“¾æ¡ä¸­çš„æ—¶é—´æ­¥tã€‚ç›¸åï¼Œå½“Z~t~æ¥è¿‘0æ—¶ï¼Œæ–°çš„éšçŠ¶æ€Htå°±ä¼šæ¥è¿‘å€™é€‰éšçŠ¶æ€ËœH~t~ã€‚ ![image 20250209165927032](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091659071.png) R~t~: æ§åˆ¶å•å…ƒ, æ§åˆ¶ä¹‹å‰æ•°æ®å’Œè¿™æ¬¡æ•°æ®çš„æƒé‡, ç”¨äºè®¡ç®—ä¸€ä¸ªæ–°çš„æƒé‡ Z~t~: æ§åˆ¶å•å…ƒ, æ§åˆ¶å½“å‰è®°å½•çš„ä¿¡æ¯çš„æƒé‡å’Œæ–°è®¡ç®—å‡ºæ¥çš„æƒé‡çš„é…æ¯” ![image 20250209175125710](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091751771.png) ## ä»£ç å®ç° ````python import torch from torch import nn from d2l import torch as d2l batch_size, num_steps 32, 35 train_iter, vocab d2l.load_data_time_machine(batch_size, num_steps) ```` åˆå§‹åŒ–ä½¿ç”¨çš„å‚æ•° ```python def get_params(vocab_size, num_hiddens, device): num_inputs num_outputs vocab_size def normal(shape): return torch.randn(size shape, device device)*0.01 def three(): return (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device device)) W_xz, W_hz, b_z three() # æ›´æ–°é—¨å‚æ•° W_xr, W_hr, b_r three() # é‡ç½®é—¨å‚æ•° W_xh, W_hh, b_h three() # å€™é€‰éšçŠ¶æ€å‚æ•° # è¾“å‡ºå±‚å‚æ•° W_hq normal((num_hiddens, num_outputs)) b_q torch.zeros(num_outputs, device device) # é™„åŠ æ¢¯åº¦ params [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q] for param in params: param.requires_grad_(True) return params ``` åˆå§‹åŒ–ä¸€ä¸‹çŠ¶æ€ ````python def init_gru_state(batch_size, num_hiddens, device): return (torch.zeros((batch_size, num_hiddens), device device), ) ```` å®šä¹‰ä¸€ä¸‹è®¡ç®— ```python def gru(inputs, state, params): W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q params H, state outputs [] for X in inputs: Z torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z) R torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r) H_tilda torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h) H Z * H + (1 Z) * H_tilda Y H @ W_hq + b_q outputs.append(Y) return torch.cat(outputs, dim 0), (H,) ``` ä½¿ç”¨ä¹‹å‰å®ç°çš„å‡½æ•°è¿›è¡Œè®­ç»ƒ ```python vocab_size, num_hiddens, device len(vocab), 256, d2l.try_gpu() num_epochs, lr 500, 1 model d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_params, init_gru_state, gru) d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) ``` ### ç®€å•å®ç° ```python num_inputs vocab_size gru_layer nn.GRU(num_inputs, num_hiddens) model d2l.RNNModel(gru_layer, len(vocab)) model model.to(device) d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-17-23å¾®è°ƒ.html":{"title":"å¾®è°ƒ","content":"# å¾®è°ƒ å®é™…æ ‡æ³¨ä¸€ä¸ªå¤§çš„æ•°æ®é›†æ˜¯å¾ˆè´µçš„, é€šå¸¸æˆ‘ä»¬åœ¨ä¸€ä¸ªå¤§çš„æ•°æ®é›†ä¸Šé¢è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œå¾®è°ƒ ä¸€ä¸ªç¥ç»ç½‘ç»œä¸€èˆ¬æœ‰ä¸¤åŒºåŸŸ, ä¸€éƒ¨åˆ†æ˜¯è¿›è¡Œç‰¹å¾çš„æå–, å¦ä¸€éƒ¨åˆ†æ˜¯è¿›è¡Œçº¿æ€§åˆ†ç±» å¾®è°ƒçš„å«ä¹‰æ˜¯ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„ç‰¹å¾æå–æ¨¡å‹åº”è¯¥å¯ä»¥å¯¹æ‰€æœ‰å½¢å¼çš„æ•°æ®è¿›è¡Œç‰¹å¾æå–, ä½¿ç”¨å·²ç»è®­ç»ƒå¥½çš„æ•°æ®ä½œä¸ºæ¨¡å‹çš„åˆå§‹åŒ–çš„å‚æ•° è®­ç»ƒæ˜¯åœ¨ç›®æ ‡è®­ç»ƒé›†ä¸Šé¢çš„æ­£å¸¸çš„ä»»åŠ¡, ä½†æ˜¯ä½¿ç”¨æ›´å¼ºçš„æ­£åˆ™åŒ–, æ›´å°çš„å­¦ä¹ ç‡, åŸæ•°æ®é›†éœ€è¦è¿œè¿œå¤æ‚äºç°æœ‰çš„æ•°æ®é›†, ä¹Ÿå¯ä»¥æœ‰ç›®æ ‡æ•°æ®é›†é‡Œé¢çš„éƒ¨åˆ†æ ‡å· ç¥ç»ç½‘ç»œé‡Œé¢åº•å±‚çš„ä¿¡æ¯ä¸€èˆ¬æ¯”è¾ƒé€šç”¨, é«˜å±‚çš„ç‰¹å¾å’Œæ•°æ®é›†ç›¸å…³, å¯ä»¥å›ºå®šåº•éƒ¨çš„ä¸€éƒ¨åˆ†å±‚çš„å‚æ•°ä¸å‚ä¸æ›´æ–°(æ•°æ®é›†å¾ˆå°çš„æ—¶å€™å¯ä»¥ä½¿ç”¨) ## å®é™…ä½¿ç”¨ ```python %matplotlib inline import os import torch import torchvision from torch import nn from d2l import torch as d2l ``` + ä¸‹è½½æ•°æ®é›† ```python d2l.DATA_HUB['hotdog'] (d2l.DATA_URL + 'hotdog.zip', 'fba480ffa8aa7e0febbb511d181409f899b9baa5') data_dir d2l.download_extract('hotdog') ``` + åŠ è½½æ•°æ®é›† ```python train_imgs torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train')) test_imgs torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test')) ``` + çœ‹ä¸€ä¸‹æ•°æ® ```python hotdogs [train_imgs[i][0] for i in range(8)] not_hotdogs [train_imgs[ i 1][0] for i in range(8)] d2l.show_images(hotdogs + not_hotdogs, 2, 8, scale 1.4) ``` ![image 20250117231751401](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501172317497.png) + å¯¹æ•°æ®è¿›è¡Œä¸€äº›å¤„ç† ```python # ç”¨äºåœ¨è®­ç»ƒæœŸé—´åŠ è½½å›¾åƒçš„æ•°æ®é›†, ä½œç”¨æ˜¯å°†å›¾åƒè½¬æ¢ä¸ºæ¨¡å‹çš„è¾“å…¥ # ä½¿ç”¨è¿™ä¸ªæ•°æ®é›†çš„æ—¶å€™, normalizeå‚æ•°å°†è¢«ä¼ é€’ç»™torchvision.transforms.Compose, # ç”¨äºæ ‡å‡†åŒ–æ¯ä¸ªé€šé“, è¿™é‡Œçš„æ•°æ®æ˜¯å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹, æ‰€ä»¥ä½¿ç”¨äº†é¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•° # å¯¹åº”RGBé€šé“çš„å‡å€¼å’Œæ ‡å‡†å·® normalize torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) train_augs torchvision.transforms.Compose([ torchvision.transforms.RandomResizedCrop(224), torchvision.transforms.RandomHorizontalFlip(), torchvision.transforms.ToTensor(), normalize]) test_augs torchvision.transforms.Compose([ torchvision.transforms.Resize(256), torchvision.transforms.CenterCrop(224), torchvision.transforms.ToTensor(), normalize]) ``` + ä½¿ç”¨é¢„åŠ è½½çš„æ¨¡å‹ ```python pretrained_net torchvision.models.resnet18(pretrained True) # é¢„è®­ç»ƒæ¨¡å‹ pretrained_net.fc # æœ€åä¸€å±‚å…¨è¿æ¥å±‚ ``` + æ¨¡å‹çš„æœ€åä¸€å±‚ä½¿ç”¨2ä¸ªè¾“å‡ºçš„çº¿æ€§å±‚ ```python finetune_net torchvision.models.resnet18(pretrained True) # é‡æ–°å®šä¹‰æœ€åä¸€å±‚å…¨è¿æ¥å±‚çš„è¾“å‡ºä¸ªæ•°ç­‰äº2 finetune_net.fc nn.Linear(finetune_net.fc.in_features, 2) # åˆå§‹åŒ–æœ€åä¸€å±‚å…¨è¿æ¥å±‚çš„æƒé‡ nn.init.xavier_uniform_(finetune_net.fc.weight) ``` + å®é™…è®­ç»ƒçš„æ—¶å€™æœ€åçš„åˆ†ç±»å±‚å­¦ä¹ ç‡æ¯”è¾ƒå¤§ ```python def train_fine_tuning(net, learning_rate, batch_size 128, num_epochs 5, param_group True): train_iter torch.utils.data.DataLoader(torchvision.datasets.ImageFolder( os.path.join(data_dir, 'train'), transform train_augs), batch_size, shuffle True) test_iter torch.utils.data.DataLoader(torchvision.datasets.ImageFolder( os.path.join(data_dir, 'test'), transform test_augs), batch_size) devices d2l.try_all_gpus() loss nn.CrossEntropyLoss(reduction \"none\") if param_group: params_1x [param for name, param in net.named_parameters() if name not in ['fc.weight', 'fc.bias']] # å°†æœ€åä¸€å±‚å…¨è¿æ¥å±‚çš„å­¦ä¹ ç‡è®¾ä¸ºå·²ç»é¢„è®­ç»ƒè¿‡çš„å±‚çš„10å€ trainer torch.optim.SGD([{'params': params_1x}, {'params': net.fc.parameters(), 'lr': learning_rate * 10}], lr learning_rate, weight_decay 0.001) else: trainer torch.optim.SGD(net.parameters(), lr learning_rate, weight_decay 0.001) d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices) ``` + å¼€å§‹è®­ç»ƒ ```python train_fine_tuning(finetune_net, 5e 5) ``` ![image 20250117232058664](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501172320728.png) ![image 20250117232027224](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501172320301.png) + å¯¹æ¯”æ²¡æœ‰ä½¿ç”¨é»˜è®¤å‚æ•°çš„è®­ç»ƒ ```python scratch_net torchvision.models.resnet18() scratch_net.fc nn.Linear(scratch_net.fc.in_features, 2) train_fine_tuning(scratch_net, 5e 4, param_group False) ``` ![image 20250117232042588](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501172320668.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2024-10-31-01.html":{"title":"01 å…¥é—¨","content":"# 01 å…¥é—¨ [è¯¾ç¨‹å®‰æ’ åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ è¯¾ç¨‹ (d2l.ai)](https://courses.d2l.ai/zh v2/) [å‰è¨€ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0 documentation (d2l.ai)](https://zh v2.d2l.ai/chapter_preface/index.html) [Latest ä¸­æ–‡ç‰ˆ topics D2L Discussionè®ºå›](https://discuss.d2l.ai/c/chinese version/16) [PyTorch Forums](https://discuss.pytorch.org/) [CNN Explainer](https://poloclub.github.io/cnn explainer/) ## åŸºç¡€çŸ¥è¯† ![image 20241031130356749](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410311303879.png) ![image 20241031131130173](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410311311229.png) > é¢†åŸŸä¸“å®¶ä¸»è¦æ˜¯AIçš„åº”ç”¨åœ¨ä»–çš„é¢†åŸŸçš„åº”ç”¨ > > æ•°æ®ä¸“å®¶æ˜¯æŠŠæ•°æ®è¿›è¡ŒæŠ½è±¡è¯, è½¬ä¸ºæœºå™¨å¯ä»¥å¤„ç†çš„æ•°æ®ä»¥åŠæ¨¡å‹ > > AIä¸“å®¶å¯¹æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥çš„ä¼˜åŒ– ## ç¯å¢ƒ ```bash apt install build essential ``` > gccä¹‹ç±»çš„ç¯å¢ƒ ```bash apt install python3.8 ``` ä¹‹åå®‰è£…miniconda ```python pip install jupyter d2l torch torchvision ``` > d2læ˜¯è¿™æœ¬ä¹¦ä½¿ç”¨çš„åº“ [å‰è¨€ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0 documentation (d2l.ai)](https://zh v2.d2l.ai/chapter_preface/index.html) ![image 20241103100025173](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202411031000348.png) > ä¸‹è½½ä¸€ä¸‹è®°äº‹æœ¬"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-5-28æ ·å¼è¿ç§».html":{"title":"æ ·å¼è¿ç§»","content":"# æ ·å¼è¿ç§» ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼Œè‡ªåŠ¨å°†ä¸€ä¸ªå›¾åƒä¸­çš„é£æ ¼åº”ç”¨åœ¨å¦ä¸€å›¾åƒä¹‹ä¸Šï¼Œå³é£æ ¼è¿ç§»(åŠ ä¸€ä¸ªæ»¤é•œ) ![QQ_1738741328183](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502051542951.png) è¿™ä¸‰ä¸ªç½‘ç»œæ˜¯ä¸€æ ·çš„æ¨¡å‹, é¦–å…ˆï¼Œæˆ‘ä»¬åˆå§‹åŒ–åˆæˆå›¾åƒï¼Œä¾‹å¦‚å°†å…¶åˆ å§‹åŒ–ä¸ºå†…å®¹å›¾åƒã€‚è¯¥åˆæˆå›¾åƒæ˜¯é£æ ¼è¿ç§»è¿‡ç¨‹ä¸­å”¯ä¸€éœ€è¦æ›´æ–°çš„å˜é‡ï¼Œå³é£æ ¼è¿ç§»æ‰€éœ€è¿­ä»£çš„æ¨¡å‹å‚æ•°ã€‚ç„¶ åï¼Œæˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªé¢„è®­ç»ƒçš„å·ç§¯ç¥ç»ç½‘ç»œæ¥æŠ½å–å›¾åƒçš„ç‰¹å¾ï¼Œå…¶ä¸­çš„æ¨¡å‹å‚æ•°åœ¨è®­ç»ƒä¸­æ— é¡»æ›´æ–°ã€‚è¿™ä¸ªæ·±åº¦ å·ç§¯ç¥ç»ç½‘ç»œå‡­å€Ÿå¤šä¸ªå±‚é€çº§æŠ½å–å›¾åƒçš„ç‰¹å¾ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©å…¶ä¸­æŸäº›å±‚çš„è¾“å‡ºä½œä¸ºå†…å®¹ç‰¹å¾æˆ–é£æ ¼ç‰¹å¾ã€‚ æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é€šè¿‡å‰å‘ä¼ æ’­ï¼ˆå®çº¿ç®­å¤´æ–¹å‘ï¼‰è®¡ç®—é£æ ¼è¿ç§»çš„æŸå¤±å‡½æ•°ï¼Œå¹¶é€šè¿‡åå‘ä¼ æ’­ï¼ˆè™šçº¿ç®­å¤´æ–¹å‘ï¼‰è¿­ ä»£æ¨¡å‹å‚æ•°ï¼Œå³ä¸æ–­æ›´æ–°åˆæˆå›¾åƒã€‚é£æ ¼è¿ç§»å¸¸ç”¨çš„æŸå¤±å‡½æ•°ç”±3éƒ¨åˆ†ç»„æˆï¼š 1. å†…å®¹æŸå¤±ä½¿åˆæˆå›¾åƒä¸å†…å®¹å›¾åƒåœ¨å†…å®¹ç‰¹å¾ä¸Šæ¥è¿‘ï¼› 2. é£æ ¼æŸå¤±ä½¿åˆæˆå›¾åƒä¸é£æ ¼å›¾åƒåœ¨é£æ ¼ç‰¹å¾ä¸Šæ¥è¿‘ï¼› 3. å…¨å˜åˆ†æŸå¤±åˆ™æœ‰åŠ©äºå‡å°‘åˆæˆå›¾åƒä¸­çš„å™ªç‚¹ã€‚ > å®é™…çš„åŸç†æ˜¯ä½¿ç”¨åŸå§‹çš„å›¾åƒä¸ºå‚æ•°, æå–æ€»æ¨¡å‹é‡Œé¢çš„å‡ å±‚, åˆ†åˆ«å’Œæ ·å¼çš„å›¾ç‰‡åœ¨è¿™å‡ å±‚çš„å‚æ•°ç®—ä¸€ä¸‹å‡æ–¹å·®ä¹‹ç±»çš„è¯¯å·®, ä¹˜ä»¥æƒé‡å†ç›¸åŠ  ## ä»£ç å®ç° ```python %matplotlib inline import torch import torchvision ``` å¯¼å…¥ä½¿ç”¨çš„å›¾ç‰‡ ```python from torch import nn from d2l import torch as d2l d2l.set_figsize() content_img d2l.Image.open(\"E:/JHY/python/2024 11 3 pytorchLiMu/jupyrt/img/rainier.jpg\") d2l.plt.imshow(content_img) ``` ![image 20250205172536078](C:\\Users\\jiao\\AppData\\Roaming\\Typora\\typora user images\\image 20250205172536078.png) ```python style_img d2l.Image.open('E:/JHY/python/2024 11 3 pytorchLiMu/jupyrt/img/autumn oak.jpg') d2l.plt.imshow(style_img) ``` ![image 20250205172549452](C:\\Users\\jiao\\AppData\\Roaming\\Typora\\typora user images\\image 20250205172549452.png) + é¢„å¤„ç†å›¾ç‰‡ä½¿å›¾ç‰‡ä¾¿äºå¤„ç† ```python rgb_mean torch.tensor([0.485, 0.456, 0.406]) rgb_std torch.tensor([0.229, 0.224, 0.225]) # å¤„ç†ç”¨ä¸€ä¸‹å›¾ç‰‡ def preprocess(img, image_shape): transforms torchvision.transforms.Compose([ torchvision.transforms.Resize(image_shape), torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean rgb_mean, std rgb_std)]) return transforms(img).unsqueeze(0) def postprocess(img): img img[0].to(rgb_std.device) img torch.clamp(img.permute(1, 2, 0) * rgb_std + rgb_mean, 0, 1) return torchvision.transforms.ToPILImage()(img.permute(2, 0, 1)) ``` + åŠ è½½ä¸€ä¸ªå›¾å½¢å¤„ç†æ¨¡å‹ ```python pretrained_net torchvision.models.vgg19(pretrained True) ``` + ç¡®å®šä¸€ä¸‹ä½¿ç”¨çš„å±‚ ```python # æ ·å¼ä»¥åŠå†…å®¹å±‚, åº•å±‚å¯¹äºå›¾åƒçš„ç»†èŠ‚æè¿°æ›´åŠ è¯¦ç»†, è€Œé«˜å±‚å¯¹äºå›¾åƒçš„å…¨å±€ä¿¡æ¯æè¿°æ›´åŠ è¯¦ç»† style_layers, content_layers [0, 5, 10, 19, 28], [25] ``` å®é™…ä½¿ç”¨çš„æ—¶å€™åªåŠ è½½è¿™å‡ ä¸ªå±‚ä½œä¸ºæ¨¡å‹ ```python net nn.Sequential(*[pretrained_net.features[i] for i in range(max(content_layers + style_layers) + 1)]) ``` + å¯¹äºä¸€ä¸ªè¾“å…¥çš„Xä¾æ¬¡é€šè¿‡è¿™å‡ ä¸ªå±‚è·å–å‚æ•° ```python # è·å–ä¸€ä¸‹å†…å®¹å’Œæ ·å¼çš„ç‰¹å¾, ç”±äºä¸è¿›è¡Œæ”¹å˜,æ‰€ä»¥å¯ä»¥ç›´æ¥è¿›è¡ŒæŠ½å– def extract_features(X, content_layers, style_layers): contents [] styles [] for i in range(len(net)): X net[i](X) if i in style_layers: styles.append(X) if i in content_layers: contents.append(X) return contents, styles ``` + è®¡ç®—è·å–å‚æ•° ```python def get_contents(image_shape, device): content_X preprocess(content_img, image_shape).to(device) # é¢„å¤„ç†å›¾ç‰‡ # æå–å†…å®¹çš„ç‰¹å¾å±‚ contents_Y, _ extract_features(content_X, content_layers, style_layers) return content_X, contents_Y # è·å–æ ·å¼å›¾åƒ def get_styles(image_shape, device): style_X preprocess(style_img, image_shape).to(device) # æå–æ ·å¼å›¾ç‰‡çš„æ ·å¼å±‚ _, styles_Y extract_features(style_X, content_layers, style_layers) return style_X, styles_Y ``` + å®é™…çš„è®¡ç®—æŸå¤±çš„å‡½æ•° ```python # å†…å®¹æŸå¤± def content_loss(Y_hat, Y): # æˆ‘ä»¬ä»åŠ¨æ€è®¡ç®—æ¢¯åº¦çš„æ ‘ä¸­åˆ†ç¦»ç›®æ ‡ï¼š # è¿™æ˜¯ä¸€ä¸ªè§„å®šçš„å€¼ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå˜é‡ã€‚å®é™…æ˜¯è®¡ç®—åŸå§‹å›¾åƒå’Œç”Ÿæˆå›¾åƒçš„å†…å®¹çš„å‡æ–¹å·® return torch.square(Y_hat Y.detach()).mean() # æˆ‘ä»¬å¯ä»¥å°†æ­¤è¾“å‡ºè½¬æ¢ä¸ºçŸ©é˜µXï¼Œå…¶æœ‰cè¡Œå’Œhwåˆ—ã€‚è¿™ä¸ªçŸ©é˜µå¯ä»¥è¢«çœ‹ä½œç”±cä¸ªé•¿åº¦ä¸ºhwçš„ # å‘é‡x1,...,xcç»„åˆè€Œæˆçš„ã€‚å…¶ä¸­å‘é‡xiä»£è¡¨äº†é€šé“iä¸Šçš„é£æ ¼ç‰¹å¾ã€‚ def gram(X): num_channels, n X.shape[1], X.numel() // X.shape[1] # é€šé“æ•°å’Œåƒç´ æ•° X X.reshape((num_channels, n)) # å°†é€šé“æ•°æ”¾åˆ°ç¬¬ä¸€ç»´ return torch.matmul(X, X.T) / (num_channels * n) # è®¡ç®—gramçŸ©é˜µ # é£æ ¼æŸå¤± def style_loss(Y_hat, gram_Y): return torch.square(gram(Y_hat) gram_Y.detach()).mean() # æˆ‘ä»¬å­¦åˆ°çš„åˆæˆå›¾åƒé‡Œé¢æœ‰å¤§é‡é«˜é¢‘å™ªç‚¹ï¼Œå³æœ‰ç‰¹åˆ«äº®æˆ–è€…ç‰¹åˆ«æš—çš„é¢—ç²’åƒç´ ã€‚ä¸€ç§å¸¸è§çš„å»å™ªæ–¹ # æ³•æ˜¯å…¨å˜åˆ†å»å™ªï¼ˆtotalvariationdenoisingï¼‰ï¼šå‡è®¾xi,jè¡¨ç¤ºåæ ‡(i,j)å¤„çš„åƒç´ å€¼ï¼Œé™ä½å…¨å˜åˆ†æŸå¤± def tv_loss(Y_hat): return 0.5 * (torch.abs(Y_hat[:, :, 1:, :] Y_hat[:, :, : 1, :]).mean() + torch.abs(Y_hat[:, :, :, 1:] Y_hat[:, :, :, : 1]).mean()) ``` ![image 20250205173342810](C:\\Users\\jiao\\AppData\\Roaming\\Typora\\typora user images\\image 20250205173342810.png) + ä¸€ä¸ªå®é™…è¦è®­ç»ƒçš„å‚æ•° ```python class SynthesizedImage(nn.Module): # å®é™…è®­ç»ƒçš„å‚æ•°, ä¹Ÿå°±æ˜¯åˆæˆå›¾åƒ def __init__(self, img_shape, **kwargs): super(SynthesizedImage, self).__init__(**kwargs) self.weight nn.Parameter(torch.rand(*img_shape)) def forward(self): return self.weight ``` + å¯¹å‚æ•°è¿›è¡Œä¸€ä¸‹åˆå§‹åŒ– ```python def get_inits(X, device, lr, styles_Y): gen_img SynthesizedImage(X.shape).to(device) gen_img.weight.data.copy_(X.data) # åˆå§‹åŒ–ä¸ºåŸå§‹çš„å†…å®¹å›¾åƒ trainer torch.optim.Adam(gen_img.parameters(), lr lr) styles_Y_gram [gram(Y) for Y in styles_Y] return gen_img(), styles_Y_gram, trainer ``` + æ›´å…·ä¸åŒçš„æƒé‡, ç®—ä¸€ä¸‹æœ€åçš„æŸå¤± æƒé‡çš„é€‰å–å®é™…æ˜¯é€šè¿‡åœ¨æœ€åçš„ç»“æœè®¡ç®—çš„å¤§å°å·®ä¸å¤šå¾—åˆ°çš„ ```python # ä¸åŒçš„å±‚æœ‰ä¸åŒçš„æƒé‡ content_weight, style_weight, tv_weight 1, 1e3, 10 def compute_loss(X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram): # åˆ†åˆ«è®¡ç®—å†…å®¹æŸå¤±ã€é£æ ¼æŸå¤±å’Œå…¨å˜åˆ†æŸå¤± contents_l [content_loss(Y_hat, Y) * content_weight for Y_hat, Y in zip( contents_Y_hat, contents_Y)] styles_l [style_loss(Y_hat, Y) * style_weight for Y_hat, Y in zip( styles_Y_hat, styles_Y_gram)] tv_l tv_loss(X) * tv_weight # å¯¹æ‰€æœ‰æŸå¤±æ±‚å’Œ l sum(10 * styles_l + contents_l + [tv_l]) return contents_l, styles_l, tv_l, l ``` + è®­ç»ƒå‡½æ•° ```python def train(X, contents_Y, styles_Y, device, lr, num_epochs, lr_decay_epoch): X, styles_Y_gram, trainer get_inits(X, device, lr, styles_Y) scheduler torch.optim.lr_scheduler.StepLR(trainer, lr_decay_epoch, 0.8) animator d2l.Animator(xlabel 'epoch', ylabel 'loss', xlim [10, num_epochs], legend ['content', 'style', 'TV'], ncols 2, figsize (7, 2.5)) for epoch in range(num_epochs): trainer.zero_grad() contents_Y_hat, styles_Y_hat extract_features( X, content_layers, style_layers) contents_l, styles_l, tv_l, l compute_loss( X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram) l.backward() trainer.step() scheduler.step() if (epoch + 1) % 10 0: animator.axes[1].imshow(postprocess(X)) animator.add(epoch + 1, [float(sum(contents_l)), float(sum(styles_l)), float(tv_l)]) return X ``` + å¼€å§‹è®­ç»ƒ ```python device, image_shape d2l.try_gpu(), (300, 450) net net.to(device) content_X, contents_Y get_contents(image_shape, device) _, styles_Y get_styles(image_shape, device) output train(content_X, contents_Y, styles_Y, device, 0.3, 500, 50) ``` ![image 20250205173712473](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502051739641.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-5-29åºåˆ—æ¨¡å‹.html":{"title":"åºåˆ—æ¨¡å‹","content":"# åºåˆ—æ¨¡å‹ å®é™…å·¥ä½œé‡Œé¢åˆå¾ˆå¤šçš„æ•°æ®æ˜¯æœ‰æ—¶é—´åºåˆ—çš„, æ¯”å¦‚ç”µå½±çš„è¯„åˆ†ä¼šå—åˆ°è¯„å¥–çš„å½±å“, åŒæ ·é¢˜æç”µå½±éšæ—¶é—´å˜åŒ–, å¯¼æ¼”çš„è´Ÿé¢æŠ¥é“ç­‰ è¿˜æœ‰éŸ³ä¹, è¯­è¨€å’Œæ–‡æœ¬ç­‰, ä»¥åŠäººçš„äº¤äº’, é¢„æµ‹è‚¡ç¥¨ç­‰ ## ç»Ÿè®¡å·¥å…· å¤„ç†åºåˆ—æ•°æ®éœ€è¦ç»Ÿè®¡å·¥å…·å’Œæ–°çš„æ·±åº¦ç¥ç»ç½‘ç»œæ¶æ„ã€‚ ![image 20250205210840704](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502052108828.png) å…¶ä¸­ï¼Œç”¨xtè¡¨ç¤ºä»·æ ¼ï¼Œå³åœ¨æ—¶é—´æ­¥ï¼ˆtimestepï¼‰tâˆˆZ+æ—¶ï¼Œè§‚å¯Ÿåˆ°çš„ä»·æ ¼xtã€‚è¯·æ³¨æ„ï¼Œtå¯¹äºæœ¬æ–‡ä¸­çš„åºåˆ—é€šå¸¸ æ˜¯ç¦»æ•£çš„ï¼Œå¹¶åœ¨æ•´æ•°æˆ–å…¶å­é›†ä¸Šå˜åŒ–ã€‚å‡è®¾ä¸€ä¸ªäº¤æ˜“å‘˜æƒ³åœ¨tæ—¥çš„è‚¡å¸‚ä¸­è¡¨ç°è‰¯å¥½ï¼Œäºæ˜¯é€šè¿‡ä»¥ä¸‹é€”å¾„é¢„æµ‹xt x~t~âˆ¼ P(x~t~ x~t~âˆ’1,...,x~1~) ![image 20250205211512307](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502052115355.png) > æ­£å‘å’Œåå‘, åå‘ä¸ä¸€å®šæ˜¯æˆç«‹çš„, å·²çŸ¥ç»“æœæ¨åŸç† ![image 20250205211828134](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502052118182.png) ä½¿ç”¨å‰é¢çš„æ ·æœ¬æ¨å‡ºæ¥ä¸€ä¸ªå’Œå‰é¢æ ·æœ¬ç›¸åŒçš„æ–°çš„æ ·æœ¬, éœ€è¦è®¡ç®—få’Œp, æœ‰å‡ ç§å‡è®¾ ![image 20250205212009505](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502052120554.png) è¿™æ ·è®¡ç®—çš„æ—¶å€™æ‰€éœ€è¦è®¡ç®—çš„æ•°æ®æ•°é‡æ˜¯ä¸€å®šçš„, æ˜¯å‚æ•°çš„æ•°é‡æ€»æ˜¯ä¸å˜çš„ï¼Œè‡³å°‘ åœ¨t >Ï„æ—¶å¦‚æ­¤ï¼Œè¿™å°±ä½¿æˆ‘ä»¬èƒ½å¤Ÿè®­ç»ƒä¸€ä¸ªä¸Šé¢æåŠçš„æ·±åº¦ç½‘ç»œã€‚è¿™ç§æ¨¡å‹è¢«ç§°ä¸º**è‡ªå›å½’æ¨¡å‹** ![image 20250205212335849](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502052123894.png) ä¿ç•™ä¸€äº›å¯¹è¿‡å»è§‚æµ‹çš„æ€»ç»“h~t~, æ˜¯ä¸€ä¸ªå‘é‡æˆ–è€…ä¸€ä¸ªæ•°ä¹‹ç±»çš„æ•°æ®, æ˜¯ä¸€ä¸ªä¸æ–­æ›´æ–°çš„æ•°æ®, è¿™æ ·å¯ä»¥å‡å°‘ç›¸å…³çš„å˜é‡, è®¡ç®—æ›´åŠ å®¹æ˜“, ç”±äºh~t~ä»æœªè¢«è§‚æµ‹åˆ°ï¼Œè¿™ç±»æ¨¡å‹ä¹Ÿè¢«ç§° ä¸ºéšå˜é‡è‡ªå›å½’æ¨¡å‹ ## å®é™…ä½¿ç”¨ è¿™é‡Œå†™ä¸€ä¸ªä½¿ç”¨å››ä¸ªæ•°æ®é¢„æµ‹ä¸‹ä¸€ä¸ªæ•°æ®çš„æ¨¡å‹ ```python %matplotlib inline import torch from torch import nn from d2l import torch as d2l ``` ç”Ÿæˆä¸€ä¸ªåˆå§‹çš„æ•°æ® ```python T 1000 # æ€»å…±äº§ç”Ÿ1000ä¸ªç‚¹ time torch.arange(1, T + 1, dtype torch.float32) x torch.sin(0.01 * time) + torch.normal(0, 0.2, (T,)) d2l.plot(time, [x], 'time', 'x', xlim [1, 1000], figsize (6, 3)) ``` ![image 20250205215501661](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502052155713.png) ```python tau 4 features torch.zeros((T tau, tau)) for i in range(tau): features[:, i] x[i: T tau + i] labels x[tau:].reshape(( 1, 1)) # æ¯ä¸€é¡¹è®°å½•å‰é¢çš„4ä¸ªç‚¹ï¼Œé¢„æµ‹æ˜¯ä¸‹ä¸€ä¸ªç‚¹ print(features[0],features.shape, labels.shape) \"\"\" tensor([ 0.1637, 0.2549, 0.0939, 0.1010]) torch.Size([996, 4]) torch.Size([996, 1]) \"\"\" ``` ä½¿ç”¨å‰å››ä¸ªæ•°æ®ä¸ºè¾“å…¥, ä¸‹ä¸€ä¸ªæ•°æ®æ˜¯è¾“å‡º, ä¸‹é¢åˆ’åˆ†è®­ç»ƒçš„æ•°æ®é›† ```python batch_size, n_train 16, 600 # åªæœ‰å‰n_trainä¸ªæ ·æœ¬ç”¨äºè®­ç»ƒ train_iter d2l.load_array((features[:n_train], labels[:n_train]), batch_size, is_train True) ``` ```python # åˆå§‹åŒ–ç½‘ç»œæƒé‡çš„å‡½æ•° def init_weights(m): if type(m) nn.Linear: nn.init.xavier_uniform_(m.weight) # ä¸€ä¸ªç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœº def get_net(): net nn.Sequential(nn.Linear(4, 10), nn.ReLU(), nn.Linear(10, 1)) net.apply(init_weights) return net # å¹³æ–¹æŸå¤±ã€‚æ³¨æ„ï¼šMSELossè®¡ç®—å¹³æ–¹è¯¯å·®æ—¶ä¸å¸¦ç³»æ•°1/2 # å‡æ–¹è¯¯å·®ï¼ˆMean Squared Errorï¼ŒMSEï¼‰æ˜¯å›å½’é—®é¢˜ä¸­æœ€å¸¸ç”¨çš„æ€§èƒ½åº¦é‡ loss nn.MSELoss(reduction 'none') ``` å»ºç«‹ä¸€ä¸ªç®€å•çš„ç½‘ç»œ ````python onestep_preds net(features) d2l.plot([time, time[tau:]], [x.detach().numpy(), onestep_preds.detach().numpy()], 'time', 'x', legend ['data', '1 step preds'], xlim [1, 1000], figsize (6, 3)) ```` é¢„æµ‹ä¸€ä¸‹ ![image 20250205215646885](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502052156935.png) åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™, æˆ‘ä»¬éœ€è¦ä½¿ç”¨è‡ªå·±é¢„æµ‹çš„æ•°æ®ä½œä¸ºå‚æ•°é¢„æµ‹ä¸‹ä¸€ä¸ªæ•°æ® ```python multistep_preds torch.zeros(T) multistep_preds[: n_train + tau] x[: n_train + tau] for i in range(n_train + tau, T): # ä½¿ç”¨å‰é¢çš„æ•°æ®é¢„æµ‹ä¸ºä¸‹ä¸€ä¸ªçš„å‚æ•° multistep_preds[i] net( multistep_preds[i tau:i].reshape((1, 1))) ``` ```python d2l.plot([time, time[tau:], time[n_train + tau:]], [x.detach().numpy(), onestep_preds.detach().numpy(), multistep_preds[n_train + tau:].detach().numpy()], 'time', 'x', legend ['data', '1 step preds', 'multistep preds'], xlim [1, 1000], figsize (6, 3)) ``` ![image 20250205215935851](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502052159904.png) ä¸‹é¢æ˜¯ä¸€ä¸ªéšç€é¢„æµ‹èŒƒå›´å¢å¤§å‡ºç°çš„åç§»æƒ…å†µ ```python max_steps 64 features torch.zeros((T tau max_steps + 1, tau + max_steps)) # åˆ—iï¼ˆi<tauï¼‰æ˜¯æ¥è‡ªxçš„è§‚æµ‹ï¼Œå…¶æ—¶é—´æ­¥ä»ï¼ˆiï¼‰åˆ°ï¼ˆi+T tau max_steps+1ï¼‰ for i in range(tau): features[:, i] x[i: i + T tau max_steps + 1] # åˆ—iï¼ˆi> tauï¼‰æ˜¯æ¥è‡ªï¼ˆi tau+1ï¼‰æ­¥çš„é¢„æµ‹ï¼Œå…¶æ—¶é—´æ­¥ä»ï¼ˆiï¼‰åˆ°ï¼ˆi+T tau max_steps+1ï¼‰ # é’ˆå¯¹tauåˆ°tau + max_stepsèŒƒå›´å†…çš„æ¯ä¸€ä¸ªiï¼Œ # æ¨¡å‹netä½¿ç”¨ä¹‹å‰tauä¸ªæ—¶é—´æ­¥é•¿çš„æ•°æ®æ¥å¯¹æ—¶é—´æ­¥iè¿›è¡Œé¢„æµ‹ã€‚ # é¢„æµ‹ç»“æœè¢«é‡å¡‘ä»¥åŒ¹é…æ ·æœ¬æ•°é‡ã€‚ for i in range(tau, tau + max_steps): features[:, i] net(features[:, i tau:i]).reshape( 1) ``` featureså‰å››ä¸ªæ˜¯åŸå§‹çš„æ•°æ®, ä¹‹åæ˜¯ä½¿ç”¨è¿™å››ä¸ªæ•°æ®ä¾æ¬¡é¢„æµ‹å¾—åˆ°çš„æ•°æ® ```python steps (1, 4, 16, 64) d2l.plot([time[tau + i 1: T max_steps + i] for i in steps], [features[:, (tau + i 1)].detach().numpy() for i in steps], 'time', 'x', legend [f'{i} step preds' for i in steps], xlim [5, 1000], figsize (6, 3)) ``` ![image 20250205223542214](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502052235296.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/0000-0-0-00åŸºç¡€numpy.html":{"title":"Numpy","content":"# Numpy ## æ•°æ®ç±»å‹ Numpyçš„æ•°ç»„é‡Œé¢åªä¼šæœ‰ä¸€ç§æ•°æ®ç±»å‹, ç”¨äºèŠ‚çº¦å†…å­˜, å¦‚æœé‡Œé¢æœ‰æµ®ç‚¹æ•°, æ‰€æœ‰çš„æ•°æ®éƒ½ä½¿ç”¨æµ®ç‚¹æ•°å­˜å‚¨ ```python arr1 np.array([[1, 2, 3], [4, 5, 6]]) arr1 \"\"\" array([[1, 2, 3], [4, 5, 6]]) \"\"\" ``` åœ¨ä¸€ä¸ªè¯ä¹¦çš„æ•°ç»„é‡Œé¢åŠ å…¥æµ®ç‚¹æ•°, è¿™ä¸€ä¸ªæµ®ç‚¹æ•°ä¼šè¢«æˆªæ–­, åœ¨æµ®ç‚¹æ•°é‡Œé¢æ’å…¥æ•´æ•°, è¿™ä¸€ä¸ªæ•´æ•°ä¼šè¢«å‡çº§ä¸ºæµ®ç‚¹æ•° å¦‚æœä¸€ä¸ªæ•°ç»„æƒ³è¦è½¬æ¢ç±»å‹, éœ€è¦ä½¿ç”¨æ–¹æ³•`astype` `arr1.astype(np.float64)` åœ¨å®é™…çš„è®¡ç®—çš„æ—¶å€™, æ•´æ•°å‹çš„æ•°ç»„å¯ä»¥å› ä¸ºè®¡ç®—å‡çº§ä¸ºæµ®ç‚¹å‹çš„æ•°ç»„, æ¯”å¦‚åŠ ä¸€ä¸ªæˆ–ä¹˜ä»¥æµ®ç‚¹æ•°, ä»¥åŠåšé™¤æ³• æ•°ç»„çš„å½¢çŠ¶å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå…ƒç»„è¡¨ç¤º, ä½¿ç”¨å±æ€§`shape`è¿›è¡Œè¿”å› å¯ä»¥ä½¿ç”¨`reshape()`è¿›è¡Œæ•°ç»„çš„å½¢çŠ¶çš„è½¬æ¢, åœ¨ä¼ å‚æ•°çš„æ—¶å€™, æŸä¸€ä¸ªå‚æ•°ä½¿ç”¨ 1, è¿™ä¸€ä¸ªç»´åº¦çš„å¤§å°è‡ªåŠ¨è®¡ç®— ## å»ºç«‹ 1. ä½¿ç”¨å¤šç»´çš„æ•°ç»„å®ç°åˆ›å»º ```python arr1 np.array([1, 2, 3]) arr2 np.array([[2], [3]]) ``` 2. ä½¿ç”¨`np.arange(num)`å»ºç«‹ä¸€ä¸ªé€’å¢çš„æ•°ç»„, ä»0å¼€å§‹, ä¹Ÿå¯ä»¥`(begin, end, step)` 3. å»ºç«‹ä¸€ä¸ªåŒæ•°æ®ä½›æ•°ç»„çš„æ—¶å€™, å¯ä»¥ä½¿ç”¨å‡½æ•°`zeros`æˆ–è€…`ones`, å‚æ•°æ˜¯æ•°ç»„çš„å½¢çŠ¶, ä¹‹åå¯ä»¥ä½¿ç”¨ä¹˜æ³•ä»¥åŠåŠ æ³•å®ç° > è¿™ä¸¤ä¸ªå‡½æ•°å®é™…çš„è¾“å‡ºæ˜¯ä¸€ä¸ªæµ®ç‚¹çš„æ•°ç»„ 4. å»ºç«‹ä¸€ä¸ªéšæœºçš„æ•°ç»„, å¯ä»¥ä½¿ç”¨`np.ramdom.random(shape)`å»ºç«‹ä¸€ä¸ªéšæœºçš„floatæ•°ç»„, è¿™ä¸€ä¸ªæ•°ç»„çš„æ•°æ®ç»„åœ¨0 1, å®é™…ä½¿ç”¨çš„æ—¶å€™å¯ä»¥ä¹˜æ³•åŠ åŠ æ³•å˜åŒ– 5. `np.ramdom.randint(begin, end, shape)`å»ºç«‹ä¸€ä¸ªæ•´å½¢çš„æ•°ç»„ 6. `np.ramdom.normal(å‡å€¼, æ ‡å‡†å·®, shape)`æ­£æ€åˆ†å¸ƒçš„æµ®ç‚¹å‹æ•°ç»„ ## ç´¢å¼• ```python arr np.arange(16).reshape((4, 4)) print(arr) print(arr[[2, 1], [0, 2]]) # æ‰“å°ä¸€ä¸‹ç¬¬ä¸‰è¡Œç¬¬äºŒåˆ—å’Œç¬¬ä¸€è¡Œç¬¬ä¸‰åˆ—çš„å…ƒç´  print(arr[[1, 2, 3], [1, 2, 3]]) # æ‰“å°ç¬¬äºŒè¡Œç¬¬äºŒåˆ—ï¼Œç¬¬ä¸‰è¡Œç¬¬ä¸‰åˆ—ï¼Œç¬¬å››è¡Œç¬¬å››åˆ—çš„å…ƒç´  ``` è¿™ä¸€ä¸ªè¾“å‡ºçš„æ˜¯ä¸€ä¸ªå‘é‡ > **æ³¨æ„: **ä½¿ç”¨è¿™ä¸€ä¸ªè¿›è¡Œåˆ‡ç‰‡çš„æ—¶å€™, åªæ˜¯ä¸€ä¸ªè§†å›¾, ä¸ä¼šå»ºç«‹æ–°çš„å˜é‡, æ”¹å˜åˆ‡ç‰‡çš„æ—¶å€™åŸæ•°ç»„ä¹Ÿä¼šæ”¹å˜, å¦‚æœå¸Œæœ›æœ‰ä¸€ä¸ªæ–°çš„å˜é‡, å¯ä»¥åœ¨åé¢åŠ ä¸€ä¸ª`.copy()` > > numpyä½¿ç”¨ç­‰å·è¿›è¡Œå¤åˆ¶çš„æ—¶å€™ä¹Ÿä¸ä¼šå»ºç«‹ä¸€ä¸ªæ–°çš„æ•°ç»„ ### å˜å½¢è½¬ç½® åœ¨ä½¿ç”¨è½¬ç½®çš„æ—¶å€™, å¿…é¡»å…ˆå˜ä¸ºçŸ©é˜µæ‰å¯ä»¥è¿›è¡Œå˜æ¢ ```python arr np.arange(4) print(arr) arr2 arr.reshape((1, 1)) print(arr2) print(arr.T) print(arr2.T) \"\"\" [0 1 2 3] [[0 1 2 3]] [0 1 2 3] [[0] [1] [2] [3]] \"\"\" # è¿™ä¸ªä¹Ÿå¯ä»¥ä½¿ç”¨reshapä¸€æ­¥åˆ°ä½ print(arr.reshape(( 1, 1))) \"\"\" [[0] [1] [2] [3]] \"\"\" ``` ### ç¿»è½¬ æœ‰ä¸¤ç§, ä¸Šä¸‹çš„`np.flipud()`, å·¦å³çš„`np.fliplr()`, å‘é‡åˆ™å¯ä»¥ä½¿ç”¨udçš„ ### æ‹¼æ¥ ```python arr1 np.array([1, 2, 3]) arr2 np.array([4, 5, 6]) print(np.concatenate([arr1, arr2])) ``` > å¯ä»¥ä½¿ç”¨axiså‚æ•°é€‰æ‹©å®é™…çš„æ‹¼æ¥çš„å±‚ ### åˆ†è£‚ ```python arr np.arange(10) arr2, arr3, arr4 np.split(arr, [3, 7]) print(arr2, arr3, arr4) \"\"\" [0 1 2] [3 4 5 6] [7 8 9] \"\"\" ``` > é»˜è®¤`axis 0` ## è®¡ç®— ä½¿ç”¨è¿ç®—ç¬¦è¿›è¡Œè®¡ç®—çš„æ—¶å€™, å®é™…æ˜¯å¯¹ç›¸åŒä½ç½®çš„å…ƒç´ ä½¿ç”¨è¿™ä¸€ä¸ªè¿ç®—ç¬¦ ### å¹¿æ’­ åœ¨è¿ç®—çš„æ—¶å€™, å¦‚æœæ•°ç»„çš„å½¢çŠ¶ä¸åŒä½†æ˜¯å¯ä»¥é€šè¿‡å¤åˆ¶æ‹“å±•è·å¾—æ¯”è¾ƒå¤§çš„å½¢çŠ¶, åˆ™è‡ªåŠ¨è¿›è¡Œ ### å„ç§è¿ç®— `np.dot()`, å®é™…è®¡ç®—çš„æ—¶å€™, å¦‚æœæœ‰ä¸€ä¸ªä¸€ä½çš„å‘é‡, å¯ä»¥ä½œä¸ºè¡Œæˆ–è€…åˆ—ä½¿ç”¨ `np.abs()`ç»å¯¹å€¼ `np.sin() np.cos() np.tan()`ä¸‰è§’å‡½æ•° `np.exp()`æŒ‡æ•°å‡½æ•°eä¸ºåº•æ•° `np.log(num)`å¯¹æ•°å‡½æ•°, å¯ä»¥ä½¿ç”¨`np.log(x) / np.log(num)`å®ç°æ¢åº•å‡½æ•° `np.max()`æœ€å¤§å€¼å‡½æ•°, ä¸ä½¿ç”¨`axis`å‚æ•°çš„æ—¶æ±‚çš„æ˜¯æ‰€æœ‰çš„æ•°å­—é‡Œé¢çš„æœ€å¤§å€¼ `np.sum()`, å¯ä»¥ä½¿ç”¨`axis`å‚æ•°æŒ‡å®šæ±‚å’Œçš„ç»´åº¦ `np.mean()`å‡å€¼å‡½æ•° `np.std()`æ ‡å‡†å·®å‡½æ•° `np.prod()`ä¹˜ç§¯ > äºŒç»´çš„æ—¶å€™`axis 0`æ˜¯å•ç‹¬çš„ä¸€åˆ—çš„æ‰€æœ‰è¡Œæ“ä½œ, `axis 1`çš„æ—¶å€™æ˜¯å¯¹å•ç‹¬çš„ä¸€è¡Œ, æ‰€æœ‰çš„åˆ—æ“ä½œ **æ³¨: **åœ¨ä½¿ç”¨æ˜¯å¯èƒ½ä¼šå‡ºç°ä¸ºNone çš„æ•°æ®è¿™æ—¶å€™å¯ä»¥åœ¨å‡½æ•°å‰é¢åŠ nanè·å–ä¸€ä¸ªå®‰å…¨çš„å‡½æ•°å¦‚`np.nanmax()` ## Boolæ•°ç»„ ä½¿ç”¨`> < > < `è¿›è¡Œæ¯”è¾ƒçš„æ—¶å€™ä¼šå‡ºç°çš„æ•°ç»„,, å¦‚æœæœ‰å¤šä¸ªæ¡ä»¶, ä½¿ç”¨` & ~`è¿›è¡Œè¿æ¥è€Œä¸æ˜¯`or and not` è·å–è¿™ä¸€ç§æ•°ç»„ä»¥åå¯ä»¥ä½¿ç”¨sumå‡½æ•°è·å–`True`çš„ä¸ªæ•° åŒæ—¶å¯ä»¥ä½¿ç”¨`np.any()`å‡½æ•°, å¦‚æœæ•°ç»„é‡Œé¢æœ‰ä¸€ä¸ªTrueå°±è¿”å›True è¿˜å¯ä»¥ä½¿ç”¨è¿™ä¸€ä¸ªæ•°ç»„ä½œä¸ºæ©ç è¿›è¡Œç­›é€‰ ```python arr np.arange(16).reshape((4, 4)) print((arr > 4) & (arr < 10), \"\\n\\n\", arr[(arr > 4) & (arr < 10)]) \"\"\" [[False False False False] [False True True True] [ True True False False] [False False False False]] [5 6 7 8 9] \"\"\" ``` è¿˜å¯ä»¥é…åˆwhereå‡½æ•°è¿”å›æ»¡è¶³å…ƒç´ çš„ç´¢å¼•`np.where(arr > 100)`, è¿™ä¸ªå‡½æ•°çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå…ƒç»„çš„æ•°ç»„, ç¬¬ä¸€ä¸ªå…ƒç´ çš„æ˜¯æ‰€åœ¨çš„ä½ç½®, ç¬¬äºŒä¸ªå…ƒç´ æ˜¯è¿™ä¸€ä¸ªå…ƒç´ çš„ç±»å‹ ## åˆ°å¼ é‡ å‡ ä¹æ‰€æœ‰çš„è¯­æ³•æ˜¯ç›¸åŒçš„`torch.tensor()`å’Œ`np.array()`å¯ä»¥ä½¿ä¹‹ç›¸äº’è½¬æ¢ ![image 20250107195117299](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501071951416.png) > v: å‘é‡(ä¸€ç»´), m:çŸ©é˜µ(å¤šç»´), matmuléƒ½å¯ä»¥"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-08-04æ•°æ®é›†.html":{"title":"æ•°æ®é›†","content":"# æ•°æ®é›† ## å›¾åƒåˆ†ç±»æ•°æ®é›† MNISTæ˜¯æ¯”è¾ƒå¹¿æ³›ä½¿ç”¨çš„æ‰‹å†™æ•°å­—æ•°æ®é›†, ä½†æ˜¯è¿™ä¸€ä¸ªæ•°æ®é›†æ¯”è¾ƒç®€å•, æ‰€ä»¥ä½¿ç”¨Fashion MNISTæ•°æ®é›†è¿›è¡Œå®éªŒ ```python %matplotlib inline import torch import torchvision from torch.utils import data from torchvision import transforms from d2l import torch as d2l d2l.use_svg_display() # ä½¿ç”¨çŸ¢é‡å›¾æ˜¾ç¤º ``` + è·å–ä¸€ä¸‹æ•°æ®é›†, ç›´æ¥è½¬æ¢ä¸ºtensor ```python # ä½¿ç”¨ToTensorå®ä¾‹å°†å›¾åƒæ•°æ®ä»PILç±»å‹å˜æ¢æˆ32ä½æµ®ç‚¹æ•°æ ¼å¼ # å¹¶é™¤ä»¥255ä½¿å¾—æ‰€æœ‰çš„åƒç´ çš„æ•°å€¼å‡åœ¨0åˆ°1ä¹‹é—´ trans transforms.ToTensor() # è¯»å–Fashion MNISTæ•°æ®é›† mnist_train torchvision.datasets.FashionMNIST(root \"../data\", train True, transform trans, download True) mnist_test torchvision.datasets.FashionMNIST(root \"../data\", train False, transform trans, download True) len(mnist_train), len(mnist_test) ``` + çœ‹ä¸€ä¸‹ç¬¬ä¸€ä¸ªæ•°æ®çš„å¤§å° ```python mnist_test[0][0].shape, mnist_test # ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å›¾åƒæ•°æ®ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯æ ‡ç­¾, è·å–ç¬¬ä¸€ä¸ªå…ƒç´ çš„å½¢çŠ¶ \"\"\" torch.Size([1, 28, 28]) \"\"\" ``` > è¿™æ˜¯ä¸€ä¸ªé»‘ç™½çš„28*28çš„å›¾ç‰‡ + åŠ è½½ä¸ºæ•°æ®é›† ```python batch_size 256 def get_dataloader_workers(): #@save \"\"\"ä½¿ç”¨4ä¸ªè¿›ç¨‹æ¥è¯»å–æ•°æ®ã€‚\"\"\" return 8 train_iter data.DataLoader(mnist_train, batch_size, shuffle True, num_workers get_dataloader_workers()) timer d2l.Timer() for X, y in train_iter: continue f'{timer.stop():.2f} sec' ``` + æŠŠä»¥ä¸Šçš„å†…å®¹æ•´åˆä¸ºä¸€ä¸ªå‡½æ•°, åŒæ—¶åŠ å…¥resize ```python def load_data_fashion_mnist(batch_size, resize None): #@save \"\"\"ä¸‹è½½Fashion MNISTæ•°æ®é›†ï¼Œç„¶åå°†å…¶åŠ è½½åˆ°å†…å­˜ä¸­ã€‚\"\"\" trans [transforms.ToTensor()] if resize: trans.insert(0, transforms.Resize(resize)) trans transforms.Compose(trans) mnist_train torchvision.datasets.FashionMNIST(root \"../data\", train True, transform trans, download True) mnist_test torchvision.datasets.FashionMNIST(root \"../data\", train False, transform trans, download True) return (data.DataLoader(mnist_train, batch_size, shuffle True, num_workers get_dataloader_workers()), data.DataLoader(mnist_test, batch_size, shuffle False, num_workers get_dataloader_workers())) ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-6-30æ–‡å­—å¤„ç†.html":{"title":"æ–‡å­—å¤„ç†","content":"# æ–‡å­—å¤„ç† å¤„ç†æ–‡å­—çš„æ—¶å€™éœ€è¦å¯¹æ–‡å­—è¿›è¡ŒæŒ‰ç…§ä¸€å®šæ ¼å¼åˆ†å‰², ä¸å¦‚è¯è¯­æˆ–è€…å­—æ¯, ä¹‹åå®‰è£…å‡ºç°çš„æ¬¡æ•°å»ºç«‹ä¸€ä¸ªè¯è¡¨, ç»™æ¯ä¸€ä¸ªè¯è¯­ä¸€ä¸ªæ•°å­—ç´¢å¼•(è¯è¡¨) å¾ˆå°‘å‡ºç°çš„è¯å…ƒé€šå¸¸è¢«ç§»é™¤ï¼Œè¿™å¯ä»¥é™ä½å¤æ‚æ€§ã€‚å¦ å¤–ï¼Œè¯­æ–™åº“ä¸­ä¸å­˜åœ¨æˆ–å·²åˆ é™¤çš„ä»»ä½•è¯å…ƒéƒ½å°†æ˜ å°„åˆ°ä¸€ä¸ªç‰¹å®šçš„æœªçŸ¥è¯å…ƒâ€œâ€ æˆ‘ä»¬å¯ä»¥é€‰æ‹©å¢åŠ ä¸€ä¸ª åˆ—è¡¨ï¼Œç”¨äºä¿å­˜é‚£äº›è¢«ä¿ç•™çš„è¯å…ƒï¼Œä¾‹å¦‚ï¼šå¡«å……è¯å…ƒï¼ˆâ€œ`<pad>`â€ï¼‰ï¼›åºåˆ—å¼€å§‹è¯å…ƒï¼ˆâ€œ`<bos>`â€ï¼‰ï¼›åºåˆ—ç»“æŸè¯å…ƒ ï¼ˆâ€œ`<eos>`â€) ## é¢„å¤„ç† ```python import collections import re from d2l import torch as d2l ``` + åŠ è½½ä¸€ä¸ªæ–‡æœ¬ ```python #@save d2l.DATA_HUB['time_machine'] (d2l.DATA_URL + 'timemachine.txt', '090b5e7e70c295757f55df93cb0a180b9691891a') def read_time_machine(): #@save \"\"\"å°†æ—¶é—´æœºå™¨æ•°æ®é›†åŠ è½½åˆ°æ–‡æœ¬è¡Œçš„åˆ—è¡¨ä¸­\"\"\" with open(d2l.download('time_machine'), 'r') as f: lines f.readlines() # æŠŠéå­—æ¯å­—ç¬¦æ›¿æ¢ä¸ºç©ºæ ¼ï¼ŒæŠŠå¤§å†™å­—æ¯è½¬æ¢ä¸ºå°å†™å­—æ¯ return [re.sub('[^A Za z]+', ' ', line).strip().lower() for line in lines] lines read_time_machine() print(f'# æ–‡æœ¬æ€»è¡Œæ•°: {len(lines)}') print(lines[0]) print(lines[10]) \"\"\" Downloading ../data\\timemachine.txt from http://d2l data.s3 accelerate.amazonaws.com/timemachine.txt... # æ–‡æœ¬æ€»è¡Œæ•°: 3221 the time machine by h g wells twinkled and his usually pale face was flushed and animated the \"\"\" ``` + å»ºç«‹ä¸€ä¸ªtokenize, æŠŠå¥å­æŒ‰è¯è¯­åˆ†å¼€ ```python def tokenize(lines, token 'word'): #@save \"\"\"å°†æ–‡æœ¬è¡Œæ‹†åˆ†ä¸ºå•è¯æˆ–å­—ç¬¦è¯å…ƒ\"\"\" if token 'word': return [line.split() for line in lines] elif token 'char': return [list(line) for line in lines] else: print('é”™è¯¯ï¼šæœªçŸ¥è¯å…ƒç±»å‹ï¼š' + token) tokens tokenize(lines) for i in range(11): print(tokens[i]) ``` + å»ºç«‹ä¸€ä¸ªç´¢å¼•è¡¨ ```python # å°†å­—ç¬¦ä¸²ç±»å‹çš„è¯å…ƒæ˜ å°„åˆ°ä»0å¼€å§‹çš„æ•°å­—ç´¢å¼•ä¸­ class Vocab: #@save \"\"\"æ–‡æœ¬è¯è¡¨\"\"\" # tokensæ˜¯ä¹‹å‰åˆ†è¯å™¨å¤„ç†ä»¥åå¾—ç»“æœ def __init__(self, tokens None, min_freq 0, reserved_tokens None): # tokens: è¯å…ƒåˆ—è¡¨, æ¯ä¸ªè¯å…ƒæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸² # min_freq: è¯é¢‘é˜ˆå€¼, å°‘äºè¯¥å€¼çš„è¯å°†è¢«ä¸¢å¼ƒ # reserved_tokens: ä¿ç•™çš„ç‰¹æ®Šè¯å…ƒåˆ—è¡¨ if tokens is None: tokens [] if reserved_tokens is None: reserved_tokens [] # æŒ‰å‡ºç°é¢‘ç‡æ’åº counter count_corpus(tokens) self._token_freqs sorted(counter.items(), key lambda x: x[1], reverse True) # æœªçŸ¥è¯å…ƒçš„ç´¢å¼•ä¸º0 self.idx_to_token ['<unk>'] + reserved_tokens # è¯å…ƒåˆ°ç´¢å¼•çš„æ˜ å°„ self.token_to_idx {token: idx for idx, token in enumerate(self.idx_to_token)} for token, freq in self._token_freqs: if freq < min_freq: break if token not in self.token_to_idx: self.idx_to_token.append(token) # è¯é¢‘å¤§äºé˜ˆå€¼çš„è¯å…ƒåŠ å…¥è¿™ä¸ªåˆ—è¡¨ self.token_to_idx[token] len(self.idx_to_token) 1 # ä»0å¼€å§‹çš„å­—å…¸, keyæ˜¯è¯å…ƒ, valueæ˜¯ç´¢å¼• def __len__(self): return len(self.idx_to_token) # å­—ç¬¦ä¸² ç´¢å¼•æ˜ å°„ def __getitem__(self, tokens): # ä½¿ç”¨[]çš„æ—¶å€™, å¦‚æœtokensæ˜¯åˆ—è¡¨, è¿”å›ç´¢å¼•åˆ—è¡¨, å¦‚æœtokensæ˜¯å­—ç¬¦ä¸², è¿”å›ç´¢å¼• if not isinstance(tokens, (list, tuple)): # å¦‚æœtokensæ˜¯å­—ç¬¦ä¸²çš„è¯, è¿”å›ç´¢å¼• return self.token_to_idx.get(tokens, self.unk) return [self.__getitem__(token) for token in tokens] # ç´¢å¼• å­—ç¬¦ä¸²æ˜ å°„ def to_tokens(self, indices): # ä½¿ç”¨to_tokensçš„æ—¶å€™, å¦‚æœindicesæ˜¯åˆ—è¡¨, è¿”å›è¯å…ƒåˆ—è¡¨, å¦‚æœindicesæ˜¯æ•°å­—, è¿”å›è¯å…ƒ if not isinstance(indices, (list, tuple)): return self.idx_to_token[indices] return [self.idx_to_token[index] for index in indices] @property def unk(self): # æœªçŸ¥è¯å…ƒçš„ç´¢å¼•ä¸º0 return 0 @property def token_freqs(self): # è¿”å›è¯å…ƒé¢‘ç‡ return self._token_freqs def count_corpus(tokens): #@save \"\"\"ç»Ÿè®¡è¯å…ƒçš„é¢‘ç‡\"\"\" # è¿™é‡Œçš„tokensæ˜¯1Dåˆ—è¡¨æˆ–2Dåˆ—è¡¨ if len(tokens) 0 or isinstance(tokens[0], list): # å°†è¯å…ƒåˆ—è¡¨å±•å¹³æˆä¸€ä¸ªåˆ—è¡¨ tokens [token for line in tokens for token in line] return collections.Counter(tokens) # è¿”å›ä¸€ä¸ªå­—å…¸, keyæ˜¯è¯å…ƒ, valueæ˜¯è¯é¢‘ ``` + çœ‹ä¸€ä¸‹æ•ˆæœ ```python vocab Vocab(tokens) print(list(vocab.token_to_idx.items())[:10]) \"\"\" [('<unk>', 0), ('the', 1), ('i', 2), ('and', 3), ('of', 4), ('a', 5), ('to', 6), ('was', 7), ('in', 8), ('that', 9)] \"\"\" ``` + æµ‹è¯•ä¸€ä¸‹æ•ˆæœ ```python for i in [0, 10]: print('æ–‡æœ¬:', tokens[i]) print('ç´¢å¼•:', vocab[tokens[i]]) ``` + ç»¼åˆä¸ºä¸€ä¸ªå‡½æ•° ```python def load_corpus_time_machine(max_tokens 1): #@save \"\"\"è¿”å›æ—¶å…‰æœºå™¨æ•°æ®é›†çš„è¯å…ƒç´¢å¼•åˆ—è¡¨å’Œè¯è¡¨\"\"\" lines read_time_machine() tokens tokenize(lines, 'char') # å­—ç¬¦çº§åˆ«çš„æ ‡è®° vocab Vocab(tokens) # å› ä¸ºæ—¶å…‰æœºå™¨æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ–‡æœ¬è¡Œä¸ä¸€å®šæ˜¯ä¸€ä¸ªå¥å­æˆ–ä¸€ä¸ªæ®µè½ï¼Œ # æ‰€ä»¥å°†æ‰€æœ‰æ–‡æœ¬è¡Œå±•å¹³åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­ corpus [vocab[token] for line in tokens for token in line] if max_tokens > 0: corpus corpus[:max_tokens] return corpus, vocab corpus, vocab load_corpus_time_machine() # corpusæ˜¯ä¸€ä¸ªåˆ—è¡¨, æ¯ä¸ªå…ƒç´ åŸæ¥æ–‡æœ¬é‡Œé¢è¯è¯­çš„ç´¢å¼•, vocabæ˜¯ä¸€ä¸ªVocabå¯¹è±¡, ç°åœ¨æ˜¯æŒ‰ç…§å­—æ¯è¿›è¡Œåˆ†çš„ len(corpus), len(vocab) \"\"\" (170580, 28) \"\"\" ``` ## è¯­è¨€æ¨¡å‹ å‡è®¾é•¿åº¦ä¸ºTçš„æ–‡æœ¬åºåˆ—ä¸­çš„è¯å…ƒä¾æ¬¡ä¸ºx1,x2,...,xTã€‚äºæ˜¯ï¼Œxtï¼ˆ1â‰¤tâ‰¤Tï¼‰å¯ä»¥è¢«è®¤ä¸ºæ˜¯æ–‡ æœ¬åºåˆ—åœ¨æ—¶é—´æ­¥tå¤„çš„è§‚æµ‹æˆ–æ ‡ç­¾ã€‚åœ¨ç»™å®šè¿™æ ·çš„æ–‡æœ¬åºåˆ—æ—¶ï¼Œè¯­è¨€æ¨¡å‹ï¼ˆlanguagemodelï¼‰çš„ç›®æ ‡æ˜¯ä¼°è®¡åº åˆ—çš„è”åˆæ¦‚ç‡ ![image 20250206212840754](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502062128818.png) åªéœ€è¦ä¸€æ¬¡æŠ½å–ä¸€ä¸ªè¯å…ƒxtâˆ¼P(xt xtâˆ’1,...,x1)ï¼Œä¸€ä¸ªç†æƒ³çš„è¯­è¨€æ¨¡å‹å°±èƒ½å¤ŸåŸºäºæ¨¡å‹æœ¬èº«ç”Ÿæˆè‡ª ç„¶æ–‡æœ¬ã€‚ä¸çŒ´å­ä½¿ç”¨æ‰“å­—æœºå®Œå…¨ä¸åŒçš„æ˜¯ï¼Œä»è¿™æ ·çš„æ¨¡å‹ä¸­æå–çš„æ–‡æœ¬éƒ½å°†ä½œä¸ºè‡ªç„¶è¯­è¨€ï¼ˆä¾‹å¦‚ï¼Œè‹±è¯­æ–‡æœ¬ï¼‰ æ¥ä¼ é€’ã€‚åªéœ€è¦åŸºäºå‰é¢çš„å¯¹è¯ç‰‡æ–­ä¸­çš„æ–‡æœ¬ï¼Œå°±è¶³ä»¥ç”Ÿæˆä¸€ä¸ªæœ‰æ„ä¹‰çš„å¯¹è¯ã€‚æ˜¾ç„¶ï¼Œæˆ‘ä»¬ç¦»è®¾è®¡å‡ºè¿™æ ·çš„ ç³»ç»Ÿè¿˜å¾ˆé¥è¿œï¼Œå› ä¸ºå®ƒéœ€è¦â€œç†è§£â€æ–‡æœ¬ï¼Œè€Œä¸ä»…ä»…æ˜¯ç”Ÿæˆè¯­æ³•åˆç†çš„å†…å®¹ã€‚ ![image 20250206213550026](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502062135178.png) ![image 20250206213721730](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502062137808.png) > å‡ å…ƒè¯­æ³•æ˜¯ä¸‹ä¸€ä¸ªè¯å’Œå‰é¢çš„å¤šå°‘çš„è¯æ˜¯ç›¸å…³çš„, è®°å½•ä¸€ä¸‹è¿™å‡ ä¸ªæŒ‰ç…§ä¸€å®šæ¬¡åºå‡ºç°çš„æ¦‚ç‡, å’Œnæ˜¯ä¸€ä¸ªæŒ‡æ•°å…³ç³», åˆ†åˆ«è¦è®°å½•n, n^2^...ä¸ªæ•°æ®"},"/note/æœºå™¨å­¦ä¹ /2024-9-8-æœºå™¨å­¦ä¹ .html":{"title":"æœºå™¨å­¦ä¹ ","content":" layout: post title: \"æœºå™¨å­¦ä¹ \" date: 2024 8 5 15:39:08 +0800 tags: AI æœºå™¨å­¦ä¹  # æœºå™¨å­¦ä¹  how to make machine learn to do it by itself ä¾æ®å½“å‰è·å–çš„æ•°æ®, è·å–æ•°æ®çš„ç‰¹å¾å€¼ > æ·±åº¦å­¦ä¹ : ç§ç‰¹æ®Šçš„æœºå™¨å­¦ä¹ ï¼Œå®ƒé€šè¿‡å­¦ä¹ å°†ä¸–ç•Œè¡¨ç¤ºä¸ºåµŒå¥—çš„æ¦‚å¿µå±‚æ¬¡ç»“æ„æ¥å®ç°å¼ºå¤§çš„åŠŸèƒ½å’Œçµæ´»æ€§ï¼Œæ¯ä¸ªæ¦‚å¿µéƒ½æ˜¯æ ¹æ®æ›´ç®€å•çš„æ¦‚å¿µè¿›è¡Œå®šä¹‰çš„ï¼Œè€Œæ›´æŠ½è±¡çš„æ¦‚å¿µåˆ™æ˜¯ç”¨ä¸é‚£ä¹ˆæŠ½è±¡ï¼ˆæ›´åŠ å…·è±¡ï¼‰çš„æ¦‚å¿µè®¡ç®—å‡ºæ¥çš„ > åŒºåˆ« :æ·±åº¦å­¦ä¹ ä¼šè‡ªåŠ¨æ‰¾å‡ºå¯¹åˆ†ç±»å¾ˆé‡è¦çš„ç‰¹å¾ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­æˆ‘ä»¬å¿…é¡»æ‰‹åŠ¨æä¾›è¿™äº›ç‰¹å¾ã€‚ é‡è¦çš„åŒºåˆ«ä¼šéšç€æ•°æ®è§„æ¨¡çš„å¢å¤§è€Œè¡¨ç°å‡ºæ¥ > > å½“æ•°æ®å¾ˆå°æ—¶ï¼Œæ·±åº¦å­¦ä¹ ç®—æ³•è¡¨ç°ä¸ä½³ã€‚è¿™æ˜¯å› ä¸ºæ·±åº¦å­¦ä¹ ç®—æ³•éœ€è¦å¤§é‡æ•°æ®æ‰èƒ½å®Œç¾ç†è§£å®ƒã€‚å¦ä¸€æ–¹é¢ï¼Œä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ ç®—æ³•åŠå…¶æ‰‹å·¥åˆ¶ä½œçš„è§„åˆ™åœ¨è¿™ç§æƒ…å†µä¸‹å æ®ä¼˜åŠ¿ã€‚ > > é€šå¸¸ï¼Œæ·±åº¦å­¦ä¹ ç®—æ³•éœ€è¦å¾ˆé•¿æ—¶é—´æ¥è®­ç»ƒã€‚è¿™æ˜¯å› ä¸ºæ·±åº¦å­¦ä¹ ç®—æ³•ä¸­æœ‰å¾ˆå¤šçš„å‚æ•°ï¼Œæ‰€ä»¥è®­ç»ƒå®ƒä»¬éœ€è¦æ›´é•¿çš„æ—¶é—´ã€‚æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ ç®—æ³•ResNetéœ€è¦å¤§çº¦ä¸¤å‘¨æ—¶é—´æ‰èƒ½å®Œå…¨ä»0å¼€å§‹çš„è®­ç»ƒã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæœºå™¨å­¦ä¹ çš„è®­ç»ƒæ—¶é—´è¦çŸ­å¾—å¤šï¼Œä»å‡ ç§’é’Ÿåˆ°å‡ å°æ—¶ä¸ç­‰ã€‚ æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„å®ç°æ–¹æ³•, æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€éƒ¨åˆ†, æ˜¯ä»–çš„ä¸€ä¸ªæ–¹æ³• ## Algorithms æœºå™¨å­¦ä¹ ä¸»è¦æœ‰ä¸¤ç§, ç›‘ç®¡å­¦ä¹ (supervised learning)å’Œæ— ç›‘ç®¡å­¦ä¹ (unsupervised learning), ç¬¬ä¸€ç§ä½¿ç”¨çš„æ¯”è¾ƒå¤š, è¿˜æœ‰ä¸€ç§å¼ºåŒ–å­¦ä¹ (Reinforcement learning) ### supervised learningç›‘ç£å­¦ä¹  input to output mappings learn from being given the right answers #### å›å½’Regression predict a number from infinitely many possible numbers, ä»æ— æ•°ä¸ªæ•°å­—é‡Œé¢é¢„æµ‹æ–°çš„æ•°å­—, æƒ³åŠæ³•æ‰¾åˆ°ä¸€ä¸ªæœ€é€‚åˆçš„ç›´çº¿, å°½å¯èƒ½çš„æ‹Ÿåˆæ›´å¤šçš„ç‚¹ ![image 20240908122138302](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409081221363.png) è¿™é‡Œçš„$ \\theta0 $ ç¬¦å·æ˜¯ä¸€ä¸ªåç½®, åœ¨å®é™…è®¡ç®—çš„æ—¶å€™, ç›¸å½“äºçŸ©é˜µé‡Œé¢åŠ ä¸€åˆ—å€¼ä¸º1çš„$\\theta_0$è¿™é‡Œä½¿ç”¨1çš„åŸå› æ˜¯ $\\theta_0$å’Œ1ä¹˜çš„ç»“æœæ˜¯æœ¬èº«çš„æ•°å­— è¯¯å·®: çœŸå®å€¼å’Œé¢„æµ‹å€¼ä¹‹é—´æ˜¯å­˜åœ¨ä¸€ä¸ªè¯¯å·®çš„, ä½¿ç”¨$\\varepsilon$è¡¨ç¤º, $y^{(i)} \\theta^Tx^{(i)}+\\varepsilon^{(i)}$â€‹ è¿™é‡Œçš„è¯¯å·®æ˜¯ç‹¬ç«‹çš„å…·æœ‰ç›¸åŒçš„åˆ†å¸ƒ, æœä»äºå‡å€¼ä¸º0æ–¹å·®ä¸º$\\theta^2$â€‹çš„é«˜æ–¯åˆ†å¸ƒ, ä½¿ç”¨çš„æ•°æ®å°½å¯èƒ½æ¥è‡ªç›¸åŒçš„åˆ†å¸ƒ(å…¨éƒ¨æ¥è‡ªåŒä¸€ä¸ªå¯¹è±¡) è¿™é‡Œé¢çš„å‚æ•°è¢«å«åšç³»æ•°(coefficients)æˆ–è€…æƒé‡(weights), å®é™…è®¡ç®—çš„æ—¶å€™, æŠŠé¢„æµ‹å€¼å’Œå®é™…çš„å€¼è¿›è¡Œä½œå·®, å¹³æ–¹, è®¡ç®—æ‰€æœ‰çš„å·®çš„å¹³æ–¹çš„å¹³å‡æ•°, æœ€å°çš„æ—¶å€™å³ä¸ºæ‰€æ±‚, åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™, ä¼šå¤šé™¤ä»¥ä¸€ä¸ª2, ç”¨äºä½¿ä¸€ä¸ªæ¯”è¾ƒå¤§çš„çš„æ•°å­—çœ‹èµ·æ¥æ¯”è¾ƒæ•´æ´ Squared error cost function, è¿™ä¸€ä¸ªè®¡ç®—çš„æ–¹å¼åœ¨ä½¿ç”¨çº¿æ€§å›å½’çš„æ—¶å€™æ•ˆæœæœ€å¥½, å…¶ä»–çš„æ–¹ç¨‹ä¹Ÿå·®ä¸å¤š ![image 20240910221432231](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409102214559.png) #### classificationåˆ†ç±»ç®—æ³• ä¾æ®ç°æœ‰çš„æ•°æ®, å¯¹ä¸€ä¸ªæ–°çš„æ•°æ®è¿›è¡Œåˆ†ç±», ä½¿ç”¨è¿™ä¸€ç§ç®—æ³•è¿›è¡Œé¢„æµ‹çš„æ—¶å€™, å®é™… è·å–çš„æ•°å­—ä¸æ˜¯è¿ç»­çš„ ### Unsupervised Learningæ— ç›‘ç£å­¦ä¹  åœ¨ä½¿ç”¨è¿™ä¸€ä¸ªå­¦ä¹ çš„æ–¹å¼çš„æ—¶å€™, æˆ‘ä»¬æä¾›æ•°æ®, ä½†æ˜¯ä¸ä¼šå¯¹ä¸€ä¸ªæ•°æ®è¿›è¡Œå®é™…çš„åˆ†ç±» è¿™ä¸€ä¸ªæ–¹æ³•å¯ä»¥ç”¨äºå¯¹å¤§é‡çš„æ•°æ®è¿›è¡Œåˆ†ç±», æ¯”å¦‚è¯´Googleçš„æ–°é—»åˆ†ç±», DNAåºåˆ—çš„åˆ†ç±», è¿™ä¸€ä¸ªæ–¹å¼è¢«å«åšclustering è¿™ä¸€ç§å­¦ä¹ çš„æ–¹å¼æ˜¯åªæœ‰è¾“å…¥çš„æ ‡ç­¾X, ä½†æ˜¯æ²¡æœ‰è¾“å‡ºçš„æ ‡ç­¾Y, ä½¿ç”¨çš„ç®—æ³•æ•°æ®, ç”±ç®—æ³•å»æŸ¥æ‰¾æ•°æ®é‡Œé¢çš„ç»“æ„ + Anomaly detectionå¼‚å¸¸æ£€æµ‹ å¯ä»¥ç”¨äºé‡‘èé¢†åŸŸé‡Œé¢, ç”¨äºæ£€æµ‹æ˜¯ä¸æ˜¯å­˜åœ¨è¯ˆéª— + Dimensionality reduction é™ç»´ æŠŠä¸€ä¸ªæ¯”è¾ƒå¤§çš„æ•°æ®è¿›è¡Œç¼©å°ä¸ºä¸€ä¸ªå°½å¯èƒ½å°çš„æ•°æ®é›†, åŒæ—¶å°½å¯èƒ½çš„å‡å°‘æ•°æ®çš„ä¸¢å¤±, å¯ä»¥ç”¨äºä¸€ä¸ªæ¯”è¾ƒå¤§çš„æ•°æ®çš„å‹ç¼© ## å®é™…æ¨¡å‹ ### Linear Regression Model çº¿æ€§å›å½’æ¨¡å‹ ### æ¢¯åº¦ä¸‹é™ç®—æ³• æ˜¯ä¸€ä¸ªç”¨äºæ±‚$J(W1, w2, ..., w3, b)$è¿™ä¸€ä¸ªå¼å­çš„æœ€å°å€¼çš„æ–¹æ³•, ä¸€ç›´æ”¹å˜wå’Œbçš„å€¼, ç›´åˆ°è·å–è¿™ä¸€ä¸ªå‡½æ•°çš„æœ€å°å€¼ å¦‚æœè¿™ä¸€ä¸ªæ–¹ç¨‹ä¸æ˜¯ä¸€ä¸ªçº¿æ€§æ–¹ç¨‹ä»¥åŠä½¿ç”¨ä¸€ä¸ªå¹³æ³•è¯¯å·®æ–¹ç¨‹, å®é™…çš„è·å–çš„Jå‡½æ•°å¯èƒ½æ¯”è¾ƒå¤æ‚, è¿™ä¸€ä¸ªå‡½æ•°çš„å®é™…å®ç°æ–¹å¼æ˜¯è®¡ç®—ä¸€ä¸‹å½“å‰ä½ç½®çš„æ‰€æœ‰æ–¹å‘æ–œç‡æœ€å¤§çš„ä¸€ä¸ª, ä¹‹åå‘è¿™ä¸€ä¸ªæ–¹å‘ åœ¨èµ·æ—¶çš„æ—¶å€™é€‰æ‹©ä¸åŒçš„ä½ç½®, å¯èƒ½ä¼šåˆ°è¾¾ä¸åŒçš„æœ€å°å€¼çš„ä½ç½®, è¿™æ—¶å€™æ‰¾åˆ°çš„æœ€å°å€¼æ˜¯ä¸€ä¸ªå±€éƒ¨æœ€å°å€¼ $w w \\alpha\\frac{\\partial}{\\partial w}J(w,b)$, åˆ™è¿™ä¸€ä¸ªå¼å­é‡Œé¢, $\\alpha$è¢«å«åšå­¦ä¹ ç‡, è¿™ä¸€ä¸ªå€¼ä¸€èˆ¬æ˜¯ä¸€ä¸ª0 1ä¹‹é—´çš„æ•°å­—, ä½¿ç”¨è¿™ä¸€ä¸ªå€¼è¡¨ç¤ºä½ çš„ä¸‹å±±çš„ä¸€æ­¥çš„æ­¥é•¿, å’Œ$b b \\alpha\\frac{\\partial}{\\partial b}J(w,b)$å¼å­ä¸€èµ·ä½¿ç”¨ åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™, ä¼šä½¿ç”¨ä¸€ä¸ªä¸´æ—¶å€¼è®°å½•ä¸€ä¸‹æ›´æ–°å‰çš„æ•°å­—, ä¹‹åè¿›è¡Œè®¡ç®—, è®¡ç®—ç»“æŸä»¥åå†æŠŠè¿™ä¸¤ä¸ªæ•°å­—åŒæ—¶å†™å…¥è¿›å», è¿™é‡Œå®é™…æ˜¯åº”ç”¨äº†ä¸€ä¸‹æ¢¯åº¦çš„å®šä¹‰ $\\frac{\\partial}{\\partial w}J(w,b)$è¿™ä¸€ä¸ªå¼å­å¦‚æœè®¡ç®—çš„æ˜¯![image 20240910221432231](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409102214559.png), æ±‚å¯¼ä»¥åå¾—å¼å­æ˜¯$\\frac{1}{m}\\sum_{i 1}^m(f_{w, b}(x^{(i)}) y^{(i)})x^{(i)}$ $\\frac{\\partial}{\\partial b}J(w,b)$çš„ç»“æœæ˜¯$\\frac{1}{m}\\sum_{i 1}^m(f_{w, b}(x^{(i)}) y^{(i)})$"},"/note/æœºå™¨å­¦ä¹ /vllmä»£ç åˆ†æ/2024-12-31-00-æ•´ä½“æ¡†æ¶.html":{"title":"","content":"## æ€è·¯ [å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼švLLMæºç è§£æ1ï¼Œæ•´ä½“æ¶æ„ çŸ¥ä¹](https://zhuanlan.zhihu.com/p/691045737) ![img](https://pic4.zhimg.com/v2 e902e6b12166aaebd2d9b50b0370ae8d_1440w.jpg) **`add_request()`**ï¼šè¯¥æ–¹æ³•å°†æ¯ä¸€ä¸ªè¯·æ±‚åŒ…è£…æˆvLLMèƒ½å¤„ç†çš„æ•°æ®ç±»å‹(SequenceGroupï¼Œåé¢æˆ‘ä»¬ä¼šè¯¦ç»†è§£é‡Š)ï¼Œå¹¶å°†å…¶åŠ å…¥è°ƒåº¦å™¨ï¼ˆSchedulerï¼‰çš„waitingé˜Ÿåˆ—ä¸­ã€‚**åœ¨LLMEngineä¸­ï¼Œè¿™ä¸ªå‡½æ•°æ˜¯æŒ‰ç…§â€œåŒæ­¥â€çš„æ–¹å¼è®¾è®¡çš„**ï¼Œä¹Ÿå°±æ˜¯å®ƒè¢«è®¾è®¡ä¸ºâ€œéå†batchä¸­çš„æ¯æ¡æ•°æ®ï¼Œç„¶ååšç›¸åº”å¤„ç†â€ã€‚æ‰€ä»¥è¿™ä¸ªå‡½æ•°æœ¬èº«åªé€‚åˆæ‰¹å¤„ç†åœºæ™¯ã€‚åœ¨å¼‚æ­¥çš„online servingä¸­å°†ä¼šæŠŠå®ƒé‡å†™æˆå¼‚æ­¥çš„å½¢å¼ã€‚ **`abort_request`**ï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„è¯·æ±‚éƒ½èƒ½æœ‰è¿”å›ç»“æœã€‚æ¯”å¦‚å®¢æˆ·ç«¯æ–­å¼€è¿æ¥æ—¶ï¼Œè¿™ä¸ªè¯·æ±‚çš„æ¨ç†å°±å¯ä»¥ç»ˆæ­¢äº†ï¼ˆabortï¼‰ï¼Œè¿™ä¸ªå‡½æ•°å°±è¢«ç”¨æ¥åšè¿™ä¸ªæ“ä½œã€‚ **`step()`ï¼šè´Ÿè´£æ‰§è¡Œ1æ¬¡æ¨ç†è¿‡ç¨‹ï¼ˆ1ä¸ªprefillç®—1ä¸ªæ¬¡æ¨ç†ï¼Œæ¯ä¸ªdecodeå„ç®—1æ¬¡æ¨ç†ï¼‰**ã€‚åœ¨è¿™ä¸ªå‡½æ•°ä¸­ï¼ŒvLLMçš„è°ƒåº¦å™¨ä¼šå†³å®šè¦é€é‚£äº›æ•°æ®å»æ‰§è¡Œæœ¬æ¬¡æ¨ç†ï¼Œå¹¶è´Ÿè´£ç»™è¿™äº›æ•°æ®åˆ†é…å¥½ç‰©ç†å—ï¼ˆè¿™äº›ä¿¡æ¯éƒ½è¢«ä½œä¸ºmetadataæ”¾åœ¨è¦é€ç»™æ¨¡å‹åšæ¨ç†çš„æ•°æ®ä¸­ï¼‰ã€‚æ¨¡å‹ä¼šæ ¹æ®è¿™äº›ä¿¡æ¯ï¼Œé‡‡ç”¨PagedAttentionæ–¹æ³•ï¼Œå®é™…å®Œæˆæ¨ç†ã€‚ > åœ¨æ–‡ä»¶E:\\aå­¦ä¹ \\22 æœºå™¨å­¦ä¹ \\vllm main\\vllm\\engine\\llm_engine.pyé‡Œé¢ > > ![img](https://pic1.zhimg.com/v2 eee036cd8edbc2b94d8758721b9809e8_1440w.jpg) **Centralized Controllerï¼Œä¹Ÿå°±æ˜¯å‰æ–‡æˆ‘ä»¬æ‰€è¯´çš„è°ƒåº¦å™¨(Scheduler)**ã€‚å®ƒå’ŒLLMEngineæ‰€åœ¨çš„è¿›ç¨‹æ˜¯åŒä¸€ä¸ªï¼Œä¸”ä¸¤è€…éƒ½æ˜¯åœ¨CPUä¸Šçš„ã€‚ **è°ƒåº¦å™¨çš„ä¸»è¦ä½œç”¨å°±æ˜¯ï¼Œåœ¨æ¯1ä¸ªæ¨ç†é˜¶æ®µï¼Œå†³å®šè¦æŠŠå“ªäº›æ•°æ®é€ç»™æ¨¡å‹åšæ¨ç†ï¼ŒåŒæ—¶è´Ÿè´£ç»™è¿™äº›æ¨¡å‹åˆ†é…[KV Cache](https://zhida.zhihu.com/search?content_id 241696234&content_type Article&match_order 1&q KV+Cache&zhida_source entity)ç‰©ç†å—**ã€‚ä½†è¦æ³¨æ„ï¼Œå®ƒåªæ˜¯åˆ†é…äº†ç‰©ç†å—çš„idï¼Œè€Œä¸æ˜¯ç‰©ç†å—æœ¬èº«ã€‚ç‰©ç†å—çš„å®é™…åˆ†é…æ˜¯æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ ¹æ®ç‰©ç†å—idæ¥æ“ä½œçš„ï¼Œä¹Ÿå°±æ˜¯[CacheEngine](https://zhida.zhihu.com/search?content_id 241696234&content_type Article&match_order 1&q CacheEngine&zhida_source entity)åšçš„äº‹æƒ…ã€‚ **è°ƒåº¦å™¨ä¸‹ç»´æŠ¤ç€BlockSpaceManagerã€‚å®ƒè´Ÿè´£ç®¡ç†BlockAllocatorï¼ˆå®é™…å‚ä¸åˆ†é…ç‰©ç†å—çš„ç±»ï¼‰ã€‚BlockAllocatoråˆåˆ†æˆgpuå’Œcpuä¸¤ç§ç±»å‹ï¼Œåˆ†åˆ«ç®¡ç†è¿™ä¸¤ç±»è®¾å¤‡ä¸Šçš„ç‰©ç†å—**ã€‚**ä½ å¯èƒ½ä¼šé—®ï¼Œcpuä¸Šçš„ç‰©ç†å—æ˜¯ä»€ä¹ˆå‘¢**ï¼Ÿä½ è¿˜è®°å¾—è°ƒåº¦å™¨æœ‰ä¸€ä¸ªswapç­–ç•¥å—ï¼Ÿå½“gpuä¸Šæ˜¾å­˜ä¸è¶³æ—¶ï¼Œå®ƒä¼šæŠŠåæ¥çš„è¯·æ±‚æŠ¢å ï¼Œå¹¶å°†å…¶ç›¸å…³çš„KV cacheç‰©ç†å—å…¨éƒ¨éƒ½å…ˆswapï¼ˆç½®æ¢ã€å¸è½½ï¼‰åœ¨cpuä¸Šï¼Œç­‰åç»­gpuæ˜¾å­˜å……è¶³æ—¶ï¼Œå†æŠŠå®ƒä»¬åŠ è½½å›gpuä¸Šç»§ç»­åšç›¸å…³è¯·æ±‚çš„æ¨ç†ã€‚æ‰€ä»¥åœ¨cpuä¸Šæˆ‘ä»¬ä¹Ÿéœ€è¦ä¸€ä¸ªç®¡æ§ç‰©ç†å—çš„BlockAllocatorã€‚**å®é™…ä»£ç å®ç°æ—¶ï¼ŒBlockç›¸å…³çš„éƒ¨åˆ†å¯ä¸æ­¢è¿™ä¸¤ä¸ªclassï¼Œè¿˜æœ‰ä¸€äº›æ›´å¤æ‚çš„é€»è¾‘ç»†èŠ‚ã€‚è¿™ä¸ªæˆ‘ä»¬æ”¾åœ¨æœ¬ç³»åˆ—åé¢çš„æ–‡ç« ä¸­è®²è§£**ã€‚ Distributed Workersï¼Œä¹Ÿå°±æ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿï¼Œä½ å¯ä»¥å°†æ¯ä¸ªworkerç†è§£æˆä¸€å—gpuã€‚å®ƒçš„ä½œç”¨æ˜¯å°†æˆ‘ä»¬è¦ä½¿ç”¨çš„æ¨¡å‹loadåˆ°å„å—å¡ä¸Šï¼ˆç›®å‰å¯¹å•å¡è£…ä¸ä¸‹çš„æ¨¡å‹ï¼ŒvLLMæ”¯æŒtp/ppæ¨ç†ï¼‰ï¼Œç„¶åå¯¹Controllerä¼ æ¥çš„æ•°æ®åš1æ¬¡æ¨ç†ï¼Œè¿”å›ç›¸å…³ç»“æœã€‚æˆ‘ä»¬æ¥ç»†çœ‹ä¸‹è¿™å—ï¼š **Distributed Workers**ï¼šå›¾ä¸­ç»˜åˆ¶ä¸ºDistributed Workersè¿™ä¸ªç»¿è‰²å—ï¼Œ**å…¶å®æŒ‰vLLMçš„æºç å†…å®¹ï¼Œå†™æˆExecutorä¼šæ›´åˆé€‚ä¸€äº›**ã€‚**å®ƒå°±æ˜¯æ‰€æœ‰Workersçš„ç®¡æ§ä¸­å¿ƒ**ï¼Œå®ƒæŒ‡å®šäº†ç”¨ä»€ä¹ˆæ–¹æ³•ç®¡æ§è¿™äº›Workersï¼Œè´Ÿè´£åˆ†å¸ƒå¼ç¯å¢ƒçš„åˆå§‹åŒ–ï¼Œç›®å‰æ”¯æŒçš„æ–¹æ³•æœ‰ï¼š cpu_executorï¼šï¼ˆè¾ƒå°‘ç”¨ï¼‰ï¼Œä½¿ç”¨cpuåšæ¨ç†æ—¶å¯è€ƒè™‘ gpu_executorï¼šå•å¡ï¼ˆworld_size 1ï¼‰çš„æƒ…å†µä¸‹å¯ç”¨ ray_gpu_executorï¼šä½¿ç”¨rayè¿™ä¸ªåˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶å®ç°çš„executorï¼Œé€‚ç”¨äºå¤šå¡ç¯å¢ƒ **Worker**ï¼š**åœ¨ç¡¬ä»¶ä¸Šï¼Œå®ƒæŒ‡gpuï¼›åœ¨ä»£ç ä¸Šï¼Œå®ƒæŒ‡çš„æ˜¯Workerå®ä¾‹ï¼ˆæ¯ä¸ªgpuä¸Šçš„è¿›ç¨‹ç»´æŠ¤è‡ªå·±çš„Workerå®ä¾‹ï¼‰**ã€‚åœ¨æ¯ä¸ªWorkerå®ä¾‹ä¸­åˆç®¡æ§ç€å¦‚ä¸‹ä¸¤ä¸ªé‡è¦å®ä¾‹ï¼š **CacheEngineï¼š**è´Ÿè´£ç®¡æ§gpu/cpuä¸Šçš„KV cacheç‰©ç†å—ï¼ˆè°ƒåº¦å™¨çš„block manageråªè´Ÿè´£ç‰©ç†å—idçš„åˆ†é…ï¼ŒCacheEngineåˆ™æ˜¯æ ¹æ®è¿™ä¸ªidåˆ†é…ç»“æœå®æ‰“å®åœ°åœ¨ç®¡ç†ç‰©ç†å—ä¸­çš„æ•°æ®ï¼‰ **Worker.model**ï¼šæ ¹æ®vLLMä»£ç ï¼Œè¿™é‡Œå†™æˆ**model_runner**ä¼šæ›´åˆé€‚ä¸€äº›ã€‚**å®ƒè´Ÿè´£åŠ è½½æ¨¡å‹ï¼Œå¹¶æ‰§è¡Œæ¨ç†**ã€‚PagedAttentionçš„ç›¸å…³é€»è¾‘ï¼Œå°±ç»´æŠ¤è¿™ä¸ªå®ä¾‹å…³è”çš„ä»£ç ä¸‹ã€‚ ## æ–‡ä»¶æ„æˆ ![image 20241231170219993](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202412311702190.png) ![image 20241231170824801](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202412311708851.png) ## Debug ä½¿ç”¨ä¸‹é¢çš„è„šæœ¬ ![image 20241231171219425](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202412311712460.png) ```python from vllm import LLM, SamplingParams # Sample prompts. prompts [ \"Hello, my name is\", \"The president of the United States is\", \"The capital of France is\", \"The future of AI is\", ] # Create a sampling params object. sampling_params SamplingParams(temperature 0.8, top_p 0.95) # Create an LLM. llm LLM(model \"facebook/opt 125m\") # Generate texts from the prompts. The output is a list of RequestOutput objects # that contain the prompt, generated text, and other information. outputs llm.generate(prompts, sampling_params) # Print the outputs. for output in outputs: prompt output.prompt generated_text output.outputs[0].text print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\") ``` è¿™é‡Œåœ¨åˆå§‹åŒ–çš„æ—¶å€™åŠ è½½äº†ä¸€ä¸ªæ¨¡å‹, è¿™ä¸ªæ¨¡å‹çš„ç±»å‹æ˜¯ä¸€ä¸ªLLMç±»å‹çš„, åœ¨æ–‡ä»¶`llm.py`é‡Œé¢ ![image 20241231173220166](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202412311732206.png) LLM >EngineArgs >LLMEngine ä½¿ç”¨EngineArgsè¿›è¡Œå‚æ•°çš„åˆå§‹åŒ–, ä¹‹åä½¿ç”¨æ ‡å‡†åŒ–çš„å‚æ•°è¿›è¡Œåˆå§‹åŒ–ä¸€ä¸ªEngine åœ¨Engineé‡Œé¢ä¸»è¦æ˜¯åˆå§‹åŒ–Tokenizer, model_executer, init_kv_cacheä»¥åŠschedular, è¿™é‡Œé¢æœ€ä¸»è¦çš„æ˜¯æ‰§è¡Œå™¨model_executer ![image 20250102132307961](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501021323221.png) åœ¨è¿™ä¸€ä¸ªæ–‡ä»¶å¤¹é‡Œé¢æ˜¯å„ç§å„æ ·çš„æ‰§è¡Œå™¨, æ‰€æœ‰çš„æ‰§è¡Œå™¨ä½¿ç”¨ç»Ÿä¸€çš„çˆ¶ç±»ExecutorBase, åœ¨executor_baseæ–‡ä»¶é‡Œé¢, gpué‡Œé¢æœ€åä½¿ç”¨çš„åˆå§‹åŒ–å‡½æ•°å¦‚ä¸‹ ```python def _init_executor(self) > None: \"\"\"Initialize the worker and load the model. \"\"\" assert self.parallel_config.world_size 1, ( \"GPUExecutor only supports single GPU.\") self.driver_worker self._create_worker() self.driver_worker.init_device() self.driver_worker.load_model() ``` åœ¨å»ºç«‹workerçš„æ—¶å€™ä½¿ç”¨çš„ç±»æ˜¯WorkerWrapperBase, è¿™ä¸€å±‚æœ€åæ“ä½œçš„ä¸ºModelRunnerè¿™ä¸€ä¸ªå±‚é¢, åˆ°äº†è¿™ä¸€å±‚ä»¥åå®é™…åŠ è½½çš„æ¨¡å‹ä¸åŒä½¿ç”¨ä¸åŒçš„åŠ è½½æ–¹å¼ ### æ¨ç† åœ¨å®é™…è°ƒç”¨çš„æ—¶å€™ä½¿ç”¨çš„æ˜¯æŠŠæ•°æ®è°ƒç”¨llmçš„generateæ–¹æ³•è¿›è¡Œç”Ÿæˆ è¿™ä¸€ä¸ªå‡½æ•°å¯¹ä¼ è¿›æ¥çš„å‚æ•°è¿›è¡Œå¤„ç†ä»¥åä½¿ç”¨å‡½æ•°_add_requestå‡½æ•°è¿›è¡Œæ·»åŠ å‚æ•°, æœ€åä½¿ç”¨run_engineå‡½æ•° å®é™…æ˜¯æŠŠæ•°æ®ä¼ é€’ç»™engine ![image 20250102141010599](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501021410675.png) _add_processed_requestè¿™ä¸€ä¸ªå‡½æ•°é‡Œé¢æŠŠæ•°æ®åŠ å…¥SequenceGroup, ä½¿ç”¨add_seq_groupç»™è°ƒåº¦å™¨ å®é™…çš„æ‰§è¡Œæ˜¯åœ¨llmçš„run_engineé‡Œé¢ ![image 20250102141532186](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501021415245.png) æ¯ä¸€æ­¥å®é™…æ˜¯åœ¨executer_model ## è°ƒåº¦å™¨ å†å¼€å§‹çš„æ—¶å€™åˆå§‹åŒ–ä¸€ä¸ªå—ç®¡ç†å™¨ ```c class Circle{ // å…¬å…±æƒé™ public: int radius; double calculateArea(){ return 3.14159 * radius * radius; } }; int main(void){ Circle circle; circle.radius 10; std::cout << \"The area of the circle is: \" << circle.calculateArea() << std::endl; return 0; } ```"},"/note/æœºå™¨å­¦ä¹ /vllmä»£ç åˆ†æ/2024-12-31-01-collect_env.html":{"title":"","content":"## åŒ… ```python import datetime import locale import os import re import subprocess import sys # Unlike the rest of the PyTorch this file must be python2 compliant. # This script outputs relevant system environment info # Run it with `python collect_env.py` or `python m torch.utils.collect_env` from collections import namedtuple from vllm.envs import environment_variables # å°è¯•è·å–ä¸€ä¸‹torch try: import torch TORCH_AVAILABLE True except (ImportError, NameError, AttributeError, OSError): TORCH_AVAILABLE False ``` ### ä¸»å‡½æ•°main é¦–å…ˆä½¿ç”¨`output get_pretty_env_info()`è·å–ç³»ç»Ÿçš„ä¿¡æ¯, è¿™ä¸€ä¸ªå‡½æ•°å®é™…æ˜¯å¯¹`get_env_info`å‡½æ•°è·å–çš„ä¿¡æ¯è¿›è¡Œå¤„ç† ### get_env_infoè·å–ä¿¡æ¯ é¦–å…ˆä½¿ç”¨`et_pip_packages`å‡½æ•°è·å–pipçš„åŒ… ä½¿ç”¨`python mpip list format freeze`å‘½ä»¤, ç”¨`run`å‡½æ•°è¿›è¡Œè¿è¡Œ `python`: è¡¨ç¤ºè¦è¿è¡ŒPythonè§£é‡Šå™¨ ` m pip`: è¡¨ç¤ºè¦è¿è¡Œpipæ¨¡å—ï¼Œä½¿ç”¨è¯¥é€‰é¡¹è¿è¡Œpipæ¨¡å—å¯ä»¥åœ¨ä¸å®‰è£…pipçš„æƒ…å†µä¸‹ä½¿ç”¨pipçš„åŠŸèƒ½ `list`: è¡¨ç¤ºè¦åˆ—å‡ºå·²å®‰è£…çš„åŒ… ` format freeze`: è¡¨ç¤ºä»¥ç‰¹å®šæ ¼å¼æ˜¾ç¤ºå·²å®‰è£…çš„åŒ…åˆ—è¡¨ï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯freezeæ ¼å¼ï¼Œå³æ¯ä¸ªåŒ…çš„åç§°å’Œç‰ˆæœ¬å·éƒ½è¢«åˆ—å‡ºæ¥ã€‚freezeæ ¼å¼å¸¸ç”¨äºç”Ÿæˆrequirements.txtæ–‡ä»¶ï¼Œç±»ä¼¼äºä½¿ç”¨pip freezeå‘½ä»¤ã€‚ ä¹‹åå¦‚æœå¯ä»¥å¯¼å…¥`torch`\t ### run() ```python def run(command): ``` > å®é™…çš„è¿è¡Œå‡½æ•°, ä½¿ç”¨ä¼ è¿›æ¥çš„å‘½ä»¤å»ºç«‹ä¸€ä¸ªè¿›è¡Œ, è¿›è¡Œä»»åŠ¡çš„æ‰§è¡Œä»¥åŠè·å–è¿”å›å€¼ > > å®é™…çš„è¿”å›å€¼æ˜¯è¿›è¡Œçš„è¿”å›å€¼ä»¥åŠstderr, stdoutçš„è¾“å‡º è¿™ä¸€ä¸ªå‡½æ•°å®é™…æ˜¯ä½œä¸ºä¸€ä¸ªå‡½æ•°æŒ‡é’ˆè¿›è¡Œè°ƒç”¨çš„ run_lambda run"},"/note/æœºå™¨å­¦ä¹ /2024-10-7-Pandasåº“.html":{"title":"Pandasåº“","content":" layout: post title: \"Pandasåº“\" date: 2024 8 5 15:39:08 +0800 tags: AI æœºå™¨å­¦ä¹  # pandasåº“ [æœºå™¨å­¦ä¹ ï¼šPythonå¸¸ç”¨åº“â€”â€”Pandasåº“ çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/231466121#:~:text Pandasåº“åœ¨æ•°æ®) Pandasåº“åœ¨æ•°æ®åˆ†æä¸­æ˜¯éå¸¸å¸¸ç”¨çš„åº“ï¼Œåœ¨[æ•°æ®é¢„å¤„ç†](https://www.zhihu.com/search?q æ•°æ®é¢„å¤„ç†&search_source Entity&hybrid_search_source Entity&hybrid_search_extra {\"sourceType\"%3A\"article\"%2C\"sourceId\"%3A231466121})ã€ç¼ºå¤±å€¼å¡«è¡¥ã€æ—¶é—´åºåˆ—ã€[å¯è§†åŒ–](https://www.zhihu.com/search?q å¯è§†åŒ–&search_source Entity&hybrid_search_source Entity&hybrid_search_extra {\"sourceType\"%3A\"article\"%2C\"sourceId\"%3A231466121})ç­‰æ–¹é¢éƒ½æœ‰åº”ç”¨ã€‚ ```python import pandas as pd ``` + æ•°æ®è¯»å– Pandaså¯ä»¥è¯»å–txtã€csvã€xlsç­‰ç»“æ„çš„æ•°æ®ã€‚è¯»å–csvæ•°æ®å¯ä»¥ä½¿ç”¨`pd.read_csv()`å‡½æ•° ```python import pandas as pd result pd.read_csv(\"E:\\Pandascsv.csv\") #æ¯ä¸ªäººæ–‡ä»¶è·¯å¾„ä¸åŒ print(result.head()) # è¯»å–å‰äº”æ¡æ•°æ® ``` + æ•°æ®æå– å¦‚æœæˆ‘ä»¬æƒ³å•ç‹¬çœ‹ä½“é‡ï¼ˆweightï¼‰è¿™ä¸€æ ï¼Œå¯ä»¥ç”¨åˆ—åç›´æ¥æå–ï¼š ```python print(result[\"weight(kg)\"].head(6)) ``` å¦‚æœæƒ³çœ‹3æœˆä»½åˆ°6æœˆä»½çš„æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨**iloc[è¡Œ, åˆ—]**æ–¹æ³•ï¼š ```python print(result.iloc[2:6,:]) ``` ç±»ä¼¼çš„åˆ‡ç‰‡æ–¹æ³•è¿˜æœ‰**locã€ix**ç­‰ï¼ŒåŒºåˆ«å¦‚ä¸‹ï¼š l locï¼šé€šè¿‡è¡Œæ ‡ç­¾ç´¢å¼•è¡Œæ•°æ®ï¼› l ilocï¼šé€šè¿‡è¡Œå·ç´¢å¼•è¡Œæ•°æ®ï¼› l ixï¼šé€šè¿‡è¡Œæ ‡ç­¾æˆ–è¡Œå·ç´¢å¼•è¡Œæ•°æ®ï¼ˆåŸºäºlocå’Œilocçš„æ··åˆï¼‰"},"/note/æœºå™¨å­¦ä¹ /2024-10-6-Juoyter.html":{"title":"Jupyter","content":" layout: post title: \"Jupyter\" date: 2024 8 5 15:39:08 +0800 tags: AI æœºå™¨å­¦ä¹  # Jupyter ## é­”æ³•æŒ‡ä»¤ ### è®¡ç®—æ—¶é—´ ```python %%time # pythonè¯­å¥ ``` > ä¼šè®¡ç®—è¿™ä¸€ä¸ªä»£ç æ¡†çš„æ‰§è¡Œæ—¶é—´ ## å¿«æ·é”® ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i blog.csdnimg.cn/blog_migrate/897be6c748f267e56a5c8471a3cc2262.png#pic_center)"},"/note/æœºå™¨å­¦ä¹ /2024-10-9-transformså®æˆ˜.html":{"title":"Transformerså®æˆ˜","content":" layout: post title: \"Transformerså®æˆ˜\" date: 2024 8 5 15:39:08 +0800 tags: AI æœºå™¨å­¦ä¹  # Transformerså®æˆ˜ ## åŸºäºTransformsçš„NLPè§£å†³ > NLPè‡ªç„¶è¯­è¨€å¤„ç†, *ModelForSequenceClassification + å¯¼å…¥ç›¸å…³çš„åŒ… General + åŠ è½½æ•°æ®é›† Dataset + æ•°æ®é›†åˆ’åˆ† Dataset + æ•°æ®é›†é¢„å¤„ç† Tokenizer + Dataset + æ„å»ºæ¨¡å‹ Model + è®¾ç½®è¯„ä¼°å‡½æ•° Evaluate + è®¾ç½®è®­ç»ƒå‚æ•° TrainingArguments + åˆ›å»ºè®­ç»ƒå™¨ trainer + Data Collator + è¯„ä¼°æ¨¡å‹, é¢„æµ‹æ•°æ®é›† Trainer + æ¨¡å‹é¢„æµ‹, å•æ¡ Pipe ## æ˜¾å­˜ä¼˜åŒ– ### å ç”¨åˆ†æ + æ¨¡å‹çš„æƒé‡ 4Bytes * æ¨¡å‹çš„å‚æ•°é‡ > å¤§æ¨¡å‹æƒé‡æ˜¯æŒ‡æ¨¡å‹ä¸­æ¯ä¸ªç¥ç»å…ƒè¿æ¥çš„å‚æ•°ã€‚è¿™äº›æƒé‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­è°ƒæ•´ï¼Œä»¥ä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å‡†ç¡®åœ°é¢„æµ‹è¾“å‡ºã€‚ç®€å•æ¥è¯´ï¼Œæƒé‡å†³å®šäº†è¾“å…¥æ•°æ®å¦‚ä½•é€šè¿‡æ¨¡å‹è¢«å¤„ç†å’Œè½¬æ¢ã€‚ + ä¼˜åŒ–å™¨çŠ¶æ€optimizer state adamçš„momentum + variance å  2*4Byte å†²é‡å’Œæ–¹å·® æ··åˆç²¾åº¦çš„å®ç°ä¸­ï¼Œéœ€è¦å¤åˆ¶ä¸€ä»½fp32çš„å‚æ•°ä½œä¸ºè¢«optimizeræ›´æ–°çš„å‚æ•°ï¼Œ 1*4Byte > è¿™äº›æ•°æ®åŒ…æ‹¬æ¨¡å‹æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ã€å­¦ä¹ ç‡ã€åŠ¨é‡ç­‰ä¿¡æ¯ï¼Œé€šè¿‡è¿™äº›æ•°æ®ï¼Œä¼˜åŒ–å™¨èƒ½å¤Ÿå¸®åŠ©æ¨¡å‹é€æ­¥æ”¶æ•›åˆ°æœ€ä¼˜è§£ã€‚ > > 1. æ¢¯åº¦æ›´æ–°ï¼šä¼˜åŒ–å™¨èƒ½å¤Ÿæ ¹æ®æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦æ¥æ›´æ–°å‚æ•°å€¼ï¼Œé€šè¿‡ä¸æ–­è¿­ä»£ä¼˜åŒ–å‚æ•°ï¼Œä½¿æ¨¡å‹é€æ¸æ”¶æ•›åˆ°æœ€ä¼˜è§£ã€‚ > 2. å­¦ä¹ ç‡è°ƒæ•´ï¼šä¼˜åŒ–å™¨å¯ä»¥æ ¹æ®æ¨¡å‹å½“å‰çš„æ€§èƒ½è¡¨ç°åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡ï¼Œä½¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´åŠ ç¨³å®šå’Œé«˜æ•ˆã€‚ > 3. åŠ¨é‡è®¡ç®—ï¼šä¼˜åŒ–å™¨è¿˜å¯ä»¥é€šè¿‡è®°å½•çš„åŠ¨é‡ä¿¡æ¯ï¼Œå¸®åŠ©æ¨¡å‹åœ¨æ›´æ–°å‚æ•°æ—¶æ›´å¥½åœ°è·³å‡ºå±€éƒ¨æœ€ä¼˜è§£ï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ã€‚ > 4. è¿‡æ‹Ÿåˆé¿å…ï¼šä¼˜åŒ–å™¨è¿˜å¯ä»¥é€šè¿‡è®°å½•çš„æ•°æ®å¸®åŠ©æ¨¡å‹é¿å…è¿‡æ‹Ÿåˆï¼Œé€šè¿‡æ­£åˆ™åŒ–ç­‰æŠ€æœ¯æ¥ä¿æŒæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ + æ¢¯åº¦ 4 Byte * æ¨¡å‹å‚æ•°é‡ > æ¢¯åº¦æ•°æ®æ˜¯æŒ‡æ¯ä¸ªå‚æ•°å¯¹åº”çš„æ¢¯åº¦å€¼ï¼Œè¡¨ç¤ºäº†ç›®æ ‡å‡½æ•°åœ¨å½“å‰å‚æ•°å€¼å¤„çš„å˜åŒ–ç‡ã€‚ + å‘å‰æ¿€æ´»é‡ åºåˆ—é•¿åº¦, éšå±‚ç»´åº¦, Batchå¤§å°ç­‰ > ä»è¾“å…¥å±‚å¼€å§‹å‘å‰ä¼ æ’­çš„æ¿€æ´»å€¼ã€‚åœ¨æ·±åº¦ç¥ç»ç½‘ç»œä¸­ï¼Œæ¯ä¸ªç¥ç»å…ƒéƒ½æœ‰ä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼Œæ¿€æ´»å‡½æ•°å¯¹è¾“å…¥çš„åŠ æƒå’Œè¿›è¡Œéçº¿æ€§å˜æ¢å¹¶äº§ç”Ÿè¾“å‡ºï¼Œè¿™ä¸ªè¾“å‡ºå°±æ˜¯æ¿€æ´»å€¼ã€‚ > > åœ¨æ¨¡å‹çš„å‘å‰ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œè¾“å…¥æ•°æ®ç»è¿‡å¤šå±‚ç¥ç»å…ƒè¿›è¡ŒåŠ æƒå’Œæ¿€æ´»æ“ä½œï¼Œé€å±‚ä¼ é€’å¹¶äº§ç”Ÿæ–°çš„æ¿€æ´»å€¼ï¼Œæœ€ç»ˆåœ¨è¾“å‡ºå±‚äº§ç”Ÿé¢„æµ‹æˆ–åˆ†ç±»ç»“æœã€‚è¿™ä¸€ç³»åˆ—æ¿€æ´»å€¼ç›¸äº’ä¼ é€’ï¼Œå¹¶åœ¨å„å±‚ä¹‹é—´åæ˜ äº†æ¨¡å‹å¯¹æ•°æ®çš„ç†è§£å’Œæå–çš„ç‰¹å¾ã€‚ > > éšå±‚ï¼ˆæˆ–éšè—å±‚ï¼‰ç»´åº¦æ˜¯æŒ‡ç¥ç»ç½‘ç»œä¸­çš„ä¸­é—´å±‚çš„ç»´åº¦å¤§å°ã€‚éšå±‚æ˜¯ä»‹äºè¾“å…¥å±‚å’Œè¾“å‡ºå±‚ä¹‹é—´çš„ä¸€å±‚æˆ–å¤šå±‚ç¥ç»å…ƒå±‚ï¼Œè´Ÿè´£å¯¹è¾“å…¥æ•°æ®è¿›è¡Œç‰¹å¾æå–å’Œè¡¨ç¤ºå­¦ä¹ ã€‚éšå±‚çš„ç»´åº¦å†³å®šäº†ç¥ç»ç½‘ç»œå¯ä»¥å­¦ä¹ åˆ°çš„ç‰¹å¾çš„å¤æ‚åº¦å’Œä¸°å¯Œæ€§ã€‚ ### å®é™…ä¼˜åŒ– ä½¿ç”¨æ¨¡å‹æ˜¯`hfl/chinese macbert large` ä½¿ç”¨çš„å‚æ•°ä¸ºbach 32, maxlength 128 + å¼€å§‹å‰ ![image 20241011180016774](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410111800477.png) ![image 20241011180107925](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410111801981.png) å®é™…çš„è®­ç»ƒéå¸¸çš„æ…¢é¢„ä¼°ä¸€ä¸ªå¤šå°æ—¶![image 20241011182919692](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410111829757.png) + ä½¿ç”¨bach sizeä¸º1, ä½†æ˜¯gradient accumulationä¸º32, ä¹Ÿå°±æ˜¯æ¯è®¡ç®—32æ¬¡æ›´æ–°ä¸€ä¸‹å‚æ•°, ä¼˜åŒ–å‘å‰æ¿€æ´»å€¼ ```python gradient_accumulation_steps 32, ``` ä½¿ç”¨è¿™ä¸€ä¸ªçš„æ—¶å€™ä½¿ç”¨çš„å†…å­˜ä¸‹é™, ä½†æ˜¯è®­ç»ƒä½¿ç”¨çš„æ—¶é—´å¤§å¤§åŠ é•¿(æˆ‘çš„ç”µè„‘çš„æ˜¾å­˜è¿˜æ˜¯å…¨éƒ¨å ç”¨), ä¸‹é™äº†ä¸€åŠ GPUä¸€èˆ¬æ¯”è¾ƒæ“…é•¿å¹¶è¡Œçš„è®¡ç®—, æ‰€ä»¥è¿™ä¸€ä¸ªæ²¡æœ‰å……åˆ†åˆ©ç”¨ + åœ¨è®¡ç®—çš„æ—¶å€™æœ‰å¾ˆå¤šä¸­é—´çš„ç»“æœ, å¯ä»¥ä¸è®°å½•, ä½¿ç”¨çš„æ—¶å€™å†æ¬¡è®¡ç®—Gradient Checkpoints ```python gradient_checkpointing True ``` + ä½¿ç”¨å†…å­˜å ç”¨æ¯”è¾ƒå°çš„ä¼˜åŒ–å™¨, é»˜è®¤ä½¿ç”¨çš„æ˜¯adamw_torchè¿™ä¸€ä¸ªä¼˜åŒ–å™¨ ```python optim \"adafactor\" ``` GPUå†…å­˜ä½¿ç”¨çš„å†æ¬¡ä¸‹é™, æ—¶é—´åŠ é•¿ + åœ¨è®­ç»ƒçš„æ—¶å€™åªè®­ç»ƒä¸€éƒ¨åˆ†çš„å‚æ•°, æ¯”å¦‚åªè®­ç»ƒå…¨è¿æ¥å±‚, ä¸è®­ç»ƒbert > åœ¨åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œå…¨è¿æ¥å±‚é€šå¸¸ä½œä¸ºç½‘ç»œçš„æœ€åä¸€å±‚ï¼Œç›´æ¥å°†å…¨è¿æ¥å±‚çš„ç»´åº¦è®¾ä¸ºç±»åˆ«æ•°é‡æˆ–é€šè¿‡Softmaxå‡½æ•°è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä»è€Œå®ç°å¯¹è¾“å…¥æ•°æ®çš„åˆ†ç±»ã€‚å¦‚æœè¯´å·ç§¯å±‚ã€æ± åŒ–å±‚å’Œæ¿€æ´»å‡½æ•°ç­‰æ“ä½œæ˜¯å°†åŸå§‹æ•°æ®æ˜ å°„åˆ°éšå±‚ç‰¹å¾ç©ºé—´çš„è¯ï¼Œå…¨è¿æ¥å±‚åˆ™èµ·åˆ°å°†å­¦åˆ°çš„â€œåˆ†å¸ƒå¼ç‰¹å¾è¡¨ç¤ºâ€æ˜ å°„åˆ°æ ·æœ¬æ ‡è®°ç©ºé—´çš„ä½œç”¨ã€‚ > > [è¯»æ‡‚BERTï¼Œçœ‹è¿™ä¸€ç¯‡å°±å¤Ÿäº† çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/403495863) ```python for name, param in model.bert.named_parameters(): param.requires_grad False ``` ## å‘½åå®ä½“è¯†åˆ« NER Named Entity(å®ä½“) Recognitionç”¨äºè¯†åˆ«æ–‡æœ¬é‡Œé¢çš„ç‰¹å®šæ„ä¹‰çš„å®ä½“, äººååœ°å, æœºæ„å, ä¸“æœ‰åè¯ç­‰, ä¸»è¦æ˜¯åŒ…æ‹¬ä¸¤éƒ¨åˆ†(1)å®ä½“è¾¹ç•Œè¯†åˆ«(2)ç¡®å®šå®ä½“è¯†åˆ«(äººå, åœ°å, æœºæ„å) > *ModelForTokenClassification ![image 20241012095849325](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410120958515.png) ![image 20241012100051830](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121000892.png) ![image 20241012100903586](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121009651.png) ### æ¨¡å‹ç»“æ„ ![image 20241012101417218](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121014290.png) ![image 20241012102025517](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121020584.png) ![image 20241012102319901](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121023968.png) ### å®é™…è®­ç»ƒ ä½¿ç”¨çš„æ•°æ®é›†æ˜¯`peoples_daily_ner`, ä½¿ç”¨çš„æ¨¡å‹æ˜¯`hfl/chinese macbert base` + å¯¼åŒ… ```python import evaluate from datasets import load_dataset from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification ``` + è·å–æ•°æ®é›† ```python ner_dataset load_dataset(\"peoples_daily_ner\", trust_remote_code True) ner_dataset[\"train\"][0] ``` > ```python > {'id': '0', > 'tokens':['æµ·','é’“','æ¯”','èµ›','åœ°','ç‚¹','åœ¨','å¦','é—¨','ä¸', > 'é‡‘','é—¨','ä¹‹','é—´','çš„','æµ·','åŸŸ','ã€‚'], > 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6, 0, 0, 0, 0, 0, 0]} > ``` > > ```python > ner_dataset[\"train\"].features > \"\"\" > {'id': Value(dtype 'string', id None), > 'tokens': Sequence(feature Value(dtype 'string', id None), length 1, id None), > 'ner_tags': Sequence(feature ClassLabel(names ['O', 'B PER', 'I PER', 'B ORG', 'I ORG', 'B LOC', 'I LOC'], id None), length 1, id None)} > PER: äººå ORG: ç»„ç»‡å LOC: åœ°å > \"\"\" > ``` ```python label_list ner_dataset[\"train\"].features[\"ner_tags\"].feature.names ``` + å¤„ç†æ•°æ®é›† ```python tokenizer AutoTokenizer.from_pretrained(\"hfl/chinese macbert base\") # åœ¨å¤„ç†çš„æ—¶å€™ç”±äºå·²ç»åˆ†è¯, æ‰€ä»¥éœ€è¦ä½¿ç”¨è¿™ä¸€ä¸ªå‚æ•° tokenizer(ner_dataset[\"train\"][0][\"tokens\"], is_split_into_words True) ``` > ä½†æ˜¯è¿™ä¸€ä¸ªæ‹†åˆ†å¯èƒ½ä¸æ˜¯åˆ†è¯å™¨ä½¿ç”¨çš„æ‹†åˆ†æ–¹å¼, å¯ä»¥ä½¿ç”¨è·å–ä¿¡æ¯word_idsåŒºåˆ†å“ªå‡ ä¸ªToken_idsæ˜¯ä¸€ä¸ªè¯çš„ > > ![image 20241012110603090](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121106150.png) ```python def process_function(examples): tokenized_examples tokenizer(examples[\"tokens\"], max_length 128, truncation True, is_split_into_words True) labels [] for i, label in enumerate(examples[\"ner_tags\"]): # è·å–ä¸€ä¸ªæ ‡ç­¾ word_ids tokenized_examples.word_ids(batch_index i) label_ids [] for word_idx in word_ids: # è·å–å½“å‰ token æ˜¯å¦æ˜¯ä¸€ä¸ª word çš„ç¬¬ä¸€ä¸ª token if word_idx is None: label_ids.append( 100) # 100 ä»£è¡¨ä¸æ˜¯ä¸€ä¸ª token else: label_ids.append(label[word_idx]) labels.append(label_ids) tokenized_examples[\"labels\"] labels return tokenized_examples tokenized_datasets ner_dataset.map(process_function, batched True, remove_columns ner_dataset[\"train\"].column_names) ``` > ```python > tokenized_datasets[\"train\"][0] > ``` > > ```python > {'input_ids': [101,3862,7157,3683, > ..., > 1818,511,102], > 'token_type_ids': [0,0,0, > ..., > 0,0], > 'attention_mask': [1,1, > ..., > 1], > 'labels': [ 100, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6, 0, 0, 0, 0, 0, 0, 100]} > ``` + æ¨¡å‹ ```pyrhon model AutoModelForTokenClassification.from_pretrained(\"hfl/chinese macbert base\") ``` + è¯„ä¼°å‡½æ•° ```python seqeval evaluate.load(\"seqeval\") ``` ![image 20241012113140256](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121131311.png) ![image 20241012113533547](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121135608.png) ```python import numpy as np def eval_metric(pred): predictions, labels pred predictions np.argmax(predictions, axis 1) # è·å–å®é™…çš„é¢„æµ‹å€¼ # Remove ignored index (special tokens) true_predictions [ [label_list[p] for (p, l) in zip(prediction, label) if l ! 100] # å¯¹åº”æ¯ä¸€ä¸ªæ•°æ® for prediction, label in zip(predictions, labels) # éå†ä¸€ä¸ªbatch ] true_labels [ [label_list[l] for (p, l) in zip(prediction, label) if l ! 100] for prediction, label in zip(predictions, labels) ] results seqeval.compute(true_predictions, true_labels, mode \"strict\", scheme \"BIO2\") return { \"f1\": results[\"overall_f1\"] } ``` + å‚æ•° ```python args TrainingArguments( output_dir \"model_for_ner\", per_device_eval_batch_size 64, per_device_train_batch_size 128, evaluation_strategy \"epoch\", save_strategy \"epoch\", metric_for_best_model \"f1\", load_best_model_at_end True, logging_steps 50 ) ``` ```python trainer.train() trainer.evaluate(eval_dataset tokenized_datasets[\"test\"]) ``` + æµ‹è¯• ```python from transformers import pipeline model.config.id2label {idx: label for idx, label in enumerate(label_list)} # ä¿®æ”¹ä¸€ä¸‹æ˜ å°„ \"\"\"é»˜è®¤çš„æ˜ å°„æ˜¯ \"id2label\": { \"0\": \"LABEL_0\", \"1\": \"LABEL_1\", \"2\": \"LABEL_2\", \"3\": \"LABEL_3\", \"4\": \"LABEL_4\", \"5\": \"LABEL_5\", \"6\": \"LABEL_6\" }, \"\"\" ner_pipe pipeline(\"token classification\", model model, tokenizer tokenizer, device 0, aggregation_strategy \"simple\") # ä½¿ç”¨èšåˆçš„æ¨¡å¼è¾“å‡º \"\"\" [{'entity_group': 'PER', 'score': 0.99990124, 'word': 'å² å‡¯ æ­Œ', 'start': 0, 'end': 3}, {'entity_group': 'LOC', 'score': 0.9998995, 'word': 'åŒ— äº¬', 'start': 4, 'end': 6}] \"\"\" ``` > [Pipelines (huggingface.co)](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TokenClassificationPipeline) > > â€œnoneâ€ : Will simply not do any aggregation and simply return raw results from the model > â€œsimpleâ€ : Will attempt to group entities following the default schema. (A, B TAG), (B, I TAG), (C, I TAG), (D, B TAG2) (E, B TAG2) will end up being [{â€œwordâ€: ABC, â€œentityâ€: â€œTAGâ€}, {â€œwordâ€: â€œDâ€, â€œentityâ€: â€œTAG2â€}, {â€œwordâ€: â€œEâ€, â€œentityâ€: â€œTAG2â€}] Notice that two consecutive B tags will end up as different entities. On word based languages, we might end up splitting words undesirably : Imagine Microsoft being tagged as [{â€œwordâ€: â€œMicroâ€, â€œentityâ€: â€œENTERPRISEâ€}, {â€œwordâ€: â€œsoftâ€, â€œentityâ€: â€œNAMEâ€}]. Look for FIRST, MAX, AVERAGE for ways to mitigate that and disambiguate words (on languages that support that meaning, which is basically tokens separated by a space). These mitigations will only work on real words, â€œNew yorkâ€ might still be tagged with two different entities. > â€œfirstâ€ : (works only on word based models) Will use the `SIMPLE` strategy except that words, cannot end up with different tags. Words will simply use the tag of the first token of the word when there is ambiguity. > â€œaverageâ€ : (works only on word based models) Will use the `SIMPLE` strategy except that words, cannot end up with different tags. scores will be averaged first across tokens, and then the maximum label is applied. > â€œmaxâ€ : (works only on word based models) Will use the `SIMPLE` strategy except that words, cannot end up with different tags. Word entity will simply be the token with the maximum score. + å»ç©ºæ ¼ ```python x \"å²å‡¯æ­Œåœ¨åŒ—äº¬åƒå±\" res ner_pipe(x) ner_result {} for r in res: if r[\"entity_group\"] not in ner_result: ner_result[r[\"entity_group\"]] [] ner_result[r[\"entity_group\"]].append(x[r[\"start\"]:r[\"end\"]]) ner_result ``` ## æœºå™¨é˜…è¯»ç†è§£ Machine Reading Comprehension ç®€ç§°MRC, æ˜¯ä¸€ä¸ªè®©æœºå™¨å›ç­”ç»™å®šçš„ä¸Šä¸‹æ–‡çš„æ¥æµ‹è¯•æœºå™¨é˜…è¯»ç†è§£è‡ªç„¶è¯­è¨€çš„ç¨‹åº¦çš„ä»»åŠ¡ å®ƒçš„å½¢å¼æ˜¯æ¯”è¾ƒå¤šæ ·åŒ–çš„, å¸¸è§çš„æœ‰å®Œå½¢å¡«ç©º, ç­”æ¡ˆé€‰æ‹©, ç‰‡æ®µæŠ½å–, è‡ªç”±ç”Ÿæˆ ![image 20241012193301378](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121933591.png) ![image 20241012193555638](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121935736.png) ### æ•°æ®é¢„å¤„ç† ![image 20241012194222195](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121942295.png) ### åŸç† ![image 20241012194951132](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410121949249.png) [#å½»åº•ç†è§£# pytorch ä¸­çš„ squeeze() å’Œ unsqueeze()å‡½æ•° çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/368920094) > åœ¨PyTorchä¸­ï¼Œtorch.squeezeå‡½æ•°çš„å‚æ•°ä¸º 1æ—¶è¡¨ç¤ºç§»é™¤ç»´åº¦ä¸º1çš„ç»´åº¦ã€‚å…·ä½“æ¥è¯´ï¼Œå½“ä½¿ç”¨torch.squeeze( 1)æ—¶ï¼Œä¼šå°†å¼ é‡çš„æœ€åä¸€ä¸ªç»´åº¦ä¸º1çš„ç»´åº¦ç§»é™¤ï¼Œä½¿å¾—å¼ é‡çš„ç»´åº¦å‡å°‘1ã€‚ > > ä¾‹å¦‚ï¼Œå¦‚æœæœ‰ä¸€ä¸ªç»´åº¦ä¸ºï¼ˆ2ï¼Œ1ï¼Œ3ï¼‰çš„å¼ é‡ï¼Œä½¿ç”¨torch.squeeze( 1)åä¼šå¾—åˆ°ä¸€ä¸ªç»´åº¦ä¸ºï¼ˆ2ï¼Œ3ï¼‰çš„å¼ é‡ã€‚ > > æ€»çš„æ¥è¯´ï¼Œtorch.squeeze( 1)çš„ä½œç”¨å°±æ˜¯ç§»é™¤å¼ é‡ä¸­ç»´åº¦ä¸º1çš„ç»´åº¦ã€‚ ![image 20241013103939723](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410131039811.png) é™å¹…ã€‚å°†inputçš„å€¼é™åˆ¶åœ¨[min, max]ä¹‹é—´ï¼Œå¹¶è¿”å›ç»“æœã€‚out ([Tensor](https://so.csdn.net/so/search?q Tensor&spm 1001.2101.3001.7020), optional) â€“ è¾“å‡ºå¼ é‡ï¼Œä¸€èˆ¬ç”¨ä¸åˆ°è¯¥å‚æ•°ã€‚ ![image 20241013105032554](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410131050644.png) ### å®é™…ä½¿ç”¨ + å¯¼åŒ… ```python from datasets import load_dataset from transformers import AutoTokenizer, AutoModelForQuestionAnswering, Trainer, TrainingArguments, DefaultDataCollator ``` + è·å–æ•°æ® ```python dataset load_dataset(\"cmrc2018\", trust_remote_code True) ``` + æ•°æ®å¤„ç† é¦–å…ˆä»answeré‡Œé¢è·å–æ•°æ®çš„èµ·å§‹ä½ç½®, ä¹‹åé€šè¿‡æ•°æ®çš„é•¿åº¦è®¡ç®—ç»“æŸçš„ä½ç½®, è¿™ä¸ªæ—¶å€™è·å–çš„æ•°æ®æ˜¯åœ¨å­—ç¬¦é‡Œé¢çš„ä½ç½®, éœ€è¦è¿›è¡Œè½¬æ¢è·å–ä»–åœ¨tokené‡Œé¢çš„æ•°æ®, å¯ä»¥ä½¿ç”¨offset_mapping(è®°å½•æ¯ä¸€ä¸ªtokençš„èµ·å§‹ä»¥åŠç»“æŸçš„charçš„ä½ç½®)è¿›è¡Œè½¬æ¢, æŠŠå¾—åˆ°çš„ç»“æœåˆ¤æ–­ä¸€ä¸‹æ˜¯ä¸æ˜¯åœ¨æˆªå–çš„æ•°æ®é‡Œé¢, å¦‚æœæ˜¯çš„è¯è·å–ä¸€ä¸‹å¯¹åº”çš„token, è®°å½•åœ¨è¿”å›å€¼é‡Œé¢ ```python tokenizer AutoTokenizer.from_pretrained(\"E:/JHY/python/2024 10 5 transforms/hlfrbt3\") ``` > æµ‹è¯•: > > ```python > sample_dataset dataset[\"train\"].select([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) > tokenized_example tokenizer(text sample_dataset[\"question\"], text_pair sample_dataset[\"context\"]) # ä½¿ç”¨åˆ†è¯å™¨å¤„ç†, åŒæ—¶è¿›è¡Œåˆ†ç±» > print(tokenized_example[\"input_ids\"][0]) > print(len(tokenized_example[\"input_ids\"][0])) > > \"\"\" > [101, 5745, 2455, 7563,...] > 767 > \"\"\" > > print(list(zip(tokenized_example[\"input_ids\"][0], tokenized_example[\"token_type_ids\"][0]))) > > \"\"\" > [(101, 0), (5745, 0), (2455, 0), (7563, 0), ...(5745, 1), (2455, 1), (7563, 1), ...] > \"\"\" > ``` > > å¯ä»¥å§é—®é¢˜ä»¥åŠæ•°æ®åˆå¹¶åœ¨ä¸€èµ· > > ```python > # åˆå¹¶é—®é¢˜å’Œæ–‡æœ¬ï¼Œæœ€å¤§é•¿åº¦384ï¼Œæˆªæ–­æ–‡æœ¬ï¼Œå¡«å……åˆ°æœ€å¤§é•¿åº¦ï¼Œè¿”å›offsets_mapping(ç”¨äºåç»­å¤„ç†ç­”æ¡ˆçš„ä½ç½®, å¯ä»¥å¯¹åº”Tokençš„å­—ç¬¦offsetä½ç½®) > tokenized_example tokenizer(text sample_dataset[\"question\"], > text_pair sample_dataset[\"context\"], > max_length 384, truncation \"only_second\", > padding \"max_length\", > return_offsets_mapping True) > ``` + å®é™…è·å–ç›®æ ‡çš„ç»“æœçš„èµ·å§‹ä»¥åŠç»“æŸtoken ```python for idx, offsets in enumerate(offset_mapping): # 'answers': {'text': ['1963å¹´'], 'answer_start': [30]}} answer sample_dataset[idx][\"answers\"] # è·å–ç­”æ¡ˆ start_char answer[\"answer_start\"][0] # çœŸå®ç­”æ¡ˆåœ¨å­—ç¬¦é‡Œé¢çš„ä½ç½® end_char start_char + len(answer[\"text\"][0]) print(answer, start_char, end_char) # ä¹‹åå®šä½ç­”æ¡ˆåœ¨tokenä¸­çš„ä½ç½® # è·å–contextçš„èµ·å§‹ç»“æŸ, ä¹‹åæ ¹æ®ç­”æ¡ˆçš„èµ·å§‹ç»“æŸä½ç½®ï¼Œæ‰¾åˆ°å¯¹åº”çš„tokenä½ç½® context_start tokenized_example.sequence_ids(idx).index(1) context_end tokenized_example.sequence_ids(idx).index(None, context_start) 1 print(context_start, context_end) # è¯„æ–­æ–‡æœ¬çš„èµ·å§‹ä½ç½®ç»“æŸ(å­—ç¬¦)æ˜¯å¦åœ¨contextä¸­, ä½¿ç”¨offsetè¿›è¡Œtokenåˆ°charçš„è½¬æ¢ if offsets[context_end][1] < start_char or offsets[context_start][0] > end_char: # print(\"ç­”æ¡ˆä¸åœ¨contextä¸­\") start_token_pos 0 end_token_pos 0 else: token_id context_start while token_id < context_end and offsets[token_id][0] < start_char: token_id + 1 start_token_pos token_id token_id context_end while token_id > context_start and offsets[token_id][1] > end_char: token_id 1 end_token_pos token_id print(start_token_pos, end_token_pos) print(\"token answer decode: \", tokenizer.decode(tokenized_example[\"input_ids\"][idx][start_token_pos:end_token_pos+1])) ``` > è¿›è¡Œå°è£…å¯ä»¥è·å¾— ```python def process_func(examples): # åˆå¹¶é—®é¢˜å’Œæ–‡æœ¬ï¼Œæœ€å¤§é•¿åº¦384ï¼Œæˆªæ–­æ–‡æœ¬ï¼Œå¡«å……åˆ°æœ€å¤§é•¿åº¦ï¼Œè¿”å›offsets_mapping(ç”¨äºåç»­å¤„ç†ç­”æ¡ˆçš„ä½ç½®, å¯ä»¥å¯¹åº”Tokençš„å­—ç¬¦offsetä½ç½®) tokenized_examples tokenizer(examples[\"question\"], examples[\"context\"], max_length 512, truncation \"only_second\", padding \"max_length\", return_offsets_mapping True) # ä¿å­˜ç­”æ¡ˆçš„tokenä½ç½® offset_mapping tokenized_examples.pop(\"offset_mapping\") # 'answers': {'text': ['1963å¹´'], 'answer_start': [30]}} start_positions [] end_positions [] for idx, offsets in enumerate(offset_mapping): answer examples[\"answers\"][idx] # è·å–ç­”æ¡ˆ start_char answer[\"answer_start\"][0] # çœŸå®ç­”æ¡ˆåœ¨å­—ç¬¦é‡Œé¢çš„ä½ç½® end_char start_char + len(answer[\"text\"][0]) # ä¹‹åå®šä½ç­”æ¡ˆåœ¨tokenä¸­çš„ä½ç½® # è·å–contextçš„èµ·å§‹ç»“æŸ, ä¹‹åæ ¹æ®ç­”æ¡ˆçš„èµ·å§‹ç»“æŸä½ç½®ï¼Œæ‰¾åˆ°å¯¹åº”çš„tokenä½ç½® context_start tokenized_examples.sequence_ids(idx).index(1) context_end tokenized_examples.sequence_ids(idx).index(None, context_start) 1 # è¯„æ–­æ–‡æœ¬çš„èµ·å§‹ä½ç½®ç»“æŸ(å­—ç¬¦)æ˜¯å¦åœ¨contextä¸­, ä½¿ç”¨offsetè¿›è¡Œtokenåˆ°charçš„è½¬æ¢ if offsets[context_end][1] < start_char or offsets[context_start][0] > end_char: # print(\"ç­”æ¡ˆä¸åœ¨contextä¸­\") start_token_pos 0 end_token_pos 0 else: token_id context_start while token_id < context_end and offsets[token_id][0] < start_char: token_id + 1 start_token_pos token_id token_id context_end while token_id > context_start and offsets[token_id][1] > end_char: token_id 1 end_token_pos token_id start_positions.append(start_token_pos) end_positions.append(end_token_pos) # ä¿å­˜ç­”æ¡ˆçš„tokenä½ç½® tokenized_examples[\"start_positions\"] start_positions tokenized_examples[\"end_positions\"] end_positions return tokenized_examples tokenized_dataset dataset.map(process_func, batched True, remove_columns dataset[\"train\"].column_names) ``` + è®­ç»ƒ ```python model AutoModelForQuestionAnswering.from_pretrained(\"E:/JHY/python/2024 10 5 transforms/hlfrbt3\") args TrainingArguments( output_dir \"model_for_qa\", per_device_eval_batch_size 32, per_device_train_batch_size 32, evaluation_strategy \"epoch\", save_strategy \"epoch\", load_best_model_at_end True, logging_steps 50 ) trainer Trainer( model model, args args, train_dataset tokenized_dataset[\"train\"], eval_dataset tokenized_dataset[\"validation\"], data_collator DefaultDataCollator(), tokenizer tokenizer ) trainer.train() ``` + é¢„æµ‹ ```python # æ¨¡å‹é¢„æµ‹ from transformers import pipeline pipe pipeline(\"question answering\", model model, tokenizer tokenizer, device 0) pipe({ \"question\": \"ä»€ä¹ˆæ—¶å€™æˆç«‹çš„\", \"context\": \"ä¸­åäººæ°‘å…±å’Œå›½æˆç«‹äº1949å¹´10æœˆ1æ—¥ã€‚\" }) ``` ### æ»‘åŠ¨çª—å£ ç”¨äºå¤„ç†æ•°æ®æ¯”è¾ƒé•¿çš„æ—¶å€™, å¦‚æœåªæ˜¯ç®€å•çš„æˆªæ–­, ä¼šå‡ºç°ç­”æ¡ˆè¢«æˆªæ–­çš„é—®é¢˜, æ‰€ä»¥åœ¨æˆªæ–­çš„æ—¶å€™ä¸€èˆ¬ä¼šæœ‰ä¸€éƒ¨åˆ†çš„é‡å , é‡å çš„é•¿çŸ­ä¼šä½¿å¾—ä½¿ç”¨è¿™ä¸€ç§çš„æ—¶å€™ä¼šå¯¼è‡´æ•°æ®çš„æ•°é‡å¢å¤§, é‡å éƒ¨åˆ†æ¯”è¾ƒå°çš„æ—¶å€™ä¼šå‡ºç°é•¿ä¸‹æ–‡ä¸¢å¤±ä»¥åŠç­”æ¡ˆä¸å®Œæ•´ æœ€åè·å–åˆ°å¤šä¸ªæ•°æ®çš„é¢„æµ‹ç»“æœè¿›è¡Œèšåˆ #### å®é™…å®ç° ä½¿ç”¨ä¸€ä¸ªnltkåº“ > nltkåº“æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸæœ€ä¸ºçŸ¥åä¸”å¹¿æ³›ä½¿ç”¨çš„Pythonåº“ä¹‹ä¸€ï¼Œå…¶åŠŸèƒ½åŒ…æ‹¬æ–‡æœ¬åˆ†æã€æ ‡æ³¨ã€åˆ†è¯ã€å¥æ³•åˆ†æã€è¯­ä¹‰åˆ†æã€è¯­æ–™åº“ç®¡ç†ç­‰ã€‚nltkåº“è¿˜æä¾›äº†ä¸°å¯Œçš„è¯­è¨€å¤„ç†å·¥å…·å’Œèµ„æºï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·è¿›è¡Œæ–‡æœ¬æŒ–æ˜ã€ä¿¡æ¯æ£€ç´¢ã€æ–‡æœ¬åˆ†ç±»ã€è¯­è¨€æ¨¡å‹ç­‰ä»»åŠ¡ã€‚é€šè¿‡nltkåº“ï¼Œç”¨æˆ·å¯ä»¥è½»æ¾åœ°å¤„ç†æ–‡æœ¬æ•°æ®ï¼Œè¿›è¡Œæ–‡æœ¬åˆ†æå’ŒæŒ–æ˜ï¼Œä»è€Œå®ç°è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³çš„å„ç§åº”ç”¨å’Œç ”ç©¶ã€‚ ```bash pip install nltk ``` ```python import nltk nltk.download(\"punkt\") ``` + tokenizerå¤„ç†å‡½æ•°æ”¹å˜ ```python sample_dataset dataset[\"train\"].select([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) # åˆå¹¶é—®é¢˜å’Œæ–‡æœ¬ï¼Œæœ€å¤§é•¿åº¦384ï¼Œæˆªæ–­æ–‡æœ¬ï¼Œå¡«å……åˆ°æœ€å¤§é•¿åº¦ï¼Œè¿”å›offsets_mapping(ç”¨äºåç»­å¤„ç†ç­”æ¡ˆçš„ä½ç½®, å¯ä»¥å¯¹åº”Tokençš„å­—ç¬¦offsetä½ç½®) tokenized_example tokenizer(text sample_dataset[\"question\"], text_pair sample_dataset[\"context\"], max_length 384, truncation \"only_second\", padding \"max_length\", return_offsets_mapping True, return_overflowing_tokens True) tokenized_example.keys() ``` > åŠ å…¥å‚æ•°return_overflowing_tokens, é»˜è®¤çš„æ—¶å€™æ˜¯æ²¡æœ‰è¿›è¡Œé‡å æ“ä½œçš„, å¯ä»¥ä½¿ç”¨strideå‚æ•°æŒ‡å®š > > ![image 20241015191930969](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410151919615.png) > > ![image 20241015192230343](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410151922391.png) + ä¸å¤„ç†å‡½æ•°, å¯¹æ•°æ®è¿›è¡Œå¤„ç†, è·å–éœ€è¦çš„æ•°æ® ```python def process_func(examples): # åˆå¹¶é—®é¢˜å’Œæ–‡æœ¬ï¼Œæœ€å¤§é•¿åº¦384ï¼Œæˆªæ–­æ–‡æœ¬ï¼Œå¡«å……åˆ°æœ€å¤§é•¿åº¦ï¼Œè¿”å› # offsets_mapping(ç”¨äºåç»­å¤„ç†ç­”æ¡ˆçš„ä½ç½®, # å¯ä»¥å¯¹åº”Tokençš„å­—ç¬¦offsetä½ç½®) tokenized_examples tokenizer(examples[\"question\"], examples[\"context\"], max_length 384, truncation \"only_second\", padding \"max_length\", return_offsets_mapping True, return_overflowing_tokens True, stride 128) sample_mapping tokenized_examples.get(\"overflow_to_sample_mapping\") # ä¿å­˜ç­”æ¡ˆçš„tokenä½ç½® # offset_mapping tokenized_examples.pop(\"offset_mapping\") # 'answers': {'text': ['1963å¹´'], 'answer_start': [30]}} start_positions [] end_positions [] example_ids [] for idx,_ in enumerate(sample_mapping): # è·å–ç­”æ¡ˆ, ä¸€ä¸ªç­”æ¡ˆå¯èƒ½å¯¹åº”å¤šä¸ªæ•°æ® answer examples[\"answers\"][sample_mapping[idx]] # çœŸå®ç­”æ¡ˆåœ¨å­—ç¬¦é‡Œé¢çš„ä½ç½® start_char answer[\"answer_start\"][0] end_char start_char + len(answer[\"text\"][0]) # ä¹‹åå®šä½ç­”æ¡ˆåœ¨tokenä¸­çš„ä½ç½® # è·å–contextçš„èµ·å§‹ç»“æŸ, ä¹‹åæ ¹æ®ç­”æ¡ˆçš„èµ·å§‹ç»“æŸä½ç½® # æ‰¾åˆ°å¯¹åº”çš„tokenä½ç½®, ä½¿ç”¨indexå‡½æ•°è·å–ç¬¬ä¸€ä¸ª1çš„ä½ç½® context_start tokenized_examples.sequence_ids(idx).index(1) context_end tokenized_examples.sequence_ids(idx).index(None, context_start) 1 offsets tokenized_examples.get(\"offset_mapping\")[idx] # è¯„æ–­æ–‡æœ¬çš„èµ·å§‹ä½ç½®ç»“æŸ(å­—ç¬¦)æ˜¯å¦åœ¨contextä¸­, ä½¿ç”¨offsetè¿›è¡Œtokenåˆ°charçš„è½¬æ¢ if offsets[context_end][1] < start_char or offsets[context_start][0] > end_char: # print(\"ç­”æ¡ˆä¸åœ¨contextä¸­\") start_token_pos 0 end_token_pos 0 else: token_id context_start while token_id < context_end and offsets[token_id][0] < start_char: # ä½¿ç”¨éå†çš„æ–¹æ³•è·å–ä¸€ä¸‹æ•°æ®çš„èµ·å§‹ä½ç½® token_id + 1 start_token_pos token_id token_id context_end while token_id > context_start and offsets[token_id][1] > end_char: # åå‘éå†è·å–ç»“æŸä½ç½® token_id 1 end_token_pos token_id start_positions.append(start_token_pos) end_positions.append(end_token_pos) # è®°å½•æ¯ä¸€ä¸ªæ•°æ®çš„idç”¨äºå¯¹åº” example_ids.append(examples[\"id\"][sample_mapping[idx]]) tokenized_examples[\"offset_mapping\"][idx] [ # è®°å½•ä¸€ä¸‹æœ‰æ•ˆæ•°æ®çš„tokenå¯¹åº”çš„offset(éé—®é¢˜æ•°æ®çš„ä½ç½®) (o if tokenized_examples.sequence_ids(idx)[k] 1 else None) for k, o in enumerate(tokenized_examples[\"offset_mapping\"][idx]) ] tokenized_examples[\"example_ids\"] example_ids # ä¿å­˜ç­”æ¡ˆçš„tokenä½ç½® tokenized_examples[\"start_positions\"] start_positions tokenized_examples[\"end_positions\"] end_positions return tokenized_examples ``` ```python tokenized_dataset dataset.map(process_func, batched True, remove_columns dataset[\"train\"].column_names) ``` + è·å–æ•°æ®çš„é¢„æµ‹ä»¥åŠçœŸå®çš„æ•°æ® ```python import numpy as np import collections def get_result(start_logits, end_logits, examples, features): \"\"\"_summary_ Args: start_logits (_type_): æ¨¡å‹é¢„æµ‹çš„ç»“æœèµ·å§‹ä½ç½® end_logits (_type_): ç»“æŸä½ç½®çš„é¢„æµ‹ç»“æœ examples (_type_): åŸå§‹çš„æ•°æ®é›† features (_type_): tokenizerè·å–åˆ°çš„mapping \"\"\" predictions {} references {} example_to_features collections.defaultdict(list) # ä¿å­˜æ¯ä¸€ä¸ªexampleå¯¹åº”çš„featureç¼–å· for idx, example_id in enumerate(features[\"example_ids\"]): example_to_features[example_id].append(idx) # è®°å½•ä¸€ä¸‹æ¯ä¸€ä¸ªexampleå¯¹åº”çš„è¢«åˆ†å‰²ä»¥åçš„ç¼–å· # æœ€ä¼˜ç­”æ¡ˆå€™é€‰æ•° n_best 20 max_answer_length 30 for example in examples: example_id example[\"id\"] context example[\"context\"] answers [] for feature_idx in example_to_features[example_id]: # è·å–å¯¹åº”çš„featureçš„é¢„æµ‹ç»“æœ, è¿™ä¸ªç»“æœæ“æ˜¯ä¸€ä¸ªæ•°ç»„ start_logit start_logits[feature_idx] end_logit end_logits[feature_idx] # è·å–å¯¹åº”çš„offset_mapping offset features[feature_idx][\"offset_mapping\"] # ä»å¤§åˆ°å°æ’åºï¼Œå–å‰n_best start_indexs np.argsort(start_logit)[:: 1][:n_best].tolist() # ä»å¤§åˆ°å°æ’åºï¼Œå–å‰n_best end_indexs np.argsort(end_logit)[:: 1][:n_best].tolist() for start_index in start_indexs: for end_index in end_indexs: # å¦‚æœé¢„æµ‹çš„ä½ç½®ä¸åœ¨offsetä¸­ï¼Œæˆ–è€…ç»“æŸä½ç½®åœ¨å¼€å§‹ä½ç½®ä¹‹å‰ï¼Œæˆ–è€…é•¿åº¦è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œéƒ½ä¸è¦ if offset[start_index] is None or offset[end_index] is None: continue if start_index > end_index or end_index start_index + 1 > max_answer_length: continue answers.append({ \"score\": start_logit[start_index] + end_logit[end_index], \"text\": context[offset[start_index][0]:offset[end_index][1]] }) if len(answers) > 0: # è·å–è¯„åˆ†æœ€é«˜çš„é¢„æµ‹ç»“æœ best_answer max(answers, key lambda x: x[\"score\"]) predictions[example_id] best_answer[\"text\"] else: predictions[example_id] \"\" references[example_id] example[\"answers\"][\"text\"] return predictions, references ``` + å®é™…çš„é¢„æµ‹å‡½æ•° ```python from cmrc_eval import evaluate_cmrc def metric(pred): start_logits, end_logits pred[0] if start_logits.shape[0] len(tokenized_dataset[\"validation\"]): p, r get_result(start_logits, end_logits, dataset[\"validation\"], tokenized_dataset[\"validation\"]) else: p, r get_result(start_logits, end_logits, dataset[\"test\"], tokenized_dataset[\"test\"]) return evaluate_cmrc(p, r) ``` ## å¤šé¡¹é€‰æ‹© æœºå™¨é˜…è¯»ç†è§£é‡Œé¢çš„ä¸€ä¸ªåˆ†æ”¯, ç»™å®šä¸€ä¸ªæ–‡æ¡£, ä¸€ä¸ªé—®é¢˜ä»¥åŠå¤šä¸ªç­”æ¡ˆ, ä»é‡Œé¢è·å–æ­£ç¡®çš„ç­”æ¡ˆ ### æ•°æ®å¤„ç† ![image 20241022230218638](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410222302906.png) ![image 20241022230335193](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410222303371.png) > åœ¨å®é™…å¤„ç†çš„æ—¶å€™éœ€è¦æŠŠæ•°æ®è¿›è¡Œä¸€ä¸ªèšåˆ ![image 20241022230548880](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410222305087.png) > è¿™é‡Œä½¿ç”¨çš„viewå‡½æ•°ä¼šæŒ‰ç…§æœ€é‡Œé¢ä¸€å±‚çš„å¤§å°å±•å¼€ä¸ºäºŒç»´æ•°ç»„ > > ```python > import torch > > tensor1 torch.tensor([[[1, 2], [2, 3], [3, 4]], [[5, 6], [6, 7], [7, 8]]]) > > print(tensor1.size( 1)) > tensor1 tensor1.view( 1, tensor1.size( 1)) > print(tensor1.size()) > \"\"\" > 2 > torch.Size([6, 2]) > \"\"\" > ``` ![image 20241022232644703](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410222326874.png) ### å®é™…è®­ç»ƒ è¿™é‡Œä½¿ç”¨çš„æ•°æ®é›†clueä¸‹é¢çš„C3æ•°æ®é›† https://huggingface.co/datasets/clue/clue ![image 20241024225949337](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410242259476.png) > è¿™é‡Œçš„contextå¯èƒ½æ˜¯ä¸€ä¸ªå¯¹è¯, æ˜¯å¯¹è¯çš„æ—¶å€™è¿™ä¸€ä¸ªçš„æ•°æ®æ˜¯ä¸€ä¸ªåˆ—è¡¨,è¿™é‡Œé¢çš„æ•°æ®ç”±äºtestæ•°æ®é›†æ²¡æœ‰answer, æ‰€ä»¥éœ€è¦å»é™¤"},"/note/æœºå™¨å­¦ä¹ /2024-9-23-01pytorch.html":{"title":"pytorch","content":" layout: post title: \"pytorch\" date: 2024 8 5 15:39:08 +0800 tags: AI æœºå™¨å­¦ä¹  # pytorch ## åŸºç¡€å…¥é—¨ å¯ä»¥ä½¿ç”¨dirå’Œhelpä¸¤ä¸ªå‡½æ•°è¿›è¡Œæ¢ç´¢ä½¿ç”¨pytorch ä½¿ç”¨dirå¯ä»¥å¯¹ä¸€ä¸ªåŒ…è¿›è¡Œæ‰“å¼€æ“ä½œ, ä½¿ç”¨helpå¯ä»¥è·å–æŸä¸€ä¸ªåŒ…çš„å…·ä½“ä½¿ç”¨ ![image 20240923172733947](C:\\Users\\jinhua\\AppData\\Roaming\\Typora\\typora user images\\image 20240923172733947.png) ### åè¯ #### å¼ é‡ [ç¬”è®° ä»€ä¹ˆæ˜¯å¼ é‡ï¼ˆtensorï¼‰& æ·±åº¦å­¦ä¹  çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/48982978#:~:text åœ¨æ·±åº¦å­¦ä¹ é‡Œï¼ŒTen) åœ¨æ·±åº¦å­¦ä¹ é‡Œï¼Œ**Tensorå®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªå¤šç»´æ•°ç»„ï¼ˆmultidimensional arrayï¼‰**ã€‚ è€ŒTensorçš„ç›®çš„æ˜¯**èƒ½å¤Ÿåˆ›é€ æ›´é«˜ç»´åº¦çš„çŸ©é˜µã€å‘é‡**ã€‚ ![img](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409252313363.jpeg) ä¸¾ä¸ªç®€å•çš„ä¾‹å­ï¼Œ[å½©è‰²å›¾åƒæ–‡ä»¶](https://zhida.zhihu.com/search?content_id 9946792&content_type Article&match_order 1&q å½©è‰²å›¾åƒæ–‡ä»¶&zhida_source entity)ï¼ˆRGBï¼‰ä¸€èˆ¬éƒ½ä¼šå¤„ç†æˆ3 d tensorï¼Œæ¯ä¸ª2d arrayä¸­çš„elementè¡¨ç¤ºä¸€ä¸ªåƒç´ ï¼ŒRä»£è¡¨Redï¼ŒGä»£è¡¨Greenï¼ŒBä»£è¡¨Blueï¼š ![img](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409252314013.webp) å†æ¥çœ‹çœ‹Tensorå¯¹è±¡çš„3ä¸ªå±æ€§ï¼š 1. **rank**ï¼š[number of dimensions](https://zhida.zhihu.com/search?content_id 9946792&content_type Article&match_order 1&q number+of+dimensions&zhida_source entity) 2. **shape**: number of rows and columns 3. **type**: data type of tensor's elements #### å·ç§¯ https://b23.tv/T4gTHYC å·ç§¯, å®é™…å¯ä»¥ç†è§£ä¸ºä¸¤ä¸ªå‡½æ•°çš„ç›¸äº’ä½œç”¨ æ•°å­¦ä¸Šï¼Œå…¶è¿ç»­å‡½æ•°çš„è§£æå¼å†™ä½œï¼š $ F(x) \\int_{ \\infty}^{+\\infty}f(\\tau)\\,g(x \\tau)$ $ F(x) \\sum_{\\tau 1}^N f(\\tau)\\,g(x \\tau)$ ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409252256263.gif) é€šå¸¸æƒ…å†µä¸‹ï¼Œf ( Ï„ ) è¡¨ç¤ºè¢«ç§¯å‡½æ•°ï¼Œè€Œ g ( x âˆ’ Ï„ ) è¡¨ç¤ºå·ç§¯æ ¸å‡½æ•°ã€‚è¿™é‡Œå¤šè¯´ä¸€å¥ï¼Œä¹‹æ‰€ä»¥ä¸ä½¿ç”¨ f ( x ) è¡¨ç¤ºåŸå‡½æ•°è€Œç”¨ f ( Ï„ ) ï¼Œè€Œä¸”å¼ºè°ƒ f ( Ï„ ) æ˜¯è¢«ç§¯å‡½æ•°ï¼Œæ˜¯å› ä¸º f ( x ) ä¸ f ( Ï„ ) ä¹‹é—´è¿˜å­˜åœ¨ç€å¦‚ä¸‹å…³ç³»ï¼š $ f(x) \\int_{ \\infty}^{+\\infty}f(\\tau)d\\tau$ ä¸Šå¼è¡¨æ˜çš„æ“ä½œåœ¨ç›´è§‚ä¸Šç†è§£æ˜¯å…ˆå¯¹å·ç§¯æ ¸ç¿»è½¬ï¼Œç„¶åä¸è¾“å…¥ç‚¹ä¹˜ã€æ±‚å’Œå¾—åˆ°è¾“å‡ºã€‚åœ¨æœºå™¨å­¦ä¹ é¢†åŸŸå°¤å…¶æ˜¯æ·±åº¦å­¦ä¹ ä¸­ï¼Œå·ç§¯çš„å®ç°é€šå¸¸çœå»äº†å·ç§¯æ ¸ç¿»è½¬è¿™ä¸€æ­¥ï¼Œå› ä¸ºæ·±åº¦å­¦ä¹ ä¸­çš„å·ç§¯æ ¸å‚æ•°æ˜¯ä¸æ–­å­¦ä¹ æ›´æ–°ï¼Œå› æ­¤æœ‰æ²¡æœ‰ç¿»è½¬å¹¶æ²¡æœ‰æ€§è´¨ä¸Šçš„å½±å“ã€‚ä¸¥æ ¼å®šä¹‰ä¸Šè¯´ï¼Œæ·±åº¦å­¦ä¹ ä¸­çš„å·ç§¯å®é™…ä¸Šæ˜¯å¦ä¸€ç§æ“ä½œï¼š[äº’ç›¸å…³](https://zhida.zhihu.com/search?content_id 105153470&content_type Article&match_order 1&q äº’ç›¸å…³&zhida_source entity) [Cross Correlation](https://link.zhihu.com/?target https%3A//en.wikipedia.org/wiki/Cross correlation)ã€‚å…¬å¼è¡¨ç¤ºå¦‚ä¸‹ ![image 20240925233420506](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409252334611.png) ![åŠ¨å›¾](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409252334905.webp) ![image 20240925233512203](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409252335303.png) ä¸è€ƒè™‘ paddingï¼Œä»¥ stride ä¸º 1ï¼Œé‚£ä¹ˆæˆ‘ä»¬è¿›è¡Œå·ç§¯è®¡ç®—å¾—åˆ°çš„ç»“æœä¸º ![image 20240925233556003](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409252335091.png) #### å·ç§¯çš„ä¸‰ç§æ¨¡å¼ æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­é€šå¸¸ä¼šå®ç°ä¸‰ç§ä¸åŒçš„å·ç§¯æ¨¡å¼ï¼Œåˆ†åˆ«æ˜¯ SAMEã€VALIDã€FULLã€‚è¿™ä¸‰ç§æ¨¡å¼çš„æ ¸å¿ƒåŒºåˆ«åœ¨äº**å·ç§¯æ ¸è¿›è¡Œå·ç§¯æ“ä½œçš„ç§»åŠ¨åŒºåŸŸä¸åŒ**ï¼Œè¿›è€Œå¯¼è‡´è¾“å‡ºçš„å°ºå¯¸ä¸åŒã€‚æˆ‘ä»¬ä»¥ä¸€ä¸ªä¾‹å­æ¥çœ‹è¿™ä¸‰ç§æ¨¡å¼çš„åŒºåˆ«ï¼Œè¾“å…¥å›¾ç‰‡çš„å°ºå¯¸æ˜¯ 5Ã—5 ï¼Œå·ç§¯æ ¸å°ºå¯¸æ˜¯ 3Ã—3 ï¼Œstride å– 1ã€‚ FULL æ¨¡å¼ FULL æ¨¡å¼ä¸‹å·ç§¯æ ¸**ä»ä¸è¾“å…¥æœ‰ä¸€ä¸ªç‚¹çš„ç›¸äº¤çš„åœ°æ–¹å°±å¼€å§‹å·ç§¯**ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè“æ¡†çš„ä½ç½®å°±æ˜¯å·ç§¯æ ¸ç¬¬ä¸€ä¸ªå·ç§¯çš„åœ°æ–¹ï¼Œç°è‰²éƒ¨åˆ†æ˜¯ä¸ºäº†å·ç§¯èƒ½å¤Ÿæ­£å¸¸è¿›è¡Œçš„ paddingï¼ˆä¸€èˆ¬å¡« 0ï¼‰ã€‚å› æ­¤ FULL æ¨¡å¼ä¸‹å·ç§¯æ ¸ç§»åŠ¨åŒºåŸŸæœ€å¤§ï¼Œå·ç§¯åè¾“å‡ºçš„å°ºå¯¸ä¹Ÿæœ€å¤§ã€‚ ![img](https://pica.zhimg.com/80/v2 23ba5f401533b72b0214bd51a091000c_720w.webp) VALID æ¨¡å¼ VALID æ¨¡å¼ä¸ FULL æ¨¡å¼ç›¸åï¼Œ**åœ¨æ•´ä¸ªå·ç§¯æ ¸ä¸è¾“å…¥é‡å çš„åœ°æ–¹æ‰å¼€å§‹å·ç§¯æ“ä½œ**ï¼Œå› æ­¤ä¸éœ€è¦ paddingï¼Œè¾“å‡ºçš„å°ºå¯¸ä¹Ÿæœ€å° ![img](https://pic4.zhimg.com/80/v2 fc57effd13fdf64eeb375f57e65e309d_720w.webp) SAME æ¨¡å¼ SAME æ¨¡å¼æ˜¯æœ€å¸¸ç”¨çš„ä¸€ç§æ¨¡å¼ï¼ŒSAME çš„æ„æ€æ˜¯å·ç§¯åè¾“å‡ºçš„å°ºå¯¸ä¸è¾“å…¥å°ºå¯¸ä¿æŒä¸€è‡´ï¼ˆå‡å®š stride ä¸º 1ï¼‰ã€‚é€šè¿‡å°†å·ç§¯æ ¸çš„ä¸­å¿ƒä¸è¾“å…¥çš„ç¬¬ä¸€ä¸ªç‚¹è¿›è¡Œå¯¹é½ç¡®å®šå·ç§¯æ ¸èµ·å§‹ä½ç½®ï¼Œç„¶åè¡¥é½å¯¹åº” padding å³å¯ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¯ä»¥çœ‹åˆ°å·ç§¯è¾“å‡ºçš„å°ºå¯¸ä¸å‡ºå…¥ä¿æŒä¸€è‡´ã€‚ ![img](https://pic4.zhimg.com/80/v2 a18f53d4f4d60a0eb6d1940d06bd5af5_720w.webp) SAME æ¨¡å¼ä¸‹å½“å·ç§¯æ ¸è¾¹é•¿ä¸ºå¶æ•°æ—¶ï¼Œå¯ä»¥é€šè¿‡åœ¨å…¶ä¸­ä¸€è¾¹å¢åŠ å¤šä¸€è¡Œï¼ˆåˆ—ï¼‰paddingï¼Œå³ä¸å¯¹ç§°çš„ padding å®ç°è¾“å‡ºå°ºå¯¸ä¸è¾“å…¥å°ºå¯¸ä¿æŒä¸€è‡´ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼ˆå·ç§¯æ ¸å°ºå¯¸ä¸º 2Ã—2 ï¼‰ ![img](https://pica.zhimg.com/80/v2 0ace23e8761226979fbe7ecd0a1905c8_720w.webp) ä»¥ä¸Šä¸‰ç§æ¨¡å¼åŒºåˆ«åœ¨äºå·ç§¯æ ¸è¿›è¡Œå·ç§¯æ“ä½œçš„ç§»åŠ¨åŒºåŸŸä¸åŒï¼Œå…¶å®æ˜¯ç¡®å®šäº†æ‰€éœ€çš„ paddingã€‚ #### æ± åŒ–å±‚Pooling layers å®ƒå®é™…ä¸Šæ˜¯ä¸€ç§å½¢å¼çš„é™é‡‡æ ·ã€‚æœ‰å¤šç§ä¸åŒå½¢å¼çš„éçº¿æ€§æ± åŒ–å‡½æ•°ï¼Œè€Œå…¶ä¸­â€œæœ€å¤§æ± åŒ–ï¼ˆMax poolingï¼‰â€æ˜¯æœ€ä¸ºå¸¸è§çš„ã€‚å®ƒæ˜¯å°†è¾“å…¥çš„å›¾åƒåˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªçŸ©å½¢åŒºåŸŸï¼Œå¯¹æ¯ä¸ªå­åŒºåŸŸè¾“å‡ºæœ€å¤§å€¼ã€‚ç›´è§‰ä¸Šï¼Œè¿™ç§æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°åŸå› åœ¨äºï¼Œåœ¨å‘ç°ä¸€ä¸ªç‰¹å¾ä¹‹åï¼Œå®ƒçš„ç²¾ç¡®ä½ç½®è¿œä¸åŠå®ƒå’Œå…¶ä»–ç‰¹å¾çš„ç›¸å¯¹ä½ç½®çš„å…³ç³»é‡è¦ã€‚æ± åŒ–å±‚ä¼šä¸æ–­åœ°å‡å°æ•°æ®çš„ç©ºé—´å¤§å°ï¼Œå› æ­¤å‚æ•°çš„æ•°é‡å’Œè®¡ç®—é‡ä¹Ÿä¼šä¸‹é™ï¼Œè¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šä¹Ÿæ§åˆ¶äº†è¿‡æ‹Ÿåˆã€‚é€šå¸¸æ¥è¯´ï¼ŒCNNçš„å·ç§¯å±‚ä¹‹é—´éƒ½ä¼šå‘¨æœŸæ€§åœ°æ’å…¥æ± åŒ–å±‚ã€‚ ![img](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409262220821.png) #### éçº¿æ€§æ¿€æ´» **ReLu**ï¼Œå…¨ç§°æ˜¯Rectified Linear Unitï¼Œä¸­æ–‡åç§°æ˜¯çº¿æ€§æ•´æµå‡½æ•°ï¼Œæ˜¯åœ¨ç¥ç»ç½‘ç»œä¸­å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°ã€‚é€šå¸¸æ„ä¹‰ä¸‹ï¼Œå…¶æŒ‡ä»£æ•°å­¦ä¸­çš„æ–œå¡å‡½æ•°ï¼Œå³F(X) max(0, x) ã€‚å…¶å¯¹åº”çš„å‡½æ•°å›¾åƒå¦‚ä¸‹æ‰€ç¤ºï¼š ![image 20240926225959744](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409262259886.png) **Sigmoidï¼Œ**æ˜¯å¸¸ç”¨çš„è¿ç»­ã€å¹³æ»‘çš„så‹æ¿€æ´»å‡½æ•°ï¼Œä¹Ÿè¢«ç§°ä¸ºé€»è¾‘ï¼ˆLogisticï¼‰å‡½æ•°ã€‚å¯ä»¥å°†ä¸€ä¸ªå®æ•°æ˜ å°„åˆ° ![(0, 1)](https://www.zhihu.com/equation?tex %280%2C+1%29&consumer ZHI_MENG) çš„åŒºé—´ï¼Œç”¨æ¥åšäºŒåˆ†ç±»ã€‚å…¶å‡½æ•°å®šä¹‰ä¸º $f(x) \\frac{1}{1 + e^{ x}}$ï¼Œå‡½æ•°å›¾åƒå¦‚ä¸‹æ‰€ç¤ºï¼š ![img](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409262300639.webp) **Tanhå‡½æ•°**ç§°ä¸ºåŒæ›²æ­£åˆ‡å‡½æ•°ï¼Œå‡½æ•°å®šä¹‰ä¸º $f(x) tanh(x) \\frac{e^x e^{ x}}{e^x + e^{ x}}$ï¼Œå€¼åŸŸä¸º ( 1,1)(0, 1) ï¼Œå‡½æ•°å›¾åƒå¦‚ä¸‹ï¼š ![img](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409262300689.webp) å¼•å…¥éçº¿æ€§æ¿€æ´»å‡½æ•°çš„ç›®çš„æ˜¯æé«˜ç¥ç»ç½‘ç»œçš„éçº¿æ€§æ‹Ÿåˆèƒ½åŠ›ï¼Œå¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚å› æ­¤ï¼Œåœ¨è¡¨è¯‰è¿‡ç¨‹ä¸­ï¼Œåœ¨æ²¡æœ‰æ˜ç¡®æŒ‡æ˜çš„æƒ…å†µä¸‹ï¼Œæ¿€æ´»å‡½æ•°æŒ‡ä»£éçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚ç»è¿‡ä¸¥æ ¼çš„æ•°å­¦æ¨å¯¼ï¼Œå¦‚æœç½‘ç»œä¸­æ²¡æœ‰ä½¿ç”¨æ¿€æ´»å‡½æ•°ï¼Œæ¯ä¸€å±‚çš„èŠ‚ç‚¹çš„è¾“å…¥éƒ½æ˜¯ä¸Šå±‚è¾“å‡ºçš„çº¿æ€§å‡½æ•°ï¼Œæ— è®ºç¥ç»ç½‘ç»œä¸­çš„éšå«å±‚æœ‰å¤šå°‘ï¼Œæœ€åçš„è¾“å‡ºç»“æœéƒ½æ˜¯ç½‘ç»œè¾“å…¥çš„çº¿æ€§æ‹Ÿåˆï¼Œå³éšå«å±‚æ²¡æœ‰å‘æŒ¥å…¶ä½œç”¨ã€‚ä¸ºæ­¤ï¼Œå¼•å…¥éçº¿æ€§å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°æ¥æé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚ ä¸¾ä¸ªæ —å­ï¼šå¦‚æœä¸ä½¿ç”¨éçº¿æ€§å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨é€»è¾‘å›å½’åšç®€å•çš„çº¿æ€§åˆ’åˆ†ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ![img](https://pic1.zhimg.com/v2 7a857d55584ce83c1b877ae96383c0c6_b.webp?consumer ZHI_MENG) ä½¿ç”¨ç®€å•çš„çº¿æ€§åˆ’åˆ†æ— æ³•æœ‰æ•ˆåˆ’åˆ†æ•°æ®ç±»åˆ«ï¼Œå¯¹æ­¤éœ€è¦å¼•å…¥éçº¿æ€§ï¼Œä¸ºæ•°æ®é›†åˆ’åˆ†æé«˜æœ‰æ•ˆçš„æ–¹å¼ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ![img](https://picx.zhimg.com/v2 e042df59cf85ccb712141d152d958d8d_b.webp?consumer ZHI_MENG) ç”±æ­¤å¯è§ï¼Œå¼•å…¥æ¿€æ´»å‡½æ•°èƒ½å¤Ÿæ­£ç¡®æœ‰æ•ˆåˆ’åˆ†æ•°æ®ç±»åˆ«ã€‚å¼•å…¥éçº¿æ€§å› ç´ ï¼Œä½¿å¾—ç¥ç»ç½‘ç»œèƒ½å¤Ÿæ›´å¥½åœ°è§£å†³å¤æ‚é—®é¢˜ã€‚ #### Normalization Layer [ä¸€æ–‡ææ‡‚Batch Normalization å’Œ Layer Normalization çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/647813604) Normalizationï¼šè§„èŒƒåŒ–æˆ–æ ‡å‡†åŒ–ï¼Œå°±æ˜¯æŠŠè¾“å…¥æ•°æ®Xï¼Œåœ¨è¾“é€ç»™ç¥ç»å…ƒä¹‹å‰å…ˆå¯¹å…¶è¿›è¡Œå¹³ç§»å’Œä¼¸ç¼©å˜æ¢ï¼Œå°†Xçš„åˆ†å¸ƒè§„èŒƒåŒ–æˆåœ¨å›ºå®šåŒºé—´èŒƒå›´çš„[æ ‡å‡†åˆ†å¸ƒ](https://zhida.zhihu.com/search?content_id 232088974&content_type Article&match_order 1&q æ ‡å‡†åˆ†å¸ƒ&zhida_source entity)ã€‚ ![image 20240927185243068](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409271852225.png) Î¼ï¼š[å¹³ç§»å‚æ•°](https://zhida.zhihu.com/search?content_id 232088974&content_type Article&match_order 1&q å¹³ç§»å‚æ•°&zhida_source entity) ï¼ŒÎ´ï¼šç¼©æ”¾å‚æ•° ï¼Œb ï¼šå†å¹³ç§»å‚æ•°ï¼Œ g å†ç¼©æ”¾å‚æ•°ï¼Œå¾—åˆ°çš„æ•°æ®ç¬¦åˆå‡å€¼ä¸º b ã€æ–¹å·®ä¸ºg^2 çš„åˆ†å¸ƒã€‚ Normalization çš„ä½œç”¨å¾ˆæ˜æ˜¾ï¼ŒæŠŠæ•°æ®æ‹‰å›[æ ‡å‡†æ­£æ€åˆ†å¸ƒ](https://zhida.zhihu.com/search?content_id 232088974&content_type Article&match_order 1&q æ ‡å‡†æ­£æ€åˆ†å¸ƒ&zhida_source entity)ï¼Œå› ä¸º[ç¥ç»ç½‘ç»œ](https://zhida.zhihu.com/search?content_id 232088974&content_type Article&match_order 1&q ç¥ç»ç½‘ç»œ&zhida_source entity)çš„Blockå¤§éƒ¨åˆ†éƒ½æ˜¯[çŸ©é˜µè¿ç®—](https://zhida.zhihu.com/search?content_id 232088974&content_type Article&match_order 1&q çŸ©é˜µè¿ç®—&zhida_source entity)ï¼Œä¸€ä¸ªå‘é‡ç»è¿‡çŸ©é˜µè¿ç®—åå€¼ä¼šè¶Šæ¥è¶Šå¤§ï¼Œä¸ºäº†ç½‘ç»œçš„ç¨³å®šæ€§ï¼Œæˆ‘ä»¬éœ€è¦åŠæ—¶æŠŠå€¼æ‹‰å›æ­£æ€åˆ†å¸ƒã€‚ Normalizationæ ¹æ®æ ‡å‡†åŒ–æ“ä½œçš„ç»´åº¦ä¸åŒå¯ä»¥åˆ†ä¸ºbatch Normalizationå’ŒLayer Normalizationï¼Œä¸ç®¡åœ¨å“ªä¸ªç»´åº¦ä¸Šåšnoramlizationï¼Œæœ¬è´¨éƒ½æ˜¯ä¸ºäº†è®©æ•°æ®åœ¨è¿™ä¸ªç»´åº¦ä¸Šå½’ä¸€åŒ–ï¼Œå› ä¸ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸Šä¸€å±‚ä¼ é€’ä¸‹å»çš„å€¼åƒå¥‡ç™¾æ€ªï¼Œä»€ä¹ˆæ ·å­çš„åˆ†å¸ƒéƒ½æœ‰ã€‚BatchNormå°±æ˜¯é€šè¿‡å¯¹[batch size](https://zhida.zhihu.com/search?content_id 232088974&content_type Article&match_order 1&q batch+size&zhida_source entity)è¿™ä¸ªç»´åº¦å½’ä¸€åŒ–æ¥è®©åˆ†å¸ƒç¨³å®šä¸‹æ¥ã€‚LayerNormåˆ™æ˜¯é€šè¿‡å¯¹[Hidden size](https://zhida.zhihu.com/search?content_id 232088974&content_type Article&match_order 1&q Hidden+size&zhida_source entity)è¿™ä¸ªç»´åº¦å½’ä¸€åŒ–æ¥è®©æŸå±‚çš„åˆ†å¸ƒç¨³å®šã€‚ å¯ä»¥è¿™æ ·ç†è§£ï¼Œæ·±åº¦ç½‘ç»œæ¯ä¸€å±‚ç½‘ç»œæ˜¯ç›¸å¯¹ç‹¬ç«‹çš„ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯ä¸€å±‚ç½‘ç»œå¯ä»¥å•ç‹¬çœ‹æˆä¸€ä¸ªClassifier.ä¸åœå¯¹ä¸Šä¸€å±‚çš„è¾“å‡ºæ•°æ®è¿›è¡Œåˆ†ç±»ï¼Œæ¯ä¸€å±‚è¾“å‡ºçš„æ•°æ®åˆ†å¸ƒåˆä¸ä¸€æ ·ï¼Œè¿™å°±ä¼šå‡ºç°Internal Covariate Shiftï¼ˆ[å†…éƒ¨åå˜é‡](https://zhida.zhihu.com/search?content_id 232088974&content_type Article&match_order 1&q å†…éƒ¨åå˜é‡&zhida_source entity)åç§»ï¼‰. éšç€ç½‘ç»œçš„å±‚æ•°ä¸æ–­å¢å¤§ï¼Œè¿™ç§è¯¯å·®å°±ä¼šä¸æ–­ç§¯ç´¯ï¼Œæœ€ç»ˆå¯¼è‡´æ•ˆæœæ¬ ä½³ã€‚æ˜¾ç„¶å¯¹[æ•°æ®é¢„å¤„ç†](https://zhida.zhihu.com/search?content_id 232088974&content_type Article&match_order 1&q æ•°æ®é¢„å¤„ç†&zhida_source entity)åªèƒ½è§£å†³ç¬¬ä¸€å±‚çš„é—®é¢˜ï¼Œä¹‹åéœ€è¦Normalizationç­‰æ–¹æ³•æ¥è§£å†³ã€‚ #### Recuurent Layerså¾ªç¯å±‚ Recurrent Layersçš„ä¸»è¦ä½œç”¨æ˜¯åœ¨ç¥ç»ç½‘ç»œä¸­æä¾›è®°å¿†åŠŸèƒ½ï¼Œä½¿å¾—ç½‘ç»œèƒ½å¤Ÿå¤„ç†æ—¶é—´åºåˆ—æ•°æ®æˆ–å…·æœ‰æ—¶é—´ç›¸å…³æ€§çš„æ•°æ®ã€‚é€šè¿‡åœ¨ç½‘ç»œä¸­å¼•å…¥å¾ªç¯è¿æ¥ï¼ŒRecurrent Layerså¯ä»¥å°†å…ˆå‰çš„è¾“å‡ºä½œä¸ºè¾“å…¥ä¼ é€’ç»™ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œä»è€Œå…è®¸ç½‘ç»œåœ¨å¤„ç†åºåˆ—æ•°æ®æ—¶è€ƒè™‘åˆ°ä¹‹å‰çš„ä¿¡æ¯ã€‚è¿™ç§è®°å¿†æœºåˆ¶èƒ½å¤Ÿå¸®åŠ©ç½‘ç»œæ›´å¥½åœ°ç†è§£å’Œé¢„æµ‹åºåˆ—æ•°æ®ä¸­çš„æ¨¡å¼å’Œè¶‹åŠ¿ï¼ŒåŒæ—¶ä¹Ÿæœ‰åŠ©äºè§£å†³çŸ­æœŸè®°å¿†å’Œæ¢¯åº¦æ¶ˆå¤±ç­‰é—®é¢˜ã€‚å› æ­¤ï¼ŒRecurrent Layersåœ¨è¯­è¨€æ¨¡å‹ã€æœºå™¨ç¿»è¯‘ã€æ—¶é—´åºåˆ—é¢„æµ‹ç­‰ä»»åŠ¡ä¸­å…·æœ‰é‡è¦ä½œç”¨ã€‚ #### Transform Layer è§£å†³ç‰¹å®šé—®é¢˜çš„æ—¶å€™ä½¿ç”¨ #### Linear Layer çº¿æ€§å±‚, å¯¹è¾“å…¥çš„æ¯ä¸€ä¸ªæ•°æ®ä¹˜ä»¥ä¸€ä¸ªæƒé‡, ä¹‹åç›¸åŠ  ![image 20240927191723938](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409271917063.png) #### Dropout Layers éšæœºå§ä¸€éƒ¨åˆ†çš„å…ƒç´ å˜ä¸º0, é˜²æ­¢æ•°æ®è¿‡æ‹Ÿåˆ, é˜²æ­¢åœ¨å®é™…å¤„ç†æ•°çš„æ—¶å€™æ³›ç”¨æ€§ä¸å¼º #### Sparse Layer ç”¨äºè‡ªç„¶è¯­è¨€çš„å¤„ç† #### æŸå¤±å‡½æ•°å’Œåå‘ä¼ æ’­ Loss: å®é™…è·å–çš„æ•°æ®å’ŒçœŸå®çš„æ•°æ®ä¹‹é—´çš„å·®è·, å¯ä»¥ä½¿ç”¨è¿™ä¸€ä¸ªè®¡ç®—å®é™…è¾“å‡ºå’Œç›®æ ‡çš„å·®è·, ä¹Ÿå¯ä»¥ä¸ºæ›´æ–°è¾“å‡ºæä¾›ä¾æ®(åå‘ä¼ æ’­) ### åŠ è½½æ•°æ® è¯»å–æ•°æ®çš„æ—¶å€™ä¸»è¦æœ‰ä¸¤ä¸ªç±», dataset, dataloader dataset: å¯¹æ•°æ®è¿›è¡Œåˆ†ç±»å¹¶è¿›è¡Œç¼–å·, è·å–æ•°æ®çš„lableå€¼ dataloader: å¯¹æ•°æ®è¿›è¡Œæ‰“åŒ…, ä¸ºåé¢çš„ç½‘ç»œæä¾›ä¸åŒçš„æ•°æ®å½¢å¼ **æ•°æ®é›†:** ä¸€èˆ¬ä½¿ç”¨ä¸€ä¸‹çš„æ ‡è¯†æ–¹æ³• 1. æŠŠä¸åŒçš„æ•°æ®æŒ‰ç…§æ–‡ä»¶å¤¹åˆ†ç±», æ–‡ä»¶å¤¹çš„åå­—æ ‡è¯†è¿™ä¸€ä¸ªæ•°æ®é›†çš„type 2. ä½¿ç”¨å•ç‹¬çš„æ–‡ä»¶æ ‡è¯†å›¾ç‰‡çš„lable 3. ä¹‹é—´æŠŠlableå†™åœ¨å›¾ç‰‡çš„åå­— ```c from torch.utils.data import Dataset help(Dataset) ``` > ```bash > Help on class Dataset in module torch.utils.data.dataset: > > class Dataset(typing.Generic) > An abstract class representing a :class:`Dataset`. > > All datasets that represent a map from keys to data samples should subclass > it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a > data sample for a given key. Subclasses could also optionally overwrite > :meth:`__len__`, which is expected to return the size of the dataset by many > :class:`~torch.utils.data.Sampler` implementations and the default options > of :class:`~torch.utils.data.DataLoader`. Subclasses could also > optionally implement :meth:`__getitems__`, for speedup batched samples > loading. This method accepts list of indices of samples of batch and returns > list of samples. > > .. note:: > :class:`~torch.utils.data.DataLoader` by default constructs an index > sampler that yields integral indices. To make it work with a map style > dataset with non integral indices/keys, a custom sampler must be provided. > > Method resolution order: > Dataset > typing.Generic > builtins.object > > Methods defined here: > > __add__(self, other: 'Dataset[T_co]') > 'ConcatDataset[T_co]' > > __getitem__(self, index) > +T_co > > > Data descriptors defined here: > > __dict__ > dictionary for instance variables > > __weakref__ > list of weak references to the object > > > Data and other attributes defined here: > > __annotations__ {} > > __orig_bases__ (typing.Generic[+T_co],) > > __parameters__ (+T_co,) > > > Class methods inherited from typing.Generic: > > __class_getitem__(...) > Parameterizes a generic class. > > At least, parameterizing a generic class is the *main* thing this > method does. For example, for some generic class `Foo`, this is called > when we do `Foo[int]` there, with `cls Foo` and `params int`. > > However, note that this method is also called when defining generic > classes in the first place with `class Foo[T]: ...`. > > __init_subclass__(...) > Function to initialize subclasses. > ``` > > ä¹Ÿå¯ä»¥ä½¿ç”¨`Dataset??`è¿™ä¸€ä¸ªæ–¹å¼è·å–çš„ä¿¡æ¯æ¯”è¾ƒæ¸…æ™° > > ```bash > Init signature: Dataset() > Source: > class Dataset(Generic[T_co]): > r\"\"\"An abstract class representing a :class:`Dataset`. > > All datasets that represent a map from keys to data samples should subclass > it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a > data sample for a given key. Subclasses could also optionally overwrite > :meth:`__len__`, which is expected to return the size of the dataset by many > :class:`~torch.utils.data.Sampler` implementations and the default options > of :class:`~torch.utils.data.DataLoader`. Subclasses could also > optionally implement :meth:`__getitems__`, for speedup batched samples > loading. This method accepts list of indices of samples of batch and returns > list of samples. > æ‰€æœ‰çš„æ•°æ®é›†å­ç±»éœ€è¦é›†æˆè¿™ä¸€ä¸ªç±», é‡å†™__getitem__ > > .. note:: > :class:`~torch.utils.data.DataLoader` by default constructs an index > sampler that yields integral indices. To make it work with a map style > dataset with non integral indices/keys, a custom sampler must be provided. > \"\"\" > > def __getitem__(self, index) > T_co: > raise NotImplementedError(\"Subclasses of Dataset should implement __getitem__.\") > > # def __getitems__(self, indices: List) > List[T_co]: > # Not implemented to prevent false positives in fetcher check in > # torch.utils.data._utils.fetch._MapDatasetFetcher > > def __add__(self, other: \"Dataset[T_co]\") > \"ConcatDataset[T_co]\": > return ConcatDataset([self, other]) > > # No `def __len__(self)` default? > # See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ] > # in pytorch/torch/utils/data/sampler.py > File: e:\\jhy\\python\\anaconda test\\.conda\\lib\\site packages\\torch\\utils\\data\\dataset.py > Type: type > Subclasses: IterableDataset, TensorDataset, StackDataset, ConcatDataset, Subset, MapDataPipe > ``` ### å®æˆ˜ ![image 20240923194200555](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409231942661.png) åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™ç”±äºéœ€è¦ä½¿ç”¨åˆ°å›¾ç‰‡çš„è¯»å–, æ‰€ä»¥ä¸ºè¿™é‡Œè¦å®‰è£…OpenCV` pip install opencv python`, ä¹Ÿå¯ä»¥ä½¿ç”¨PILé‡Œé¢çš„Image ```python from torch.utils.data import Dataset from PIL import Image import os # dir_path \"./hymenoptera_data/train/ants\" # img_path_list os.listdir(dir_path) # print(img_path_list) # path os.path.join(root_dir, lable_dir) # print(path) # img_path \"./hymenoptera_data/train/ants/0013035.jpg\" # img Image.open(img_path) # print(img.size) # img.show() class Mydata(Dataset): def __init__(self, read_dir, lable_dir): # åˆå§‹åŒ– self.root_dir read_dir self.lable_dir lable_dir self.path os.path.join(self.root_dir, self.lable_dir) self.img_path_list os.listdir(self.path) def __getitem__(self, index): \"\"\" Return the image and lable of the index th sample å¯ä»¥ä½¿å¯¹è±¡ä½¿ç”¨å¼•ç”¨çš„æ–¹å¼è¿›è¡Œè°ƒç”¨ \"\"\" img_name self.img_path_list[index] img_path os.path.join(self.path, img_name) img Image.open(img_path) lable self.lable_dir return img, lable def __len__(self): return len(self.img_path_list) # è·å–ç¬¬ä¸€ä¸ªæ•°æ®é›† root_dir \"./hymenoptera_data/train\" ants_lable_dir \"ants\" ants_mydata Mydata(root_dir, ants_lable_dir) img, lable ants_mydata[0] img.show() bees_lable_dir \"bees\" bees_mydata Mydata(root_dir, bees_lable_dir) bees_img, bees_lable bees_mydata[0] bees_img.show() ``` è¿™ä¸¤ä¸ªæ•°æ®é›†å¯ä»¥ä½¿ç”¨`+`è¿›è¡Œåˆå¹¶ ```python train_dataset ants_mydata + bees_mydata ``` ## tensorboard TensorBoard æ˜¯ä¸€ç»„ç”¨äºæ•°æ®å¯è§†åŒ–çš„å·¥å…·ã€‚å®ƒåŒ…å«åœ¨æµè¡Œçš„å¼€æºæœºå™¨å­¦ä¹ åº“ Tensorflow ä¸­ã€‚TensorBoard çš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š 1. å¯è§†åŒ–æ¨¡å‹çš„ç½‘ç»œæ¶æ„ 2. è·Ÿè¸ªæ¨¡å‹æŒ‡æ ‡ï¼Œå¦‚æŸå¤±å’Œå‡†ç¡®æ€§ç­‰ 3. æ£€æŸ¥æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸­æƒé‡ã€åå·®å’Œå…¶ä»–ç»„ä»¶çš„ç›´æ–¹å›¾ 4. æ˜¾ç¤ºéè¡¨æ ¼æ•°æ®ï¼ŒåŒ…æ‹¬å›¾åƒã€æ–‡æœ¬å’ŒéŸ³é¢‘ 5. å°†é«˜ç»´åµŒå…¥æŠ•å½±åˆ°ä½ç»´ç©ºé—´ è¿™ä¸€ä¸ªåœ¨torché‡Œé¢æœ‰è°ƒç”¨æ¨¡å—çš„, ä½¿ç”¨`pip install tensorboard`å®‰è£… ```c from torch.utils.tensorboard import SummaryWriter write SummaryWriter(\"logs\") # æ˜¯è¦ç”¨è¿™ä¸€ä¸ªæ–‡ä»¶å¤¹å­˜æ”¾æ•°æ® # write.add_image() for i in range(100): write.add_scalar(\"y x\", i, i) # ç”»å›¾çš„æ—¶å€™ï¼Œyè½´æ˜¯iï¼Œxè½´æ˜¯i, ä¸åŒçš„æ–‡ä»¶éœ€è¦ä½¿ç”¨ä¸åŒçš„title write.close() ``` > ä¹‹åä½¿ç”¨å‘½ä»¤`tensorboard logdir logs`å³å¯æ‰“å¼€ç”Ÿæˆçš„æ–‡ä»¶(è¿™é‡Œçš„å‚æ•°æ˜¯æ•°æ®ä¿å­˜çš„é‚£ä¸€ä¸ªæ–‡ä»¶å¤¹), å¯ä»¥ä½¿ç”¨` port port`è®¾ç½®ç«¯å£, é»˜è®¤çš„æ—¶å€™ä¼šä½¿ç”¨ç½‘é¡µhttp://localhost:6006/è¿›è¡Œæ˜¾ç¤º ![image 20240923233445226](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409232334463.png) ### æ˜¾ç¤ºå›¾ç‰‡ ```python from torch.utils.tensorboard import SummaryWriter import numpy as np from PIL import Image write SummaryWriter(\"logs\") # æ˜¯è¦ç”¨è¿™ä¸€ä¸ªæ–‡ä»¶å¤¹å­˜æ”¾æ•°æ® image_path \"hymenoptera_data/train/ants/0013035.jpg\" img Image.open(image_path) img_array np.array(img) # åœ¨ä½¿ç”¨npè¿™ä¸€ä¸ªæ ¼å¼çš„æ—¶å€™éœ€è¦åŠ ä¸Šdataformatsè¿™ä¸€ä¸ªå‚æ•° # ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯çª—å£åŒºåˆ†, ç¬¬äºŒä¸ªæ˜¯å›¾ç‰‡æ•°æ®, ç¬¬ä¸‰ä¸ªæ˜¯ç¬¬å‡ æ­¥(å¯ä»¥ä½¿ç”¨æ»‘å—æ¢æ­¥) write.add_image(\"test\", img_array, 1, dataformats 'HWC') ``` ![image 20240924100139724](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409241001865.png) ### æ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹ ```python # è¿™é‡Œçš„jiaoæ˜¯è®­ç»ƒä½¿ç”¨çš„ä¸€ä¸ªMoudle # inputæ˜¯è¾“å…¥çš„æ•°æ® writer SummaryWriter(\"logs\") writer.add_graph(jiao, input) writer.close() ``` ![image 20240927225748432](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409272257605.png) ![image 20240927225841697](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409272258867.png) ## transforms ### ToTensor ToTensoræ•°æ®ç±»å‹: ä½¿ç”¨`from torchvision import transforms`æ–‡ä»¶ä¸‹é¢çš„ToTensorå¯ä»¥æŠŠPILæˆ–è€…ä¸€ä¸ª`numpy.ndarray`è½¬æ¢ä¸ºä¸€ä¸ªtensoræ•°æ®ç±»å‹, è¿™ä¸€ä¸ªæ•°æ®ç±»å‹å®é™…æ˜¯å¯¹å›¾ç‰‡è¿›è¡Œä¸€äº›æ–¹ä¾¿ç¥ç»ç½‘ç»œçš„å°è£… ```python from torchvision import transforms from PIL import Image image_path \"hymenoptera_data/train/ants/0013035.jpg\" img Image.open(image_path) # 1. ToTensor trans1 transforms.ToTensor() img_tensor trans1(img) ``` ```python import cv2 cv_img cv2.imread(image_path) ``` > ä½¿ç”¨è¿™ç§æ–¹å¼æ‰“å¼€çš„æ–‡ä»¶æ˜¯ä¸€ä¸ª`numpy.ndarray`æ ¼å¼çš„å›¾ç‰‡ ```python from torchvision import transforms from PIL import Image from torch.utils.tensorboard import SummaryWriter image_path \"hymenoptera_data/train/ants/0013035.jpg\" img Image.open(image_path) writer SummaryWriter(\"logs\") # 1. ToTensor trans1 transforms.ToTensor() img_tensor trans1(img) print(img_tensor) writer.add_image(\"ToTensor\", img_tensor) ``` å¯ä»¥ä½¿ç”¨è¿™ä¸€ä¸ªæ–¹å¼æ˜¾ç¤ºå›¾ç‰‡ ![image 20240924122156943](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409241221068.png) ### Compose æŠŠå¤šä¸ªtransformé›†åˆåœ¨ä¸€èµ·, åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™å¯ä»¥æŠŠå¤šä¸ªå¤„ç†çš„transformæ”¾åœ¨ä¸€èµ·, ä¾æ¬¡æ‰§è¡Œ è¿™ä¸€ä¸ªåˆå§‹åŒ–çš„æ—¶å€™çš„å‚æ•°æ˜¯ä¸€ä¸ªæ•°åˆ— ```python trans4 transforms.Compose([ transforms.Resize((300, 300)), transforms.ToTensor() ]) img_tensor trans4(img) writer.add_image(\"Compose\", img_tensor, 1) ``` ### Normalize ç”¨äºå¤„ç†å›¾ç‰‡çš„å·®å¼‚, å‚æ•°æ˜¯å‡å€¼å’Œæ ‡å‡†å·®, éœ€è¦æŒ‰ç…§é€šé“çš„ä¸ªæ•°ä¼ è¿›å»ä¸€ä¸ªæ•°åˆ— è¿™ä¸€ä¸ªå‚æ•°æ•°å€¼æ˜¯éœ€è¦è®¡ç®—è·å–çš„ å®é™…çš„normalå¤„ç†äº‹input[channel] (input[channel] mean[channel]) / std[channel] å¦‚å…¬å¼æ‰€ç¤ºï¼Œé€šè¿‡å‡å»å‡å€¼å¹¶é™¤ä»¥æ ‡å‡†å·®ï¼Œæˆ‘ä»¬å¯ä»¥å°†å›¾åƒæ•°æ®çš„åˆ†å¸ƒè½¬æ¢ä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆå‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1ï¼‰ã€‚è¿™æ ·ï¼Œæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°±å¯ä»¥æ›´å®¹æ˜“åœ°å­¦ä¹ åˆ°æ•°æ®çš„ç‰¹å¾ã€‚ > æ•°æ®æ ‡å‡†åŒ–ï¼šå¦‚ä¸Šæ‰€è¿°ï¼Œtransforms.Normalize()å‡½æ•°å¯ä»¥å¯¹å›¾åƒæ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œä½¿æ•°æ®åˆ†å¸ƒç¬¦åˆæ ‡å‡†æ­£æ€åˆ†å¸ƒã€‚è¿™æœ‰åŠ©äºæ¨¡å‹æ›´å¿«åœ°æ”¶æ•›ï¼Œå¹¶æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚ > æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼šé€šè¿‡å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥å‡å°‘æ¨¡å‹å¯¹ç‰¹å®šæ•°æ®é›†çš„è¿‡æ‹Ÿåˆï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚ > åŠ é€Ÿæ¨¡å‹è®­ç»ƒï¼šæ ‡å‡†åŒ–çš„æ•°æ®å¯ä»¥ä½¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´å¿«åœ°å­¦ä¹ åˆ°æ•°æ®çš„ç‰¹å¾ï¼Œä»è€ŒåŠ é€Ÿæ¨¡å‹çš„è®­ç»ƒé€Ÿåº¦ã€‚ ```python # 2. Normalize print(img_tensor[0][0][0]) trans2 transforms.Normalize(mean [0.5, 0.5, 0.5], std [0.5, 0.5, 0.5]) img_tensor trans2(img_tensor) print(img_tensor[0][0][0]) ``` ### Resize `size((h, w))`æˆ–è€…`size(int)`ç¬¬ä¸€ä¸ªä¼šæŠŠå›¾åƒè¿›è¡Œå˜æ¢, ç¬¬äºŒä¸ªä¼šä½¿å¾—è¿™ä¸€ä¸ªå›¾å½¢æ¯”è¾ƒå°çš„ä¸€ä¸ªè¾¹å’Œè¿™ä¸€ä¸ªæ•°å­—ä¸€æ · If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means a maximum of two leading dimensions ä¹Ÿå¯ä»¥ä½¿ç”¨PILæ ¼å¼çš„æ•°æ® > ToTensorçš„è½¬æ¢æ ¼å¼æ˜¯ > > Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] ```python print(img.size) trans3 transforms.Resize((300, 300)) img_tensor trans3(img) print(img_tensor) print(img_tensor.size) ``` ## Dataset è¿™é‡Œé€‰å–å…¶ä¸­ä¸€ä¸ªæ•°æ®é›† ![image 20240924184250991](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409241842098.png) > The CIFAR 10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. ```python import torchvision from PIL import Image # è·å–CIFAR10æ•°æ®é›† train_set torchvision.datasets.CIFAR10(root \"./dataset\", train True, download True) test_set torchvision.datasets.CIFAR10(root \"./dataset\", train False, download True) # è·å–æ•°æ®é›†çš„å¤§å° print(len(train_set)) print(len(test_set)) # è·å–æ•°æ®é›†çš„æ ‡ç­¾ print(train_set.classes) print(test_set.classes) print(train_set[1]) print(test_set[1]) # æ˜¾ç¤ºå›¾ç‰‡ train_set[1][0].show() test_set[1][0].show() ``` > ```bash > PS E:\\JHY\\python\\anaconda test> & e:/JHY/python/anaconda test/.conda/python.exe e:/JHY/python/anaconda test/my_dataset.py > Files already downloaded and verified > Files already downloaded and verified > 50000 > 10000 > ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] > ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] > (<PIL.Image.Image image mode RGB size 32x32 at 0x218909AD370>, 9) > (<PIL.Image.Image image mode RGB size 32x32 at 0x218909AD160>, 8) > ``` > > ![image 20240924191954360](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409241919607.png) å¯ä»¥ç›´æ¥ä½¿ç”¨å·¥å…·é›†åœ¨è·å–æ•°æ®é›†çš„æ—¶å€™è¿›è¡ŒåŠ å·¥ ```python import torchvision from PIL import Image from torch.utils.tensorboard import SummaryWriter # åˆå§‹åŒ–æ•°æ®é›†çš„è½¬æ¢ dataset_tramsforms torchvision.transforms.Compose([ torchvision.transforms.ToTensor() ]) # è·å–CIFAR10æ•°æ®é›†, ç›´æ¥è¿›è¡Œè½¬æ¢ train_set torchvision.datasets.CIFAR10(root \"./dataset\", train True, download True, transform dataset_tramsforms) test_set torchvision.datasets.CIFAR10(root \"./dataset\", train False, download True, transform dataset_tramsforms) writer SummaryWriter(\"logs\") for i in range(10): img, lable train_set[i] writer.add_image(\"train_set\", img, i) for i in range(10): img, lable test_set[i] writer.add_image(\"test_set\", img, i) writer.close() # print(test_set[0]) ``` ## Dataloader ä¸€ä¸ªåŠ è½½å™¨, æŠŠæ•°æ®åŠ è½½åˆ°ç¥ç»ç½‘ç»œé‡Œé¢, ä»dataseté‡Œé¢å–æ•°æ®, å–çš„æ–¹æ³•å’Œæ•°é‡æ˜¯éœ€è¦ä½¿ç”¨dataloaderè¿›è¡Œè®¾ç½®çš„ ### å‚æ•° **dataset** ([*Dataset*](https://pytorch.org/docs/1.0.0/data.html#torch.utils.data.Dataset)) â€“ dataset from which to load the data. **batch_size** ([*int*](https://docs.python.org/3/library/functions.html#int)*,* *optional*) â€“ how many samples per batch to load (default: `1`).ä¸€æ¬¡åŠ è½½çš„æ•°é‡ **shuffle** ([*bool*](https://docs.python.org/3/library/functions.html#bool)*,* *optional*) â€“ set to `True` to have the data reshuffled at every epoch (default: `False`).è¿™æ•°æ®æ˜¯ä¸æ˜¯éœ€è¦æ‰“ä¹±, ä¸€èˆ¬ä½¿ç”¨true **sampler** ([*Sampler*](https://pytorch.org/docs/1.0.0/data.html#torch.utils.data.Sampler)*,* *optional*) â€“ defines the strategy to draw samples from the dataset. If specified, `shuffle` must be False. **batch_sampler** ([*Sampler*](https://pytorch.org/docs/1.0.0/data.html#torch.utils.data.Sampler)*,* *optional*) â€“ like sampler, but returns a batch of indices at a time. Mutually exclusive with `batch_size`, `shuffle`, `sampler`, and `drop_last`. **num_workers** ([*int*](https://docs.python.org/3/library/functions.html#int)*,* *optional*) â€“ how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: `0`)æ˜¯ä¸æ˜¯ä½¿ç”¨å¤šè¿›ç¨‹è¿›è¡ŒåŠ è½½, Windowsä¸‹é¢è¿™ä¸€ä¸ªå¯èƒ½æœ‰é—®é¢˜ **collate_fn** (*callable**,* *optional*) â€“ merges a list of samples to form a mini batch. **pin_memory** ([*bool*](https://docs.python.org/3/library/functions.html#bool)*,* *optional*) â€“ If `True`, the data loader will copy tensors into CUDA pinned memory before returning them. **drop_last** ([*bool*](https://docs.python.org/3/library/functions.html#bool)*,* *optional*) â€“ set to `True` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If `False` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: `False`)é™¤ä¸å°½çš„æ—¶å€™å‰©ä¸‹çš„é‚£å‡ å¼ ç‰Œæ˜¯ä¸æ˜¯è¦èˆå» **timeout** (*numeric**,* *optional*) â€“ if positive, the timeout value for collecting a batch from workers. Should always be non negative. (default: `0`) **worker_init_fn** (*callable**,* *optional*) â€“ If not `None`, this will be called on each worker subprocess with the worker id (an int in `[0, num_workers 1]`) as input, after seeding and before data loading. (default: `None`) ```python import torchvision from torch.utils.data import DataLoader # åˆå§‹åŒ–æ•°æ®é›†çš„è½¬æ¢ dataset_tramsforms torchvision.transforms.Compose([ torchvision.transforms.ToTensor() ]) test_set torchvision.datasets.CIFAR10(root \"./dataset\", train False, download True, transform dataset_tramsforms) test_loader DataLoader(test_set, batch_size 4, shuffle True, num_workers 0, drop_last False) img, targrt test_set[0] print(img.shape) print(targrt) for data in test_loader: imgs, targets data print(imgs.shape) print(targets) break ``` > ```bash > PS E:\\JHY\\python\\anaconda test> & e:/JHY/python/anaconda test/.conda/python.exe e:/JHY/python/anaconda test/my_dataloader.py > Files already downloaded and verified > torch.Size([3, 32, 32]) > 3 > torch.Size([4, 3, 32, 32]) > tensor([5, 9, 5, 9]) > ``` > > è¿™é‡Œæ˜¯æŠŠå›¾ç‰‡æŒ‰ç…§å››ä¸ªä¸€ç»„è¿›è¡Œæ‰“åŒ…, çŸ³ç¬‹è¿™ä¸€ä¸ªè¿”å›çš„æ˜¯ä¸¤ä¸ªtensoræ•°æ®ç±»å‹ ```python wrier SummaryWriter(\"logs\") step 0 for data in test_loader: imgs, targets data wrier.add_images(\"test_loader\", imgs, step) # è¿™é‡Œä½¿ç”¨imagesåŠ è½½å¤šä¸ªå›¾ç‰‡ step + 1 ``` ![image 20240925191028788](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409251910926.png) ## ç½‘ç»œæ­å»º è¿™ä¸€ä¸ªç³»åˆ—çš„å·¥å…·ä¸»è¦æ˜¯åœ¨torch.nné‡Œé¢ + Container: ä¸€ä¸ªç¥ç»ç½‘ç»œçš„æ¡†æ¶ + Convolution Layers: å·ç§¯å±‚ + Pooling Layers: æ± åŒ–å±‚ + Padding Layers: + ... ### Container è¿™é‡Œé¢æœ€å¸¸ç”¨çš„æ˜¯Moudleè¿™ä¸€ä¸ªç±», æ˜¯æ‰€æœ‰ç¥ç»ç½‘ç»œçš„åŸºç±» å®é™…çš„å¤„ç†æ•°æ®çš„å‡½æ•°æ˜¯æ¯ä¸€ä¸ªç±»é‡Œé¢çš„forwardè¿™ä¸€ä¸ªå‡½æ•° ```python import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 nn.Conv2d(1, 20, 5) self.conv2 nn.Conv2d(20, 20, 5) def forward(self, x): x F.relu(self.conv1(x)) # ä¸€æ¬¡å·ç§¯, ä¸€æ¬¡éçº¿æ€§å¤„ç† return F.relu(self.conv2(x)) # å†æ¬¡è¿›è¡Œå·ç§¯éçº¿æ€§è·å–è¾“å‡º ``` ```c from torch import nn import torch class My_Moudle(nn.Module): def __init__(self): super(My_Moudle, self).__init__() def forward(self, x): return x + 1 if __name__ \"__main__\": x torch.tensor(1.0) model My_Moudle() y model(x) print(y) ``` ```bash PS E:\\JHY\\python\\anaconda test> & e:/JHY/python/anaconda test/.conda/python.exe e:/JHY/python/anaconda test/my_moudle.py tensor(2.) ``` ### Sequential ```python # Example of using Sequential model nn.Sequential( nn.Conv2d(1,20,5), nn.ReLU(), nn.Conv2d(20,64,5), nn.ReLU() ) # Example of using Sequential with OrderedDict model nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)), ('relu1', nn.ReLU()), ('conv2', nn.Conv2d(20,64,5)), ('relu2', nn.ReLU()) ])) ``` ### å±‚ #### å·ç§¯å±‚Convolution Layers è¿™é‡Œçš„é‡Œé¢æ¯”è¾ƒå¸¸ç”¨çš„æ˜¯Conv1d, Conv2d, è¿™ä¸€ä¸ªæ–‡ä»¶çš„æ“ä½œå®é™…æ˜¯å¯¹functionalè¿™ä¸€ä¸ªæ–‡ä»¶çš„æ“ä½œè¿›è¡Œçš„å°è£… [conv_arithmetic:A technical report on convolution arithmetic in the context of deep learning GitCode](https://gitcode.com/gh_mirrors/co/conv_arithmetic/blob/master/README.md?utm_source csdn_github_accelerator&isLogin 1) + Conv2d ```python torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride 1, padding 0, dilation 1, groups 1, bias True) ``` <img src \"https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409261824662.png\" alt \"image 20240926182432173\" style \"zoom:150%;\" /> in_channels â€‹\tè¾“å…¥çš„é€šé“æ•° out_channels â€‹\tè¾“å‡ºçš„é€šé“æ•°, å®é™…æ˜¯ä½¿ç”¨å‡ ä¸ªä¸åŒçš„å·ç§¯æ ¸ç”Ÿæˆå¤šä¸ªç»“æœ kernel_size â€ƒâ€ƒå·ç§¯æ ¸çš„å¤§å°ï¼Œä¸€èˆ¬æˆ‘ä»¬ä¼šä½¿ç”¨5x5ã€3x3è¿™ç§å·¦å³ä¸¤ä¸ªæ•°ç›¸åŒçš„å·ç§¯æ ¸ï¼Œå› æ­¤è¿™ç§æƒ…å†µåªéœ€è¦å†™kernel_size 5è¿™æ ·çš„å°±è¡Œäº†ã€‚å¦‚æœå·¦å³ä¸¤ä¸ªæ•°ä¸åŒï¼Œæ¯”å¦‚3x5çš„å·ç§¯æ ¸ï¼Œé‚£ä¹ˆå†™ä½œkernel_size (3, 5)ï¼Œæ³¨æ„éœ€è¦å†™ä¸€ä¸ªtupleï¼Œè€Œä¸èƒ½å†™ä¸€ä¸ªåˆ—è¡¨ï¼ˆlistï¼‰ã€‚é‡Œé¢çš„æ•°å­—æ˜¯ä¸éœ€è¦è®¾ç½®çš„, ä¼šåœ¨è®­ç»ƒçš„æ—¶å€™è¿›è¡Œè°ƒæ•´çš„ stride 1 â€ƒâ€ƒå·ç§¯æ ¸åœ¨å›¾åƒçª—å£ä¸Šæ¯æ¬¡å¹³ç§»çš„é—´éš”ï¼Œå³æ‰€è°“çš„æ­¥é•¿ã€‚è¿™ä¸ªæ¦‚å¿µå’ŒTensorflowç­‰å…¶ä»–æ¡†æ¶æ²¡ä»€ä¹ˆåŒºåˆ«ï¼Œä¸å†å¤šè¨€ã€‚ padding â€‹\tæ‹“å±•çš„å¤§å° dilationç©ºæ´å·ç§¯, ä¸€èˆ¬ä¸ä½¿ç”¨ ![img](https://raw.gitcode.com/gh_mirrors/co/conv_arithmetic/files/master/gif/dilation.gif) groups bias True ![image 20240926193519679](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409261935794.png) > åŸç† > > ```python > torch.nn.functional.conv2d(input, weight, bias None, stride 1, padding 0, dilation 1, groups 1) > ``` > > **Parameters:** > > **input** â€“ input tensor of shape (minibatchÃ—in_channelsÃ—iHÃ—iW)è¾“å…¥çš„éœ€è¦æ˜¯ä¸€ä¸ªå››ç»´çš„æ•°ç»„, å¯ä»¥ä½¿ç”¨reshipå‡½æ•°è¿›è¡Œå˜æ¢ > **weight** â€“ filters of shape (out_channelsÃ—in_channelsgroupsÃ—kHÃ—kW) > **bias** â€“ optional bias tensor of shape (out_channelsout_channels). Default: `None` > **stride** â€“ the stride of the convolving kernel. Can be a single number or a tuple (sH, sW). Default: 1 > **padding** â€“ implicit zero paddings on both sides of the input. Can be a single number or a tuple (padH, padW). Default: 0 å¡«å…… > **dilation** â€“ the spacing between kernel elements. Can be a single number or a tuple (dH, dW). Default: 1 > **groups** â€“ split input into groups, in_channelsin_channels should be divisible by the number of groups. Default: 1 > > ```python > import torch > import torch.nn.functional as F > > input torch.tensor([[1, 2, 0, 3, 1], > [0, 1, 2, 3, 1], > [1, 2, 1, 0, 0], > [5, 2, 3, 1, 1], > [2, 1, 0, 1, 1]]) > > kernel torch.tensor([[1, 2, 1], > [0, 1, 0], > [2, 1, 0]]) > \"\"\" > ç»“æœ > 1*1 + 2*2 + 0*1 + 0*0 + 1*1 + 0*2 + 1*2 + 2*1 + 0*3 10 > 1*2 + 2*0 + 1*3 + 0*1 + 1*2 + 0*3 + 2*2 + 1*3 + 0*0 12 > ... > \"\"\" > > # è¿™é‡Œçš„å‚æ•°æ˜¯(N, C, H, W), Næ˜¯batch_size(æ¯ä¸€æ¬¡è®­ç»ƒçš„æ—¶å€™å›¾ç‰‡çš„æ•°é‡), Cæ˜¯é€šé“æ•°(äºŒç»´å‘é‡æ˜¯1), Hæ˜¯é«˜, Wæ˜¯å®½ > input torch.reshape(input, (1, 1, 5, 5)) > kernel torch.reshape(kernel, (1, 1, 3, 3)) > > print(input.shape) > print(kernel.shape) > > output F.conv2d(input, kernel, stride 1, padding 0) # è¿™é‡Œçš„strideæ˜¯æ­¥é•¿, paddingæ˜¯å¡«å…… > print(output) > > ``` > > ```bash > PS E:\\JHY\\python\\anaconda test> & e:/JHY/python/anaconda test/.conda/python.exe e:/JHY/python/anaconda test/my_conv.py > torch.Size([1, 1, 5, 5]) > torch.Size([1, 1, 3, 3]) > tensor([[[[10, 12, 12], > [18, 16, 16], > [13, 9, 3]]]]) > ``` ```python import torch import torchvision from torch.utils.data import DataLoader from torch import nn from torch.utils.tensorboard import SummaryWriter dateset torchvision.datasets.CIFAR10(root \"./dataset\", train False, download True, transform torchvision.transforms.ToTensor()) dataloader DataLoader(dateset, batch_size 64) class JIAO(nn.Module): def __init__(self): super(JIAO, self).__init__() self.conv1 nn.Conv2d(in_channels 3, out_channels 6, kernel_size 3, stride 1, padding 0) def forward(self, x): x self.conv1(x) return x jiao JIAO() \"\"\" JIAO( (conv1): Conv2d(3, 6, kernel_size (3, 3), stride (1, 1)) ) \"\"\" print(jiao) writer SummaryWriter(\"logs\") step 0 for data in dataloader: imgs, targets data output jiao(imgs) print(imgs.shape) # torch.Size([64, 3, 32, 32]) print(output.shape) # torch.Size([64, 6, 30, 30]) writer.add_images(\"input\", imgs, step) ## è¿™é‡Œçš„3æ˜¯è¾“å‡ºé€šé“æ•°, 30æ˜¯è¾“å‡ºçš„é«˜å’Œå®½, ä½¿ç”¨ 1æ˜¯è‡ªåŠ¨è®¡ç®—, 3æ˜¯å¯ä»¥æ˜¾ç¤ºçš„é€šé“æ•° output torch.reshape(output, ( 1, 3, 30, 30)) writer.add_images(\"output\", output, step) step + 1 writer.close() ``` ![image 20240926193224030](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409261932362.png) #### æ± åŒ–å±‚ Pooling layers MaxPool: æœ€å¤§æ± åŒ– MaxUnpool: ä¸Šé‡‡æ · ... æœ€å¸¸ä½¿ç”¨çš„MaxPool2d + MaxPool2d class torch.nn.MaxPool2d(kernel_size, stride None, padding 0, dilation 1,return_indices False, ceil_mode False) > **kernel_size** â€“ the size of the window to take a max overç”Ÿæˆçš„çª—å£ > **stride** â€“ the stride of the window. Default value is `kernel_size` > **padding** â€“ implicit zero padding to be added on both sides > **dilation** â€“ a parameter that controls the stride of elements in the window > **return_indices** â€“ if `True`, will return the max indices along with the outputs. Useful when Unpooling later > **ceil_mode** â€“ when True, will use ceil instead of floor to compute the output shapeå½“ä¸€ä¸ªå–å€¼èŒƒå›´ä¸èƒ½å…¨éƒ¨è¦†ç›–çš„æ—¶å€™æ˜¯ä¸æ˜¯è¿›è¡Œèˆå»æ“ä½œ #### å«å±‚Padding Layer ä½¿ç”¨æ•°å­—è¿›è¡Œå¡«å……, å‡ ä¹ç”¨ä¸åˆ° #### éçº¿æ€§æ¿€æ´»Non Linear Activactions ä¸»è¦ä½¿ç”¨çš„æ˜¯ReLu, Sigmoid, Tanhè¿™å‡ ä¸ªç®—æ³•ä½¿ç”¨çš„æ–¹å¼å’Œå‰é¢çš„åŸºæœ¬ä¸€æ · #### Normalization Layers è¿™ä¸€ä¸ªä¸å¸¸ä½¿ç”¨, ä¸»è¦ç”¨çš„å‡½æ•°æ˜¯BatchNorm2dè¿™ä¸€ä¸ªå‡½æ•°, å®ƒçš„å‚æ•°mun_featuresæŒ‡çš„æ˜¯channelçš„æ•°é‡ #### Liner Layer å‚æ•°å®é™…æ˜¯inputå’Œoutputçš„å¤§å°, æƒé‡æ˜¯æŒ‰ç…§è¾“å…¥çš„æ•°æ®è®¡ç®—çš„ ä¾‹: å®é™…çš„è®¡ç®—å¯ä»¥æŠŠä¸€ä¸ª1x1x4096çš„æ•°æ®è½¬æ¢ä¸º1x1x1000 #### flatten æŠŠè¾“å…¥çš„æ•°æ®å±•å¼€ä¸ºä¸€è¡Œ #### æŸå¤±å‡½æ•°å’Œåå‘ä¼ æ’­ + L1loss ```python classtorch.nn.L1Loss(size_average None, reduce None, reduction 'elementwise_mean') ``` ä½¿ç”¨è¿™ä¸€ä¸ªå¯ä»¥è®¡ç®—ç»“æœå’ŒçœŸå®å€¼ä¹‹é—´çš„ç»å¯¹å€¼, å¯ä»¥ä½¿ç”¨reductionæ§åˆ¶æ˜¯å¹³å‡è¿˜æ˜¯æ±‚å’Œ ```python >>> loss nn.L1Loss() >>> input torch.randn(3, 5, requires_grad True) >>> target torch.randn(3, 5) >>> output loss(input, target) >>> output.backward() ``` inputå’Œtargetéœ€è¦æ˜¯ç›¸åŒçš„å›¾å½¢ + MSELOSS è®¡ç®—å¹³æ–¹å·®çš„å¹³å‡æ•° + CrossEntorpyLossäº¤å‰ç†µ ![image 20240927232316235](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409272323402.png) æœ‰å¤šä¸ªåˆ†ç±»çš„æ—¶å€™, æ¯”å¦‚è¯´æœ‰ä¸‰ä¸ªåˆ†ç±»çš„æ—¶å€™, ä¸€å¼ å›¾ç‰‡çš„è¾“å‡ºæ˜¯[0.1, 0.2, 0.3], åˆ†åˆ«æ ‡å‡†0, 1, 2è¿™ä¸‰ä¸ªç±», å®é™…çš„åˆ†ç±»åº”è¯¥æ˜¯1 å®é™…è®¡ç®—çš„æ—¶å€™xæ˜¯è·å–çš„[0.1, 0.2, 0.3], classæ˜¯1 loss(x, class) 0.2 + log(exp(0.1) + exp(0.2) + exp(0.3)) > expæ˜¯æŒ‡æ•°å‡½æ•°$e^x$ ```python x torch.tensor([0.1, 0.2, 0.3]) y torch.tensor([1]) x torch.reshape(x, (1, 3)) loss_cross nn.CrossEntorpyLoss() result_cross loss_cross(x, y) print(result_cross) ``` ```python from torch import nn from torch.nn import Conv2d from torch.nn import MaxPool2d from torch.nn import Flatten import torch from torch.utils.tensorboard import SummaryWriter import torchvision from torchvision import transforms from torch.utils.data import DataLoader # åˆå§‹åŒ–æ•°æ®é›†çš„è½¬æ¢ dataset_tramsforms transforms.Compose([ torchvision.transforms.ToTensor() ]) train_set torchvision.datasets.CIFAR10(root \"./dataset\", train False, download True, transform dataset_tramsforms) dataloader DataLoader(train_set, batch_size 64) class JIAO(nn.Module): def __init__(self): super(JIAO, self).__init__() self.moudle1 nn.Sequential( Conv2d(in_channels 3, out_channels 32, kernel_size 5, padding 4), nn.MaxPool2d(kernel_size 2), Conv2d(32, 32, 5, padding 2), nn.MaxPool2d(2), Conv2d(32, 64, 5, padding 2), nn.MaxPool2d(2), Flatten(), nn.Linear(64*4*4, 64), nn.Linear(64, 10) ) def forward(self, x): x self.moudle1(x) return x jiao JIAO() loss nn.CrossEntropyLoss() for data in dataloader: imgs, labels data output jiao(imgs) result_loss loss(output, labels) print(result_loss) result_loss.backward() # åå‘ä¼ æ’­, å¯ä»¥ä½¿ç”¨è¿™ä¸€ä¸ªè®¡ç®—å‡ºæ¥ä¸€ä¸ªæ¢¯åº¦, ä¹‹åè¿›ä¸€æ­¥ä¼˜åŒ– break ``` #### ä¼˜åŒ–å™¨optim ```python for input, target in dataset: optimizer.zero_grad() output model(input) loss loss_fn(output, target) loss.backward() optimizer.step() ``` > **params** (*iterable*) â€“ iterable of parameters to optimize or dicts defining parameter groups, æ¨¡å‹çš„å‚æ•° > **rho** ([*float*](https://docs.python.org/3/library/functions.html#float)*,* *optional*) â€“ coefficient used for computing a running average of squared gradients (default: 0.9)å­¦ä¹ é€Ÿç‡ > **eps** ([*float*](https://docs.python.org/3/library/functions.html#float)*,* *optional*) â€“ term added to the denominator to improve numerical stability (default: 1e 6) > **lr** ([*float*](https://docs.python.org/3/library/functions.html#float)*,* *optional*) â€“ coefficient that scale delta before it is applied to the parameters (default: 1.0) > **weight_decay** ([*float*](https://docs.python.org/3/library/functions.html#float)*,* *optional*) â€“ weight decay (L2 penalty) (default: 0) #### ç°æœ‰çš„ç½‘ç»œæ¨¡å‹models [torchvision.models â€” PyTorch master documentation](https://pytorch.org/docs/0.4.1/torchvision/models.html) æ¯”è¾ƒå¸¸ç”¨çš„æ—¶å€™vgg16, vgg19 ```python torchvision.models.vgg16(pretrained False, **kwargs) ``` **pretrained** ([*bool*](https://docs.python.org/3/library/functions.html#bool)) â€“ If True, returns a model pre trained on ImageNet(åœ¨ImageNeté‡Œé¢è®­ç»ƒå‡ºæ¥çš„æ•°æ®, è¿™ä¸€ä¸ªç½‘ç»œé‡Œé¢å¯ä»¥è¿›è¡Œ1000ä¸ªåˆ†ç±», ä½†æ˜¯ç”±äºè¿™ä¸€ä¸ªæ•°æ®é›†æ¯”è¾ƒå¤§, æ‰€ä»¥æ–¹ä¾¿ä¸‹è½½) ```python vgg16_true.add_module(\"add_linear\", torch.nn.Linear(1000, 10)) # æ·»åŠ æ–°çš„å±‚ ``` ![image 20240928170922809](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409281709126.png) ```python vgg16_true.classifier.add_module(\"add_linear\", torch.nn.Linear(1000, 10)) # æ·»åŠ æ–°çš„å±‚(åœ¨ç°æœ‰çš„å±‚é‡Œé¢) ``` ![image 20240928171141329](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409281711469.png) ä¹Ÿå¯ä»¥ä½¿ç”¨ ```python vgg16_true.classifier[6] nn.Linear(4096, 10) # ä¿®æ”¹åŸæœ‰çš„å±‚ ``` ![image 20240928171449315](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409281714434.png) ## å®æˆ˜ ![image 20240927223634375](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409272236547.png) é¦–å…ˆæŠŠæ•°æ®è¿›è¡Œä¸€æ¬¡å·ç§¯æ‰©å±•ä¸€ä¸‹å±‚æ•°, ä¹‹åè¿›è¡Œä¸€æ¬¡æœ€å¤§å€¼æ± åŒ–, ä¹‹åå†æ¬¡å·ç§¯ä¸€æ¬¡, ç„¶åæœ€å¤§å€¼æ± åŒ–, å†é‡å¤ä¸€ä¸‹ç„¶åå±•å¹³, æœ€åä½¿ç”¨çº¿æ€§å±‚å¤„ç† ```python from torch import nn from torch.nn import Conv2d from torch.nn import MaxPool2d from torch.nn import Flatten import torch from torch.utils.tensorboard import SummaryWriter class JIAO(nn.Module): def __init__(self): super(JIAO, self).__init__() # self.conv1 Conv2d(in_channels 3, out_channels 32, kernel_size 5, padding 4) # self.maxpool1 nn.MaxPool2d(kernel_size 2) # self.conv2 Conv2d(32, 32, 5, padding 2) # self.maxpool2 MaxPool2d(2) # self.conv3 Conv2d(32, 64, 5, padding 2) # self.maxpool3 MaxPool2d(2) # self.flatten Flatten() # self.linear1 nn.Linear(64*4*4, 64) # self.linear2 nn.Linear(64, 10) # å¯ä»¥ä½¿ç”¨ä¸€ä¸‹çš„ä»£ç è¿›è¡Œç®€åŒ– self.moudle1 nn.Sequential( Conv2d(in_channels 3, out_channels 32, kernel_size 5, padding 4), nn.MaxPool2d(kernel_size 2), Conv2d(32, 32, 5, padding 2), nn.MaxPool2d(2), Conv2d(32, 64, 5, padding 2), nn.MaxPool2d(2), Flatten(), nn.Linear(64*4*4, 64), nn.Linear(64, 10) ) def forward(self, x): x self.moudle1(x) return x jiao JIAO() print(jiao) input torch.randn(64, 3, 32, 32) output jiao(input) print(output.shape) writer SummaryWriter(\"logs\") writer.add_graph(jiao, input) writer.close() ``` + åŠ åé¦ˆä»¥åŠä¼˜åŒ–å™¨ ```python from torch import nn from torch.nn import Conv2d from torch.nn import MaxPool2d from torch.nn import Flatten import torch from torch.utils.tensorboard import SummaryWriter import torchvision from torchvision import transforms from torch.utils.data import DataLoader # åˆå§‹åŒ–æ•°æ®é›†çš„è½¬æ¢ dataset_tramsforms transforms.Compose([ torchvision.transforms.ToTensor() ]) train_set torchvision.datasets.CIFAR10(root \"./dataset\", train False, download True, transform dataset_tramsforms) dataloader DataLoader(train_set, batch_size 64) class JIAO(nn.Module): def __init__(self): super(JIAO, self).__init__() self.moudle1 nn.Sequential( Conv2d(in_channels 3, out_channels 32, kernel_size 5, padding 4), nn.MaxPool2d(kernel_size 2), Conv2d(32, 32, 5, padding 2), nn.MaxPool2d(2), Conv2d(32, 64, 5, padding 2), nn.MaxPool2d(2), Flatten(), nn.Linear(64*4*4, 64), nn.Linear(64, 10) ) def forward(self, x): x self.moudle1(x) return x jiao JIAO() loss nn.CrossEntropyLoss() optimizer torch.optim.SGD(jiao.parameters(), lr 0.01) for i in range(20): for data in dataloader: imgs, labels data output jiao(imgs) result_loss loss(output, labels) optimizer.zero_grad() # æ¢¯åº¦æ¸…é›¶ result_loss.backward() # åå‘ä¼ æ’­ optimizer.step() # æ›´æ–°å‚æ•° print(result_loss) # break ``` ## åŠ è½½ä¿å­˜ + ç¬¬ä¸€ç§ç»“æ„åŠ å‚æ•° ```python torch.save(vgg16_true, \"vgg16.pth\") # ä¿å­˜æ¨¡å‹ ``` > è®°å½•äº†æ¨¡å‹ä»¥åŠæ¨¡å‹é‡Œé¢çš„å‚æ•° ```python torch.load(\"vgg16.pth\") ``` > ä½¿ç”¨è¿™ä¸€ä¸ªæ–¹æ³•çš„æ—¶å€™, å¦‚æœåŠ è½½çš„æ˜¯ä¸€ä¸ªè‡ªå·±å®šä¹‰çš„ç±», è¿™ä¸€ä¸ªç±»éœ€è¦å¼•å…¥ä¸€ä¸‹ + æ–¹æ³•äºŒåªè®°å½•å‚æ•° ```python torch.save(vgg16_true.state_dict(), \"vgg16.pht\") # ä¿å­˜æ¨¡å‹ ``` æ¢å¤ ```python vgg16 torchvision.models.vgg16(pretrained False) vgg16.load_state_dict(torch.load(\"vgg16.pht\")) # åŠ è½½æ¨¡å‹ ``` > **æ³¨: **ä½¿ç”¨è¿™ä¸€ä¸ªæ–¹å¼çš„æ—¶å€™éœ€è¦åˆå§‹åŒ–ä¸€ä¸ªModelå¯¹è±¡å† ## å®Œæ•´çš„è®­ç»ƒ ```python import torchvision import torch from torch.utils.tensorboard import SummaryWriter # train_data torchvision.datasets.ImageNet(root \"./dataset_ImageNet\", train True, download True, # transform torchvision.transforms.ToTensor()) # vgg16_true torchvision.models.vgg16(pretrained True) # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹, ä½¿ç”¨æ•°æ®é›†è®­ç»ƒå¥½çš„å‚æ•° # vgg16_flase torchvision.models.vgg16(pretrained False) # ä¸åŠ è½½é¢„è®­ç»ƒæ¨¡å‹, ä½¿ç”¨é»˜è®¤å‚æ•° # print(vgg16_true) # print(vgg16_flase) train_data torchvision.datasets.CIFAR10(root \"./dataset\", train True, download True, transform torchvision.transforms.ToTensor()) test_data torchvision.datasets.CIFAR10(root \"./dataset\", train False, download True, transform torchvision.transforms.ToTensor()) # vgg16_true.add_module(\"add_linear\", torch.nn.Linear(1000, 10)) # æ·»åŠ æ–°çš„å±‚ # vgg16_true.classifier.add_module(\"add_linear\", torch.nn.Linear(1000, 10)) # æ·»åŠ æ–°çš„å±‚(åœ¨ç°æœ‰çš„å±‚é‡Œé¢) # vgg16_true.classifier[6] torch.nn.Linear(4096, 10) # ä¿®æ”¹åŸæœ‰çš„å±‚ # print(vgg16_true) train_dataloader torch.utils.data.DataLoader(train_data, batch_size 64) test_dataloader torch.utils.data.DataLoader(test_data, batch_size 64) class JIAO(torch.nn.Module): def __init__(self): super(JIAO, self).__init__() self.moudle1 torch.nn.Sequential( torch.nn.Conv2d(in_channels 3, out_channels 32, kernel_size 5, padding 2), torch.nn.MaxPool2d(kernel_size 2), torch.nn.Conv2d(32, 32, 5, padding 2), torch.nn.MaxPool2d(2), torch.nn.Conv2d(32, 64, 5, padding 2), torch.nn.MaxPool2d(2), torch.nn.Flatten(), torch.nn.Linear(64*4*4, 64), torch.nn.Linear(64, 10) ) def forward(self, x): x self.moudle1(x) return x # æ‰§è¡Œçš„æ˜¯å½“å‰æ–‡ä»¶ if __name__ \"__main__\": jiao JIAO() #æŸå¤±å‡½æ•° loss_fn torch.nn.CrossEntropyLoss() #ä¼˜åŒ–å™¨ learn_rate 0.01 # 1e 2 optimizer torch.optim.SGD(jiao.parameters(), lr learn_rate) writer SummaryWriter(\"logs\") #è®­ç»ƒ epoch 20 total_step 0 for i in range(epoch): for data in train_dataloader: imgs, labels data output jiao(imgs) result_loss loss_fn(output, labels) optimizer.zero_grad() # æ¢¯åº¦æ¸…é›¶ result_loss.backward() # åå‘ä¼ æ’­ optimizer.step() # æ›´æ–°å‚æ•° # print(result_loss) # break total_step total_step + 1 if total_step % 100 0: print(\"epoch: \", i, \"step: \", total_step, \"loss: \", result_loss) writer.add_scalar(\"train_loss\", result_loss, total_step) # æµ‹è¯• total_test_loss 0 with torch.no_grad(): for data in test_dataloader: img, target data output jiao(img) loss loss_fn(output, target) total_test_loss + loss writer.add_scalar(\"test_loss\", total_test_loss, i) print(\"epoch: \", i, \"loss: \", total_test_loss) torch.save(jiao, \"./my_mod/model_{}.pth\".format(i)) writer.close() ``` ## æ­£ç¡®ç‡ åœ¨å®é™…è®­ç»ƒçš„æ—¶å€™è¾“å‡ºçš„æ˜¯å„ä¸ªé€‰é¡¹çš„æ¦‚ç‡, æ¯”å¦‚ä¸€ä¸ªåªæœ‰ä¸¤ä¸ªæ•°æ®çš„åˆ†ç±», å¯èƒ½è¾“å‡º1. [0.1, 0.2], 2. [0.3, 0.4] ä½¿ç”¨Argmaxå¯ä»¥è·å–åˆ°Preds [1\\][1\\] å¦‚æœInput targetæ˜¯[0\\][1\\] ä½¿ç”¨Preds Input targetå¯ä»¥è·å–[False, True].sum 1 ```python import torch outputs torch.tensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.2]]) # output: tensor([1, 1, 0]) print(outputs.argmax(dim 1)) # dim 1è¡¨ç¤ºæŒ‰è¡Œå–æœ€å¤§å€¼çš„ç´¢å¼• preds outputs.argmax(dim 1) targets torch.tensor([1, 0, 0]) # output: tensor([ True, False, True]) print(targets preds) print((targets preds).sum().item()) # 2 ``` ```python # import torch # outputs torch.tensor([[0.1, 0.2], # [0.3, 0.4], # [0.5, 0.2]]) # # output: tensor([1, 1, 0]) # print(outputs.argmax(dim 1)) # dim 1è¡¨ç¤ºæŒ‰è¡Œå–æœ€å¤§å€¼çš„ç´¢å¼• # preds outputs.argmax(dim 1) # targets torch.tensor([1, 0, 0]) # # output: tensor([ True, False, True]) # print(targets preds) # print((targets preds).sum().item()) # 2 import torch import torchvision from my_model_pretraines import JIAO test_data torchvision.datasets.CIFAR10(root \"./dataset\", train False, download True, transform torchvision.transforms.ToTensor()) test_dataloader torch.utils.data.DataLoader(test_data, batch_size 64) module torch.load(\"my_mod/model_19.pth\") # æµ‹è¯•ä¸€ä¸‹å‡†ç¡®ç‡ correct 0 total len(test_data) with torch.no_grad(): for data in test_dataloader: imgs, labels data outputs module(imgs) preds outputs.argmax(dim 1) correct + (preds labels).sum().item() print(\"å‡†ç¡®ç‡: \", correct / total) ``` ## ä½¿ç”¨GPU + æ–¹æ³•ä¸€ ç½‘ç»œæ¨¡å‹, æ•°æ®(è¾“å…¥, æ ‡æ³¨)ä»¥åŠæŸå¤±å‡½æ•°æœ‰ åœ¨æ¨¡å‹ä½¿ç”¨çš„æ—¶å€™ç”¨`model model.cuda()`, è¯¯å·®å‡½æ•°ä¹Ÿå¯ä»¥ä½¿ç”¨`loss_fn loss_fn.cuda()` ```python def train(jiao : JIAO, epoch : int, learn_rate : float, output_name : str, train_dataloader): jiao jiao.cuda() total_step 0 #æŸå¤±å‡½æ•° loss_fn torch.nn.CrossEntropyLoss() loss_fn loss_fn .cuda() optimizer torch.optim.SGD(jiao.parameters(), lr learn_rate) for i in range(epoch): for data in train_dataloader: imgs, labels data imgs imgs.cuda() labels labels.cuda() output jiao(imgs) result_loss loss_fn(output, labels) optimizer.zero_grad() # æ¢¯åº¦æ¸…é›¶ result_loss.backward() # åå‘ä¼ æ’­ optimizer.step() total_step total_step + 1 if total_step % 100 0: print(\"epoch: \", i, \"step: \", total_step, \"loss: \", result_loss) torch.save(jiao, output_name) ``` + æ–¹æ³•äºŒ ```python device torch.device(\"cpu\") # cuda / cuda:0 / cuda:1 å®šä¹‰ä¸€ä¸ªè®¾å¤‡ # ä¹‹åæŠŠæ¨¡å‹ä¹‹ç±»çš„ä½¿ç”¨toå®šä¹‰åˆ°è¿™ä¸€ä¸ªè®¾å¤‡ jiao jiao.to(device) loss_fn loss_fn.to(device) ``` ## æµ‹è¯•ç¯å¢ƒ [æ¬¢è¿ä½¿ç”¨ Colaboratory Colab (google.com)](https://colab.research.google.com/) ![image 20240928221225921](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409282212141.png) ![image 20240928221248593](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409282212783.png) ## æ¨¡å‹çš„æµ‹è¯• ä½¿ç”¨ä»¥åŠè®­ç»ƒå¥½çš„æ¨¡å‹, æä¾›è¾“å…¥, å¯ä»¥åœ¨githubä¸Šé¢æ‰¾, æœç´¢github ```python import PIL import PIL.Image import torchvision import torch from my_model_pretraines import JIAO img_path \"./img/shi.png\" img PIL.Image.open(img_path) classes ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] print(img) img img.convert(\"RGB\") transform torchvision.transforms.Compose([ torchvision.transforms.Resize((32, 32)), torchvision.transforms.ToTensor() ]) img transform(img) # print(img.shape) moudle torch.load(\"my_mod/model.pth\") # å¦‚æœgpuè®­ç»ƒæƒ³åœ¨cpuä½¿ç”¨ï¼Œéœ€è¦åŠ ä¸Šmap_location torch.device(\"cpu\") moudle moudle.cuda() img torch.reshape(img, (1, 3, 32, 32)) img img.cuda() moudle.eval() # æŠŠè¿™ä¸€ä¸ªæ¨¡å‹è®¾ç½®ä¸ºæµ‹è¯•æ¨¡å¼ with torch.no_grad(): output moudle(img) print(output) result output.argmax(dim 1) print(\"filename {}, class {}\".format(img_path, classes[result.item()])) ```"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/2025-12-12-05-YoloV1.html":{"title":"YoloV1","content":"# YoloV1 æŠŠä¸€ä¸ªå›¾åƒè¿›è¡Œåˆ†å‰²ä¸ºæ ¼å­, åœ¨æ¯ä¸ªæ ¼å­è¿›è¡Œé¢„æµ‹, ä¾æ®ç»éªŒç»˜åˆ¶å‡ ç§æ¡†, ä¸­å¿ƒä½ç½®å’Œä¹‹å‰çš„æ ¼å­é‡åˆ, ä¹‹åå¯¹æ¡†è¿›è¡Œå¾®è°ƒ, ä½¿ç”¨å®é™…çš„å€¼è¿›è¡ŒIoUè®¡ç®—"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/2025-12-12-04-ç»å…¸ç®—æ³•.html":{"title":"ç»å…¸ç®—æ³•","content":"# ç»å…¸ç®—æ³• ## two stageå’Œone stage + one stage: è¾“å…¥åˆ°è¾“å‡ºåªè¦ä¸€ä¸ªç½‘ç»œ, Yoloç³»åˆ— é€Ÿåº¦æ¯”è¾ƒå¿«, é€‚åˆå®æ—¶ä»»åŠ¡, ä½†æ˜¯æ•ˆæœæ¯”è¾ƒå·® + tow stage: åœ¨è¾“å‡ºçš„æ—¶å€™é¦–å…ˆè¾“å‡ºä¸€ç³»åˆ—ç»“æœä½œä¸ºåˆé€‰, ä¹‹ååœ¨è¿›ä¸€æ­¥è¿›è¡Œé¢„æµ‹, Fast rcnn Mask rcnnç³»åˆ— é€Ÿåº¦æ¯”è¾ƒæ…¢, è¾¾ä¸åˆ°å®æ—¶ ## æŒ‡æ ‡ ### map ä¸€èˆ¬æ¥çœ‹ç²¾åº¦ä»¥åŠå¬å›ç‡, ç²¾åº¦æ˜¯è¾¹æ¡†æ˜¯ä¸æ˜¯å‡†ç¡®çš„ä½ç½®, å¬å›ç‡æ˜¯çœ‹æ˜¯ä¸æ˜¯éƒ½æ‰¾åˆ°äº† Precision TP / (TP + FP) Recall TP / (TP + FN) ä¸€èˆ¬æ¥è¯´è¿™ä¸¤ä¸ªå€¼æ˜¯è´Ÿç›¸å…³çš„, æŠŠè¿™ä¸¤ä¸ªå€¼é€šè¿‡ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼è¿›è¡Œåˆ†åˆ«è®¡ç®—ç”»å›¾, mapæ˜¯å›´æˆçš„å›¾åƒçš„é¢ç§¯ <img src \"https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251212190539505.png\" alt \"image 20251212190539505\" style \"zoom:50%;\" /> ä½¿ç”¨çš„æ˜¯çº¢æ¡†çš„é¢ç§¯ > TP: True positivesé€‰å‡ºæ¥æ­£ç¡®è·å–åˆ°çš„æ•°é‡ > > FP: false positives é€‰å‡ºæ¥ä¸æ­£ç¡® > > FN: false negatives æ­£ç±»å‹åˆ¤æ–­ä¸ºè´Ÿç±»å‹ > > TN: true negatives è´Ÿç±»å‹åˆ¤æ–­ä¸ºè´Ÿç±»å‹ > > å®é™…åœ¨è·å–ä»¥ä¸Šçš„æ•°å€¼çš„æ—¶å€™, éœ€è¦è€ƒè™‘IoUä»¥åŠåˆ¤æ–­å‡ºæ¥çš„ç½®ä¿¡åº¦, ä¸åŒçš„ç½®ä¿¡åº¦é˜ˆå€¼å¯¹åº”çš„æ•°å€¼æ˜¯ä¸åŒçš„ ### IoU ä¸¤ä¸ªæ¡†çš„äº¤é›†å’Œå¹¶é›†çš„æ¯”å€¼ ,å¯ä»¥ç®—ä¸¤ä¸ªæ¡†çš„å»åˆç¨‹åº¦"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/K230/2026-1-3-02-åŸºç¡€åŸç†.html":{"title":"åŸºç¡€åŸç†","content":"# åŸºç¡€åŸç† K230å¯ä»¥ä½¿ç”¨ä¸¤ä¸ªæ ¸, ä¸€ä¸ªé‡Œé¢è¿è¡ŒLinuxå—å¦ä¸€ä¸ªè¿è¡ŒRt Smartä¸åŒåœºæ™¯ä½¿ç”¨ä¸åŒçš„ç³»ç»Ÿ RT Thread Smart Pro æ˜¯é¢å‘å®æ—¶åº”ç”¨åœºåˆçš„é«˜æ€§èƒ½æ··åˆå¾®å†…æ ¸æ“ä½œç³»ç»Ÿä¸“ä¸šç‰ˆã€‚å®ƒèƒ½å¤Ÿå¡«è¡¥ä¼ ç»Ÿ RTOS å’Œå¤§å‹æ“ä½œç³»ç»Ÿ Linux ä¹‹é—´çš„ç©ºç™½ï¼Œä¸»è¦é’ˆå¯¹ MPU ç±»èŠ¯ç‰‡ï¼Œ å…·å¤‡å†…æ ¸ç²¾ç®€ã€å¿«é€Ÿå¯åŠ¨ã€å®æ—¶æŠ¢å è°ƒåº¦ã€ç³»ç»Ÿå’Œåº”ç”¨å®‰å…¨éš”ç¦»ä¿æŠ¤ï¼Œå®Œæ•´çš„ POSIX æ¥å£ã€æ–¹ä¾¿å¼€å‘å’Œè°ƒè¯•ç­‰ç‰¹æ€§ [RT Thread Smart äº§å“](http://www.rt thread.com/products/Smart 30.html)"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/K230/2026-1-10-03-Linuxä»£ç å¼€å‘.html":{"title":"Linuxä»£ç å¼€å‘","content":"# Linuxä»£ç å¼€å‘ ## äº¤å‰å·¥å…·é“¾ ```bash /opt/toolchain/Xuantie 900 gcc linux 6.6.0 glibc x86_64 V2.10.1/bin/riscv64 unknown linux gnu gcc ``` ### ç½‘ç»œè¿æ¥ ```bash ifconfig a # æ˜¾ç¤ºç³»ç»Ÿé‡Œæ‰€æœ‰ç½‘ç»œæ¥å£ï¼ˆåŒ…å«æœªå¯ç”¨çš„ï¼‰ ifconfig wlan0 up\t# æŠŠ WLANï¼ˆæ— çº¿ç½‘å¡ï¼‰å¼€å¯ wpa_supplicant D nl80211 i wlan0 c /etc/wpa_supplicant.conf B # å¯åŠ¨ wpa_supplicantï¼Œç”¨æ¥è¿æ¥ Wi Fi wpa_cli i wlan0 scan # æ‰«æçƒ­ç‚¹ï¼ˆå¯è·³è¿‡ï¼‰ wpa_cli i wlan0 scan_result # æ‰“å°æ‰«æç»“æœï¼ˆå¯è·³è¿‡ï¼‰ wpa_cli i wlan0 add_network # åˆ›å»ºä¸€ä¸ªæ–°çš„ WiFi é…ç½® wpa_cli i wlan0 set_network 1 ssid '\"jiao\"' # è®¾ç½® WiFi åç§° # wpa_cli i wlan0 set_network 1 ssid '\"TP LINK_5G_2B18\"' # è®¾ç½® WiFi åç§° # wpa_cli i wlan0 set_network 1 psk '\"13838106970\"' # è®¾ç½® WiFi å¯†ç  wpa_cli i wlan0 set_network 1 psk '\"11111111\"' # è®¾ç½® WiFi å¯†ç  wpa_cli i wlan0 select_network 1 # å¼€å§‹è¿æ¥ç½‘ç»œ ID ä¸º 1 çš„çƒ­ç‚¹ udhcpc i wlan0 q # é€šè¿‡ DHCP è·å– IP åœ°å€ ```"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/K230/2026-1-1-01-SDKç¼–è¯‘.html":{"title":"SDKç¼–è¯‘","content":"# SDKç¼–è¯‘ ä¸¤ä¸ªä»“åº“ + [kendryte/k230_linux_sdk: K230 Linux SDK](https://github.com/kendryte/k230_linux_sdk) + [kendryte/k230_rtos_sdk](https://github.com/kendryte/k230_rtos_sdk)æ˜¯åŸºäºK230èŠ¯ç‰‡å’ŒRT Smartå®æ—¶æ“ä½œç³»ç»Ÿçš„è½¯ä»¶å¼€å‘å¥—ä»¶ï¼Œæä¾›å®Œæ•´çš„å¼€å‘ç¯å¢ƒå’Œå·¥å…·é“¾ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿæ„å»ºåµŒå…¥å¼åº”ç”¨ã€‚CanMV_K230é¡¹ç›®æ˜¯æœ¬SDKçš„å…¸å‹åº”ç”¨æ¡ˆä¾‹ï¼Œé€šè¿‡MicroPythonæ¡†æ¶ç®€åŒ–äº†ç¡¬ä»¶è¯„ä¼°å’ŒåŸå‹å¼€å‘æµç¨‹ ç»´åº¦ K230 RTOS SDK K230 Linux SDK **ç³»ç»Ÿå†…æ ¸** å®æ—¶æ“ä½œç³»ç»Ÿï¼ˆFreeRTOS/RT Threadï¼‰ Linux å†…æ ¸ï¼ˆå¦‚åŸºäº OpenWrtã€Buildroot æ„å»ºï¼‰ **èµ„æºå ç”¨** æä½ï¼ˆå†…å­˜å ç”¨é€šå¸¸ < 10MBï¼‰ è¾ƒé«˜ï¼ˆå†…å­˜å ç”¨â‰¥64MBï¼‰ **å®æ—¶æ€§** å¼ºï¼ˆå¾®ç§’çº§å“åº”ï¼‰ å¼±ï¼ˆæ¯«ç§’çº§å“åº”ï¼Œéç¡¬å®æ—¶ï¼‰ **é€‚ç”¨åœºæ™¯** å·¥ä¸šæ§åˆ¶ã€å®æ—¶æ•°æ®é‡‡é›†ã€ä½åŠŸè€—ç»ˆç«¯ å¤æ‚åº”ç”¨ï¼ˆå¦‚ Qt ç•Œé¢ã€å¤šè¿›ç¨‹æœåŠ¡ã€ç½‘ç»œåº”ç”¨ï¼‰ **å¼€å‘å¤æ‚åº¦** è¾ƒä½ï¼ˆAPI ç®€æ´ï¼Œä¸“æ³¨ç¡¬ä»¶å’Œå®æ—¶ä»»åŠ¡ï¼‰ è¾ƒé«˜ï¼ˆéœ€æŒæ¡ Linux ç³»ç»Ÿã€é©±åŠ¨å¼€å‘ã€è¿›ç¨‹ç®¡ç†ï¼‰ ç›®å‰å®˜æ–¹æä¾›çš„æœ‰ä¸‰ç§, Linux, Linux+RTOS, RTOS ## åˆ›å»ºdocker ```bash docker build f tools/docker/Dockerfile t k230/linux_sdk tools/docker docker run it h k230 e uid $(id u) e gid $(id g) e user ${USER} v ${HOME}/k230:${HOME}/k230 w $(pwd) name k230 k230/linux_sdk:latest docker run it \\ h k230 \\ e uid $(id u) \\ e gid $(id g) \\ e user ${USER} \\ v ${HOME}/k230:${HOME}/k230 \\ w $(pwd) \\ name k230 \\ privileged \\ security opt seccomp unconfined \\ k230/linux_sdk:latest ``` ## linux+RTOS [kendryte/k230_sdk: Kendryte K230 SDK](https://github.com/kendryte/k230_sdk) ```bash git clone https://github.com/kendryte/k230_sdk cd k230_sdk make prepare_sourcecode docker run u root it v $(pwd):$(pwd) v $(pwd)/toolchain:/opt/toolchain w $(pwd) ghcr.io/kendryte/k230_sdk /bin/bash make CONF k230_evb_defconfig ``` è¾“å‡ºçš„æ–‡ä»¶åœ¨k230_evb_defconfig/imagesä½ç½® ```bash ``` ## RTOSç‰ˆæœ¬CamMV ```bash pip3 install pycryptodome gmssl scons 3.1.2 repo init u git@gitee.com:canmv k230/manifest.git b master repo url git@gitee.com:canmv k230/git repo.git repo branch stable repo sync make dl_toolchain # åˆ—å‡ºå¯ç”¨çš„é…ç½®é€‰é¡¹ make list_def # é€‰æ‹©å¯¹åº”çš„æ¿å­é…ç½®æ–‡ä»¶ make xxxx_defconfig # å¼€å§‹ç¼–è¯‘ time make log ``` ## Linuxç‰ˆæœ¬ [K230 linux SDKé•œåƒç¼–è¯‘æŒ‡å— â€” K230 Linux SDK](https://www.kendryte.com/k230_linux/zh/dev/userguide/how_to_build.html) ```bash git clone git@gitee.com:kendryte/k230_linux_sdk.git # å·¥å…·é“¾é…ç½® # https://kendryte download.canaan creative.com/k230/downloads/dl/gcc/Xuantie 900 gcc linux 6.6.0 glibc x86_64 V3.0.2 20250410.tar.gz mkdir p /opt/toolchain tar zxvf Xuantie 900 gcc linux 6.6.0 glibc x86_64 V3.0.2.tar.gz C /opt/toolchain make CONF k230d_canmv_defconfig ``` è¾“å‡ºçš„æ–‡ä»¶ä¸º`output/k230d_canmv_defconfig/images/sysimage sdcard.img.gz` ### ç¼–è¯‘çš„åŸç† 1ã€ä»buildrootå®˜ç½‘ä¸‹è½½buildroot 2025.02.1.gzå‹ç¼©åŒ…ï¼Œå¹¶è§£å‹ç¼©ä¸ºoutput/buildroot 2025.02.1/ 2ã€ç”¨buildroot overlayç›®å½•è¦†ç›–output/buildroot 2025.02.1/ç›®å½• ``` rsync a buildroot overlay/ output/buildroot 2025.02.1/ ``` 3ã€è¿›å…¥output/buildroot 2025.02.1/ç›®å½•ï¼Œä½¿ç”¨k230d_canmv_defconfigé…ç½®buildrootï¼Œå¹¶æŒ‡å®šè¾“å‡ºç›®å½•ä¸ºoutput/k230d_canmv_defconfig ``` make C output/buildroot 2025.02.1 k230d_canmv_defconfig O /home/wangjianxin/k230_linux_sdk/output/k230d_canmv_defconfig ``` 4ã€ è¿›å…¥output/k230d_canmv_defconfig ç›®å½•å¹¶è¿›è¡Œç¼–è¯‘ ``` make C /home/wangjianxin/k230_linux_sdk/output/k230d_canmv_defconfig all ``` ## Micropython [è¿›é˜¶ è‡ªå®šä¹‰å›ºä»¶ â€” CanMV K230](https://www.kendryte.com/k230_canmv/zh/main/zh/userguide/how_to_build.html)"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-17-09-APP.html":{"title":"APP","content":"# APP æ‰€æœ‰çš„åº”ç”¨æ•°æ®è®°å½•åœ¨`/maixapp`ç›®å½•é‡Œé¢, è¿™ä¸ªæ–‡ä»¶å¤¹é‡Œé¢ä½¿ç”¨`/maixapp/apps/app.info`æè¿°å·²ç»å®‰è£…çš„æ–‡ä»¶ å‘è€…æˆ–ç”¨æˆ·ä¹Ÿå¯ä»¥æ‰‹åŠ¨å¤åˆ¶åº”ç”¨ç›®å½•åˆ°æ­¤ï¼Œå¹¶æ‰§è¡Œ `python gen_app_info.py` ç”Ÿæˆ `app.info` æ–‡ä»¶ã€‚ åº”ç”¨å­˜æ”¾åœ¨ `/maixapp/apps/app_id` æ–‡ä»¶å¤¹ä¸­ï¼Œæ¯ä¸ªåº”ç”¨å¿…é¡»åŒ…å« `app_id` å¯æ‰§è¡Œæ–‡ä»¶ï¼Œæˆ– `main.sh` è„šæœ¬ï¼Œæˆ– `main.py` è„šæœ¬ å¯åŠ¨åº”ç”¨æ—¶ï¼Œlauncher ä¼šåœ¨ `app_id` æ–‡ä»¶å¤¹ä¸­å¯»æ‰¾ï¼š`main.sh` > `main.py` > `app_id` æ–‡ä»¶ã€‚`main.sh` ä½¿ç”¨ `sh` æ‰§è¡Œï¼Œ`main.py` ä½¿ç”¨ `python3` æ‰§è¡Œï¼Œ`app_id` ç›´æ¥æ‰§è¡Œ + å…±äº«æ•°æ®å­˜å‚¨åœ¨ `/maixapp/share`ã€‚ + å›¾ç‰‡æ–‡ä»¶å­˜å‚¨åœ¨ `/maixapp/share/picture`ã€‚ + è§†é¢‘æ–‡ä»¶å­˜å‚¨åœ¨ `/maixapp/share/video`ã€‚ + ä¸´æ—¶æ•°æ®å¯ä»¥å­˜å‚¨åœ¨ `/maixapp/tmp`ï¼Œæ³¨æ„ï¼Œå’Œ Linux æœ¬èº«çš„`/tmp` ç›®å½•ä¸åŒçš„æ˜¯è¿™ä¸ªç›®å½•æ˜¯åœ¨æ–‡ä»¶ç³»ç»Ÿï¼ˆSDå¡ï¼‰ä¸Šçš„ï¼Œç³»ç»Ÿ`/tmp`æ˜¯åœ¨å†…å­˜ä¸Šè™šæ‹Ÿçš„æ–‡ä»¶ç³»ç»Ÿï¼Œ`/tmp`è¯»å†™é€Ÿåº¦æ›´å¿«ä½†æ˜¯å†…å­˜å¤§å°å—é™ï¼Œå¤§æ–‡ä»¶ä»¥åŠéœ€è¦é•¿æœŸè®°å½•çš„æ—¥å¿—æ–‡ä»¶ï¼ˆéšç€æ—¶é—´æ¨ç§»å¯èƒ½å˜å¾—æ¯”è¾ƒå¤§ï¼‰å»ºè®®æ”¾åœ¨`/maixapp/tmp`ç›®å½•ä¸‹ + å­—ä½“æ–‡ä»¶å­˜å‚¨åœ¨ `/maixapp/share/font`ã€‚ + å›¾æ ‡æ–‡ä»¶å­˜å‚¨åœ¨ `/maixapp/share/icon`ã€‚ + åº”ç”¨è¿è¡Œæ—¶åˆ›å»ºçš„æ•°æ®æ–‡ä»¶å¯ä»¥å­˜å‚¨åœ¨ `/maixapp/apps/app_id/data` ## åˆ‡æ¢åº”ç”¨ ä½¿ç”¨ `void maix::app::switch_app(const string &app_id, int idx 1, const std::string &start_param \"\")` å‡½æ•°æ¥åˆ‡æ¢åº”ç”¨ã€‚ è¿™å°†é€€å‡ºå½“å‰åº”ç”¨å¹¶å¯åŠ¨å¦ä¸€ä¸ªåº”ç”¨ï¼Œå¹¶å°† `start_param` å­—ç¬¦ä¸²ä¼ é€’ç»™ç›®æ ‡åº”ç”¨ï¼Œç›®æ ‡åº”ç”¨å¯ä»¥é€šè¿‡ `maix::app::get_start_param()` è·å–æ­¤å‚æ•°ã€‚ > ä¹Ÿå¯ä»¥ä½¿ç”¨`app::set_exit_flag(true) `é€€å‡º å®é™…ä½¿ç”¨è¿™ä¸ªå‡½æ•°çš„æ—¶å€™éœ€è¦æ˜¯ä½¿ç”¨APPç®¡ç†æ¡†æ¶å¯åŠ¨çš„, è®¾å¤‡å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨å¯åŠ¨ `launcher`, å¦åˆ™å®é™…æ˜¯è¿›è¡ŒAppçš„é€€å‡ºåŠŸèƒ½ ### æ‰“åŒ…App åœ¨é¡¹ç›®æ–‡ä»¶å¤¹ä¸­åˆ›å»ºä¸€ä¸ª `app.yaml`ï¼Œæ ¼å¼è§ä¸‹æ–‡ã€‚ æ‰§è¡Œ `maixcdk release P maixcam` æ¥ä¸º `maixcam` å¹³å°æ‰“åŒ… APPã€‚ åœ¨ `dist` æ–‡ä»¶å¤¹ä¸­ä¼šæ‰¾åˆ°ä¸€ä¸ª `app_store_v1.0.0.zip`ï¼Œè¿™æ˜¯æ‰“åŒ…å¥½çš„ APP æ–‡ä»¶ã€‚ ä½ å¯ä»¥å°†è¿™ä¸ªåŒ…ä¸Šä¼ åˆ° [maixhub.com/app](https://maixhub.com/app) ä¸ä»–äººåˆ†äº«ã€‚ æˆ–è€…æ‰§è¡Œ `maixcdk deploy P maixcam` æ¥å¯åŠ¨æœ¬åœ°æœåŠ¡å™¨ï¼Œå¹¶æ˜¾ç¤ºä¸€ä¸ªäºŒç»´ç ã€‚ ä½ ä¹Ÿå¯ä»¥å°†è¿™ä¸ªæ–‡ä»¶ä¸Šä¼ åˆ°è®¾å¤‡ï¼Œå¹¶æ‰§è¡Œ `app_store install app_path.zip` æ¥é€šè¿‡å‘½ä»¤å®‰è£…ã€‚ ```yaml id: my_app # å”¯ä¸€ IDï¼Œä½¿ç”¨å°å†™å­—æ¯å¹¶ç”¨ä¸‹åˆ’çº¿åˆ†éš”å•è¯ name: My APP name[zh]: æˆ‘çš„åº”ç”¨ # ä¸­æ–‡åç§° version: 1.0.0 # ç‰ˆæœ¬å·ï¼Œæ ¼å¼ä¸º major.minor.patch icon: assets/my_app.png # å›¾æ ‡æ–‡ä»¶ï¼Œå¯ä»¥æ˜¯ png æˆ– lottie json æ–‡ä»¶ï¼Œæˆ–ä¸ºç©º author: Sipeed Ltd desc: My APP description desc[zh]: æˆ‘çš„åº”ç”¨æè¿° #### åŒ…å«æ–‡ä»¶æ–¹æ³• 1ï¼š # é»˜è®¤æƒ…å†µä¸‹ï¼Œä¼šåŒ…å«é¡¹ç›®ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼Œé™¤äº†æ’é™¤æ–‡ä»¶ exclude: # ä¸æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼ï¼Œ.git å’Œ __pycache__ æ€»æ˜¯ä¼šè¢«æ’é™¤ .vscode compile build dist # extra_include: # src: dst # build/filename123: filename123 #### åŒ…å«æ–‡ä»¶æ–¹æ³• 2ï¼š # ç™½åå•æ¨¡å¼ï¼ŒåªåŒ…å« files å­—å…¸ä¸­çš„æ–‡ä»¶ã€‚ # å¦‚æœæ²¡æœ‰æ­¤é”®æˆ–å€¼ä¸ºç©ºï¼Œå°†ä½¿ç”¨æ–¹æ³• 1ã€‚ # files: # assets # hello.py # main.py #### åŒ…å«æ–‡ä»¶æ–¹æ³• 2.1ï¼š # ç™½åå•æ¨¡å¼ï¼ŒåªåŒ…å« files å­—å…¸ä¸­çš„æ–‡ä»¶ã€‚ # å¦‚æœæ²¡æœ‰æ­¤é”®æˆ–å€¼ä¸ºç©ºï¼Œå°†ä½¿ç”¨æ–¹æ³• 1ã€‚ # files: # assets: assets ``` ## æ•°æ®ç±»å‹ ### Version è®°å½•å½“å‰çš„APPçš„ç‰ˆæœ¬ ### App_Info è®°å½•APPçš„åŸºç¡€ä¿¡æ¯æ¯”å¦‚APPçš„åå­—, ç‰ˆæœ¬å·ç­‰æ¶ˆæ¯, å¯ä»¥ä½¿ç”¨`get_app_info(const std::string &app_id)`è·å–åˆ°APPçš„ä¿¡æ¯ é»˜è®¤çš„çš„æ—¶å€™ä½¿ç”¨`static std::string _app_id PROJECT_ID;`è®°å½•å½“å‰çš„APPçš„ID, ä¸€èˆ¬æ˜¯ä»æ–‡ä»¶`app.yaml`é‡Œé¢è·å–çš„idå±æ€§, æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-18-06-æ¨¡å‹ç›¸å…³å‚æ•°.html":{"title":"æ¨¡å‹ç›¸å…³å‚æ•°","content":"# æ¨¡å‹ç›¸å…³å‚æ•° ## dual_buff æ¨¡å‹è¿è¡Œç›¸å…³çš„çš„ä»£ç åˆå§‹åŒ–æ—¶æœ‰ä¸€ä¸ªå‚æ•°`dual_buff True`, ä½¿èƒ½è¿™ä¸ªåŠŸèƒ½åè¿è¡Œçš„æ•ˆç‡ä¼šæå‡ï¼Œå³å¸§ç‡ä¼šæå‡ï¼ˆä»¥ä¸Šä»£ç å‡è®¾æ‘„åƒå¤´çš„å¸§ç‡æ²¡æœ‰é™åˆ¶çš„æƒ…å†µä¸‹ï¼Œåœ¨ MaixCAM ä¸Šä¼šå‡å°‘å¾ªç¯ä¸€åŠçš„æ—¶é—´å³å¸§ç‡ç¿»å€ï¼‰ ä½†æ˜¯ä¹Ÿæœ‰ç¼ºç‚¹ï¼Œ`detect`å‡½æ•°è¿”å›çš„ç»“æœæ˜¯ä¸Šä¸€æ¬¡è°ƒç”¨`detect`å‡½æ•°çš„å›¾çš„ç»“æœï¼Œæ‰€ä»¥ç»“æœå’Œè¾“å…¥ä¼šæœ‰ä¸€å¸§çš„æ—¶é—´å·®, å¦å¤–ç”±äºå‡†å¤‡äº†åŒä»½ç¼“å†²åŒºï¼Œä¹Ÿä¼šåŠ å¤§å†…å­˜çš„ä½¿ç”¨ ### åŸç† æ¨¡å‹æ£€æµ‹ç‰©ä½“åˆ†ä¸ºäº†å‡ æ­¥ï¼š è·å–å›¾åƒ å›¾åƒé¢„å¤„ç† æ¨¡å‹è¿è¡Œ ç»“æœåå¤„ç† å…¶ä¸­åªæœ‰æ¨¡å‹è¿è¡Œè¿™ä¸€æ­¥æ˜¯ç¡¬ä»¶NPU ä¸Šè¿è¡Œçš„ï¼Œå…¶å®ƒæ­¥éª¤éƒ½åœ¨ CPU è¿è¡Œ å¦‚æœ`dual_buff`è®¾ç½®ä¸º`False`ï¼Œåœ¨`detect`çš„æ—¶å€™ï¼ŒCPU å…ˆé¢„å¤„ç†ï¼ˆæ­¤æ—¶ NPU ç©ºé—²ï¼‰ï¼Œ ç„¶åç»™ NPU è¿ç®—ï¼ˆæ­¤æ—¶ CPU ç©ºé—²ç­‰å¾… NPU è¿ç®—ç»“æŸï¼‰ï¼Œç„¶å CPU åå¤„ç†ï¼ˆNPU ç©ºé—²ï¼‰ï¼Œ æ•´è¿‡è¿‡ç¨‹æ˜¯çº¿æ€§çš„ï¼Œæ¯”è¾ƒç®€å•ã€‚ ä½†æ˜¯è¿™é‡Œå‘ç°äº†é—®é¢˜ï¼Œå°±æ˜¯ CPU å’Œ NPU ä¸¤è€…æ€»æœ‰ä¸€ä¸ªç©ºé—²ç€çš„ï¼Œå½“åŠ äº†`dual_buff True`ï¼Œ CPU é¢„å¤„ç†åäº¤ç»™ NPU è¿ç®—ï¼Œæ­¤æ—¶ CPU ä¸å†ç­‰å¾… NPU å‡ºç»“æœï¼ŒäºŒæ˜¯ç›´æ¥é€€å‡º`detect`å‡½æ•°è¿›è¡Œä¸‹ä¸€æ¬¡æ‘„åƒå¤´è¯»å–å’Œé¢„å¤„ç†ï¼Œç­‰ NPU è¿ç®—å®Œæˆåï¼Œ CPU å·²ç»å‡†å¤‡å¥½äº†ä¸‹ä¸€æ¬¡çš„æ•°æ®ç›´æ¥äº¤ç»™ NPU ç»§ç»­è¿ç®—ï¼Œä¸ç»™ NPU å–˜æ¯çš„æœºä¼šï¼Œè¿™æ ·å°±å……åˆ†åˆ©ç”¨äº† CPU å’Œ NPU é«˜æ•ˆåœ°åŒæ—¶è¿›è¡Œè¿ç®— ## æ¨¡å‹è½¬æ¢ [tpu mlir/README_cn.md at master Â· sophgo/tpu mlir](https://github.com/sophgo/tpu mlir/blob/master/README_cn.md) å®é™…è¿è¡Œçš„æ¨¡å‹æ–‡ä»¶éœ€è¦æ˜¯ä½¿ç”¨ç®—èƒ½çš„TPUæ¡†æ¶, æ‰€ä»¥éœ€è¦ä¸€ä¸ªä¸“é—¨çš„æ ¼å¼bmodel, ç®—èƒ½æä¾›ä¸“é—¨çš„è½¬æ¢å·¥å…· ### å¤§æ¨¡å‹ æŒ‰ç…§æ–‡æ¡£æŒ‰ç…§å¯¹åº”çš„dockerç¯å¢ƒ, ä½¿ç”¨ä»¥ä¸‹çš„å‘½ä»¤è¿›è¡Œè½¬æ¢ ```bash llm_convert.py m /workspace/Qwen2.5 VL 3B Instruct AWQ s 2048 q w4bf16 c bm1684x max_pixels 672,896 o qwen2.5vl_3b ``` **å‚æ•°å** **ç®€å†™** å¿…é€‰ï¼Ÿ **è¯´æ˜** model_path m æ˜¯ æŒ‡å®šæƒé‡è·¯å¾„, ä¸‹è½½çš„æºæ–‡ä»¶ seq_length s æ˜¯ æŒ‡å®šæ¨¡å‹æ¨ç†æ—¶æ”¯æŒçš„**æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆä¸Šä¸‹æ–‡é•¿åº¦ï¼‰** ä¸º 2048, åºåˆ—é•¿åº¦å†³å®šæ¨¡å‹èƒ½å¤„ç†çš„æ–‡æœ¬ Token æ€»æ•°ä¸Šé™ï¼ˆè¾“å…¥ prompt + ç”Ÿæˆçš„å›å¤ Token æ•°ä¹‹å’Œä¸èƒ½è¶…è¿‡ 2048ï¼‰ quantize q æ˜¯ æŒ‡å®šé‡åŒ–ç±»å‹, w4bf16/w4f16/bf16/f16ç­‰ç­‰, `w4`ï¼šæ¨¡å‹æƒé‡ï¼ˆweightï¼‰é‡‡ç”¨ 4bit é‡åŒ–, `bf16`ï¼šæ¨¡å‹æ¿€æ´»å€¼ï¼ˆactivationï¼‰é‡‡ç”¨ bfloat16ï¼ˆè„‘æµ®ç‚¹æ•°ï¼‰ç²¾åº¦ q_group_size g å¦ æŒ‡å®šæ¯ç»„é‡åŒ–çš„ç»„å¤§å°, é»˜è®¤64 chip c æ˜¯ æŒ‡å®šå¹³å°, å¦‚bm1684x/bm1688/cv186ah max_pixels å¦ å¤šæ¨¡æ€å‚æ•°, æŒ‡å®šæœ€å¤§å°ºå¯¸, å¯ä»¥æ˜¯`672,896`,ä¹Ÿå¯ä»¥æ˜¯`602112`, 672,896 è¡¨ç¤ºå›¾åƒé«˜ 672 åƒç´ ã€å®½ 896 åƒç´ ï¼ˆä¹Ÿå¯ç›´æ¥å†™æ€»åƒç´ æ•° 602112ï¼Œå³ 672Ã—896ï¼‰ï¼Œé™åˆ¶å›¾åƒåˆ†è¾¨ç‡ä¸Šé™ï¼Œé€‚é…æ¨¡å‹çš„è§†è§‰å¤„ç†èƒ½åŠ› out_dir o æ˜¯ æŒ‡å®šè¾“å‡ºç›®å½• #### æ¨¡å‹æƒé‡ é¦–å…ˆè¦æ˜ç¡®ï¼š**å¤§æ¨¡å‹æœ¬è´¨æ˜¯è¶…å¤§è§„æ¨¡çš„ç¥ç»ç½‘ç»œ**ï¼Œè¿™ä¸¤ä¸ªæ¦‚å¿µæ˜¯ç¥ç»ç½‘ç»œè¿è¡Œçš„æ ¸å¿ƒ â€”â€” æƒé‡æ˜¯ â€œé™æ€çš„çŸ¥è¯†å‚æ•°â€ï¼Œæ¿€æ´»å€¼æ˜¯ â€œåŠ¨æ€çš„è®¡ç®—ä¸­é—´ç»“æœâ€ æƒé‡æ˜¯ç¥ç»ç½‘ç»œä¸­**ç¥ç»å…ƒä¹‹é—´è¿æ¥çš„ â€œå¼ºåº¦ç³»æ•°â€**ï¼Œæ˜¯æ¨¡å‹ä»æµ·é‡æ•°æ®ä¸­ â€œå­¦â€ åˆ°çš„æ ¸å¿ƒå‚æ•°ï¼š è®­ç»ƒé˜¶æ®µï¼šæ¨¡å‹é€šè¿‡åå‘ä¼ æ’­ä¸æ–­è°ƒæ•´æƒé‡ï¼Œè®©æƒé‡é€‚é…ä»»åŠ¡ï¼ˆæ¯”å¦‚ç†è§£è¯­ä¹‰ã€è¯†åˆ«å›¾åƒç‰¹å¾ï¼‰ï¼› æ¨ç†é˜¶æ®µï¼šæƒé‡ä¸€æ—¦è®­ç»ƒå®Œæˆå°±å›ºå®šä¸å˜ï¼ˆé™æ€ï¼‰ï¼Œæ˜¯æ¨¡å‹ â€œè®°ä½â€ çš„æ‰€æœ‰çŸ¥è¯†çš„è½½ä½“ã€‚ è¿™äº›æƒé‡æ˜¯æ¨¡å‹ä½“ç§¯çš„ä¸»è¦æ„æˆ â€”â€” æ¯”å¦‚ â€œ3B æ¨¡å‹â€ æŒ‡æƒé‡å‚æ•°æ€»é‡çº¦ 30 äº¿ä¸ªï¼Œæƒé‡æ–‡ä»¶é€šå¸¸å  GB çº§å­˜å‚¨ç©ºé—´ï¼ˆæœªé‡åŒ–çš„ Qwen2.5 VL 3B æƒé‡çº¦ 6GBï¼Œbf16 ç²¾åº¦ä¸‹æ¯ä¸ªå‚æ•°å  2 å­—èŠ‚ï¼‰ æƒé‡æ˜¯**é™æ€æ•°æ®**ï¼Œå¯¹é‡åŒ–çš„å®¹å¿åº¦ç›¸å¯¹é«˜ï¼ˆä½æ¯”ç‰¹é‡åŒ–åç²¾åº¦æŸå¤±å¯æ§ï¼‰ï¼Œå› æ­¤æ˜¯æ¨¡å‹å‹ç¼©çš„æ ¸å¿ƒç›®æ ‡ï¼š ä¹‹å‰å‘½ä»¤ä¸­çš„`w4`å³ â€œæƒé‡ 4bit é‡åŒ–â€ï¼šæŠŠåŸæœ¬ç”¨ 16bit/32bit å­˜å‚¨çš„æƒé‡ï¼Œå‹ç¼©åˆ° 4bit å­˜å‚¨ï¼Œèƒ½å¤§å¹…é™ä½æ˜¾å­˜å ç”¨ã€æå‡æ¨ç†é€Ÿåº¦ï¼ˆæ¯”å¦‚ 4bit é‡åŒ–åæƒé‡ä½“ç§¯ä»…ä¸º 16bit çš„ 1/4ï¼‰ã€‚ #### æ¿€æ´»å€¼ æ¿€æ´»å€¼æ˜¯ç¥ç»ç½‘ç»œä¸­**ç¥ç»å…ƒæ¥æ”¶åˆ°è¾“å…¥åï¼Œç»è¿‡è®¡ç®—è¾“å‡ºçš„åŠ¨æ€å€¼**ï¼š æ¨ç†é˜¶æ®µï¼šè¾“å…¥ä¸åŒçš„æ–‡æœ¬ / å›¾åƒï¼ˆæ¯”å¦‚é—® â€œä»Šå¤©å¤©æ°”å¦‚ä½•â€ vs â€œè¿™å¼ å›¾é‡Œæœ‰ä»€ä¹ˆâ€ï¼‰ï¼Œæ¿€æ´»å€¼ä¼šå®Œå…¨ä¸åŒï¼› è®¡ç®—é€»è¾‘ï¼šæŸä¸€å±‚çš„æ¿€æ´»å€¼ ä¸Šä¸€å±‚æ¿€æ´»å€¼ Ã— æœ¬å±‚æƒé‡ + åç½®ï¼ˆBiasï¼‰ â†’ ç»è¿‡æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ ReLUã€SwiGLUï¼‰åçš„è¾“å‡ºã€‚ æ•´ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ¿€æ´»å€¼æ˜¯ â€œæµåŠ¨çš„ä¿¡å·â€ï¼Œæ¯ä¸€æ­¥è®¡ç®—éƒ½ä¼šäº§ç”Ÿæ–°çš„æ¿€æ´»å€¼ï¼Œä¸”ä»…åœ¨æ¨ç†æ—¶ä¸´æ—¶ç”Ÿæˆï¼ˆç”¨å®Œå³é‡Šæ”¾ï¼Œä¸é•¿æœŸå­˜å‚¨ï¼‰ æ¿€æ´»å€¼æ˜¯**åŠ¨æ€è®¡ç®—æ•°æ®**ï¼Œå¯¹ç²¾åº¦æå…¶æ•æ„Ÿï¼šå¦‚æœç”¨è¿‡ä½æ¯”ç‰¹ï¼ˆæ¯”å¦‚ 4bitï¼‰é‡åŒ–æ¿€æ´»å€¼ï¼Œä¼šå¯¼è‡´è®¡ç®—è¯¯å·®å¿«é€Ÿç´¯ç§¯ï¼Œæ¨¡å‹è¾“å‡ºå®Œå…¨å¤±çœŸï¼ˆæ¯”å¦‚ç­”éæ‰€é—®ã€å›¾åƒè¯†åˆ«é”™è¯¯ï¼‰ ç»´åº¦ æ¨¡å‹æƒé‡ï¼ˆWeightï¼‰ æ¨¡å‹æ¿€æ´»å€¼ï¼ˆActivationï¼‰ æ€§è´¨ é™æ€ï¼ˆè®­ç»ƒåå›ºå®šï¼Œæ¨ç†æ—¶ä¸å˜ï¼‰ åŠ¨æ€ï¼ˆæ¨ç†æ—¶éšè¾“å…¥å˜åŒ–ï¼Œä¸´æ—¶ç”Ÿæˆï¼‰ å­˜å‚¨æ–¹å¼ é•¿æœŸå­˜å‚¨åœ¨ç¡¬ç›˜ / æ˜¾å­˜ï¼ˆæ¨¡å‹æ–‡ä»¶çš„æ ¸å¿ƒï¼‰ ä»…æ¨ç†æ—¶ä¸´æ—¶å­˜åœ¨æ˜¾å­˜ï¼ˆç”¨å®Œé‡Šæ”¾ï¼‰ æ•°é‡è§„æ¨¡ å›ºå®šï¼ˆå¦‚ 3B æ¨¡å‹çº¦ 30 äº¿ä¸ªï¼‰ éšè¾“å…¥é•¿åº¦ / å›¾åƒå°ºå¯¸å˜åŒ–ï¼ˆæ¯”å¦‚åºåˆ— 2048 æ—¶ï¼Œæ¿€æ´»å€¼è§„æ¨¡è¿œå¤§äºæƒé‡ï¼‰ é‡åŒ–å®¹å¿åº¦ é«˜ï¼ˆ4bit é‡åŒ–ä»èƒ½ä¿æŒæ ¸å¿ƒç²¾åº¦ï¼‰ ä½ï¼ˆéœ€ 16bit ä»¥ä¸Šç²¾åº¦ï¼Œå¦åˆ™è¯¯å·®ç´¯ç§¯ï¼‰ æ ¸å¿ƒä½œç”¨ å†³å®šæ¨¡å‹ â€œçŸ¥é“ä»€ä¹ˆâ€ï¼ˆæ ¸å¿ƒçŸ¥è¯†ï¼‰ å†³å®šæ¨¡å‹ â€œå¦‚ä½•å¤„ç†å½“å‰è¾“å…¥â€ï¼ˆå®æ—¶è®¡ç®—ï¼‰ #### æ¯ç»„é‡åŒ–çš„ç»„å¤§å° ç»„å¤§å°ï¼ˆä¹Ÿå«é‡åŒ–åˆ†ç»„å°ºå¯¸ï¼Œå¯¹åº”å‚æ•°` g`ï¼‰æ˜¯**ä½æ¯”ç‰¹é‡åŒ–æ¨¡å‹æƒé‡æ—¶çš„æ ¸å¿ƒç²’åº¦å‚æ•°**ï¼šåœ¨å¯¹æƒé‡åš 4bit/8bit ç­‰ä½æ¯”ç‰¹é‡åŒ–æ—¶ï¼Œä¸ä¼šæŠŠæ•´ä¸ªæƒé‡çŸ©é˜µå½“æˆä¸€ä¸ªæ•´ä½“å¤„ç†ï¼Œè€Œæ˜¯å°†è¿ç»­çš„æƒé‡å€¼åˆ’åˆ†æˆè‹¥å¹²ä¸ª â€œå°ç»„â€ï¼ˆæ¯ç»„åŒ…å«`q_group_size`ä¸ªæƒé‡å€¼ï¼‰ï¼Œ**ä»¥ â€œç»„â€ ä¸ºå•ä½è®¡ç®—é‡åŒ–æ‰€éœ€çš„ç¼©æ”¾å› å­ï¼ˆscaleï¼‰ã€é›¶ç‚¹ï¼ˆzero pointï¼‰**ï¼Œå†åŸºäºè¿™äº›å‚æ•°å¯¹ç»„å†…çš„æ¯ä¸ªæƒé‡å€¼åšä½æ¯”ç‰¹ç¼–ç  æŠŠæƒé‡é‡åŒ–æ¯”ä½œ â€œç»™å•†å“å®šä»·æ‰“åŒ…â€ï¼š æƒé‡å€¼ ä¸åŒä»·æ ¼çš„å•†å“ï¼ˆæ¯”å¦‚ 10 å…ƒã€25 å…ƒã€18 å…ƒã€30 å…ƒâ€¦ï¼‰ï¼› ä½æ¯”ç‰¹é‡åŒ– ç”¨ â€œåŒºé—´æ ‡ç­¾â€ ä»£æ›¿å…·ä½“ä»·æ ¼ï¼ˆæ¯”å¦‚ç”¨ 1bit è¡¨ç¤º â€œâ‰¤20 å…ƒâ€/â€œï¼20 å…ƒâ€ï¼Œç”¨ 4bit è¡¨ç¤º 16 ä¸ªä»·æ ¼åŒºé—´ï¼‰ï¼› ç»„å¤§å° æ¯æ¬¡æ‰“åŒ…çš„å•†å“æ•°é‡ï¼ˆæ¯”å¦‚æ¯ç»„ 64 ä»¶ï¼‰ï¼š å¦‚æœä¸åˆ†ç»„ï¼ˆæ•´çŸ©é˜µç®—ï¼‰ï¼Œå•†å“ä»·æ ¼è·¨åº¦å¤ªå¤§ï¼ˆ10 å…ƒï½1000 å…ƒï¼‰ï¼Œç”¨ 4bit æ ‡ç­¾ä¼šå®Œå…¨å¤±çœŸï¼› æ¨ç†æ—¶ï¼Œç”¨æ¯ç»„çš„ scale å’Œ zero pointï¼ŒæŠŠ 4bit ç¼–ç å€¼è¿˜åŸæˆæ¥è¿‘åŸå§‹ 32bit çš„æ•°å€¼ï¼ˆä¿è¯è®¡ç®—ç²¾åº¦ï¼‰ã€‚ ç»„å¤§å°å–å€¼ é‡åŒ–ç²¾åº¦ æ¨ç†é€Ÿåº¦ / æ˜¾å­˜å ç”¨ é€‚ç”¨åœºæ™¯ å°ï¼ˆå¦‚ 32ï¼‰ æ›´é«˜ ç¨æ…¢ / ç¨é«˜ å¯¹ç²¾åº¦æ•æ„Ÿçš„åœºæ™¯ï¼ˆæ¯”å¦‚å°æ¨¡å‹ã€æ ¸å¿ƒä»»åŠ¡ï¼‰ ä¸­ï¼ˆ64ï¼Œé»˜è®¤ï¼‰ å¹³è¡¡ï¼ˆç²¾åº¦æŸå¤±å¯æ§ï¼‰ æœ€ä¼˜ï¼ˆé€Ÿåº¦ / æ˜¾å­˜å¹³è¡¡ï¼‰ ç»å¤§å¤šæ•°é€šç”¨åœºæ™¯ï¼ˆå¦‚ä½ ç”¨çš„ Qwen2.5 VL 3Bï¼‰ å¤§ï¼ˆå¦‚ 128/256ï¼‰ ç¨ä½ æ›´å¿« / æ›´ä½ å¯¹é€Ÿåº¦è¦æ±‚é«˜ã€ç²¾åº¦è¦æ±‚ä½çš„åœºæ™¯ï¼ˆæ¯”å¦‚è¾¹ç¼˜ç«¯æ¨ç†ï¼‰ ## Yoloæ¨¡å‹ å¦‚æœæ¨¡å‹æ˜¯å›¾ç‰‡è¾“å…¥ï¼Œåœ¨è½¬æ¨¡å‹ä¹‹å‰æˆ‘ä»¬éœ€è¦äº†è§£æ¨¡å‹çš„é¢„å¤„ç†ã€‚å¦‚æœæ¨¡å‹ç”¨é¢„å¤„ç†åçš„npzæ–‡ä»¶åšè¾“å…¥ï¼Œåˆ™ä¸éœ€è¦è€ƒè™‘é¢„å¤„ç†ã€‚ é¢„å¤„ç†è¿‡ç¨‹ç”¨å…¬å¼è¡¨è¾¾å¦‚ä¸‹ï¼ˆxä»£è¡¨è¾“å…¥) `y ï¼ˆx meanï¼‰ \\times scale` å®˜ç½‘yolov5çš„å›¾ç‰‡æ˜¯rgbï¼Œæ¯ä¸ªå€¼ä¼šä¹˜ä»¥`1/255`ï¼Œè½¬æ¢æˆmeanå’Œscaleå¯¹åº”ä¸º`0.0,0.0,0.0`å’Œ`0.0039216,0.0039216,0.0039216` > å› ä¸º YOLOv5 æ²¡æœ‰åš â€œå‡å‡å€¼â€ çš„ä¸­å¿ƒåŒ–æ“ä½œï¼ˆæ¯”å¦‚ ImageNet é¢„è®­ç»ƒæ¨¡å‹ä¼šå‡ (0.485,0.456,0.406)ï¼Œä½† YOLOv5 è¿½æ±‚ç®€æ´ï¼Œæ— éœ€è¿™ä¸€æ­¥ï¼‰ã€‚ä¸‰ä¸ªé€šé“å‡ä¸º`1/255 â‰ˆ 0.0039215686`ï¼Œå››èˆäº”å…¥åå°±æ˜¯`0.0039216` #### æ¨¡å‹è½¬F16 è¿™ä¸ªå‘½ä»¤æ˜¯**YOLOv5s æ¨¡å‹éƒ¨ç½²æµç¨‹çš„ â€œå‰ç½®è½¬æ¢æ­¥éª¤â€** â€”â€” æ ¸å¿ƒæ˜¯æŠŠã€ŒONNX æ ¼å¼çš„ YOLOv5s æ¨¡å‹ã€è½¬æ¢æˆã€Œè·¨æ¡†æ¶ / è·¨ç¡¬ä»¶çš„ MLIR é€šç”¨ä¸­é—´è¡¨ç¤ºæ ¼å¼ã€ï¼ŒåŒæ—¶å®Œæˆæ¨¡å‹è¾“å…¥çš„æ ‡å‡†åŒ–é¢„å¤„ç†ã€æŒ‡å®šè¾“å‡ºèŠ‚ç‚¹ã€ç”Ÿæˆæµ®ç‚¹æ¨¡å‹çš„åŸºå‡†è¾“å‡ºï¼ˆç”¨äºåç»­é‡åŒ–ç²¾åº¦éªŒè¯ï¼‰ï¼Œä¸ºåç»­çš„æ ¡å‡†ã€é‡åŒ–ç”Ÿæˆ bmodel æ‰“ä¸‹åŸºç¡€ > ONNX æ˜¯ â€œæ¡†æ¶çº§â€ ä¸­é—´æ ¼å¼ï¼ˆæ¯”å¦‚ PyTorchâ†’ONNXï¼‰ï¼Œä½†ä¸åŒç¡¬ä»¶å‚å•†ï¼ˆå¦‚æ¯”ç‰¹å¤§é™†ã€è‹±ä¼Ÿè¾¾ï¼‰çš„éƒ¨ç½²å·¥å…·é“¾éš¾ä»¥ç›´æ¥é€‚é…ï¼›è€Œ MLIR æ˜¯ â€œç¡¬ä»¶æ— å…³â€ çš„åº•å±‚ä¸­é—´è¡¨ç¤ºï¼Œèƒ½ç»Ÿä¸€å¤„ç†ä¸åŒæ¡†æ¶çš„æ¨¡å‹ï¼Œè¿˜èƒ½æ–¹ä¾¿åœ°æ’å…¥é‡åŒ–ã€ä¼˜åŒ–ç­‰æ“ä½œï¼Œæ˜¯è¿æ¥ â€œæ¡†æ¶æ¨¡å‹â€ å’Œ â€œç¡¬ä»¶ä¸“ç”¨æ¨¡å‹ï¼ˆbmodelï¼‰â€ çš„æ¡¥æ¢ ```bash model_transform.py \\ model_name yolov5s \\ model_def ../yolov5s.onnx \\ input_shapes [[1,3,640,640]] \\ mean 0.0,0.0,0.0 \\ scale 0.0039216,0.0039216,0.0039216 \\ keep_aspect_ratio \\ pixel_format rgb \\ output_names 350,498,646 \\ test_input ../image/dog.jpg \\ test_result yolov5s_top_outputs.npz \\ mlir yolov5s.mlir ``` **å‚æ•°å** å¿…é€‰ï¼Ÿ **è¯´æ˜** model_name æ˜¯ æŒ‡å®šæ¨¡å‹åç§°, ç”¨äºæ ‡è®°, ä¹‹åæ–¹ä¾¿ä½¿ç”¨ model_def æ˜¯ æŒ‡å®šæ¨¡å‹å®šä¹‰æ–‡ä»¶ï¼Œæ¯”å¦‚`.onnx`æˆ–`.pt`æˆ–`.tflite`æˆ–`.prototxt`æ–‡ä»¶, ONNX æ˜¯è·¨æ¡†æ¶çš„æ ‡å‡†åŒ–æ¨¡å‹æ ¼å¼ï¼Œè¿™é‡Œæ˜¯ YOLOv5s å¯¼å‡ºçš„ ONNX æ¨¡å‹æ–‡ä»¶ï¼ŒåŒ…å«æ¨¡å‹çš„ç½‘ç»œç»“æ„å’Œæƒé‡ model_data å¦ æŒ‡å®šæ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œcaffeæ¨¡å‹éœ€è¦ï¼Œå¯¹åº”`.caffemodel`æ–‡ä»¶ input_shapes å¦ æŒ‡å®šè¾“å…¥çš„shapeï¼Œä¾‹å¦‚`[[1,3,640,640]]`ï¼›äºŒç»´æ•°ç»„ï¼Œå¯ä»¥æ”¯æŒå¤šè¾“å…¥æƒ…å†µ, æŒ‡å®šæ¨¡å‹è¾“å…¥å¼ é‡çš„å½¢çŠ¶ï¼ˆshapeï¼‰ï¼ŒäºŒç»´æ•°ç»„æ ¼å¼ï¼ˆæ”¯æŒå¤šè¾“å…¥ï¼Œæ­¤å¤„ä¸ºå•è¾“å…¥ï¼‰ï¼š resize_dims å¦ `1` æ‰¹å¤§å°ï¼ˆbatch_sizeï¼‰ï¼Œè¡¨ç¤ºä¸€æ¬¡å¤„ç† 1 å¼ å›¾ç‰‡ï¼›åŸå§‹å›¾ç‰‡éœ€è¦resizeä¹‹åçš„å°ºå¯¸ï¼›å¦‚æœä¸æŒ‡å®šï¼Œåˆ™resizeæˆæ¨¡å‹çš„è¾“å…¥å°ºå¯¸ keep_aspect_ratio å¦ `3` é€šé“æ•°ï¼ˆRGBï¼‰ï¼›åœ¨Resizeæ—¶æ˜¯å¦ä¿æŒé•¿å®½æ¯”ï¼Œé»˜è®¤ä¸ºfalseï¼›è®¾ç½®æ—¶ä¼šå¯¹ä¸è¶³éƒ¨åˆ†è¡¥0, å¦åˆ™è¿›è¡Œç›´æ¥æ‹‰ä¼¸ mean å¦ `640,640` è¾“å…¥å›¾ç‰‡çš„é«˜ / å®½ï¼ˆYOLOv5 é»˜è®¤è¾“å…¥å°ºå¯¸ï¼‰ï¼›å›¾åƒæ¯ä¸ªé€šé“çš„å‡å€¼ï¼Œé»˜è®¤ä¸º0.0,0.0,0.0, æŒ‡å®šå›¾åƒä¸‰ä¸ªé€šé“ï¼ˆRGBï¼‰çš„é¢„å¤„ç†å‡å€¼ï¼Œä¸ YOLOv5 çš„é¢„å¤„ç†é€»è¾‘ä¸€è‡´ scale å¦ æ•´ä½“è¡¨ç¤ºæ¨¡å‹æ¥æ”¶`1Ã—3Ã—640Ã—640`çš„å¼ é‡è¾“å…¥å›¾ç‰‡æ¯ä¸ªé€šé“çš„æ¯”å€¼ï¼Œé»˜è®¤ä¸º1.0,1.0,1.0 pixel_format å¦ å›¾ç‰‡ç±»å‹ï¼Œå¯ä»¥æ˜¯rgbã€bgrã€grayã€rgbdå››ç§æƒ…å†µ output_names å¦ æŒ‡å®šè¾“å‡ºçš„åç§°ï¼Œå¦‚æœä¸æŒ‡å®šï¼Œåˆ™ç”¨æ¨¡å‹çš„è¾“å‡ºï¼›æŒ‡å®šåç”¨è¯¥æŒ‡å®šåç§°åšè¾“å‡º test_input å¦ æŒ‡å®šè¾“å…¥æ–‡ä»¶ç”¨äºéªŒè¯ï¼Œå¯ä»¥æ˜¯å›¾ç‰‡æˆ–npyæˆ–npzï¼›å¯ä»¥ä¸æŒ‡å®šï¼Œåˆ™ä¸ä¼šæ­£ç¡®æ€§éªŒè¯ test_result å¦ æŒ‡å®šéªŒè¯åçš„è¾“å‡ºæ–‡ä»¶ excepts å¦ æŒ‡å®šéœ€è¦æ’é™¤éªŒè¯çš„ç½‘ç»œå±‚çš„åç§°ï¼Œå¤šä¸ªç”¨,éš”å¼€ debug å¦ æŒ‡å®šåä¿ç•™ä¸­é—´ä¸´æ—¶æ–‡ä»¶ï¼›å¦åˆ™ä¼šæ¸…ç†æ‰ä¸­é—´ä¸´æ—¶æ–‡ä»¶ mlir æ˜¯ æŒ‡å®šè¾“å‡ºçš„mliræ–‡ä»¶è·¯å¾„ #### è¾“å‡ºèŠ‚ç‚¹é€‰æ‹© YOLOv8/YOLO11 çš„æ¨ç†æµç¨‹æ˜¯ã€Œç‰¹å¾æå–â†’å¤šå°ºåº¦èåˆâ†’è¾“å‡ºè§£ç ã€ï¼Œæ–‡æ¡£ä¸­é€‰æ‹©çš„èŠ‚ç‚¹éƒ½æ˜¯æ¨¡å‹ã€Œæœ€ç»ˆå¯è§£ç çš„è¾“å‡ºå±‚ã€ï¼Œä¸åŒèŠ‚ç‚¹å¯¹åº”ä¸åŒçš„è¾“å‡ºé˜¶æ®µ **Concat ç±»èŠ‚ç‚¹**ï¼ˆæ–¹æ¡ˆä¸€æ ¸å¿ƒï¼‰ï¼šæ˜¯ã€Œå¤šå°ºåº¦ç‰¹å¾èåˆåçš„åŸå§‹è¾“å‡ºã€ã€‚YOLO æ¨¡å‹ä¸ºäº†æ£€æµ‹ä¸åŒå¤§å°çš„ç›®æ ‡ï¼ˆå¤§ / ä¸­ / å°ï¼‰ï¼Œä¼šåœ¨å¤šä¸ªå°ºåº¦ä¸Šæå–ç‰¹å¾ï¼ŒConcat èŠ‚ç‚¹å°±æ˜¯å°†è¿™äº›ä¸åŒå°ºåº¦çš„ç‰¹å¾å›¾æ‹¼æ¥åçš„ç»“æœï¼ˆå¦‚ Concat_1/2/3 å¯¹åº” 3 ä¸ªå°ºåº¦ï¼‰ã€‚CPU å¯ä»¥ç›´æ¥å¯¹è¿™äº›åŸå§‹ç‰¹å¾å›¾è¿›è¡Œè§£ç ï¼ˆè®¡ç®—è¾¹ç•Œæ¡†ã€ç±»åˆ«ç½®ä¿¡åº¦ã€å…³é”®ç‚¹åæ ‡ç­‰ï¼‰ **dfl/conv/Conv_output_0**ï¼šæ˜¯ã€Œåˆ†å¸ƒç„¦ç‚¹æŸå¤±ï¼ˆDFLï¼‰çš„å·ç§¯è¾“å‡ºã€ã€‚DFL æ˜¯ YOLO ç”¨äºè¾¹ç•Œæ¡†å›å½’çš„æ ¸å¿ƒæ¨¡å—ï¼Œè¯¥èŠ‚ç‚¹è¾“å‡ºçš„æ˜¯è¾¹ç•Œæ¡†åæ ‡çš„é¢„æµ‹ç‰¹å¾ï¼ŒNPU å¯¹å·ç§¯è¿ç®—æœ‰ç¡¬ä»¶ä¼˜åŒ–ï¼Œèƒ½å¿«é€Ÿå¤„ç† **Sigmoid_output_0**ï¼šæ˜¯ã€Œç±»åˆ« / ç½®ä¿¡åº¦çš„æ¿€æ´»è¾“å‡ºã€ã€‚Sigmoid å‡½æ•°å°†æ¨¡å‹é¢„æµ‹çš„åŸå§‹åˆ†æ•°æ˜ å°„åˆ° 0 1 ä¹‹é—´ï¼ˆè¡¨ç¤ºç½®ä¿¡åº¦ï¼‰ï¼ŒNPU å¯ç›´æ¥å¤„ç†æ¿€æ´»è¿ç®—ï¼Œå‡å°‘ CPU è´Ÿæ‹… **é¢å¤–èŠ‚ç‚¹ï¼ˆå¦‚ output1ã€Concat_output_0ï¼‰**ï¼šå¯¹åº”æ‰©å±•ä»»åŠ¡çš„è¾“å‡ºã€‚ä¾‹å¦‚ï¼š åˆ†å‰²ï¼ˆsegï¼‰æ¨¡å‹çš„ã€Œoutput1ã€ï¼šæ˜¯åˆ†å‰²æ©ç çš„é¢„æµ‹è¾“å‡ºï¼ˆåˆ†å‰²ä»»åŠ¡éœ€è¦åŒæ—¶è¾“å‡ºè¾¹ç•Œæ¡†å’Œæ©ç ï¼Œå› æ­¤å¤šä¸€ä¸ªèŠ‚ç‚¹ï¼‰ï¼› å…³é”®ç‚¹ï¼ˆposeï¼‰æ¨¡å‹çš„ã€ŒConcat_output_0ã€ï¼šæ˜¯å…³é”®ç‚¹åæ ‡çš„ç‰¹å¾è¾“å‡ºï¼ˆé™¤äº†è¾¹ç•Œæ¡†ï¼Œè¿˜éœ€é¢„æµ‹å…³é”®ç‚¹ï¼Œå› æ­¤å¢åŠ è¯¥èŠ‚ç‚¹ï¼‰ å®é™…æ˜¯CPUä»¥åŠNPUçš„å·¥ä½œåˆ†é…é—®é¢˜ æ–¹æ¡ˆä¸€ï¼ˆCPU å¤šå¹²æ´»ï¼‰ è¾“å‡ºèŠ‚ç‚¹æ˜¯ã€ŒåŸå§‹ Concat ç‰¹å¾ã€ï¼Œåç»­çš„è§£ç ï¼ˆè¾¹ç•Œæ¡†å›å½’ã€ç±»åˆ«åˆ¤æ–­ã€å…³é”®ç‚¹è®¡ç®—ï¼‰å…¨éƒ¨äº¤ç»™ CPU å¤„ç†ï¼› ä¼˜åŠ¿ï¼šCPU å¤„ç†çš„è§£ç é€»è¾‘æ›´çµæ´»ï¼Œé‡åŒ–æ—¶ï¼ˆå°†æ¨¡å‹æƒé‡ä»æµ®ç‚¹è½¬æ•´å‹ï¼Œé€‚é…è¾¹ç¼˜è®¾å¤‡ï¼‰ä¸å®¹æ˜“å‡ºç°ç²¾åº¦æŸå¤±ï¼ˆé‡åŒ–å¤±è´¥é£é™©ä½ï¼‰ï¼› åŠ£åŠ¿ï¼šCPU è¿ç®—é€Ÿåº¦æ¯” NPU æ…¢ï¼Œæ•´ä½“æ¨ç†é€Ÿåº¦ç•¥é€Šäºæ–¹æ¡ˆäºŒã€‚ æ–¹æ¡ˆäºŒï¼ˆNPU å¤šå¹²æ´»ï¼‰ è¾“å‡ºèŠ‚ç‚¹æ˜¯ã€ŒDFL å·ç§¯ + Sigmoid æ¿€æ´»åçš„ç»“æœã€ï¼Œè¿™äº›æ˜¯æ¨¡å‹æ¨ç†ä¸­è®¡ç®—é‡æœ€å¤§çš„éƒ¨åˆ†ï¼ˆå·ç§¯ã€æ¿€æ´»ï¼‰ï¼Œç›´æ¥äº¤ç»™ NPU å¤„ç†ï¼ˆNPU æ“…é•¿å¹¶è¡Œè®¡ç®—ï¼Œé€Ÿåº¦è¿œå¿«äº CPUï¼‰ï¼› ä¼˜åŠ¿ï¼šNPU æ‰¿æ‹…æ ¸å¿ƒè®¡ç®—ï¼Œæ•´ä½“æ¨ç†é€Ÿåº¦æ›´å¿«ï¼ˆMaixCAM æ¨èæ–¹æ¡ˆï¼‰ï¼› åŠ£åŠ¿ï¼šNPU å‚ä¸é‡åŒ–æ—¶ï¼Œéƒ¨åˆ†ç¡¬ä»¶ï¼ˆå¦‚ MaixCAM2ï¼‰å¯¹ DFL+Sigmoid çš„é‡åŒ–å…¼å®¹æ€§ä¸å¥½ï¼Œå®¹æ˜“å‡ºç°é‡åŒ–å¤±è´¥ï¼ˆæ¨¡å‹æ— æ³•è¿è¡Œæˆ–ç²¾åº¦æš´è·Œï¼‰ã€‚ > **ç»å¯¹ä¸å¯ä»¥éšä¾¿é€‰è¾“å‡ºèŠ‚ç‚¹**â€”â€” éšä¾¿é€‰çš„ç»“æœå¤§æ¦‚ç‡æ˜¯ã€Œæ¨¡å‹æ— æ³•è¿è¡Œã€ã€Œè¾“å‡ºç»“æœå®Œå…¨é”™è¯¯ï¼ˆå¦‚æ— æ£€æµ‹æ¡†ã€å…³é”®ç‚¹ / åˆ†å‰²æ©ç ä¸¢å¤±ï¼‰ã€ã€Œé‡åŒ–å¤±è´¥ã€ï¼Œç”šè‡³ç›´æ¥è§¦å‘ç¡¬ä»¶æ¨ç†æŠ¥é”™ã€‚ > > æ ¸å¿ƒåŸå› åœ¨äºï¼šè¾“å‡ºèŠ‚ç‚¹çš„é€‰æ‹©ä¸æ˜¯ â€œä»»é€‰â€ï¼Œè€Œæ˜¯**å’Œæ¨¡å‹ç»“æ„ã€ç¡¬ä»¶èƒ½åŠ›ã€MaixPy çš„åå¤„ç†é€»è¾‘å¼ºç»‘å®š**ï¼Œæ¯ä¸€ä¸ªèŠ‚ç‚¹éƒ½å¯¹åº” YOLO æ¨ç†çš„æ ¸å¿ƒç»´åº¦ï¼Œå°‘é€‰ã€é”™é€‰ã€ä¹±é€‰éƒ½ä¼šç ´åå®Œæ•´çš„æ¨ç†é“¾è·¯ ##### é€‰æ‹©æµ‹è¯•é—®é¢˜ æµ‹è¯•ç›´æ¥ä½¿ç”¨output0ä½œä¸ºè¾“å‡º, å®é™…ç»“æœå¤±è´¥ MaixPy è¿è¡Œçš„ç¡¬ä»¶ï¼ˆMaixCAM/MaixCAM2ï¼‰ä¾èµ– â€œæ¨¡å‹é‡åŒ–â€ï¼ˆå°†æµ®ç‚¹æƒé‡è½¬æ•´å‹ï¼‰æ‰èƒ½é«˜æ•ˆè¿è¡Œï¼Œè€ŒåŸç”Ÿ output0 æœ‰ä¸¤ä¸ªè‡´å‘½é—®é¢˜ï¼š é‡åŒ–ç²¾åº¦æŸå¤±ï¼šoutput0 æ˜¯ â€œæµ®ç‚¹å‹ç«¯åˆ°ç«¯è¾“å‡ºâ€ï¼Œç›´æ¥é‡åŒ–ä¼šå¯¼è‡´æ¡†åæ ‡ã€ç½®ä¿¡åº¦çš„ç²¾åº¦æš´è·Œï¼ˆæ¯”å¦‚ç›®æ ‡ç½®ä¿¡åº¦ä» 0.9 é‡åŒ–åå˜æˆ 0.1ï¼Œæ¼æ£€ / é”™æ£€ä¸¥é‡ï¼‰ï¼› é‡åŒ–å…¼å®¹æ€§ï¼šæ–‡æ¡£ä¸­çš„æ–¹æ¡ˆä¸€ / äºŒèŠ‚ç‚¹ï¼ˆConcat/dfl/Sigmoidï¼‰æ˜¯ â€œä½ç»´åº¦ã€æ˜“é‡åŒ–çš„ä¸­é—´ç‰¹å¾â€ï¼ˆæ¯”å¦‚ Concat èŠ‚ç‚¹è¾“å‡ºçš„æ˜¯ç‰¹å¾å›¾ï¼Œè€Œéæœ€ç»ˆé”šæ¡†ï¼‰ï¼Œé‡åŒ–æ—¶æ•°å€¼æ³¢åŠ¨å°ã€ç¨³å®šæ€§é«˜ï¼›è€Œ output0 æ˜¯é«˜ç»´åº¦å¼ é‡ï¼Œé‡åŒ–æ—¶ææ˜“è§¦å‘ç¡¬ä»¶å…¼å®¹é—®é¢˜ï¼ˆæ¯”å¦‚ MaixCAM2 ç›´æ¥é‡åŒ–å¤±è´¥ï¼‰ã€‚ #### MLIRè½¬Int8 è¿™æ®µæ“ä½œçš„æ ¸å¿ƒæ˜¯**å°† YOLOv5s æµ®ç‚¹æ¨¡å‹é‡åŒ–ä¸ºé€‚é… BM1684x èŠ¯ç‰‡çš„ INT8 ä½ç²¾åº¦æ¨¡å‹**ï¼Œç›®çš„æ˜¯åœ¨ä¿è¯ç²¾åº¦æŸå¤±å¯æ§çš„å‰æä¸‹ï¼Œæå‡æ¨¡å‹åœ¨ä¸“ç”¨ AI ç¡¬ä»¶ä¸Šçš„æ¨ç†é€Ÿåº¦ã€é™ä½å­˜å‚¨å¼€é”€å’ŒåŠŸè€—ã€‚ > æ·±åº¦å­¦ä¹ æ¨¡å‹é»˜è®¤æ˜¯ FP32ï¼ˆ32 ä½æµ®ç‚¹ï¼‰æ ¼å¼ï¼Œç²¾åº¦é«˜ä½†è®¡ç®— / å­˜å‚¨æˆæœ¬å¤§ï¼›è€Œè¾¹ç¼˜ç«¯ / ä¸“ç”¨ AI èŠ¯ç‰‡ï¼ˆå¦‚æ¯”ç‰¹å¤§é™† BM1684xï¼‰å¯¹ä½ç²¾åº¦ï¼ˆINT8ï¼‰è®¡ç®—çš„æ”¯æŒæ›´é«˜æ•ˆ â€”â€”INT8 çš„è®¡ç®—é‡ä»…ä¸º FP32 çš„ 1/4ï¼Œå­˜å‚¨å ç”¨ä»…ä¸º 1/4ï¼Œæ¨ç†é€Ÿåº¦èƒ½æå‡ 3~5 å€ï¼ˆç”šè‡³æ›´é«˜ï¼‰ è½¬INT8æ¨¡å‹å‰éœ€è¦è·‘calibrationï¼Œå¾—åˆ°é‡åŒ–è¡¨ï¼›è¾“å…¥æ•°æ®çš„æ•°é‡æ ¹æ®æƒ…å†µå‡†å¤‡100~1000å¼ å·¦å³ã€‚ > ç”¨ä¸€æ‰¹çœŸå®æ•°æ®ï¼ˆCOCO2017ï¼‰è·‘æ¨¡å‹ï¼Œç»Ÿè®¡æ¨¡å‹å„å±‚å¼ é‡çš„æ•°å€¼åˆ†å¸ƒï¼ˆæ¯”å¦‚æœ€å¤§å€¼ / æœ€å°å€¼ã€æ•°æ®åˆ†å¸ƒè§„å¾‹ï¼‰ï¼Œè®¡ç®—å‡º**æµ®ç‚¹å€¼â†’INT8 å€¼çš„æœ€ä¼˜æ˜ å°„å‚æ•°**ï¼ˆå³ â€œé‡åŒ–è¡¨â€ï¼‰ ç„¶åç”¨é‡åŒ–è¡¨ï¼Œç”Ÿæˆå¯¹ç§°æˆ–éå¯¹ç§°bmodelã€‚å¦‚æœå¯¹ç§°ç¬¦åˆéœ€æ±‚ï¼Œä¸€èˆ¬ä¸å»ºè®®ç”¨éå¯¹ç§°ï¼Œå› ä¸ºéå¯¹ç§°çš„æ€§èƒ½ä¼šç•¥å·®ä¸å¯¹ç§°æ¨¡å‹ ``` run_calibration.py yolov5s.mlir \\ dataset ../COCO2017 \\ input_num 100 \\ o yolov5s_cali_table ``` > `yolov5s.mlir`ï¼šè¾“å…¥çš„æ¨¡å‹æ–‡ä»¶ï¼ˆMLIR æ˜¯è·¨æ¡†æ¶ / è·¨ç¡¬ä»¶çš„é€šç”¨æ¨¡å‹ä¸­é—´è¡¨ç¤ºï¼Œè§£å†³ä¸åŒæ¡†æ¶ï¼ˆPyTorch/TensorFlowï¼‰å’Œç¡¬ä»¶çš„é€‚é…é—®é¢˜ï¼‰ > > ` dataset ../COCO2017`ï¼šæ ¡å‡†ç”¨çš„æ•°æ®é›†ï¼ˆé€‰ COCO2017 æ˜¯å› ä¸º YOLOv5 çš„è®­ç»ƒ / æµ‹è¯•åŸºäºè¯¥æ•°æ®é›†ï¼Œæ•°æ®åˆ†å¸ƒåŒ¹é…ï¼Œæ ¡å‡†ç»“æœæ›´å¯é ï¼‰ï¼› > > ` input_num 100`ï¼šç”¨ 100 å¼ å›¾åšæ ¡å‡†ï¼ˆ100~1000 æ˜¯ç»éªŒå€¼ï¼Œæ•°é‡å¤ªå°‘ç»Ÿè®¡ä¸å‡†ï¼Œå¤ªå¤šè€—æ—¶ï¼‰ï¼› > > ` o yolov5s_cali_table`ï¼šè¾“å‡ºé‡åŒ–è¡¨ï¼ˆæ ¸å¿ƒæ–‡ä»¶ï¼ŒåŒ…å«å„å±‚çš„ç¼©æ”¾å› å­ï¼ˆscaleï¼‰ã€é‡åŒ–èŒƒå›´ç­‰å…³é”®å‚æ•°ï¼‰ è½¬æˆINT8å¯¹ç§°é‡åŒ–æ¨¡å‹ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š ``` model_deploy.py \\ mlir yolov5s.mlir \\ quantize INT8 \\ calibration_table yolov5s_cali_table \\ processor bm1684x \\ test_input yolov5s_in_f32.npz \\ test_reference yolov5s_top_outputs.npz \\ tolerance 0.85,0.45 \\ model yolov5s_1684x_int8.bmodel ``` åŸºäºç¬¬ä¸€æ­¥çš„é‡åŒ–è¡¨ï¼Œå°† MLIR æ ¼å¼çš„æµ®ç‚¹æ¨¡å‹è½¬æ¢æˆ**BM1684x èŠ¯ç‰‡ä¸“ç”¨çš„ INT8 é‡åŒ–æ¨¡å‹ï¼ˆbmodel æ ¼å¼ï¼‰** å‚æ•° ä½œç”¨ ` mlir yolov5s.mlir` åŸå§‹çš„ FP32 æµ®ç‚¹æ¨¡å‹ï¼ˆMLIR æ ¼å¼ï¼‰ ` quantize INT8` æŒ‡å®šé‡åŒ–ç±»å‹ä¸º INT8ï¼ˆå¯¹æ¯” FP32/FP16ï¼Œä¼˜å…ˆé€‰ INT8 å¹³è¡¡æ€§èƒ½å’Œç²¾åº¦ï¼‰ ` calibration_table yolov5s_cali_table` åŠ è½½ç¬¬ä¸€æ­¥ç”Ÿæˆçš„é‡åŒ–è¡¨ï¼ˆç¡®å®šæµ®ç‚¹â†’INT8 çš„æ˜ å°„å…³ç³»ï¼‰ ` processor bm1684x` æŒ‡å®šç›®æ ‡ç¡¬ä»¶ä¸ºæ¯”ç‰¹å¤§é™† BM1684x èŠ¯ç‰‡ï¼ˆbmodel ä¼šé€‚é…è¯¥èŠ¯ç‰‡çš„æŒ‡ä»¤é›†ï¼‰ ` test_input yolov5s_in_f32.npz` æµ‹è¯•ç”¨è¾“å…¥æ•°æ®ï¼ˆFP32 æ ¼å¼ï¼Œnpz æ˜¯ numpy å‹ç¼©æ ¼å¼ï¼Œæ¨¡æ‹ŸçœŸå®æ¨ç†è¾“å…¥ï¼‰ ` test_reference yolov5s_top_outputs.npz` æµ®ç‚¹æ¨¡å‹çš„è¾“å‡ºç»“æœï¼ˆä½œä¸º â€œæ ‡å‡†ç­”æ¡ˆâ€ï¼Œç”¨äºå¯¹æ¯”é‡åŒ–åæ¨¡å‹çš„ç²¾åº¦ï¼‰ ` tolerance 0.85,0.45` ç²¾åº¦å®¹å¿åº¦ï¼ˆé‡åŒ–åæ¨¡å‹ä¸æµ®ç‚¹æ¨¡å‹çš„ç²¾åº¦å·®å¼‚é˜ˆå€¼ï¼Œæ¯”å¦‚ç¬¬ä¸€ä¸ªå€¼å¯èƒ½æ˜¯ mAP å®¹å¿åº¦ï¼Œç¬¬äºŒä¸ªæ˜¯åˆ†ç±»ç²¾åº¦å®¹å¿åº¦ï¼›è‹¥å·®å¼‚è¶…è¿‡è¯¥å€¼ï¼Œé‡åŒ–å¤±è´¥ï¼‰ ` model yolov5s_1684x_int8.bmodel` è¾“å‡ºæœ€ç»ˆçš„ INT8 é‡åŒ–æ¨¡å‹ï¼ˆbmodel æ˜¯ BM ç³»åˆ—èŠ¯ç‰‡çš„ä¸“ç”¨æ ¼å¼ï¼Œå¯ç›´æ¥åœ¨ BM1684x ä¸Šæ¨ç†ï¼‰ **å¯¹ç§°é‡åŒ–**ï¼šå°†æµ®ç‚¹çš„æ­£è´ŸèŒƒå›´å¯¹ç§°æ˜ å°„åˆ° INT8 çš„ [ 127,127]ï¼ˆèˆå» 128ï¼‰ï¼Œè®¡ç®—é€»è¾‘ç®€å•ï¼ˆä»…éœ€ç¼©æ”¾å› å­ scaleï¼‰ï¼Œç¡¬ä»¶æ‰§è¡Œæ•ˆç‡æœ€é«˜ï¼› **éå¯¹ç§°é‡åŒ–**ï¼šæ˜ å°„åˆ° [0,255]ï¼ˆæ— ç¬¦å·ï¼‰æˆ– [ 128,127]ï¼ˆæœ‰ç¬¦å·ï¼‰ï¼Œéœ€é¢å¤–è®¡ç®—åç§»é‡ï¼ˆzero pointï¼‰ï¼Œç²¾åº¦å¯èƒ½ç•¥é«˜ä½†è®¡ç®—æ­¥éª¤å¤šï¼Œæ€§èƒ½ç•¥å·®ï¼› å› æ­¤ä¼˜å…ˆé€‰å¯¹ç§°é‡åŒ–ï¼Œä»…å½“å¯¹ç§°é‡åŒ–ç²¾åº¦ä¸è¾¾æ ‡æ—¶æ‰ç”¨éå¯¹ç§°"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-11-02-æ¨¡å‹è®­ç»ƒ.html":{"title":"æ¨¡å‹è®­ç»ƒ","content":"# æ¨¡å‹è®­ç»ƒ [MaixHub](https://maixhub.com/)å¯ä»¥åœ¨è¿™ä¸ªç•Œé¢è¿›è¡Œçº¿ä¸Šçš„æ¨¡å‹è®­ç»ƒ ## åŸºç¡€ä½¿ç”¨ ![image 20251211210232571](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112102710.png) æœ‰ä¸¤ç§, ä¸€ç§æ˜¯åˆ†ç±»ä¸€ç§æ˜¯ä½ç½®æ£€æµ‹ ![image 20251211210353836](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112103996.png) ![image 20251211210409936](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112104015.png) ![image 20251211210433138](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112104266.png) ![image 20251211210522292](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112105441.png) ![image 20251211211124974](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112111232.png) è‡ªåŠ¨æ ‡æ³¨ä½¿ç”¨çš„æ˜¯è§†é¢‘é‡Œé¢çš„æ ‡æ³¨, ä½¿ç”¨å…¶ä¸­ä¸€å¸§è‡ªåŠ¨æ ‡æ³¨ä¹‹åçš„æ•°æ® ![image 20251211211703426](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112117733.png) ![image 20251211211939002](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112119161.png) å¯ä»¥é€‚å½“æé«˜åˆ†è¾¨ç‡, å®é™…éƒ¨ç½²çš„æ—¶å€™å›¾ç‰‡çš„å¤„ç†éœ€è¦å’Œè®­ç»ƒçš„æ—¶å€™æ˜¯ä¸€æ ·çš„, æ ‡å‡†åŒ–æ˜¯ä¸ºäº†å¯¹åƒç´ è¿›è¡Œé¢„å¤„ç†, ä¸€èˆ¬æ˜¯å˜ä¸º0 1ä¹‹é—´çš„æ•°å­— ![image 20251211212007445](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112120508.png) ![image 20251211212058391](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112120571.png) ![image 20251211212414774](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112124916.png) ## éƒ¨ç½² ### è‡ªåŠ¨éƒ¨ç½² ä½¿ç”¨å¼€å‘æ¿ä¸Šé¢çš„MaicHub Clientæ‰«ç å°±å¯ä»¥è¿›è¡Œéƒ¨ç½² ### ä»£ç éƒ¨ç½² ![image 20251211215345449](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112153538.png) ```python from maix import camera, display, image, nn, app, comm import struct, os report_on True APP_CMD_DETECT_RES 0x02 def encode_objs(objs): ''' encode objs info to bytes body for protocol 2B x(LE) + 2B y(LE) + 2B w(LE) + 2B h(LE) + 2B idx + 4B score(float) ... ''' body b'' for obj in objs: body + struct.pack(\"<hhHHHf\", obj.x, obj.y, obj.w, obj.h, obj.class_id, obj.score) return body model_path \"model_245391.mud\" if not os.path.exists(model_path): model_path \"/root/models/maixhub/245391/model_245391.mud\" detector nn.YOLOv5(model model_path) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) dis display.Display() p comm.CommProtocol(buff_size 1024) while not app.need_exit(): # msg p.get_msg() img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) if len(objs) > 0 and report_on: body encode_objs(objs) p.report(APP_CMD_DETECT_RES, body) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'frog: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) dis.show(img) ```"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-20-09-MaixPyç¼–è¯‘.html":{"title":"MaixPyç¼–è¯‘","content":"# MaixPyç¼–è¯‘ ## setup.py åœ¨è¿™ä¸ªæ–‡ä»¶é‡Œé¢ä½¿ç”¨`project.py`ç¼–è¯‘ä¸€ä¸‹maixcamè¿™ä¸ªé¡¹ç›® ä½¿ç”¨å‘½ä»¤ ```bash python project.py build p maixcam release config file configs/config_platform_maixcam.mk ``` è¿™ä¸ªå‘½ä»¤ä¼šåŒ…æ‰€æœ‰çš„æ–‡ä»¶ç¼–è¯‘ä¸ºåº“æ–‡ä»¶, è¿™äº›åº“æ–‡ä»¶æ”¾åœ¨ ç”Ÿæˆå¯¹åº”çš„æ–‡æ¡£æ–‡ä»¶, ä½¿ç”¨ `pybind11 stubgen` ä¸º C++ æ‰©å±•ç”Ÿæˆ `.pyi` å­˜æ ¹æ–‡ä»¶ ```bash python u components/maix/gen_api.py doc docs/api sdk_path {maixcdk_path} ``` æŒ‡å®šåœ¨æ‰“åŒ…çš„æ—¶å€™æŠŠmaixcdkçš„åº“æ–‡ä»¶ç¼–è¯‘è¿›å» ## maixé¡¹ç›®ä»£ç  ### gen_api_cpp 1. **ç”Ÿæˆ pybind11 æ¨¡å—ä»£ç ** è‡ªåŠ¨ç”Ÿæˆ `maixpy_wrapper.cpp` ä¸­çš„ PYBIND11_MODULE éƒ¨åˆ† å°† C++ ç±»ã€å‡½æ•°ã€å˜é‡ã€æšä¸¾ç­‰æš´éœ²ç»™ Python 2. **è§£æ API å®šä¹‰** ä» C++ å¤´æ–‡ä»¶ä¸­æå– MaixPy APIï¼ˆé€šè¿‡ç‰¹æ®Šæ³¨é‡Šæ ‡è®°ï¼‰ é€’å½’æ‰«æ SDK çš„ [components](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) ç›®å½•ä¸­çš„æ‰€æœ‰ `.h` å’Œ `.hpp` æ–‡ä»¶ æ’é™¤ `3rd_party` ç›®å½•ä¸‹çš„ä»£ç  3. **å¤„ç†ä¸åŒçš„ API ç±»å‹** **æ¨¡å—ï¼ˆmoduleï¼‰**ï¼šåˆ›å»ºå­æ¨¡å— **ç±»ï¼ˆclassï¼‰**ï¼šç”Ÿæˆç±»ç»‘å®šï¼ŒåŒ…æ‹¬æ„é€ å‡½æ•°ã€æˆå‘˜å‡½æ•°ã€æˆå‘˜å˜é‡ **å‡½æ•°ï¼ˆfuncï¼‰**ï¼šå¤„ç†æ™®é€šå‡½æ•°å’Œé™æ€æ–¹æ³• **å˜é‡ï¼ˆvarï¼‰**ï¼šç»‘å®šç±»æˆå‘˜å’Œæ¨¡å—å˜é‡ï¼ˆåªè¯»/è¯»å†™ï¼‰ **æšä¸¾ï¼ˆenumï¼‰**ï¼šç”Ÿæˆæšä¸¾ç±»å‹ç»‘å®š 4. **ä¼˜åŒ–å¤´æ–‡ä»¶é¡ºåº** æ ¹æ® `headers_priority.txt` æ–‡ä»¶æ’åºå¤´æ–‡ä»¶ï¼Œç¡®ä¿ä¾èµ–å…³ç³»æ­£ç¡® 5. **å‘½ä»¤è¡Œå·¥å…·** å¯ç‹¬ç«‹è¿è¡Œç”Ÿæˆ API åŒ…è£…ä»£ç  æ”¯æŒè‡ªå®šä¹‰è¾“å‡ºè·¯å¾„å’Œ SDK è·¯å¾„"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-3-00-èµ„æ–™.html":{"title":"èµ„æ–™","content":"# èµ„æ–™ LinuxSDK: https://github.com/sipeed/LicheeRV Nano Build/tree/main ä½¿ç”¨çš„linuxç³»ç»Ÿ MaixPy: https://github.com/sipeed/MaixPy ç›¸å…³å¼€å‘ç¯å¢ƒ MaixCDK: https://github.com/sipeed/MaixCDK MaixCDKæ‰‹å†Œ: https://wiki.sipeed.com/maixcdk/doc/zh/index.html C++ç›¸å…³çš„ç¯å¢ƒ MaixPyæ‰‹å†Œ: https://wiki.sipeed.com/maixpy/doc/zh/index.html"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-16-06-maixcdkå·¥å…·.html":{"title":"Maixcdkå·¥å…·","content":"# Maixcdkå·¥å…· https://github.com/Neutree/c_cpp_project_frameworkä½¿ç”¨çš„æ˜¯è¿™ä¸ªåŸºç¡€æ¡†æ¶å°è£… > æ•´ä¸ªå·¥ä½œæµç¨‹å¯ä»¥ç†è§£æˆï¼š > > `maixcdk build` å…ˆç”¨ Python è„šæœ¬ç”Ÿæˆè¿™ä¸ªæç®€çš„ `CMakeLists.txt`ã€‚ > > ç„¶ååœ¨buildç›®å½•é‡Œè°ƒç”¨ > > ``` > cmake å‚æ•° .. > ``` > > CMake è¯»åˆ°è¿™ä¸ª `CMakeLists.txt`ï¼› > é€šè¿‡ `include(${SDK_PATH}/tools/cmake/compile.cmake)` æŠŠ MaixCDK çš„é€šç”¨æ„å»ºé€»è¾‘æ‹‰è¿›æ¥ï¼› > åˆ©ç”¨ä¼ å…¥çš„ `PROJECT_PATH`ã€`PLATFORM`ã€ç»„ä»¶ CMakeLists ç­‰ï¼Œç”Ÿæˆå®Œæ•´çš„ Makefileã€‚ > > å†ç”¨ `cmake build .` çœŸæ­£å»ç¼–è¯‘ã€‚ `tools/maixtool/maixtool/maixcdk.py` è¿™ä¸ªæ–‡ä»¶å®é™…çš„å·¥ä½œæ˜¯æŸ¥æ‰¾ä¸€ä¸‹CDKçš„æ ¹ç›®å½•, ä¹‹åæ·»åŠ `tools/cmake`ç›®å½•åˆ°æœç´¢è·¯å¾„, ç„¶åè°ƒç”¨`/tools/cmake/project.py`é‡Œé¢çš„mainå‡½æ•°, å‚æ•°æ˜¯CDKçš„è·¯å¾„ä»¥åŠå½“å‰çš„è·¯å¾„ ```python def exec_project_py(): # 1. get MaixCDK path sdk_path get_sdk_path() print(\" SDK_PATH:{}\".format(sdk_path)) project_path os.path.abspath(\".\") # 2. execute project script from SDK project_file_path sdk_path+\"/tools/cmake/project.py\" sys.path.insert(0, os.path.dirname(project_file_path)) from project import main main(sdk_path, project_path) ``` ## project.py ### get_extra_cmds ä»`tools/cmds`æ–‡ä»¶å¤¹é‡Œé¢è·å–åˆ°æ‰€æœ‰æœ‰`parser`å‚æ•°çš„å·¥å…· ```python def get_extra_cmds(sdk_path) > tuple: ''' return extra_tools { \"run\": { \"obj\": tool_object, \"cmd\": cmd, \"parser\": arg_parser } } ''' # find extra tools tools_dir os.path.join(sdk_path, \"tools\", \"cmds\") sys.path.insert(1, tools_dir) # find all .py files in tools dir extra_tools_names [] extra_tools {} for name in os.listdir(tools_dir): if name.endswith(\".py\"): extra_tools_names.append(name[: 3]) # import all tools for name in extra_tools_names: # import from tool file tool __import__(name) if hasattr(tool, \"parser\"): extra_tools[tool.__name__] { \"obj\": tool, \"cmd\": tool.parser.prog, \"parser\": tool.parser } return extra_tools ``` ### parse_argså‚æ•°è§£æå™¨ ```python def parse_args(sdk_path, project_path, extra_tools): \t# åˆ›å»ºä¸€ä¸ªproject.pyçš„è§£é‡Šå™¨ parser argparse.ArgumentParser(description 'build tool, e.g. `python project.py build`', prog \"project.py\") # æ·»åŠ ä¸€ä¸ªå­è§£é‡Šå™¨ç”¨äºå¤„ç†ä¸åŒçš„å‘½ä»¤, æ¯”å¦‚build, cleanç­‰ # è§£æä»¥åä½¿ç”¨args.cmdè·å–ä½¿ç”¨çš„å‚æ•° subparsers parser.add_subparsers(help 'command help', dest \"cmd\") # ä¸ºä¹‹å‰çš„é¢å¤–çš„å‘½ä»¤åˆ›å»ºè§£é‡Šå™¨ for k,v in extra_tools.items(): sub_parser v[\"parser\"] subparsers.add_parser(sub_parser.prog, parents [sub_parser], help sub_parser.description) # cmd build æ·»åŠ buildä»¥åŠ parser_build subparsers.add_parser(\"build\", help \"start compile project, temp files in `build` dir, dist files in `dist` dir, build command by default always execute cmake to regenerate, to disable file change scan (cmake execute), use build2 command or add no gen option to only compile changed files, warning build2 will not detect file additions and deletions\") parser_build2 subparsers.add_parser(\"build2\", help \"same as `maixcdk build no gen`, compile project, not scan files additions and deletions, only compile changed files, so build faster but be attention you should use build again if you add new file or delete files\") parser_build.add_argument(\" no gen\", action \"store_true\", default False, help \"same as command build2, by default the build command do the same action as rebuild to avoid user can't understand rebuild, but if you don't want to re execute cmake command, and only compile, use this option\") # è¿™ä¸¤ä¸ªbuildéƒ½æœ‰çš„å‚æ•° def add_build_args(parser_): parser_.add_argument(' config file', help 'config file path, e.g. config_defaults.mk', metavar 'PATH', default \"{}/config_defaults.mk\".format(project_path)) parser_.add_argument(' verbose', help 'for build command, execute `cmake build . verbose` to compile', action \"store_true\", default False) parser_.add_argument(' G', ' generator', default \"\", help \"project type to generate, supported type on your platform see `cmake help`\") parser_.add_argument(' release', action \"store_true\", default False, help \"release mode, default is release mode\") parser_.add_argument(' debug', action \"store_true\", default False, help \"debug mode, default is release mode\") parser_.add_argument(' build type', default None, help \"build type, [Debug, Release, MinRelSize, RelWithDebInfo], you can also set build type by CMAKE_BUILD_TYPE environment variable\") parser_.add_argument(' p', \" platform\", default \"\", help \"device name, e.g. linux, maixcam, m2dock\", choices get_platforms(sdk_path)) parser_.add_argument(' toolchain id', default \"\", help \"toolchain id, if platform has multiple toolchains, use this option to select one. Empty will let you select one interactively, 'default' means use the default toolchain defined in platform yaml file.\") add_build_args(parser_build) add_build_args(parser_build2) # cmd menuconfigé…ç½®å‘½ä»¤çš„è§£æå‚æ•°æ·»åŠ  parser_menuconfig subparsers.add_parser(\"menuconfig\", help \"open menuconfig panel, a visual config panel\") parser_menuconfig.add_argument(' config file', help 'config file path, e.g. config_defaults.mk', metavar 'PATH', default \"{}/config_defaults.mk\".format(project_path)) parser_menuconfig.add_argument(' p', \" platform\", default \"\", help \"device name, e.g. linux, maixcam, m2dock\", choices get_platforms(sdk_path)) # cmd clean subparsers.add_parser(\"clean\", help \"clean build files, won't clean configuration\") # cmd distclean subparsers.add_parser(\"distclean\", help \"clean all generated files, including build files and configuration\") \t\t# å®é™…çš„è§£æå‘½ä»¤, å¯ä»¥ä½¿ç”¨cmds.å¯¹åº”çš„åå­—è·å–å®é™…çš„è¯»å–å‚æ•° args parser.parse_args() return args, parser ``` ### é…ç½®æ–‡ä»¶å¤„ç† åœ¨build/config/project_vars.jsonå¯ä»¥æ‰¾åˆ°ä½¿ç”¨çš„é…ç½®æ–‡ä»¶, é‡Œé¢è®°å½•äº†ç¼–è¯‘æ¨¡å¼ä¹‹ç±»çš„ä¿¡æ¯ ```json { \"PROJECT_ID\": \"hello_world\", \"SDK_PATH\": \"/home/jiao/Maix/MaixCDK\", \"PROJECT_PATH\": \"/home/jiao/Maix/MaixCDK/examples/hello_world\", \"MAIXCDK_EXTRA_COMPONENTS_PATH\": \"\", \"PY_PKG_COMPONENTS_PATH\": \"/home/jiao/miniconda3/envs/maix/lib/python3.11/site packages\", \"PY_USR_PKG_COMPONENTS_PATH\": \"\", \"CMAKE_BUILD_TYPE\": \"MinSizeRel\", \"BUILD_TYPE\": \"Release\", \"PLATFORM\": \"linux\", \"CMAKE_GENERATOR\": \"Unix Makefiles\", \"TOOLCHAIN_ID\": \"\", \"DEFAULT_CONFIG_FILE\": \"\", \"PLATFORM_LINUX\": 1 } ``` åŒæ—¶æ ¹æ®ç”¨æˆ·ä¼ å…¥çš„ä¿¡æ¯ç”Ÿæˆä¸€éƒ¨åˆ†æ¯æ¬¡ç¼–è¯‘éƒ½è¦é‡æ–°ç”Ÿæˆçš„é…ç½®ä¿¡æ¯ ### ç”ŸæˆCMakeList.txtæ–‡ä»¶ åœ¨`check_project_cmakelists`å‡½æ•°é‡Œé¢æŸ¥çœ‹æ–‡ä»¶ç›®å½•ä¸‹é¢çš„CMakeList.txtæ˜¯ä¸æ˜¯å­˜åœ¨ ### æŸ¥æ‰¾ç¼–è¯‘ä½¿ç”¨çš„å·¥å…· ä¹‹åä»`platforms/maixcam.yaml`æŸ¥æ‰¾å®é™…ä½¿ç”¨çš„ç¼–è¯‘çš„é…ç½® ```yaml toolchain: name: MUSL toolchain optimize by t head id: musl_t head default: true url: https://github.com/sipeed/MaixCDK/releases/download/v0.0.0/host tools 2025.7.28.tar.xz urls: https://sophon file.sophon.cn/sophon prod s3/drive/23/03/07/16/host tools.tar.gz # old version sites: https://github.com/sophgo/cvi_mmf_sdk sha256sum: 968b179a7faebfe8914e5163b2d85038b71824780fccde0b4b3ee9f67472d007 filename: host tools 2025.7.28.tar.xz path: toolchains/maixcam bin_path: toolchains/maixcam/host tools/gcc/riscv64 linux musl x86_64/bin prefix: riscv64 unknown linux musl c_flags: mcpu c906fdv march rv64imafdcv0p7xthead mcmodel medany mabi lp64d cxx_flags: mcpu c906fdv march rv64imafdcv0p7xthead mcmodel medany mabi lp64d ``` è°ƒç”¨`tools/cmake/check_toolchain.py`æ–‡ä»¶é‡Œé¢çš„mainå‡½æ•° æ›´å…·è¿™ä¸ªé…ç½®æœ€åç”Ÿæˆçš„é…ç½®æ–‡ä»¶`build/config/toolchain_config.cmake` ```cmake set(CONFIG_TOOLCHAIN_PATH \"/home/jiao/Maix/MaixCDK/dl/extracted/toolchains/maixcam/host tools/gcc/riscv64 linux musl x86_64/bin\") set(CONFIG_TOOLCHAIN_PREFIX \"riscv64 unknown linux musl \") ``` ## å®é™…çš„ç¼–è¯‘ ç¼–è¯‘è°ƒç”¨çš„æ˜¯`tools/cmake/build.py`æ–‡ä»¶é‡Œé¢çš„rebuildå‡½æ•° ### get_all_components_dl_info > è¿›è¡Œå¯¹ä¾èµ–çš„ç»„ä»¶è¿›è¡Œä¸‹è½½ CDKé‡Œé¢çš„componenté…ç½®å®é™…æ˜¯ä¸€ä¸ªCmakeæ–‡ä»¶ä»¥åŠä¸€ä¸ªcomponent.pyçš„pythonæ–‡ä»¶, é‡Œé¢è®°å½•ä¸‹è½½è¿™ä¸ªç»„ä»¶ä½¿ç”¨çš„ä¿¡æ¯ ä½¿ç”¨get_components_filesè·å–åˆ°æ‰€æœ‰çš„component.pyé‡Œé¢è®°å½•çš„ä¸‹è½½å‡½æ•°, æœ€åä½¿ç”¨å‡½æ•°`download_extract_files`è¿›è¡Œä¸‹è½½ ```python ''' @param confs kconfig vars, dict type @return list type, items is dict type ''' version \"3.11.3\" url f\"https://github.com/nlohmann/json/releases/download/v3.11.3/json.tar.xz\" if version \"3.11.3\": sha256sum \"d6c65aca6b1ed68e7a182f4757257b107ae403032760ed6ef121c9d55e81757d\" else: raise Exception(f\"version {version} not support\") sites [\"https://github.com/nlohmann/json\"] filename f\"json.tar.xz\" path f\"json_srcs\" check_file 'json' rename { f'json': 'json' } return [ { 'url': f'{url}', 'urls': [], 'sites': sites, 'sha256sum': sha256sum, 'filename': filename, 'path': path, 'check_files': [ check_file ], 'rename': rename } ] ``` ä¸‹è½½çš„å‹ç¼©åŒ…åœ¨`dl/pkgs/json_srcs`è§£å‹ä»¥åçš„æ–‡ä»¶åœ¨`dl/extracted/json_srcs/json` #### find_valid_components ä»æ‰€æœ‰èƒ½æ‰¾åˆ°çš„ç»„ä»¶é‡Œï¼Œåªä¿ç•™ `main` ä»¥åŠè¢« `main` ç›´æ¥æˆ–é—´æ¥ä¾èµ–åˆ°çš„é‚£äº›ç»„ä»¶ é¦–å…ˆä½¿ç”¨æ‰€æœ‰å¯ä»¥æ‰¾åˆ°çš„ç»„ä»¶æ„å»ºä¸€ä¸ªä¾èµ–çš„è¡¨(ä»ä»–ä»¬çš„component.pyæˆ–CMakeList.txtæ–‡ä»¶é‡Œé¢æŸ¥æ‰¾ä¾èµ–), ä¹‹åä½¿ç”¨è¿™ä¸ªä¾èµ–çš„è¡¨å®ç°, ç”±äºè¿™ä¸ªè¡¨é‡Œé¢æ²¡æœ‰ç³»ç»Ÿåº“, æ‰€ä»¥åªæ˜¯æ£€ç´¢å·²ç»æœ‰é…ç½®æ–‡ä»¶çš„ç»„ä»¶ > æ¯æ¬¡ç¼–è¯‘æ—¶ä¼šå°†æ‰€æœ‰éœ€è¦ä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨å†™å…¥åˆ°`dl/pkgs_info.json`ï¼Œç”¨æˆ·æœ‰ç½‘é€Ÿé—®é¢˜çš„å¯ä»¥åˆ°å®˜æ–¹ QQ ç¾¤æˆ–è€…ç¬¬ä¸‰æ–¹æä¾›çš„ç½‘ç›˜æ‰‹åŠ¨ä¸‹è½½æ”¾åˆ°`dl/pkgs`ç›®å½•å³å¯ ``` main > basic > \tini \tyaml \tntp_client ``` #### è¿è¡Œcmakeå‘½ä»¤ ```bash cmake G Unix Makefiles DPROJECT_ID hello_world DSDK_PATH /home/jiao/Maix/MaixCDK DPROJECT_PATH /home/jiao/Maix/MaixCDK/examples/hello_world DMAIXCDK_EXTRA_COMPONENTS_PATH DPY_PKG_COMPONENTS_PATH /home/jiao/miniconda3/envs/maix/lib/python3.11/site packages DPY_USR_PKG_COMPONENTS_PATH DCMAKE_BUILD_TYPE MinSizeRel DBUILD_TYPE Release DPLATFORM maixcam DCMAKE_GENERATOR Unix Makefiles DTOOLCHAIN_ID musl_t head DDEFAULT_CONFIG_FILE DPLATFORM_MAIXCAM 1 DCMAKE_C_FLAGS mcpu c906fdv march rv64imafdcv0p7xthead mcmodel medany mabi lp64d DCMAKE_CXX_FLAGS mcpu c906fdv march rv64imafdcv0p7xthead mcmodel medany mabi lp64d DCMAKE_EXE_LINKER_FLAGS DCMAKE_C_LINK_FLAGS DCMAKE_CXX_LINK_FLAGS .. ``` åœ¨å½“å‰ `build` ç›®å½•é‡Œï¼ŒæŒ‰æŒ‡å®šå‚æ•°ä¸º `hello_world` ç”Ÿæˆ Unix Makefiles çš„å·¥ç¨‹ï¼Œç„¶ååç»­ç”¨ `cmake build .` çœŸæ­£ç¼–è¯‘ **æŠŠ â€œhello_world + MaixCDK + maixcam å¹³å° + æŒ‡å®š toolchain/CPU å‚æ•°â€ è¿™ä¸€æ•´å¥—ä¿¡æ¯å‘Šè¯‰ CMakeï¼Œè®©å®ƒç”Ÿæˆåç»­ `make` è¦ç”¨çš„ Makefile** #### build ```python def build(build_path, configs, toolchain_info, verbose): if not os.path.exists(build_path): rebuild(build_path, configs, toolchain_info, verbose) return os.chdir(build_path) # æŸ¥çœ‹æ˜¯ä¸æ˜¯ä½¿ç”¨è¯¦ç»†è¾“å‡º if verbose: if configs[\"CMAKE_GENERATOR\"] \"Unix Makefiles\": res subprocess.call([\"cmake\", \" build\", \".\", \" target\", \"all\", \" \", \"VERBOSE 1\"]) elif configs[\"CMAKE_GENERATOR\"] \"Ninja\": res subprocess.call([\"cmake\", \" build\", \".\", \" target\", \"all\", \" \", \" v\"]) else: res subprocess.call([\"cmake\", \" build\", \".\", \" target\", \"all\"]) else: \t# å®é™…è¿è¡Œçš„ if configs[\"CMAKE_GENERATOR\"] in [\"Unix Makefiles\", \"Ninja\"]: res subprocess.call([\"cmake\", \" build\", \".\", \" target\", \"all\", \" \", \" j{}\".format(thread_num)]) else: res subprocess.call([\"cmake\", \" build\", \".\", \" target\", \"all\"]) if res ! 0: exit(1) ``` ## CMakeæ–‡ä»¶ ```cmake # !!! This file is auto generated by MaixCDK, don't modify it manually !!! cmake_minimum_required(VERSION 3.13) # æˆ‘è‡ªå·±åŠ çš„ set(CMAKE_EXPORT_COMPILE_COMMANDS ON) # cmake used vars defined in MaixCDK/tools/cmake/project.py's get_configs function include(${SDK_PATH}/tools/cmake/compile.cmake) project(${PROJECT_ID}) ``` CMake ä¼šå»åŒ…å« `MaixCDK/tools/cmake/compile.cmake`ã€‚ è¿™ä¸ªè„šæœ¬é‡Œå®Œæˆäº†æ‰€æœ‰â€œçœŸæ­£çš„æ´»â€ï¼š è¯»å– `build/config/global_config.cmake` å’Œ Kconfig ç”Ÿæˆçš„å„ç§é…ç½®ï¼› æ ¹æ® `PROJECT_PATH` / `PLATFORM` ç­‰å˜é‡æ‰«æç»„ä»¶ç›®å½•ï¼› å¤„ç†å„ `components/**/CMakeLists.txt` é‡Œçš„ `ADD_SRCS` / `ADD_REQUIREMENTS` ç­‰ï¼› å®šä¹‰ç›®æ ‡ï¼ˆå¯æ‰§è¡Œæ–‡ä»¶ / åº“ï¼‰ã€æ·»åŠ  include è·¯å¾„ã€ç¼–è¯‘é€‰é¡¹ã€é“¾æ¥ç³»ç»Ÿåº“ç­‰ã€‚ `project(${PROJECT_ID})` `PROJECT_ID` åŒæ ·æ¥è‡ªå‘½ä»¤è¡Œï¼š` DPROJECT_ID hello_world`ã€‚ è¿™é‡Œå‘Šè¯‰ CMakeï¼šå½“å‰å·¥ç¨‹åå°±å« `hello_world`ã€‚ åç»­ `compile.cmake` ä¼šç”¨è¿™ä¸ªåå­—æ¥ç»™ target å‘½åã€ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åç­‰ã€‚"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-17-08-Cameraç¤ºä¾‹.html":{"title":"Cameraç¤ºä¾‹","content":"# Cameraç¤ºä¾‹ **å„ä¸ªæ–‡ä»¶ä¸»è¦åšä»€ä¹ˆ** [app.hpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) å£°æ˜æ•´ä¸ªç›¸æœºåº”ç”¨çš„ç”Ÿå‘½å‘¨æœŸå‡½æ•°ï¼šapp_pre_init / app_init / app_loop / app_deinit ä»¥åŠ app_base_*ã€‚ æŠŠ UIï¼ˆui_screen / ui_event_handler / ui_utilsï¼‰å’Œ maix çš„ camera / display / touchscreen / lvgl å¤´æ–‡ä»¶éƒ½ä¸²èµ·æ¥ã€‚ [app.cpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼š ç»´æŠ¤ä¸€ä¸ªå¤§çš„ priv çŠ¶æ€ç»“æ„ï¼ˆæ‹ç…§/å½•åƒæ ‡å¿—ã€åˆ†è¾¨ç‡ã€ç ç‡ã€éŸ³é¢‘å¼€å…³ã€æ—¶é—´æˆ³å¼€å…³ã€å®šæ—¶æ‹ã€å»¶æ—¶æ‘„å½±ã€ç¼–ç å™¨ã€ffmpeg_packerã€audio_recorderã€Region è¦†ç›–å›¾å±‚ç­‰ï¼‰ã€‚ åœ¨ app_pre_init é‡Œè¯»å– sensor åˆ†è¾¨ç‡ã€åˆå§‹åŒ– UI é…ç½®ï¼ˆåˆ†è¾¨ç‡åˆ—è¡¨ã€ç ç‡åˆ—è¡¨ç­‰ï¼‰ã€‚ åœ¨ app_init é‡Œæ‰“å¼€ cameraã€æ˜¾ç¤ºå±ã€è§¦æ‘¸å±ï¼Œé…ç½®ç¼–ç å™¨ã€ffmpeg ç­‰ã€‚ åœ¨ app_loop é‡Œå¾ªç¯ï¼š ä» camera å–å¸§ã€åœ¨å±å¹•æ˜¾ç¤ºï¼› æ ¹æ® ui_event_handler æä¾›çš„ ui_get_xxx æ ‡å¿—åˆ¤æ–­æ˜¯å¦æ‹ç…§ã€å¼€å§‹/åœæ­¢å½•åƒã€æ›´æ–°å‚æ•°ï¼› å¤„ç†éŸ³é¢‘å½•åˆ¶ã€è§†é¢‘æ‰“åŒ…ã€æ—¶é—´æˆ³å åŠ ã€timelapse ç­‰ã€‚ è¿™æ˜¯â€œä¸šåŠ¡ä¸­æ¢â€ï¼šUI é€šè¿‡æ ‡å¿—/å‚æ•°å’Œè¿™é‡Œäº¤äº’ï¼Œè¿™é‡Œå†è·Ÿåº•å±‚ç¡¬ä»¶/ä¸­é—´ä»¶æ‰“äº¤é“ã€‚ [app_ex.hpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) æ‰©å±•åŠŸèƒ½æ¨¡å—ï¼Œä¸»è¦ä¸¤å¤§å—ï¼š 1. TMC2209 æ­¥è¿›ç”µæœºæ»‘å°ï¼ˆç”¨äºå¯¹ç„¦/ç„¦ç‚¹å †æ ˆï¼‰ï¼š é€šè¿‡ UART æ‰«æ TMC2209ï¼Œåˆå§‹åŒ– ScrewSlide å¯¹è±¡ï¼Œä¿å­˜å½“å‰æ­¥è·ã€é€Ÿåº¦ç­‰ã€‚ æä¾› tmc2209_exist_c ç»™ C ä»£ç åˆ¤æ–­æ˜¯å¦æ¥äº†æ»‘å°ã€‚ æœ‰ä¸€å †æ­¥é•¿é…ç½®ï¼ˆ2um8ã€22um4ã€1mmã€2mm ç­‰ï¼‰å’Œ TMC2209Status ç»“æ„ï¼Œç»™å¯¹ç„¦ã€ç„¦ç‚¹å †æ ˆä½¿ç”¨ã€‚ 2. é«˜é€Ÿå¿«é—¨è§¦å‘ HP_SHOTï¼ˆé€šè¿‡ GPIO æ§åˆ¶ A15 ç­‰ï¼‰ä»¥åŠå…¶ä»–è§¦å‘é€»è¾‘ã€‚ å’Œ ui_stackã€è‡ªåŠ¨å¯¹ç„¦ç­‰é…åˆï¼Œå±äºâ€œé«˜çº§ç©æ³•â€ã€‚ [ui_screen.h](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) / [ui_screen.c](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) è´Ÿè´£â€œç”»ç•Œé¢â€ï¼šç”¨ LVGL æ­å‡ºæ•´ä¸ªç›¸æœº UIã€‚ å®šä¹‰äº† priv_tï¼ˆå·¦å³å±å®½åº¦ç™¾åˆ†æ¯”ã€delay/resolution/bitrate é…ç½®ç­‰ï¼‰ä»¥åŠå¤§é‡å…¨å±€ lv_obj_t æŒ‡é’ˆï¼ˆå„ç§æŒ‰é’®ã€å›¾ç‰‡ã€å°é¢„è§ˆã€å¤§é¢„è§ˆã€èœå•é¢æ¿ï¼‰ã€‚ left_screen_initï¼šå·¦ä¾§æ˜¯é¢„è§ˆåŒºåŸŸå’Œä¸€åˆ—åŠŸèƒ½æŒ‰é’®ï¼ˆé—ªå…‰ç¯ã€RAWã€ç ç‡ã€æ—¶é—´æˆ³ã€timelapseã€stack ç­‰ï¼‰ã€‚ right_screen_initï¼šå³ä¾§æ˜¯æ¨¡å¼åˆ‡æ¢ï¼ˆæ‹ç…§/å½•åƒï¼‰ã€å¿«é—¨æŒ‰é’®ã€å°ç¼©ç•¥å›¾ï¼Œä»¥åŠ TMC2209 çš„ä¸Šä¸‹æŒ‰é’®ç­‰ã€‚ adjust_screen_initï¼šä¸­é—´ä¸€æ¡å‚æ•°è°ƒèŠ‚æ ï¼ˆSã€ISOã€EVã€WBï¼‰ç­‰ã€‚ screen_delay_initã€screen_resolution_initã€screen_bitrate_initã€screen_timelapse_initï¼šå››ä¸ªå¼¹å‡ºè®¾ç½®é¢æ¿ï¼Œå¯¹åº”å»¶æ—¶æ‹ã€åˆ†è¾¨ç‡ã€ç ç‡ã€timelapseã€‚ å†…éƒ¨ä¼šç”¨ ui_camera_config_tï¼ŒæŠŠ app ä¾§ç»™çš„åˆ†è¾¨ç‡/ç ç‡é…ç½®æ¸²æŸ“æˆæŒ‰é’®åˆ—è¡¨ã€‚ [ui_event_handler.h](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) / [ui_event_handler.c](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) â€œäº‹ä»¶é€»è¾‘å±‚â€å’Œâ€œUI çŠ¶æ€ç¼“å†²åŒºâ€ï¼š å®šä¹‰æ‰€æœ‰ LVGL å›è°ƒå‡½æ•°ï¼ševent_touch_xxx_cbã€event_iso_bar_update_cb ç­‰ï¼Œå“åº”æŒ‰é’®ç‚¹å‡»ã€æ»šåŠ¨ã€æ»‘æ¡æ”¹å˜ã€‚ å†…éƒ¨æœ‰ä¸€ä¸ª priv ç»“æ„ä¿å­˜å„ç§æ ‡å¿—ï¼šæ‹ç…§/å½•åƒå¼€å§‹/åœæ­¢ã€é€€å‡ºã€å½“å‰æ˜¯å¦åœ¨çœ‹ç…§ç‰‡ã€å“ªç§è®¾ç½®é¢æ¿æ‰“å¼€ã€æ˜¯å¦è‡ªåŠ¨æ›å…‰/è‡ªåŠ¨ ISO/è‡ªåŠ¨ WBã€RAW/å…‰æº/æ—¶é—´æˆ³æŒ‰é’®çš„è§¦æ‘¸ä¸æ›´æ–°æ ‡å¿—ã€åˆ†è¾¨ç‡/ç ç‡/timelapse çš„å½“å‰å€¼ç­‰ç­‰ã€‚ å¯¹å¤–æä¾›ä¸€å † ui_get_xxx / ui_set_xxx / ui_update_xxx å‡½æ•°ï¼š [app.cpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) æ¯ä¸€å¸§åœ¨ app_loop é‡Œé€šè¿‡è¿™äº›å‡½æ•°è¯»å–â€œç”¨æˆ·è¯·æ±‚â€ï¼ˆæ¯”å¦‚ ui_get_cam_snap_flagã€ui_get_cam_video_start_flagã€ui_get_resulutionã€ui_get_bitrateã€ui_get_timelapse_s ç­‰ï¼‰ï¼Œç„¶åæ‰§è¡Œå®é™…æ“ä½œã€‚ åŒæ—¶æŠŠç»“æœå›å†™åˆ° UIï¼ˆæ¯”å¦‚ ui_update_small_imgã€ui_set_record_timeã€ui_set_bitrateã€ui_set_timelapse_s ç­‰ï¼‰ã€‚ å¯ä»¥ç†è§£ä¸ºï¼šå®ƒæŠŠ LVGL çš„äº‹ä»¶å›è°ƒè½¬æˆä¸€ä¸ªæ¯”è¾ƒæ˜“ç”¨çš„â€œçŠ¶æ€æ¥å£â€ç»™ä¸šåŠ¡é€»è¾‘ç”¨ã€‚ [ui_utils.h](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) / [ui_utils.c](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) å’Œç…§ç‰‡æ–‡ä»¶ç›¸å…³çš„è¾…åŠ©å·¥å…·ï¼š ui_list_valid_picture_pathï¼šéå†æŒ‡å®šç›®å½•ï¼ˆæŒ‰æ—¥æœŸå­ç›®å½• yyyy mm ddï¼‰ï¼Œæ‰“å°æ‰€æœ‰ jpg/jpeg æ–‡ä»¶ã€‚ ui_find_latest_pictureï¼šåœ¨è¿™äº›æ—¥æœŸç›®å½•ä¸­æ‰¾åˆ°æœ€æ–°æ—¥æœŸã€å†ä»é‡Œé¢é€‰ä¿®æ”¹æ—¶é—´æœ€å¤§çš„é‚£å¼ ç…§ç‰‡ï¼Œè¿”å›è·¯å¾„ï¼ˆéœ€è¦ freeï¼‰ã€‚ ui_get_sys_dateï¼šè¿”å›å½“å‰ç³»ç»Ÿæ—¥æœŸå­—ç¬¦ä¸²ï¼ˆéœ€è¦ freeï¼‰ã€‚ ä¸»è¦ç»™â€œæŸ¥çœ‹æœ€è¿‘ç…§ç‰‡â€â€œæŒ‰æ—¥æœŸå»ºç›®å½•â€ä¹‹ç±»é€»è¾‘æœåŠ¡ã€‚ [focus.hpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) / [focus.cpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) è‡ªåŠ¨å¯¹ç„¦/è¾…åŠ©å¯¹ç„¦ç®—æ³•ï¼š å®šä¹‰äº†ä¸€å¥—æ¥å£ï¼š IContrastAlgoï¼ˆå¯¹ç„¦è¯„ä»·ç®—æ³•æ¥å£ï¼‰ï¼Œæœ‰å¤šç§å®ç°ï¼šæ–¹å·®ã€æ¢¯åº¦èƒ½é‡ã€Brennerã€Laplace ç­‰ã€‚ ICVMatCreater / IImageCreater / IImageCropper ç­‰ï¼ŒæŠŠ maix::image::Image è½¬æˆ cv::Matã€ç°åº¦å›¾ã€è£å‰ªä¸ºä¸­å¿ƒåŒºåŸŸç­‰ã€‚ FullScan ç­‰å¯¹ç„¦æ‰«æå™¨ï¼šé©±åŠ¨æ»‘å°ä¸æ–­ç§»åŠ¨ï¼Œé‡‡é›†ä¸åŒä½ç½®çš„æ¸…æ™°åº¦ï¼Œå¯¹æ¯”ç»“æœæ‰¾åˆ°æœ€ä½³ç„¦ç‚¹ï¼›å†…éƒ¨è¿˜æ”¯æŒä¿å­˜åˆ†ææ•°æ®åˆ°æ–‡ä»¶ã€‚ ä½¿ç”¨ OpenCV åšå›¾åƒè¿ç®—ï¼Œç»“åˆ maix::image çš„æ ¼å¼è½¬æ¢ã€‚ å’Œ [app_ex.hpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) é‡Œçš„ TMC2209 æ»‘å°ã€ä»¥åŠ UI ä¸­çš„å¯¹ç„¦/stack åŠŸèƒ½è”åŠ¨ã€‚ [region.hpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) ä»¥åŠ [region.cpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html)ã€[region.cpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html)ã€[region.cpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) Region ç±»ï¼šåœ¨è§†é¢‘å›¾åƒä¸Šå åŠ ä¸€ä¸ªâ€œåŒºåŸŸâ€ï¼ˆoverlayï¼‰ï¼Œç”¨äºç”»å°å›¾/æ ‡è®°æ¡†ç­‰ã€‚ æ„é€ å‡½æ•°ä¸­ç»‘å®š camera é€šé“ï¼Œåœ¨ sophgo_middleware ä¸­åˆ›å»ºåŒºåŸŸï¼›get_canvas è·å–ç”»å¸ƒæŒ‡é’ˆï¼ŒåŒ…è£…æˆ maix::image::Imageï¼›update_canvas æŠŠä½ ç”»å¥½çš„å†…å®¹ï¼ˆBGRA8888ï¼‰å†™å›ç¡¬ä»¶ overlayã€‚ ä¸åŒå¹³å°ä¸‹çš„ [region.cpp](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) å®ç°å¯èƒ½ç•¥æœ‰å·®å¼‚ï¼Œä½†æ¥å£ä¸€è‡´ã€‚"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-11-03-å¸¸ç”¨çš„æ¨¡å‹.html":{"title":"å¸¸ç”¨æ¨¡å‹","content":"# å¸¸ç”¨æ¨¡å‹ ## MobileNet Google é’ˆå¯¹æ‰‹æœºå’ŒåµŒå…¥å¼åœºæ™¯æå‡ºçš„ä¸€ç§è½»é‡çº§çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå…¶ä¸»è¦ç‰¹ç‚¹æ˜¯ä½¿ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆdepthwise separable convolutionï¼‰æ¥æ›¿ä»£æ™®é€šå·ç§¯ï¼Œä»è€Œå‡å°‘è®¡ç®—é‡ï¼Œæé«˜ç½‘ç»œçš„è®¡ç®—æ•ˆç‡ã€‚è¯¥ç½‘ç»œåœ¨ ImageNet æ•°æ®é›†ä¸Šçš„åˆ†ç±»ç²¾åº¦è¾¾åˆ°äº† 70.8%ï¼Œåœ¨æŸå¤±äº†ä¸å¤šç²¾åº¦çš„æƒ…å†µä¸‹ï¼Œæå¤§åœ°å‡å°‘äº†è®¡ç®—é‡ > ç›®æ ‡: æŒ‰é¡ºåºè¾“å…¥è‹¥å¹²å¼ å›¾åƒï¼Œè¾“å‡ºæ¯å¼ å›¾åƒå±äºå“ªä¸ªåˆ†ç±»ï¼Œä»¥åŠè¯¥åˆ†ç±»çš„ç½®ä¿¡åº¦ ### åŸç† ä½¿ç”¨å·ç§¯æå–å›¾ç‰‡çš„ç‰¹å¾, å¯ä»¥åœ¨[TensorSpace Playground MobileNetv1](https://tensorspace.org/html/playground/mobilenetv1.html)è¿™é‡Œçœ‹åˆ° ç»è¿‡æ•´ä¸ªç”±æ— æ•°ä¸ªå·ç§¯è®¡ç®—å’Œå…¶å®ƒè®¡ç®—ç»„æˆçš„ç½‘ç»œè®¡ç®—ï¼Œæœ€åè¾“å‡ºä¸€ä¸ªåªæœ‰ 1000 ä¸ªåƒç´ ç‚¹çš„å›¾åƒï¼Œä¸åŒåˆ†ç±»çš„å›¾è¾“å…¥ï¼Œåœ¨è¾“å‡ºå±‚çš„ 1000 ä¸ªåƒç´ ç‚¹ä¸­ï¼Œå…¶ä¸­ä¸€ä¸ªåƒç´ ç‚¹çš„å€¼ä¼šè¾ƒå¤§ï¼Œè¿™ä¸ªåƒç´ ç‚¹å¯¹åº”çš„åˆ†ç±»å°±æ˜¯ç½‘ç»œçš„è¾“å‡ºç»“æœã€‚æ¯”å¦‚ä¸€åªç†ŠçŒ«å›¾åƒè¾“å…¥ï¼Œå¦‚æœè¾“å‡ºå±‚çš„ç¬¬ 388 ä¸ªåƒç´ ç‚¹çš„å€¼è¾ƒå¤§ï¼Œå¹¶ä¸”å€¼ä¸º 0.8ï¼Œæˆ‘ä»¬å°±é€šè¿‡è¿™ä¸ªç½‘ç»œè¯†åˆ«åˆ°äº†è¿™å¼ å›¾åƒæ˜¯ä¸€åªç†ŠçŒ« > æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆDepthwise Separable Convolutionï¼‰æ˜¯ä¸€ç§æŠŠæ ‡å‡†å·ç§¯åˆ†è§£æˆä¸¤æ­¥çš„å·ç§¯æ“ä½œï¼Œæ—¨åœ¨é™ä½å‚æ•°é‡å’Œè®¡ç®—é‡ã€‚å®ƒé€šå¸¸åŒ…å«ä¸¤éƒ¨åˆ†ï¼š > > 1. **Depthwise å·ç§¯ï¼ˆé€é€šé“å·ç§¯ï¼‰**ï¼šå¯¹æ¯ä¸ªè¾“å…¥é€šé“ç‹¬ç«‹åº”ç”¨ä¸€ä¸ªç©ºé—´å·ç§¯ï¼ˆå¦‚ 3x3ï¼‰ï¼Œä¸è·¨é€šé“æ··åˆã€‚ > 2. **Pointwise å·ç§¯ï¼ˆ1x1 å·ç§¯ï¼‰**ï¼šç”¨ä¸€ä¸ª 1x1 çš„å·ç§¯æ ¸å¯¹æ¯ä¸ªåƒç´ ç‚¹çš„é€šé“è¿›è¡Œçº¿æ€§ç»„åˆï¼Œä»è€Œå®ç°è·¨é€šé“çš„ä¿¡æ¯æ··åˆã€‚ > > ä¸ä¼ ç»Ÿçš„æ ‡å‡†å·ç§¯ç›¸æ¯”ï¼Œæ·±åº¦å¯åˆ†ç¦»å·ç§¯æŠŠä¸€ä¸ª DkÃ—Dk*D**k*Ã—*D**k* çš„å·ç§¯æ ¸çš„è®¡ç®—é‡ä» CinÃ—CoutÃ—Dk2*C**in*Ã—*C**o**u**t*Ã—*D**k*2 é™ä½åˆ°ï¼š > > Depthwiseï¼šCinÃ—Dk2Ã—HÃ—W*C**in*Ã—*D**k*2Ã—*H*Ã—*W*ï¼ˆæ¯ä¸ªè¾“å…¥é€šé“ä¸€ä¸ªå·ç§¯æ ¸ï¼‰ > Pointwiseï¼šCinÃ—CoutÃ—HÃ—W*C**in*Ã—*C**o**u**t*Ã—*H*Ã—*W*ï¼ˆ1x1 è·¨é€šé“æ··åˆï¼‰ > > æ€»é‡çº¦ç­‰äºæ ‡å‡†å·ç§¯çš„ä¸€ä¸ªåˆ†æ•°ï¼Œä¾èµ–äºé€šé“æ•°å’Œæ ¸å¤§å°ã€‚ ## Yolov2 YOLO(You Only Look Once) v2 æˆåŠŸè®©ç›®æ ‡æ£€æµ‹è¾¾åˆ°å®æ—¶çš„åŒæ—¶ï¼Œæœ‰ç€è¾ƒé«˜æ£€æµ‹å‡†ç¡®ç‡ï¼Œæ­£å¦‚å…¶åå­—ä¸€æ ·ï¼Œä½ åªéœ€è¦çœ‹ä¸€çœ¼ï¼Œå°±èƒ½çŸ¥é“ç»“æœ YOLO v2 å› å…¶æ£€æµ‹æ•ˆç‡é«˜ï¼Œå¯ä»¥åœ¨æ€§èƒ½ä¸æ˜¯å¾ˆå¼ºçš„è¾¹ç¼˜è®¾å¤‡è¿è¡Œï¼Œä¸è¿‡ä¹Ÿæœ‰ç¼ºç‚¹ï¼Œå°±æ˜¯å¯¹äºå°ç‰©ä½“çš„æ£€æµ‹èƒ½åŠ›ä¸å¤Ÿ > ç›®æ ‡: è¾“å…¥ä¸€å¼ å›¾ç‰‡ï¼Œè¾“å‡ºå›¾ç‰‡ä¸­çš„ç›®æ ‡ç±»åˆ«å’Œä½ç½®ï¼Œèƒ½åŒæ—¶æ£€æµ‹å¤šä¸ªç‰©ä½“ã€‚ YOLOV2 ä¸»å¹²ç½‘ç»œä¹Ÿæ˜¯å·ç§¯ç½‘ç»œï¼Œè¾“å‡ºå±‚åˆ™ä½¿ç”¨äº† S x S x B(4 + 1 + C) è¿™æ ·ä¸€ä¸ªä¸‰ç»´ç»“æ„ï¼Œå…¶ä¸­ S æ˜¯ç½‘æ ¼çš„å¤§å°ï¼ŒB æ˜¯æ¯ä¸ªç½‘æ ¼é¢„æµ‹çš„è¾¹ç•Œæ¡†æ•°é‡(Anchor æ•°é‡ï¼‰ï¼Œ 4 ä¸ªé¢„æµ‹æ¡†çš„åæ ‡å€¼ï¼ˆxmin,ymin,xmax,ymaxï¼‰ï¼Œ 1 ä¸ªç½®ä¿¡åº¦ï¼ŒC æ˜¯ç±»åˆ«æ•°é‡ > åœ¨ S x S ä¸ªç½‘æ ¼ä¸­ï¼Œæ¯ä¸ªç½‘æ ¼é¢„æµ‹ B ä¸ªæ¡†ï¼Œæ¯ä¸ªæ¡†æœ‰ 5 ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯ x, y, w, h, p, æœ€å C ä¸ªå‚æ•°åˆ†åˆ«æ˜¯å¯¹åº”ç±»åˆ«çš„æ¦‚ç‡ å¯¹äºè¿™ B ä¸ªæ¡†ï¼Œé¢„å…ˆæˆ‘ä»¬æ‰‹åŠ¨ç¡®å®šäº† B ä¸ª anchorï¼ˆé¢„é€‰æ¡†ï¼‰ï¼Œæ¯ä¸ª anchor æœ‰ w, h ä¸¤ä¸ªå‚æ•°ï¼Œè¿™é‡Œ B ä¸ªé¢„æµ‹æ¡†çš„ w, h æ˜¯ç›¸å¯¹äºè¿™ B ä¸ª anchor çš„ç¼©æ”¾ç³»æ•°ï¼Œè¿™æ ·é¢„æµ‹æ¡†çš„ w, h å°±å¯ä»¥æ˜¯ä»»æ„å€¼äº† > è¿™ B ä¸ª Anchor æ˜¯ä½¿ç”¨ K Means ç®—æ³•å¯¹è®­ç»ƒçš„æ•°æ®æ‰€æœ‰æ ‡æ³¨æ¡†çš„å®½é«˜èšç±»å¾—åˆ°çš„ï¼Œèšç±»çš„ç›®æ ‡æ˜¯è®©æ¯ä¸ª anchor çš„å®½é«˜æ¯”æ¥è¿‘çœŸå®æ¡†çš„å®½é«˜æ¯”ï¼Œè¿™æ ·é¢„æµ‹æ¡†çš„å®½é«˜æ¯”å°±ä¼šæ›´æ¥è¿‘çœŸå®æ¡†çš„å®½é«˜æ¯”ï¼Œä»è€Œæé«˜æ£€æµ‹ç²¾åº¦ã€‚æ‰€ä»¥ä»£ç é‡Œé¢ä¼šæœ‰ä¸€ä¸ª anchors å‚æ•°ï¼Œè¿™ä¸ªå‚æ•°å°±æ˜¯æˆ‘ä»¬è®­ç»ƒçš„æ—¶å€™ç»Ÿè®¡è®­ç»ƒæ•°æ®å¾—åˆ°çš„ B ä¸ª anchorï¼Œå®é™…åœ¨è·‘æ¨¡å‹æ—¶ä¸€å®šè¦ä¿è¯è¿™ä¸ªå‚æ•°å’Œè®­ç»ƒæ—¶çš„ä¸€è‡´ åœ¨è·å¾—æ‰€æœ‰é¢„æµ‹æ¡†åï¼Œè¿˜éœ€è¦å¯¹é¢„æµ‹æ¡†è¿›è¡Œè¿‡æ»¤ï¼Œå»é™¤ä¸€äº›ç½®ä¿¡åº¦ä½çš„æ¡†ï¼Œå³ä¸Šé¢è¯´çš„ pï¼Œè¿™ä¹Ÿå°±æ˜¯æˆ‘ä»¬åœ¨ä»£ç é‡Œçœ‹åˆ°çš„é˜ˆå€¼ï¼ˆthresholdï¼‰; ä»¥åŠéœ€è¦è¿›è¡Œ nmsï¼ˆnon maximum suppression/éæå¤§å€¼æŠ‘åˆ¶ï¼‰ è®¡ç®—å»é™¤é¢„æµ‹å‡ºç›¸åŒåˆ†ç±»å¹¶ä¸”æœ‰å¤ªå¤šé‡å éƒ¨åˆ†çš„æ¡†ï¼Œä¿ç•™æ¦‚ç‡å¤§çš„ä¸€ä¸ªå³å¯ï¼Œæ‰€ä»¥ä»£ç é‡Œé¢æˆ‘ä»¬çœ‹åˆ°æœ‰ä¸€ä¸ª nms_threshold å‚æ•°ï¼Œè¿™ä¸ªå‚æ•°å°±æ˜¯ç”¨æ¥è¿‡æ»¤ IOUï¼ˆä¸¤ä¸ªæ¡†çš„ç›¸äº¤åŒºåŸŸï¼ˆäº¤é›†ï¼‰é¢ç§¯/å¹¶é›†é¢ç§¯ï¼‰å¤§äºè¿™ä¸ªé˜ˆå€¼çš„æ¡†çš„ ## FOMO FOMO(Faster Objects, More Objects) æ˜¯ç”± Edgeimpulse å·¥ç¨‹å¸ˆæå‡ºçš„ä¸€ç§è½»é‡çº§çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œå…¶ä¸»è¦ç‰¹ç‚¹æ˜¯æ¨¡å‹éå¸¸å°ï¼Œè®¡ç®—é‡ä¹Ÿå¾ˆå°ï¼Œè¡¨ç°å‡ºæ¥å°±æ˜¯é€Ÿåº¦éå¸¸å¿«ï¼Œç²¾åº¦ä¹Ÿä¸é”™ > è¾“å…¥å›¾ç‰‡ï¼Œæ£€æµ‹ç›®æ ‡çš„ä½ç½®å’Œå¤§å°ï¼Œå¹¶è¯†åˆ«å‡ºç‰©ä½“çš„ç±»åˆ«ï¼Œèƒ½åŒæ—¶æ£€æµ‹å¤šä¸ªç‰©ä½“ã€‚ å’Œ YOLO v2 ç±»ä¼¼ï¼Œç›®çš„éƒ½æ˜¯æ£€æµ‹åˆ°ç‰©ä½“ï¼Œä½†æ˜¯ YOLO v2 çš„åå¤„ç†è¿˜æ˜¯æ¯”è¾ƒå¤æ‚ï¼Œæœ‰å¤§é‡çš„æ¡†éœ€è¦å¤„ç†ï¼Œæƒ³åœ¨æ²¡æœ‰ç¡¬ä»¶åŠ é€Ÿçš„å•ç‰‡æœºä¸Šè¿è¡Œè¿˜æ˜¯å¾ˆåƒåŠ›çš„ FOMO é‡‡ç”¨æ›´ç®€å•çš„æ€è·¯æ¥åšæ£€æµ‹ï¼š ä½¿ç”¨ä¸€ä¸ªç»å…¸ç½‘ç»œä½œä¸ºç‰¹å¾æå–å™¨ï¼Œæ¯”å¦‚ MobileNet v1ï¼Œ ç„¶åä»ç½‘ç»œä¸­é—´æˆªæ–­ï¼Œå¾—åˆ°ä¸€ä¸ªç‰¹å¾å›¾ï¼Œè¿™ä¸ªç‰¹å¾å›¾çš„å¤§å°æ˜¯ n x n x c, n æ˜¯ç‰¹å¾å›¾çš„å®½é«˜ï¼Œc æ˜¯ç‰¹å¾å›¾çš„é€šé“æ•° è¿™é‡Œ n çš„å–å€¼å–å†³äºä»ç½‘ç»œå“ªé‡Œæˆªæ–­ï¼Œæ¯”å¦‚æˆ‘ä»¬è¾“å…¥åˆ†è¾¨ç‡æ˜¯ 128 x 128, æƒ³è¦ä¸€ä¸ª 8 x 8 çš„ç‰¹å¾å›¾è¾“å‡ºï¼Œç›¸å½“äºæŠŠå›¾ç‰‡åˆ†è¾¨ç‡é™ä½äº† 16 å€ï¼Œä»ç½‘ç»œæ‰¾åˆ°è¯¥å±‚æˆªæ–­å¾—åˆ° 8 x 8 çš„ç‰¹å¾å›¾ è¿™ä¸ª n x n x cï¼Œ c ä»£è¡¨äº†æœ‰ c ä¸ªåˆ†ç±»ï¼Œæ¯ä¸€å±‚ç”¨æ¥æ‰¾ä¸€ä¸ªåˆ†ç±»çš„ç‰©ä½“çš„ä½ç½®ï¼Œæ¯å±‚æœ‰ n x n ä¸ªåƒç´ ï¼Œæ¯ä¸ªåƒç´ ä»£è¡¨äº†åœ¨è¯¥ä½ç½®æ˜¯å¦æœ‰è¯¥åˆ†ç±»çš„ç‰©ä½“ï¼ˆçš„ç½®ä¿¡åº¦ï¼‰ éå†è¿™ä¸ª n x n x c çš„ç‰¹å¾å›¾ï¼Œæ‰¾åˆ°ç½®ä¿¡åº¦è¶…è¿‡è®¾ç½®çš„é˜ˆå€¼çš„åƒç´ åæ ‡ï¼Œæˆ‘ä»¬å°±è®¤ä¸ºè¿™äº›åœ°æ–¹æœ‰ç‰©ä½“å­˜åœ¨ï¼Œç„¶åæŒ‰ç…§ç¼©æ”¾æ¯”ä¾‹æ˜ å°„åˆ°åŸå›¾ï¼Œæ¯”å¦‚åªæœ‰ä¸€ä¸ªåˆ†ç±»å³ c ä¸º 1 æ—¶ï¼Œæˆ‘ä»¬è¦æ£€æµ‹ä¸€ä¸ªæ¯å­ï¼Œå¾—åˆ°å¦‚ä¸‹çš„ç»“æœ ![img](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512112252246.jpeg) åœ¨å¾—åˆ°äº†ä¸€å¤§å †çœ‹èµ·æ¥æœ‰æ•ˆçš„åæ ‡ç‚¹åï¼Œæˆ‘ä»¬è®¤ä¸ºè¿™äº›åœ°æ–¹æœ‰ç‰©ä½“å­˜åœ¨ï¼Œä½†æ˜¯æœ‰ä¸€å¤§å †ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°å°†æŒ¨ç€çš„ç‚¹åˆå¹¶æˆä¸€ä¸ªæ¡†ï¼Œè¿™æ ·å°±å¾—åˆ°äº†ä¸€ä¸ªå¤§æ¡† `mobilenetv1_0.25_8`è¿™æ ·çš„åå­—ä»£è¡¨ä½¿ç”¨äº†`mobilenetv1`ç½‘ç»œï¼Œ alpha ä¸º 0.25, è¿™ä¸ªæ•°å€¼è¶Šå°ç½‘ç»œè¶Šå°ï¼Œå‡†ç¡®ç‡è¶Šä½ï¼Œæœ€åé¢çš„ 8 åˆ™ä»£è¡¨äº†è¾“å‡ºåˆ†è¾¨ç‡æ˜¯è¾“å…¥åˆ†è¾¨ç‡çš„ 1/8 ï¼Œæ¯”å¦‚ è¾“å…¥ 128x128ï¼Œè¾“å‡ºå°±æ˜¯ 16x16ï¼Œè¾“å‡ºçš„åˆ†è¾¨ç‡è¶Šå¤§è¶Šé€‚åˆæ£€æµ‹å°ä¸€ç‚¹çš„ç‰©ä½“ï¼Œæ ¹æ®ä½ çš„å•ç‰‡æœºæ€§èƒ½å’Œè¢«æ£€æµ‹çš„ç‰©ä½“å¤§å°æ¥é€‰æ‹©ã€‚ > å®šä¹‰ï¼šalpha æ˜¯å®½åº¦ä¹˜å­ï¼Œç”¨æ¥æŒ‰æ¯”ä¾‹ç¼©æ”¾æ¯å±‚çš„é€šé“æ•°ã€‚è‹¥åŸºçº¿ Mobilenetv1 æŸä¸€å±‚æœ‰ C ä¸ªè¾“å‡ºé€šé“ï¼Œä½¿ç”¨ alpha 0.25 æ—¶ï¼Œè¯¥å±‚å®é™…è¾“å‡ºé€šé“æ•°ä¸º 0.25 Ã— Cï¼ˆé€šå¸¸å–æ•´åˆ°æœ€è¿‘çš„æ•´æ•°ï¼‰ã€‚ > ä½œç”¨ï¼š > æ¨¡å‹è§„æ¨¡å˜å°ï¼šé€šé“æ•°å‡å°‘ï¼Œå‚æ•°é‡å’Œæµ®ç‚¹è¿ç®—é‡ï¼ˆFLOPsï¼‰æ˜¾è‘—é™ä½ã€‚ > æ¨ç†é€Ÿåº¦æé«˜ï¼šæ›´å°‘çš„è®¡ç®—å’Œå†…å­˜å¸¦å®½éœ€æ±‚é€šå¸¸å¸¦æ¥æ›´å¿«çš„æ¨ç†ï¼Œç‰¹åˆ«æ˜¯åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šã€‚"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-19-08-æ¨¡å‹å®ç°.html":{"title":"æ¨¡å‹å®ç°","content":"# æ¨¡å‹å®ç° ```cpp class YOLOv8 : public YOLO11 YOLOv8(const string &model \"\", bool dual_buff true) : YOLO11(model, \"yolov8\", dual_buff) { } ``` YOLOv8çš„æ¨¡å‹å®é™…æ˜¯ä½¿ç”¨YOLOv11çš„æ¨¡å‹çš„å®ç°, ä½¿ç”¨type_stråŒºåˆ†ä¸åŒçš„æ¨¡å‹ ä½¿ç”¨ä¸‹é¢çš„ç»“æ„ä½“è®°å½•æ¨¡å‹åœ¨è½¬æ¢ä¸ºNPUæ¨¡å‹ä»¥åå¾—è¾“å‡ºä½ç½® ```cpp struct _OutIdxes { // mode 1 int det0; // 1x144x80x80 int det1; // 1x144x40x40 int det2; // 1x144x20x20 // mode 2 int dfl; // 1x1x4x8400 int sigmoid; // 1x80x8400 // optional node // seg mask 1x32x160x160 // seg mask weight 1x32x8400 int seg_mask; int seg_mask_weight; // obb 1x1x8400 int obb_angle; // pose 1x51x8400 int pose; }; ``` `det0 / det1 / det2`ï¼ˆmode 1ï¼‰ åˆ†åˆ«å¯¹åº” 3 ä¸ªä¸åŒå°ºåº¦çš„æ£€æµ‹ç‰¹å¾å›¾ï¼š `det0`: 1Ã—144Ã—80Ã—80ï¼ˆstride 8ï¼Œå¤§ç‰¹å¾å›¾ï¼Œæ£€æµ‹å°ç›®æ ‡ï¼‰ `det1`: 1Ã—144Ã—40Ã—40ï¼ˆstride 16ï¼‰ `det2`: 1Ã—144Ã—20Ã—20ï¼ˆstride 32ï¼Œå°ç‰¹å¾å›¾ï¼Œæ£€æµ‹å¤§ç›®æ ‡ï¼‰ é€šå¸¸ channel æ•° `num_classes + reg_max*4`ï¼Œé‡Œé¢æ—¢æœ‰åˆ†ç±»åˆ†æ•°ä¹Ÿæœ‰ bbox å›å½’åˆ†å¸ƒã€‚ `dfl`ï¼ˆmode 2ï¼‰ DFLï¼ˆDistribution Focal Lossï¼‰å›å½’è¾“å‡ºçš„ç´¢å¼•ã€‚ å½¢çŠ¶ç±»ä¼¼ 1Ã—1Ã—4Ã—8400 æˆ– 1Ã—4Ã—8400Ã—1ï¼Œå¯¹åº”æ¯ä¸ª anchor çš„ 4 ä¸ªè¾¹ç•Œæ¡†è·ç¦»çš„ç¦»æ•£åˆ†å¸ƒã€‚ `sigmoid`ï¼ˆmode 2ï¼‰ åˆ†ç±»/ç½®ä¿¡åº¦è¾“å‡ºçš„ç´¢å¼•ã€‚ å½¢çŠ¶ç±»ä¼¼ 1Ã—80Ã—8400ï¼ˆ80 ç±» Ã— 8400 anchorï¼‰ï¼Œåå¤„ç†æ—¶ä¼šåš sigmoid å¾—åˆ°æ¯ä¸€ç±»çš„æ¦‚ç‡ã€‚ `seg_mask`ï¼ˆå¯é€‰ï¼Œåˆ†å‰²æ¨¡å‹ï¼‰ è¯­ä¹‰åˆ†å‰²çš„ç‰¹å¾å›¾ï¼ˆå¦‚ 1Ã—32Ã—160Ã—160ï¼‰ï¼Œæ˜¯â€œåŸå§‹æ©ç ç‰¹å¾â€ã€‚ åå¤„ç†æ—¶ï¼Œä¼šé€šè¿‡ `seg_mask_weight` å’Œæ£€æµ‹åˆ°çš„æ¡†ä¸€èµ·ï¼Œç»„åˆå‡ºæ¯ä¸ªç›®æ ‡çš„æœ€ç»ˆåˆ†å‰²æ©ç ã€‚ `seg_mask_weight`ï¼ˆå¯é€‰ï¼Œåˆ†å‰²æ¨¡å‹ï¼‰ å¯¹åº”æ¯ä¸ª anchor çš„ mask æƒé‡ï¼ˆ1Ã—32Ã—8400ï¼‰ã€‚ å¯ä»¥ç†è§£ä¸ºæ¯ä¸ªç›®æ ‡åœ¨ 32 ä¸ª mask é€šé“ä¸Šçš„çº¿æ€§ç»„åˆç³»æ•°ï¼Œç”¨æ¥ä» `seg_mask` ç”Ÿæˆè¯¥ç›®æ ‡çš„åƒç´ çº§æ©ç ã€‚ `obb_angle`ï¼ˆå¯é€‰ï¼Œæ—‹è½¬æ¡† OBB æ¨¡å‹ï¼‰ æ—‹è½¬æ¡†çš„è§’åº¦è¾“å‡ºèŠ‚ç‚¹ç´¢å¼•ï¼ˆ1Ã—1Ã—8400ï¼‰ï¼Œæ¯ä¸ª anchor ä¸€ä¸ªè§’åº¦å€¼ã€‚ æœ‰çš„æ¨¡å‹è§’åº¦è¾“å‡ºéœ€è¦ sigmoid æ˜ å°„åˆ°è§’åº¦èŒƒå›´ï¼Œæœ‰çš„åˆ™ä¸éœ€è¦ï¼Œæ‰€ä»¥ä»£ç é‡Œè¿˜æœ‰ `_obb_need_sigmoid` æ¥åŒºåˆ†ã€‚ `pose`ï¼ˆå¯é€‰ï¼Œå§¿æ€/å…³é”®ç‚¹æ¨¡å‹ï¼‰ å…³é”®ç‚¹è¾“å‡ºçš„ç´¢å¼•ï¼ˆçº¦ 1Ã—51Ã—8400ï¼š17 ç‚¹Ã—(x,y,score)Ã—8400ï¼‰ã€‚ åå¤„ç†æ—¶ä¼šæ ¹æ®è¿™ä¸ªèŠ‚ç‚¹è§£å‡ºæ¯ä¸ªæ£€æµ‹æ¡†é‡Œçš„å…³é”®ç‚¹åæ ‡å’Œç½®ä¿¡åº¦ã€‚ ## æ¨¡å‹åŠ è½½ ```cpp _model new nn::NN(model, _dual_buff); ``` é¦–å…ˆä½¿ç”¨åŠ è½½çš„`_model`å®é™…ç”¨æ¥åŠ è½½æ¨¡å‹, é¦–å…ˆæ¯”å¯¹ä¸€ä¸‹æ¨¡å‹çš„typeæ˜¯ä¸æ˜¯å¯¹çš„, ä½¿ç”¨`std::map<std::string, std::string> extra_info();`è·å–é…ç½®æ–‡ä»¶é‡Œé¢çš„ä¿¡æ¯ + æ¯”å¯¹æ¨¡å‹çš„ç±»å‹ + åŠ è½½`mean/scale`åˆ°æ•°ç»„é‡Œé¢ + è·å–åˆ°å®é™…çš„åˆ†ç±»çš„labelså¯¹åº”çš„åå­— + ä½¿ç”¨çš„åˆ†ç±»ç±»å‹ + åˆ¤æ–­ä¸€ä¸‹æ¨¡å‹çš„è¾“å…¥å¼ é‡çš„å½¢çŠ¶ï¼ˆä¾‹å¦‚ `[1, 3, 640, 640]` æˆ– `[1, 640, 640, 3]`ï¼‰, è®°å½•åœ¨_input_sizeé‡Œé¢ + è§£æä¸€ä¸‹**YOLO11 æ¨¡å‹çš„å„ä¸ªè¾“å‡ºèŠ‚ç‚¹ï¼Œå¹¶è®°ä½å®ƒä»¬çš„ä½ç½®å’Œå¸ƒå±€**"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-14-05-MaixCDKåŸºç¡€ä½¿ç”¨.html":{"title":"MaixCDKåŸºç¡€ä½¿ç”¨","content":"# MaixCDKåŸºç¡€ä½¿ç”¨ ## åŸºç¡€çš„æ„å»º ### ç¼–è¯‘ åœ¨`MaixCDK/examples/hello_world/`ç›®å½•é‡Œé¢å¯ä»¥ä½¿ç”¨å‘½ä»¤`maixcdk build`è¿›è¡Œç¼–è¯‘, ä½¿ç”¨`maixcdk distclean`æ¸…é™¤ä¹‹å‰ç¼–è¯‘çš„å†…å®¹ ç¼–è¯‘äº§ç”Ÿçš„**ç¼–è¯‘æ–‡ä»¶**å’Œ**ä¾èµ–åº“**é»˜è®¤åœ¨é¡¹ç›®æ–‡ä»¶å¤¹çš„ **../dist**é‡Œ, æ³¨æ„ **ç¼–è¯‘æ–‡ä»¶** åŒç›®å½•ä¸‹å¿…é¡»è¦æœ‰å¯¹åº”çš„**ä¾èµ–åº“ dl_lib** ![image 20251214172214170](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512141722232.png) ### æ‰“åŒ…åº”ç”¨ éœ€è¦ç¡®ä¿ä½ çš„å·¥ç¨‹ç›®å½•é‡Œæœ‰ æœ‰æ•ˆçš„**app.yaml** æ–‡ä»¶ ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨`maixcdk deploy`æ¥æ‰“åŒ…ï¼Œä½¿ç”¨ MaixCam çš„**App Store**ç›´æ¥æ‰«æ**å¼¹å‡ºçš„äºŒç»´ç **å®‰è£…åº”ç”¨ï¼Œå¿«é€Ÿæµ‹è¯• ## åŸºç¡€å‘½ä»¤ ```bash jiao virtual machine:~$ maixcdk help SDK_PATH:/home/jiao/MaixCam/maixpy/MaixCDK usage: project.py [ h] {run,install_env,flash,deploy,release,new,build,build2,menuconfig,clean,distclean} ... build tool, e.g. `python project.py build` positional arguments: {run,install_env,flash,deploy,release,new,build,build2,menuconfig,clean,distclean} command help run run program install_env install python packages for project flash flash program to device deploy deploy program to device release release program as package file new create new project build start compile project, temp files in `build` dir, dist files in `dist` dir, build command by default always execute cmake to regenerate, to disable file change scan (cmake execute), use build2 command or add no gen option to only compile changed files, warning build2 will not detect file additions and deletions build2 same as `maixcdk build no gen`, compile project, not scan files additions and deletions, only compile changed files, so build faster but be attention you should use build again if you add new file or delete files menuconfig open menuconfig panel, a visual config panel clean clean build files, won't clean configuration distclean clean all generated files, including build files and configuration options: h, help show this help message and exit ``` ## ç½‘é¡µæ–‡æ¡£ [teedoc å¿«é€Ÿå¼€å§‹ teedoc](https://teedoc.github.io/get_started/zh/usage/quick_start.html) `pip install teedoc U`å®‰è£…**teedoc**, åœ¨æ–‡æ¡£ç›®å½•`teedoc install i https://pypi.tuna.tsinghua.edu.cn/simple`å®‰è£…æ’ä»¶. ä½¿ç”¨å‘½ä»¤`teedoc serve`ä»¥å¯åŠ¨ç½‘é¡µæ–‡æ¡£"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-19-07-AIç¼–è¯‘å™¨.html":{"title":"AIç¼–è¯‘å™¨","content":"# AIç¼–è¯‘å™¨ å°†AIæ¨¡å‹éƒ¨ç½²åˆ°ä¸“ç”¨çš„ç¡¬ä»¶è®¾å¤‡, ä¼ ç»Ÿçš„GPUä¾èµ–äºCPUçš„è°ƒç”¨ä»¥åŠå­˜å‚¨å¤„ç†åˆ†ç¦»çš„æ¶æ„çš„å½±å“ æ‰€ä»¥å¯ä»¥ä½¿ç”¨TPU(å¼ é‡å¤„ç†å™¨)ä¸“ç”¨äºåŠ é€Ÿæ·±åº¦ç¥ç»ç½‘ç»œè¿ç®—çš„å®šåˆ¶åŒ–ASICèŠ¯ç‰‡ ![image 20251219081340881](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219081340881.png) ![image 20251219081441882](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219081441882.png) ## TPU MLIR ![image 20251219081909761](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219081909761.png) ![image 20251219081753702](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219081753702.png) ![image 20251219082046993](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219082046993.png) ![image 20251219082138645](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219082138645.png) ### MLIR ![image 20251219082315367](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219082315367.png) IR: ä¸­é—´è¡¨è¾¾, ç¼–è¯‘å™¨åœ¨ç¼–è¯‘è¿‡ç¨‹ä¸­çš„ä¸­é—´ä»£ç , é€šå¸¸æ˜¯ä¸€ä¸ªä»‹äºé«˜çº§è¯­è¨€å’Œä½çº§æœºå™¨ä»£ç ä¹‹é—´çš„è¯­è¨€ ![image 20251219082437901](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219082437901.png) ![image 20251219082459663](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219082459663.png) ![image 20251219082557810](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219082557810.png) ![image 20251219082701621](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219082701621.png) ![image 20251219082736206](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251219082736206.png)"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-17-07-ç»„ä»¶.html":{"title":"ç»„ä»¶","content":"# ç»„ä»¶ ## è‡ªå®šä¹‰ç»„ä»¶ ç»„ä»¶ï¼šæ¯ä¸ªåŠŸèƒ½æ¨¡å—å¯ä»¥å°è£…æˆä¸€ä¸ªç»„ä»¶ï¼Œæ–¹ä¾¿ä¸åŒåº”ç”¨é€‰æ‹©æ€§åœ°ä½¿ç”¨ã€‚ å¯ä»¥çœ‹åˆ°[examples/hello_world](https://vscode remote+ssh 002dremote 002borb.vscode resource.vscode cdn.net/home/jiao/Maix/MaixCDK/docs/doc_zh/convention/examples/hello_world)ä¸­æœ‰ä¸ª`main`ç»„ä»¶ï¼Œ[components](https://vscode remote+ssh 002dremote 002borb.vscode resource.vscode cdn.net/home/jiao/Maix/MaixCDK/docs/doc_zh/convention/components)ä¸­æœ‰å¾ˆå¤šç»„ä»¶ï¼Œè¿˜å¯ä»¥è‡ªå·±æ·»åŠ ç»„ä»¶ï¼Œæ¯”å¦‚`hello_world/component1`æˆ–è€…`hello_world/compoents/component2`ã€‚ ä¹Ÿå¯ä»¥è®¾ç½®ç¯å¢ƒå˜é‡`MAIXCDK_EXTRA_COMPONENTS_PATH`æ¥æŒ‡å®šå…¶å®ƒé¢å¤–çš„ç»„ä»¶åº“ã€‚ æ¯ä¸ªç»„ä»¶åŒ…å«ä¸€ä¸ª`CMakeLists.txt`æ¥æè¿°ç»„ä»¶å†…å®¹ï¼Œæ¯”å¦‚`list(APPEND ADD_INCLUDE \"include\")`æ¥æŒ‡å®šåŒ…å«çš„å¤´æ–‡ä»¶è·¯å¾„ï¼Œ`list(APPEND ADD_SRCS \"src/hello.c\")`æ¥åŒ…å«æºæ–‡ä»¶ï¼Œ`list(APPEND ADD_REQUIREMENTS basic)`æ¥ä¾èµ–å…¶å®ƒç»„ä»¶ç­‰ã€‚ å¦å¤–ï¼Œé»˜è®¤ä¹Ÿä¼šåˆ° python `site packages` ç›®å½•å¯»æ‰¾ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœä½ äº†è§£ python åº“æ‰“åŒ…ï¼Œä½ çš„ç»„ä»¶åŒ…å¯ä»¥ç›´æ¥å‘å¸ƒåˆ° [pypi.org](https://pypi.org/), è¿™æ ·ç”¨æˆ·é€šè¿‡`pip install maixcdk xxx` å°±å¯ä»¥å¿«é€Ÿå®‰è£…ä½ çš„ç»„ä»¶åŒ…äº†ï¼ å¯ä»¥å‚è€ƒ[examples/maixcdk example](https://github.com/sipeed/MaixCDK/blob/main//examples/maixcdk example)ç»„ä»¶ã€‚ ### æ·»åŠ pythonç»„ä»¶ è¿™é‡Œå®‰è£…çš„æ˜¯[examples/maixcdk example](https://github.com/sipeed/MaixCDK/blob/main//examples/maixcdk example)è¿™ä¸ªç»„ä»¶, ç»„ä»¶é‡Œé¢çš„CMakeæ–‡ä»¶é‡Œé¢åªæœ‰ä¸‰è¡Œ ```cmake list(APPEND ADD_INCLUDE \"include\") append_srcs_dir(ADD_SRCS \"src\") # append source file in src dir to var ADD_SRCS register_component() ``` ```bash pip install i https://pypi.tuna.tsinghua.edu.cn/simple maixcdk example ``` å®‰è£…ä»¥åå¯ä»¥åœ¨CMakelist.txtæ–‡ä»¶é‡Œé¢ ```cmake list(APPEND ADD_REQUIREMENTS basic maixcdk example) ``` ä¹‹åå°±å¯ä»¥å¼•ç”¨å¤´æ–‡ä»¶ä»¥åŠ ## CMakeæ–‡ä»¶ `register_component()` å® + è‹¥å¹² Python è„šæœ¬ã€æ¥è‡ªåŠ¨å‘ç°ã€é…ç½®ã€ç­›é€‰ã€æ’åºå¹¶é“¾æ¥ç»„ä»¶çš„ã€‚ **1. ç»„ä»¶çš„åˆ¤å®šä¸å‘ç°** åˆ¤å®šä¸€ä¸ªç›®å½•æ˜¯ä¸æ˜¯ç»„ä»¶ç”¨`is_path_component()` å¿…é¡»æ˜¯ç›®å½• ä¸èƒ½æ˜¯éšè—ç›®å½•ï¼ˆåå­—ä¸ä»¥ `.` å¼€å¤´ï¼‰ å¿…é¡»æœ‰ `CMakeLists.txt` `CMakeLists.txt` é‡Œè¦åŒ…å«å­—ç¬¦ä¸² `register_component` æ‰«æå‡½æ•°`find_components()`ä¼šåœ¨æŒ‡å®šç›®å½•æ¨¡å¼ï¼ˆæ¯”å¦‚${SDK_PATH}/components/*ï¼‰ä¸‹è°ƒç”¨`is_path_component`ï¼ŒæŠŠç¬¦åˆæ¡ä»¶çš„ç›®å½•åŠ å…¥`components_dirs`ï¼Œå¹¶é¡ºå¸¦è®°å½•ï¼š è‹¥æœ‰ [Kconfig](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) å°±è®°åˆ° `components_kconfig_files` è‹¥æœ‰ `config_defaults.mk` å°±è®°åˆ° `kconfig_defaults_files_args` è‹¥ç›®å½•åä¸º `main` å°±æ ‡è®° `found_main 1` åœ¨`project(name)`å®é‡Œï¼Œä¾æ¬¡è°ƒç”¨find_components()æ‰«æè¿™äº›ä½ç½®ï¼š `${SDK_PATH}/components/*`ã€`3rd_party/*`ã€`ext_devs/*`ã€`algo/*` `MAIXCDK_EXTRA_COMPONENTS_PATH`ã€`PY_PKG_COMPONENTS_PATH`ã€`PY_USR_PKG_COMPONENTS_PATH` `${PROJECT_SOURCE_DIR}/../components/*` `${PROJECT_SOURCE_DIR}/*` å’Œ `${PROJECT_SOURCE_DIR}/components/*` å¦‚æœæœ€ç»ˆæ²¡æœ‰å‘ç°åä¸º `main` çš„ç»„ä»¶ç›®å½•ï¼Œåˆ™ç›´æ¥ `FATAL_ERROR`ã€‚ **2. ç»„ä»¶å†…éƒ¨å¦‚ä½•æ³¨å†Œ (`register_component`)** æ¯ä¸ªç»„ä»¶è‡ªå·±çš„ `CMakeLists.txt` æœ€ç»ˆä¼šè°ƒç”¨ `register_component()`ï¼Œå‰é¢é€šå¸¸ä¼šè®¾ç½®ä¸€äº›å˜é‡ï¼Œæ¯”å¦‚ `ADD_SRCS`ã€`ADD_INCLUDE` ç­‰ï¼ˆè¿™äº›åœ¨åˆ«å¤„å®šä¹‰çº¦å®šï¼‰ï¼š æ ¹æ®å‚æ•°æ˜¯å¦åŒ…å«DYNAMIC/SHARED åˆ¤æ–­è¯¥ç»„ä»¶ç”ŸæˆåŠ¨æ€åº“è¿˜æ˜¯é™æ€åº“ï¼š `add_library(${component_name} SHARED/STATIC ...)` æˆ– `INTERFACE` åŒæ—¶æŠŠåº“è·¯å¾„è®°å½•åˆ°å…¨å±€ç¼“å­˜å˜é‡ `g_dynamic_libs` ç­‰ å¤„ç†æºæ–‡ä»¶ä¸åŒ…å«è·¯å¾„ï¼š æŠŠ `ADD_SRCS` è½¬æˆç»å¯¹è·¯å¾„ï¼Œå¹¶è®°å½•åˆ° `g_srcs` é‡Œï¼ˆæ ¼å¼ `component+abs_path`ï¼‰ æŠŠ `ADD_INCLUDE`/`ADD_PRIVATE_INCLUDE` ç›®å½•åŠ å…¥ `target_include_directories` æ‰€æœ‰å…¬å…±åŒ…å«è·¯å¾„ä¹ŸåŒæ­¥è®°å½•è¿› `g_includes` å¤„ç†ç¼–è¯‘ / é“¾æ¥é€‰é¡¹å’Œåº“è·¯å¾„ï¼š `ADD_DEFINITIONS*`ã€`ADD_LINK_DEFINITIONS*` > åˆ†åˆ«åŠ åˆ° `target_compile_options` / `target_link_options` `ADD_LINK_SEARCH_PATH` > æ ¡éªŒå­˜åœ¨æ€§ï¼Œè½¬ç»å¯¹è·¯å¾„ï¼Œå†™å…¥ `g_link_search_path` `ADD_STATIC_LIB`ã€`ADD_DYNAMIC_LIB` > åšè·¯å¾„æ£€æŸ¥ï¼Œå¿…è¦æ—¶è½¬ç»å¯¹è·¯å¾„ï¼Œç„¶å `target_link_libraries`ï¼ŒåŠ¨æ€åº“ä¿¡æ¯ä¹ŸåŠ å…¥ `g_dynamic_libs` `ADD_DIST_LIB_IGNORE` > å†™å…¥ `g_dist_ignore_libs`ï¼Œåé¢ä¼šä» `g_dynamic_libs` ä¸­å‰”é™¤è¿™äº› ç»„ä»¶ä¾èµ–ç®¡ç†ï¼š è°ƒç”¨ Pythonï¼š`build.py get_requirements ... ${component_name} ${component_dir} ...` ä»è¯¥ç»„ä»¶çš„ `component.py` ç­‰ä¿¡æ¯é‡Œç®—å‡ºå®ƒä¾èµ–çš„å…¶ä»–ç»„ä»¶ååˆ—è¡¨ `component_requires` æŠŠè¿™äº›ä¾èµ–åŠ å…¥ `ADD_REQUIREMENTS`ï¼Œå¹¶ `target_link_libraries(${component_name} ${include_type} ${ADD_REQUIREMENTS})` è°ƒç”¨ `components_depends.py append`ï¼ŒæŠŠã€Œå½“å‰ç»„ä»¶ > ä¾èµ–ç»„ä»¶åˆ—è¡¨ã€å†™å…¥ `${CMAKE_BINARY_DIR}/config/components_depends.json` **3. å¯ç”¨ / ç¦ç”¨ç»„ä»¶ä¸ä¾èµ–è£å‰ª** åœ¨ `project(name)` å®ä¸­ï¼Œå‘ç°ç»„ä»¶ä¹‹åï¼Œä¼šåšå‡ ä»¶å…³é”®äº‹ï¼š æ¸…ç©ºæ—§çš„ä¾èµ–ä¿¡æ¯ï¼š `components_depends.py clear ${CMAKE_BINARY_DIR}/config/components_depends.json` æ ¹æ® Kconfig / é…ç½®æ¨æ–­ã€Œå…è®¸ä½¿ç”¨çš„ç»„ä»¶ã€ï¼š è°ƒç”¨ `build.py get_valid_components ...` å¾—åˆ° `component_valid`ï¼ˆåªæ˜¯â€œå¯ç”¨â€çš„å€™é€‰ç»„ä»¶ååˆ—è¡¨ï¼‰ æ’åºç»„ä»¶ï¼š é€šè¿‡ `sort_components.py` ç»“åˆ `priority.conf` è¿›è¡Œæ’åºï¼Œå¾—åˆ° `component_dirs_sorted` å®é™…æ·»åŠ å­ç›®å½•ï¼š å¯¹æ¯ä¸ªcomponent_dir å–ç›®å½•å `base_dir`ï¼Œçœ‹æ˜¯å¦åœ¨ `component_valid` ä¸­ åœ¨çš„è¯ `add_subdirectory(component_dir base_dir EXCLUDE_FROM_ALL)`ï¼Œé‡Œé¢å°±ä¼šæ‰§è¡Œè¯¥ç»„ä»¶çš„ `CMakeLists` å¹¶è°ƒç”¨ `register_component` è‹¥ç”Ÿæˆäº†ç›®æ ‡ `TARGET base_dir`ï¼Œåˆ™ `add_dependencies(base_dir update_build_info)` ç„¶åæ ¹æ® `components_depends.json` å†åšã€Œä»¥ main ä¸ºæ ¹çš„ä¾èµ–è£å‰ªã€ï¼š `components_depends.py get ... main` å¾—åˆ° `main` ä¾èµ–çš„æ‰€æœ‰ç»„ä»¶åˆ—è¡¨ `main_depends` `g_enabled_components main_depends + main` `update_global_var(var_name)` å‡½æ•°ä¼šæ‰«æä¹‹å‰ç´¯ç§¯çš„å…¨å±€å˜é‡ï¼ˆä¾‹å¦‚ `g_includes`, `g_srcs`, `g_dynamic_libs`, `g_link_search_path` ç­‰ï¼‰ï¼ŒæŠŠä¸åœ¨ `g_enabled_components` ä¸­çš„æ¡ç›®å…¨éƒ¨è¿‡æ»¤æ‰ï¼Œåªä¿ç•™çœŸæ­£ä¼šå‚ä¸ `main` æœ€ç»ˆé“¾æ¥çš„ç»„ä»¶ç›¸å…³ä¿¡æ¯ã€‚ å†æŠŠ `g_dist_ignore_libs` ä¸­çš„åº“ä» `g_dynamic_libs` é‡Œåˆ é™¤ï¼Œç¡®ä¿æŸäº›åº“ä¸ä¼šè¢«æ‰“åŒ…/åˆ†å‘ã€‚ **4. å…¨å±€ä¿¡æ¯ä¿å­˜ä¸æœ€ç»ˆé“¾æ¥** è°ƒç”¨ `save_global_vars.py` æŠŠä¸Šè¿°å…¨å±€ä¿¡æ¯å†™è¿› `cmake_global_vars.json`ï¼Œä¾›å·¥å…·é“¾ï¼ˆåŒ…æ‹¬æ–‡æ¡£ç”Ÿæˆç­‰ï¼‰ä½¿ç”¨ã€‚ æ ¹æ® `g_link_search_path` æŠŠåº“æœç´¢è·¯å¾„å’Œ `rpath` åŠ åˆ° `CMAKE_C_LINK_FLAGS` / `CMAKE_CXX_LINK_FLAGS`ã€‚ ä¸ºå¯æ‰§è¡Œç¨‹åºåˆ›å»ºä¸€ä¸ªå ä½æºç exe_src.cä½¿ç”¨add_executable(${name} exe_src) `target_link_libraries(${name} main)`ï¼Œ`main` æœ¬èº«æ˜¯ä¸€ä¸ªç»„ä»¶åº“ï¼Œå®šä¹‰åº”ç”¨å…¥å£ã€‚ æœ€åå†æ ¹æ® `gen_binary.cmake` ç”Ÿæˆæ‰“åŒ…é•œåƒ / bin æ–‡ä»¶ç­‰ã€‚ > ç”±äºè¿™ä¸ªæ–‡ä»¶åªæ˜¯ä¸€ä¸ªç©ºæ–‡ä»¶, æ‰€ä»¥åœ¨å®é™…è¿è¡Œçš„æ—¶å€™ä¼šå»æŸ¥æ‰¾åˆ°mainæ¨¡å—é‡Œé¢çš„mainå‡½æ•° **å¯ä»¥ç®€å•ç†è§£ä¸ºï¼š** 1. æŒ‰ç›®å½•çº¦å®šè‡ªåŠ¨å‘ç°æ‰€æœ‰ç»„ä»¶ç›®å½•ã€‚ 2. æ¯ä¸ªç»„ä»¶é€šè¿‡ `register_component()` æŠŠè‡ªå·±çš„æºæ–‡ä»¶ã€å¤´æ–‡ä»¶ã€ç¼–è¯‘é€‰é¡¹ã€é™æ€/åŠ¨æ€åº“å’Œâ€œç»„ä»¶ä¾èµ–â€æ³¨å†Œåˆ°å…¨å±€ã€‚ 3. é€šè¿‡ Python è„šæœ¬å’Œ `component.py`ã€[Kconfig](vscode file://vscode app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron browser/workbench/workbench.html) é…ç½®ï¼Œå…ˆç­›å‡ºâ€œå€™é€‰å¯ç”¨ç»„ä»¶â€ï¼Œå†ä»¥ `main` ä¸ºæ ¹åšä¾èµ–é—­åŒ…ï¼Œåªå¯ç”¨è¿™æ¡ä¾èµ–é“¾ä¸Šçš„ç»„ä»¶ã€‚ 4. åªå¯¹å¯ç”¨çš„ç»„ä»¶æ±‡æ€» includeã€srcã€åº“è·¯å¾„ç­‰ï¼Œå…¨å±€å­˜æˆ JSONï¼Œå†ç”¨äºé“¾æ¥æœ€ç»ˆå¯æ‰§è¡Œç¨‹åºå’Œç”Ÿæˆæ–‡æ¡£/æ‰“åŒ…ã€‚"},"/note/æœºå™¨å­¦ä¹ /è§†è§‰è¯†åˆ«/MaixCAM/2025-12-5-01ç¼–è¯‘ä¸‹è½½.html":{"title":"ç¼–è¯‘ä¸‹è½½","content":"# ç¼–è¯‘ä¸‹è½½ ## Linuxå†…æ ¸ ä¸‹è½½ä»£ç  ```bash git clone https://github.com/sipeed/LicheeRV Nano Build depth 1 cd LicheeRV Nano Build git clone https://github.com/sophgo/host tools depth 1 ``` ç¼–è¯‘çš„æ—¶å€™éœ€è¦æ£€æŸ¥gité‡Œé¢çš„ä¿¡æ¯, æ‰€ä»¥éœ€è¦ä½¿ç”¨git, ä¸‹é¢æ˜¯å®é™…çš„å¯¼å‡ºå®¹å™¨ä½¿ç”¨çš„å‘½ä»¤ ```c cd host/ubuntu docker build t licheervnano build ubuntu . docker run name licheervnano build ubuntu licheervnano build ubuntu docker export licheervnano build ubuntu > licheervnano build ubuntu.tar mksquashfs licheervnano build ubuntu.tar licheervnano build ubuntu.sqfs tar mkdir p tmp_squashfs # è§£å‹ tar åŒ…åˆ°ä¸´æ—¶ç›®å½•ï¼ˆ C æŒ‡å®šè§£å‹è·¯å¾„ï¼‰ tar xf licheervnano build ubuntu.tar C tmp_squashfs mksquashfs tmp_squashfs licheervnano build ubuntu.sqfs comp gzip rm rf tmp_squashfs ``` Ubuntué»˜è®¤ä¸‹è½½çš„singularityæ˜¯ä¸å¯¹çš„éœ€è¦è‡ªå·±ç¼–è¯‘ä¸‹è½½ ```bash # å¸è½½é”™è¯¯çš„singularityæ¸¸æˆåŒ… sudo apt remove y singularity # 1. å®‰è£…ä¾èµ– sudo apt update && sudo apt install y build essential libssl dev uuid dev libgpgme11 dev squashfs tools libseccomp dev wget pkg config git cryptsetup bin wget https://go.dev/dl/go1.21.9.linux amd64.tar.gz sudo rm rf /usr/local/go sudo tar C /usr/local xzf go1.21.9.linux amd64.tar.gz echo 'export PATH $PATH:/usr/local/go/bin' >> ~/.bashrc source ~/.bashrc git clone https://github.com/sylabs/singularity.git cd singularity && git checkout v3.11.4 ./mconfig && cd builddir git submodule update init cd singularity && git checkout v3.11.4 git checkout v3.11.4 ./mconfig && cd builddir make && sudo make install singularity version cd ../../ singularity shell e licheervnano build ubuntu.sqfs ``` ç°åœ¨è¿›å…¥å¯¹åº”çš„ç¯å¢ƒé‡Œé¢äº† ```bash source build/cvisetup.sh # C906: defconfig sg2002_licheervnano_sd # A53: # defconfig sg2002_licheea53nano_sd build_all ``` ç¼–è¯‘ä»¥åå¾—ç»“æœ ```bash >8 # please use win32diskimager or dd command write it into sdcard /home/jiao/MiaxCAM/linuxSDK/LicheeRV Nano Build/install/soc_sg2002_licheervnano_sd/images/2025 12 05 16 30 27b96a.img >8 ~/MiaxCAM/linuxSDK/LicheeRV Nano Build ``` ## ç¼–è¯‘MaixPy ```bash git clone https://github.com/sipeed/MaixPy git clone https://github.com/sipeed/MaixCDK sudo apt install git cmake build essential python3 python3 pip autoconf automake libtool cmake version # cmake ç‰ˆæœ¬åº”è¯¥ > 3.13 cd MaixCDK pip install U pip # æ›´æ–° pip åˆ°æœ€æ–°ç‰ˆæœ¬ pip install U r requirements.txt # å®‰è£…ä¾èµ– export MAIXCDK_PATH ~/maix/MaixCDK cd ~/maix/MaixPy python setup.py bdist_wheel maixcam ``` æ„å»ºæˆåŠŸå, ä½ ä¼šåœ¨ `dist` ç›®å½•ä¸­æ‰¾åˆ° wheel æ–‡ä»¶, ä¼ è¾“åˆ°è®¾å¤‡ï¼ˆå¼€å‘æ¿ï¼‰ï¼Œåœ¨è®¾å¤‡ç»ˆç«¯ä¸­ä½¿ç”¨ `pip install U MaixPy****.whl` åœ¨ä½ çš„è®¾å¤‡ä¸Šå®‰è£…æˆ–å‡çº§ ## å®‰è£… å¯¹äº MaixCAM è¿˜éœ€è¦æ”¾ä¸€äº›é¢å¤–çš„æ–‡ä»¶è¿›å»ï¼Œåˆ°[MaixPy release](https://github.com/sipeed/MaixPy/releases) ä¸‹è½½æœ€æ–°çš„ `builtin_files.tar.xz` æ–‡ä»¶ã€‚ ```bash tar xJf builtin_files.tar.xz sudo apt install y mtools sudo apt install y libfuse2 ``` ```bash (base) jiao@jiao virtual machine:~/MiaxCAM/maixpy/MaixPy/tools/os/maixcam$ ./gen_os.sh /home/jiao/MiaxCAM/linuxSDK/LicheeRV Nano Build/install/soc_sg2002_licheervnano_sd/images/2025 12 05 16 30 27b96a.img ../../../dist/MaixPy 4.12.1 py3 none any.whl ./maixcam_builtin_files 0 maixcam pro ``` è¾“å‡ºç»“æœæ˜¯ ```bash ~/MaixCam/maixpy/MaixPy/tools/os/maixcam/images/maixcam pro 2025 12 12 maixpy v4.12.1.img.xz ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-13-13å·ç§¯.html":{"title":"å·ç§¯","content":"# å·ç§¯ ## è®¡ç®—äº¤å‰ç›¸ä¹˜ åœ¨ä½¿ç”¨MLPè¿›è¡Œå¤„ç†å›¾ç‰‡çš„æ—¶å€™, ç°åœ¨çš„å›¾ç‰‡åƒç´ æ¯”è¾ƒå¤§, ä¼šå¯¼è‡´åˆ†ç±»çš„æ—¶å€™è¿›è¡Œä¸€æ¬¡å•éšè—å±‚æ”¾å¤§å…ƒç´ çš„ä¸ªæ•°å¯èƒ½æ¯”æ‰€æœ‰çš„ä¸ªä½“çš„æ•°é‡éƒ½é«˜ å›¾ç‰‡è¯†åˆ«ä¸¤ä¸ªåŸåˆ™: 1. å¹³ç§»ä¸å˜æ€§, åŒä¸€ä¸ªå›¾åƒå‡ºç°åœ¨å›¾ç‰‡çš„ä¸åŒä½ç½®æ˜¯ç­‰ä»·çš„ 2. å±€éƒ¨æ€§, ä½¿ç”¨å±€éƒ¨çš„ä¿¡æ¯å³å¯è·å– æŠŠè¾“å…¥å’Œè¾“å‡ºå˜ä¸ºä¸€ä¸ªçŸ©é˜µ, æƒé‡æ˜¯ä¸€ä¸ªå››ç»´çš„å¼ é‡ > åœ¨çŸ©é˜µè¿ç®—çš„æ—¶å€™ï¼Œå…¶å®æœ€åéƒ½å¯ä»¥è½¬æˆæˆ‘ä»¬å¸¸è§çš„äºŒç»´çŸ©é˜µè¿ç®—ï¼Œéµå¾ªçš„åŸåˆ™æ˜¯ï¼šåœ¨å¤šç»´çŸ©é˜µç›¸ä¹˜ä¸­ï¼Œéœ€æœ€åä¸¤ç»´æ»¡è¶³shapeåŒ¹é…åŸåˆ™ï¼Œæœ€åä¸¤ç»´æ‰æ˜¯æœ‰æ•°æ®çš„çŸ©é˜µï¼Œå‰é¢çš„ç»´åº¦åªæ˜¯çŸ©é˜µçš„æ’åˆ—è€Œå·² > > [ã€å…¨é¢ç†è§£å¤šç»´çŸ©é˜µè¿ç®—ã€‘å¤šç»´ï¼ˆä¸‰ç»´å››ç»´ï¼‰çŸ©é˜µå‘é‡è¿ç®— è¶…å¼ºå¯è§†åŒ– çŸ¥ä¹](https://zhuanlan.zhihu.com/p/337829793) ![image 20250113154428046](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131544152.png) ![image 20250113154418438](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131544505.png) ![image 20250113110117738](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131101851.png) ![image 20250113110624570](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131106620.png) > ä¸Šé¢çš„å³ä¾§å¼å­å¯¹vçš„ä¸‹æ ‡è¿›è¡Œå˜åŒ–, ä½¿ç”¨[X]~i,j~å’Œ[H]~i,j~åˆ†åˆ«è¡¨ç¤ºè¾“å…¥å›¾åƒå’Œéšè—è¡¨ç¤ºä¸­ä½ç½®ï¼ˆi,jï¼‰å¤„çš„åƒç´  > > ä¸ºäº†ä½¿æ¯ä¸ªéšè—ç¥ç»å…ƒéƒ½èƒ½æ¥æ”¶åˆ°æ¯ä¸ªè¾“å…¥åƒç´ çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å°†å‚æ•°ä»æƒé‡çŸ©é˜µï¼ˆå¦‚åŒæˆ‘ä»¬å…ˆå‰åœ¨å¤šå±‚æ„ŸçŸ¥æœºä¸­æ‰€åšçš„é‚£æ ·ï¼‰æ›¿æ¢ä¸ºå››é˜¶æƒé‡å¼ é‡Wã€‚å‡è®¾UåŒ…å«åç½®å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¨è¿æ¥å±‚å½¢å¼åŒ–åœ°è¡¨ç¤ºä¸º > > ![image 20250113121226604](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131212684.png) ### å¹³ç§»ä¸å˜ æ£€æµ‹å¯¹è±¡åœ¨è¾“å…¥Xä¸­çš„å¹³ç§»ï¼Œåº”è¯¥ä»…å¯¼è‡´éšè—è¡¨ç¤ºHä¸­çš„å¹³ç§»ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒVå’ŒUå®é™…ä¸Šä¸ä¾èµ–äº(i,j)çš„å€¼ï¼Œå³[V]~i,j,a,b~ [V]~a,b~ã€‚å¹¶ä¸”Uæ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œæ¯”å¦‚uã€‚ ![image 20250113121324829](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131213868.png) è¿™å°±æ˜¯*å·ç§¯*ï¼ˆconvolutionï¼‰ã€‚æˆ‘ä»¬æ˜¯åœ¨ä½¿ç”¨ç³»æ•°[V]~a,b~å¯¹ä½ç½®(i,j)é™„è¿‘çš„åƒç´ (i+a,j+b)è¿›è¡ŒåŠ æƒå¾—åˆ°[H]i,jã€‚ æ³¨æ„ï¼Œ[V]~a,b~çš„ç³»æ•°æ¯”[V]~i,j,a,b~å°‘å¾ˆå¤šï¼Œå› ä¸ºå‰è€…ä¸å†ä¾èµ–äºå›¾åƒä¸­çš„ä½ç½®ã€‚ ### å±€éƒ¨æ€§ ä¸ºäº†æ”¶é›†ç”¨æ¥è®­ç»ƒå‚æ•°[H]i,jçš„ç›¸å…³ä¿¡æ¯ï¼Œæˆ‘ä»¬ä¸åº”åç¦»åˆ°è·(i,j)å¾ˆè¿œçš„åœ°æ–¹ã€‚è¿™æ„å‘³ç€åœ¨a>Î”æˆ–b>Î”çš„èŒƒå›´ä¹‹å¤–ï¼Œæˆ‘ä»¬å¯ä»¥è®¾ç½®[V]a,b 0ã€‚ ![image 20250113121708434](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131217493.png) å·ç§¯ç¥ç»ç½‘ç»œæ˜¯åŒ…å«å·ç§¯å±‚çš„ä¸€ç±»ç‰¹æ®Šçš„ç¥ç»ç½‘ç»œã€‚ åœ¨æ·±åº¦å­¦ä¹ ç ”ç©¶ç¤¾åŒºä¸­ï¼ŒVè¢«ç§°ä¸º*å·ç§¯æ ¸*ï¼ˆconvolution kernelï¼‰æˆ–è€…*æ»¤æ³¢å™¨*ï¼ˆfilterï¼‰ï¼Œäº¦æˆ–ç®€å•åœ°ç§°ä¹‹ä¸ºè¯¥å·ç§¯å±‚çš„*æƒé‡*ï¼Œé€šå¸¸è¯¥æƒé‡æ˜¯å¯å­¦ä¹ çš„å‚æ•°ã€‚ ### ä¼˜åŠ¿ ä»¥å‰ï¼Œå¤šå±‚æ„ŸçŸ¥æœºå¯èƒ½éœ€è¦æ•°åäº¿ä¸ªå‚æ•°æ¥è¡¨ç¤ºç½‘ç»œä¸­çš„ä¸€å±‚ï¼Œè€Œç°åœ¨å·ç§¯ç¥ç»ç½‘ç»œé€šå¸¸åªéœ€è¦å‡ ç™¾ä¸ªå‚æ•°ï¼Œè€Œä¸”ä¸éœ€è¦æ”¹å˜è¾“å…¥æˆ–éšè—è¡¨ç¤ºçš„ç»´æ•°ã€‚ å‚æ•°å¤§å¹…å‡å°‘çš„ä»£ä»·æ˜¯ï¼Œæˆ‘ä»¬çš„ç‰¹å¾ç°åœ¨æ˜¯å¹³ç§»ä¸å˜çš„ï¼Œå¹¶ä¸”å½“ç¡®å®šæ¯ä¸ªéšè—æ´»æ€§å€¼æ—¶ï¼Œæ¯ä¸€å±‚åªåŒ…å«å±€éƒ¨çš„ä¿¡æ¯ã€‚ ä»¥ä¸Šæ‰€æœ‰çš„æƒé‡å­¦ä¹ éƒ½å°†ä¾èµ–äºå½’çº³åç½®ã€‚å½“è¿™ç§åç½®ä¸ç°å®ç›¸ç¬¦æ—¶ï¼Œæˆ‘ä»¬å°±èƒ½å¾—åˆ°æ ·æœ¬æœ‰æ•ˆçš„æ¨¡å‹ï¼Œå¹¶ä¸”è¿™äº›æ¨¡å‹èƒ½å¾ˆå¥½åœ°æ³›åŒ–åˆ°æœªçŸ¥æ•°æ®ä¸­ã€‚ ä½†å¦‚æœè¿™åç½®ä¸ç°å®ä¸ç¬¦æ—¶ï¼Œæ¯”å¦‚å½“å›¾åƒä¸æ»¡è¶³å¹³ç§»ä¸å˜æ—¶ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯èƒ½éš¾ä»¥æ‹Ÿåˆæˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ã€‚ ### å·ç§¯ æˆ‘ä»¬è®°å¾—cross correlationçš„loopé¡ºåºæ˜¯**ä»å·¦åˆ°å³ï¼Œä»ä¸Šåˆ°ä¸‹**ï¼Œ è€Œconvolutionæ˜¯**ä»å³åˆ°å·¦ï¼Œä»ä¸‹åˆ°ä¸Š** ![image 20250113154609553](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131546680.png) å®ƒç›¸å½“äºå°†filterç¿»è½¬äº†ä¸€æ¬¡å†è¿›è¡Œcross correlation > ç”±äºä½¿ç”¨èµ·æ¥çš„æ•ˆæœç›¸åŒ, æ‰€ä»¥å®é™…æ²¡æœ‰ä½¿ç”¨ä¸¥æ ¼çš„å·ç§¯ ## å·ç§¯å±‚ ### äºŒç»´äº¤å‰ç›¸å…³ ![image 20250113153354169](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131533544.png) å¯¹åº”ä½ç½®ç›¸ä¹˜å†ç›¸åŠ , 19 0\\*0 + 1\\*1 + 3\\*2 + 4\\*3 è¾“å‡ºå¤§å°ç•¥å°äºè¾“å…¥å¤§å°ã€‚è¿™æ˜¯å› ä¸ºå·ç§¯æ ¸çš„å®½åº¦å’Œé«˜åº¦å¤§äº1ï¼Œ è€Œå·ç§¯æ ¸åªä¸å›¾åƒä¸­æ¯ä¸ªå¤§å°å®Œå…¨é€‚åˆçš„ä½ç½®è¿›è¡Œäº’ç›¸å…³è¿ç®—ã€‚ æ‰€ä»¥ï¼Œè¾“å‡ºå¤§å°ç­‰äºè¾“å…¥å¤§å°n~h~Ã—n~w~å‡å»å·ç§¯æ ¸å¤§å°k~h~Ã—k~w~ï¼Œ ![image 20250113153704413](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131537458.png) å®é™…ä½¿ç”¨çš„æ—¶å€™å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå›¾åƒä¹˜ä»¥ä¸€æ¬¡å·ç§¯è·å–ä¸€ä¸ªå›¾åƒå¤„ç†çš„æ•ˆæœ ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸€ç»´çš„(æ–‡æœ¬, è¯­è¨€, æ—¶åº), ä¸‰ç»´çš„(è§†é¢‘, åŒ»å­¦å›¾åƒ, æ°”è±¡åœ°å›¾) ### å¡«å……å’Œæ­¥å¹… æ¯ä¸€æ¬¡çš„å·ç§¯ä¼šå¯¼è‡´å›¾åƒçš„ç¼©å°, ä½¿ç”¨å¤§çš„å·ç§¯æ ¸ç¼©å°çš„æ›´å¿«, æƒ³ä½¿ç”¨æ›´æ·±çš„å°±ä¸å¯è¡Œ å¡«å……, åœ¨å¤–éƒ¨åŠ å…¥é¢å¤–çš„è¡Œå’Œåˆ— ![image 20250113171136774](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131711921.png) è¿™æ—¶å€™è¾“å‡ºçš„å›¾åƒå˜ä¸º ![image 20250113171224768](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131712828.png) > æ·»åŠ p~h~è¡Œå¡«å……ï¼ˆå¤§çº¦ä¸€åŠåœ¨é¡¶éƒ¨ï¼Œä¸€åŠåœ¨åº•éƒ¨ï¼‰å’Œp~w~åˆ—å¡«å……ï¼ˆå·¦ä¾§å¤§çº¦ä¸€åŠï¼Œå³ä¾§ä¸€åŠï¼‰ > > æˆ‘ä»¬éœ€è¦è®¾ç½®ph k~h~âˆ’1å’Œpw k~w~âˆ’1 > > å‡è®¾khæ˜¯å¥‡æ•°ï¼Œæˆ‘ä»¬å°†åœ¨é«˜åº¦çš„ä¸¤ä¾§å¡«å……ph/2è¡Œã€‚ å¦‚æœkhæ˜¯å¶æ•°ï¼Œåˆ™ä¸€ç§å¯èƒ½æ€§æ˜¯åœ¨è¾“å…¥é¡¶éƒ¨å¡«å……âŒˆph/2âŒ‰è¡Œï¼Œåœ¨åº•éƒ¨å¡«å……âŒŠph/2âŒ‹è¡Œ ```python def comp_conv2d(conv2d, X): # (1, 1)æ˜¯åŠ ä¸€ä¸ªbatch_sizeå’Œé€šé“æ•°, ä¸ºäº†é€‚åº”conv2dçš„è¾“å…¥ X X.reshape((1, 1) + X.shape) Y conv2d(X) return Y.reshape(Y.shape[2:]) # å»æ‰å‰ä¸¤ä¸ªç»´åº¦ # è¿™é‡Œçš„padding 1æ˜¯ä¸ºäº†ä¿æŒè¾“å…¥å’Œè¾“å‡ºçš„å½¢çŠ¶, åœ¨å››å‘¨å„å¡«å……ä¸€æ’0 conv2d nn.Conv2d(1, 1, kernel_size 3, padding 1) X torch.rand(size (8, 8)) comp_conv2d(conv2d, X).shape \"\"\" torch.Size([8, 8]) \"\"\" conv2d nn.Conv2d(1, 1, kernel_size (5, 3), padding (2, 1)) comp_conv2d(conv2d, X).shape \"\"\" torch.Size([8, 8]) \"\"\" ``` æ­¥å¹…: ç§»åŠ¨çª—å£çš„æ—¶å€™ç§»åŠ¨çš„ä½ç½®å¤§å° å½“å‚ç›´æ­¥å¹…ä¸ºshã€æ°´å¹³æ­¥å¹…ä¸ºswæ—¶ï¼Œè¾“å‡ºå½¢çŠ¶ä¸º ![image 20250113171735937](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131717010.png) å¦‚æœæˆ‘ä»¬è®¾ç½®äº†p~h~ k~h~âˆ’1å’Œp~w~ k~w~âˆ’1ï¼Œåˆ™è¾“å‡ºå½¢çŠ¶å°†ç®€åŒ–ä¸º ![image 20250113171926074](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131719116.png) å¯ä»¥æ•´é™¤çš„æ—¶å€™![image 20250113171942348](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131719582.png) ```python onv2d nn.Conv2d(1, 1, kernel_size 3, padding 1, stride 2) comp_conv2d(conv2d, X).shape \"\"\" torch.Size([4, 4]) \"\"\" conv2d nn.Conv2d(1, 1, kernel_size (3, 5), padding (0, 1), stride (3, 4)) comp_conv2d(conv2d, X).shape \"\"\" torch.Size([2, 2]) (8 (3 + 1) + (3 1)) / 2 (8 + 2 (5 1) + (4 1)) / 4 \"\"\" ``` > é€šå¸¸ä½¿ç”¨çš„å·ç§¯æ ¸çš„å¤§å°æ˜¯ä¸€ä¸ªå•æ•°çš„ #### å®é™…ä½¿ç”¨ ä¸€èˆ¬å¡«å……ä½¿å¾—å›¾åƒå¤§å°ä¸å˜, æ­¥å¹…ä¸€èˆ¬è®¡ç®—é‡å…è®¸çš„æ—¶å€™ä½¿ç”¨1, æ ¸å¤§å°ä¸€èˆ¬æ˜¯æœ€é‡è¦çš„å‚æ•° ### å¤šè¾“å…¥å’Œè¾“å‡ºé€šé“ å½©è‰²çš„å›¾ç‰‡æœ‰RGBä¸‰ä¸ªé€šé“, åœ¨å¤„ç†å¤šé€šé“çš„æ—¶å€™, æ¯ä¸€ä¸ªé€šé“éƒ½æœ‰è‡ªå·±çš„å·ç§¯æ ¸, ç»“æœæ˜¯æ‰€æœ‰çš„å·ç§¯æ ¸çš„å’Œ ![image 20250113181908364](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131819465.png) å®é™…çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå•é€šé“çš„, å¦‚æœå¸Œæœ›æœ‰å¤šä¸ªè¾“å‡º, å¯ä»¥æé«˜å·ç§¯æ ¸çš„ä¸ªæ•° è¾“å…¥X : c~i~Ã—n~h~Ã—n~w~ æ ¸W : c~o~Ã—c~i~Ã—m~h~Ã—m~w~ è¾“å‡ºY : c~o~Ã—m~h~Ã—m~w~ > æ¯ä¸€ä¸ªä¸åŒçš„è¾“å‡ºé€šé“è¯†åˆ«ä¸åŒçš„ä¸œè¥¿ ### 1Ã—1å·ç§¯å±‚ ä¸è¯†åˆ«ç©ºé—´æ¨¡å¼, åªæ˜¯ä¸€ä¸ªèåˆé€šé“ ![image 20250113182939083](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131829186.png) 1Ã—1å·ç§¯å±‚éœ€è¦çš„æƒé‡ç»´åº¦ä¸ºc~o~Ã—c~i~ï¼Œå†é¢å¤–åŠ ä¸Šä¸€ä¸ªåç½®, ### é€šç”¨äºŒç»´å·ç§¯ ![image 20250113183353792](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501131833871.png) > åå·®æ˜¯æ¯ä¸€ä¸ªå•å±‚çš„å·ç§¯æ ¸éƒ½æœ‰çš„ ## æ€»ç»“ å®é™…æ˜¯æŠŠè¾“å…¥å’Œæ ¸çŸ©é˜µè¿›è¡Œè¿ç®—, è·å–è¾“å‡ºçš„è¿‡ç¨‹, æ ¸çŸ©é˜µå’Œåç§»æ˜¯å¯ä»¥å­¦ä¹ çš„, æ ¸çŸ©é˜µçš„å¤§å°æ˜¯è¶…å‚æ•° ## ä»£ç å®ç° ### ä¸€ç»´ ```python def corr2d(X, K): # è·å–å·ç§¯æ ¸çš„é«˜å’Œå®½ h, w K.shape # åˆå§‹åŒ–è¾“å‡ºå¼ é‡Y Y torch.zeros((X.shape[0] h + 1, X.shape[1] w + 1)) # ä»¥åŠéå†è®¡ç®— for i in range(Y.shape[0]): for j in range(Y.shape[1]): Y[i, j] (X[i: i + h, j: j + w] * K).sum() return Y ``` + å¯ä»¥å»ºç«‹ä¸€ä¸ªå·ç§¯å±‚ ```python class Conv2D(nn.Module): def __init__(self, kernel_size): super().__init__() self.weight nn.Parameter(torch.rand(kernel_size)) self.bias nn.Parameter(torch.zeros(1)) def forward(self, x): return corr2d(x, self.weight) + self.bias ``` + å°è¯•æ£€æµ‹ä¸€ä¸‹è¾¹ç¼˜, è¿™é‡Œä½¿ç”¨çš„å·ç§¯æ ¸æ˜¯æŒ‡å®šçš„, æ£€æµ‹å‚ç›´çš„è¾¹ç¼˜ ```python # å‡è®¾è¿™æ˜¯ä¸€ä¸ªé»‘ç™½çš„å›¾åƒ, æ£€æµ‹ä¸€ä¸‹ä»–çš„è¾¹ç¼˜ X torch.ones((6, 8)) X[:, 2:6] 0 \"\"\" tensor([[1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.], [1., 1., 0., 0., 0., 0., 1., 1.]]) \"\"\" K torch.tensor([[1.0, 1.0]]) Y corr2d(X, K) \"\"\" tensor([[ 0., 1., 0., 0., 0., 1., 0.], [ 0., 1., 0., 0., 0., 1., 0.], [ 0., 1., 0., 0., 0., 1., 0.], [ 0., 1., 0., 0., 0., 1., 0.], [ 0., 1., 0., 0., 0., 1., 0.], [ 0., 1., 0., 0., 0., 1., 0.]]) \"\"\" ``` + å®é™…è®­ç»ƒè·å–ä¸€ä¸ªå·ç§¯æ ¸ ```python # è¾“å…¥å’Œè¾“å‡ºçš„é€šé“æ•°éƒ½æ˜¯1, å·ç§¯æ ¸çš„å¤§å°æ˜¯(1, 2) conv2d nn.Conv2d(1, 1, kernel_size (1, 2), bias False) # è¿™é‡Œçš„ç¬¬ä¸€ä¸ª1æ˜¯batch_size, ç¬¬äºŒä¸ª1æ˜¯é€šé“æ•°, 6æ˜¯é«˜, 8æ˜¯å®½ X X.reshape((1, 1, 6, 8)) Y Y.reshape((1, 1, 6, 7)) # æ‰‹å†™ä¸€ä¸ªæ¢¯åº¦ä¸‹é™ for i in range(10): Y_hat conv2d(X) l (Y_hat Y) ** 2 conv2d.zero_grad() l.sum().backward() conv2d.weight.data[:] 3e 2 * conv2d.weight.grad if (i + 1) % 2 0: print(f'batch {i + 1}, loss {l.sum():.3f}') conv2d.weight.data \"\"\" tensor([[[[ 1.0025, 0.9663]]]]) \"\"\" ``` ### å¤šç»´ + å¤šè¾“å…¥(é€šé“) ```python def corr2d_multi_in(X, K): # é¦–å…ˆæ²¿ç€Xå’ŒKçš„ç¬¬0ç»´(é€šé“ç»´)éå†, ç„¶åå°†ç»“æœç›¸åŠ  return sum(corr2d(x, k) for x, k in zip(X, K)) ``` + æ•°æ®æµ‹è¯• ```python # ä¸¤ä¸ªè¾“å…¥é€šé“2 * 2 * 3 X torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]], [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]]) # ä¸¤ä¸ªå·ç§¯æ ¸é€šé“2 * 2 * 2, è¾“å‡ºæ˜¯ä¸€ä¸ªé€šé“ K torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]]) corr2d_multi_in(X, K) ``` + å¤šè¾“å…¥å¤šè¾“å‡º ```python def corr2d_multi_in_out(X, K): # å¯¹Kçš„ç¬¬0ç»´éå†, æ¯æ¬¡éƒ½å¯¹è¾“å…¥Xæ‰§è¡Œä¸€æ¬¡äº’ç›¸å…³è¿ç®—, æœ€åå°†æ‰€æœ‰ç»“æœå †å åœ¨ä¸€èµ· # è¿™é‡Œçš„torch.stackæ˜¯å°†å¤šä¸ªtensorå †å åœ¨ä¸€èµ·, 0æ˜¯å †å çš„ç»´åº¦(æ–°å»ºçš„ç»´åº¦) return torch.stack([corr2d_multi_in(X, k) for k in K], 0) ``` + æµ‹è¯• ```python K2 torch.stack((K, K + 1, K + 2), 0) corr2d_multi_in_out(X, K2), K2.shape \"\"\" (tensor([[[ 56., 72.], [104., 120.]], [[ 76., 100.], [148., 172.]], [[ 96., 128.], [192., 224.]]]), torch.Size([3, 2, 2, 2])) \"\"\" ``` + è¯æ˜1x1å’Œå…¨è¿æ¥ç­‰ä»· ```python # 1x1çš„å·ç§¯å®é™…ä¸Šæ˜¯ä¸€ä¸ªå…¨è¿æ¥å±‚ def corr2d_multi_in_out_1x1(X, K): c_i, h, w X.shape c_o K.shape[0] X X.reshape((c_i, h * w)) K K.reshape((c_o, c_i)) Y torch.matmul(K, X) return Y.reshape((c_o, h, w)) X torch.rand(size (3, 3, 3)) K torch.rand(size (2, 3, 1, 1)) Y1 corr2d_multi_in_out_1x1(X, K) Y2 corr2d_multi_in_out(X, K) Y1 Y2 ``` ## ç®€å•ä½¿ç”¨ ```python nn.Conv2d(3, 2, kernel_size 1, bias False) ``` > è¾“å…¥è¾“å‡ºé€šé“æ•°, å·ç§¯æ ¸çš„å¤§å°, æ˜¯ä¸æ˜¯æœ‰åç§»"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-15-44BERT.html":{"title":"BERT","content":"# BERT ## NLPè¿ç§»å­¦ä¹  ä½¿ç”¨é¢„è®­ç»ƒçš„æ¨¡å‹æŠ½å–è¯å’Œå¥å­ç‰¹å¾, æ¯”å¦‚word2vec, ä¸æ›´æ–°è®­ç»ƒå¥½çš„æ¨¡å‹, éœ€è¦æ„å»ºæ–°çš„ç½‘ç»œæŠ“å–æ–°ä»»åŠ¡ä½¿ç”¨çš„ä¿¡æ¯ > æ›¿æ¢æ‰embedå±‚ BERTæ˜¯ä¸€ä¸ªåŸºäºå¾®è°ƒçš„NLPæ¨¡å‹, é¢„è®­ç»ƒäº†è¶³å¤Ÿå¤šçš„ä¿¡æ¯, æ–°çš„ä»»åŠ¡åªéœ€è¦åŠ ä¸€ä¸ªç®€å•çš„è¾“å‡ºå±‚, å®é™…æ˜¯ä¸€ä¸ªåªæœ‰ç¼–ç å™¨çš„Transformer ![img](https://pic1.zhimg.com/v2 bf3ee1a496cde5b6707d2ca2ffaccdda_1440w.jpg) è¿™ä¸ªæ¨¡å‹æœ‰ä¸¤ä¸ªç‰ˆæœ¬, æ”¹å˜çš„æ˜¯blockçš„æ•°é‡ä»¥åŠhidden size, headçš„å¤§å°å’Œå‚æ•°çš„æ•°é‡ ## å¯¹è¾“å…¥çš„ä¿®æ”¹ æ¯ä¸ªè¾“å…¥çš„å¥å­æ˜¯ä¸€ä¸ªå¥å­å¯¹(åŸæ¥çš„ä¸¤ä¸ªå¥å­éœ€è¦åˆ†åˆ«è¿›è¾“å…¥å’Œè¾“å‡º), å¥å­çš„å¼€å¤´å’Œåˆ†å‰²åŠ å…¥ä¸€ä¸ªåˆ†éš”ç¬¦ Embeddingç”±ä¸‰ç§Embeddingæ±‚å’Œè€Œæˆï¼š ![img](https://pica.zhimg.com/v2 86cc5ff7f5295dbf9587371034ba7abe_1440w.jpg) Token Embeddingsæ˜¯è¯å‘é‡ï¼Œç¬¬ä¸€ä¸ªå•è¯æ˜¯CLSæ ‡å¿—ï¼Œå¯ä»¥ç”¨äºä¹‹åçš„åˆ†ç±»ä»»åŠ¡ é€šè¿‡å»ºç«‹å­—å‘é‡è¡¨å°†æ¯ä¸ªå­—è½¬æ¢æˆä¸€ä¸ªä¸€ç»´å‘é‡ï¼Œä½œä¸ºæ¨¡å‹è¾“å…¥ã€‚ç‰¹åˆ«çš„ï¼Œè‹±æ–‡è¯æ±‡ä¼šåšæ›´ç»†ç²’åº¦çš„åˆ‡åˆ†ï¼Œæ¯”å¦‚playing æˆ–åˆ‡å‰²æˆ play å’Œ ##ingï¼Œä¸­æ–‡ç›®å‰å°šæœªå¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œç›´æ¥å¯¹å•å­æ„æˆä¸ºæœ¬çš„è¾“å…¥å•ä½ã€‚å°†è¯åˆ‡å‰²æˆæ›´ç»†ç²’åº¦çš„ Word Piece æ˜¯ä¸ºäº†è§£å†³æœªç™»å½•è¯çš„å¸¸è§æ–¹æ³•ã€‚ å‡å¦‚è¾“å…¥æ–‡æœ¬ â€I like dogâ€œã€‚ä¸‹å›¾åˆ™ä¸º Token Embeddings å±‚å®ç°è¿‡ç¨‹ã€‚è¾“å…¥æ–‡æœ¬åœ¨é€å…¥ Token Embeddings å±‚ä¹‹å‰è¦å…ˆè¿›æ€§ tokenization å¤„ç†ï¼Œä¸”ä¸¤ä¸ªç‰¹æ®Šçš„ Token ä¼šæ’å…¥åœ¨æ–‡æœ¬å¼€å¤´ [CLS] å’Œç»“å°¾ [SEP]ã€‚[CLS]è¡¨ç¤ºè¯¥ç‰¹å¾ç”¨äºåˆ†ç±»æ¨¡å‹ï¼Œå¯¹éåˆ†ç±»æ¨¡å‹ï¼Œè¯¥ç¬¦å·å¯ä»¥çœå»ã€‚[SEP]è¡¨ç¤ºåˆ†å¥ç¬¦å·ï¼Œç”¨äºæ–­å¼€è¾“å…¥è¯­æ–™ä¸­çš„ä¸¤ä¸ªå¥å­ã€‚ > ä½¿ç”¨è¿™ä¸¤ä¸ªæ˜¯ä¸ºäº†å¤„ç†ä¸€ä¸ªNSPåˆ†ç±»ä»»åŠ¡, ä½¿ç”¨[CLS]çš„æ ‡å¿—, å…¶è¡¨ç¤ºæ•´ä¸ªæ–‡æœ¬åºåˆ—çš„åˆ†ç±»ä¿¡æ¯ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå°†è¯¥[CLS]æ ‡å¿—çš„è¾“å‡ºå‘é‡ä¼ è¾“åˆ°ä¸€ä¸ªåˆ†ç±»å™¨ï¼ˆå¦‚softmaxå±‚ï¼‰ï¼Œä»è€Œä½¿BERTæ¨¡å‹èƒ½å¤Ÿåº”ç”¨äºæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ > > é€šè¿‡å°†æ–‡æœ¬åºåˆ—çš„è¾“å‡ºå‘é‡ä¸åˆ†ç±»å™¨è¿›è¡Œè¿æ¥ï¼ŒBERTæ¨¡å‹å¯ä»¥å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†ç±»ï¼Œå¹¶æ ¹æ®ä¸åŒä»»åŠ¡å¯¹[CLS]æ ‡å¿—çš„è¾“å‡ºè¿›è¡Œå¾®è°ƒã€‚è¿™ç§æ–¹å¼ä½¿å¾—BERTæ¨¡å‹å¯ä»¥é€‚åº”å„ç§åˆ†ç±»ä»»åŠ¡ï¼Œå¦‚æƒ…æ„Ÿåˆ†æã€æ–‡æœ¬åˆ†ç±»ã€é—®é¢˜å›ç­”ç­‰ã€‚ > > è¿™ä¸ªå‘é‡ä¸å¯ä»¥ç”¨äºä½œä¸ºæ•´ä¸ªå¥å­çš„è¯­ä¹‰ Bert åœ¨å¤„ç†è‹±æ–‡æ–‡æœ¬æ—¶åªéœ€è¦ 30522 ä¸ªè¯ï¼ŒToken Embeddings å±‚ä¼šå°†æ¯ä¸ªè¯è½¬æ¢æˆ 768 ç»´å‘é‡ï¼Œä¾‹å­ä¸­ 5 ä¸ªToken ä¼šè¢«è½¬æ¢æˆä¸€ä¸ª (6, 768) çš„çŸ©é˜µæˆ– (1, 6, 768) çš„å¼ é‡ã€‚ ![img](https://pic2.zhimg.com/v2 817b0e44f9afe2d3db8672c1cfbcb809_1440w.jpg) Segment Embeddingsç”¨æ¥åŒºåˆ«ä¸¤ç§å¥å­ï¼Œå› ä¸ºé¢„è®­ç»ƒä¸å…‰åšLMè¿˜è¦åšä»¥ä¸¤ä¸ªå¥å­ä¸ºè¾“å…¥çš„åˆ†ç±»ä»»åŠ¡ Bert èƒ½å¤Ÿå¤„ç†å¥å­å¯¹çš„åˆ†ç±»ä»»åŠ¡ï¼Œè¿™ç±»ä»»åŠ¡å°±æ˜¯åˆ¤æ–­ä¸¤ä¸ªæ–‡æœ¬æ˜¯å¦æ˜¯è¯­ä¹‰ç›¸ä¼¼çš„ã€‚å¥å­å¯¹ä¸­çš„ä¸¤ä¸ªå¥å­è¢«ç®€å•çš„æ‹¼æ¥åœ¨ä¸€èµ·åé€å…¥æ¨¡å‹ä¸­ï¼ŒBert å¦‚ä½•åŒºåˆ†ä¸€ä¸ªå¥å­å¯¹æ˜¯ä¸¤ä¸ªå¥å­å‘¢ï¼Ÿç­”æ¡ˆå°±æ˜¯ Segment Embeddingsã€‚ Segement Embeddings å±‚æœ‰ä¸¤ç§å‘é‡è¡¨ç¤ºï¼Œå‰ä¸€ä¸ªå‘é‡æ˜¯æŠŠ 0 èµ‹å€¼ç»™ç¬¬ä¸€ä¸ªå¥å­çš„å„ä¸ª Tokenï¼Œåä¸€ä¸ªå‘é‡æ˜¯æŠŠ1èµ‹å€¼ç»™å„ä¸ª Tokenï¼Œé—®ç­”ç³»ç»Ÿç­‰ä»»åŠ¡è¦é¢„æµ‹ä¸‹ä¸€å¥ï¼Œå› æ­¤è¾“å…¥æ˜¯æœ‰å…³è”çš„å¥å­ã€‚è€Œæ–‡æœ¬åˆ†ç±»åªæœ‰ä¸€ä¸ªå¥å­ï¼Œé‚£ä¹ˆ Segement embeddings å°±å…¨éƒ¨æ˜¯ 0ã€‚ ![img](https://pic1.zhimg.com/v2 888e81eea8ec993cbf676c9dd6750b50_1440w.jpg) Position Embeddingså’Œä¹‹å‰æ–‡ç« ä¸­çš„Transformerä¸ä¸€æ ·ï¼Œä¸æ˜¯ä¸‰è§’å‡½æ•°è€Œæ˜¯å­¦ä¹ å‡ºæ¥çš„ ç”±äºå‡ºç°åœ¨æ–‡æœ¬ä¸åŒä½ç½®çš„å­—/è¯æ‰€æºå¸¦çš„è¯­ä¹‰ä¿¡æ¯å­˜åœ¨å·®å¼‚(å¦‚ â€ä½ çˆ±æˆ‘â€œ å’Œ â€æˆ‘çˆ±ä½ â€œ)ï¼Œä½ å’Œæˆ‘è™½ç„¶éƒ½å’Œçˆ±å­—å¾ˆæ¥è¿‘ï¼Œä½†æ˜¯ä½ç½®ä¸åŒï¼Œè¡¨ç¤ºçš„å«ä¹‰ä¸åŒã€‚ åœ¨ RNN ä¸­ï¼Œç¬¬äºŒä¸ª â€Iâ€œ å’Œ ç¬¬ä¸€ä¸ª â€Iâ€œ è¡¨è¾¾çš„æ„ä¹‰ä¸ä¸€æ ·ï¼Œå› ä¸ºå®ƒä»¬çš„éšçŠ¶æ€ä¸ä¸€æ ·ã€‚å¯¹ç¬¬äºŒä¸ª â€Iâ€œ æ¥è¯´ï¼ŒéšçŠ¶æ€ç»è¿‡ â€I think thereforeâ€œ ä¸‰ä¸ªè¯ï¼ŒåŒ…å«äº†å‰é¢ä¸‰ä¸ªè¯çš„ä¿¡æ¯ï¼Œè€Œç¬¬ä¸€ä¸ª â€Iâ€œ åªæ˜¯ä¸€ä¸ªåˆå§‹å€¼ã€‚å› æ­¤ï¼ŒRNN çš„éšçŠ¶æ€ä¿è¯åœ¨ä¸åŒä½ç½®ä¸Šç›¸åŒçš„è¯æœ‰ä¸åŒçš„è¾“å‡ºå‘é‡è¡¨ ![img](https://pic2.zhimg.com/v2 bcba030285047b347d73721e415d3dad_1440w.jpg) Transformer ä¸­é€šè¿‡æ¤å…¥å…³äº Token çš„ç›¸å¯¹ä½ç½®æˆ–è€…ç»å¯¹ä½ç½®ä¿¡æ¯æ¥è¡¨ç¤ºåºåˆ—çš„é¡ºåºä¿¡æ¯ã€‚ä½œè€…æµ‹è¯•ç”¨å­¦ä¹ çš„æ–¹æ³•æ¥å¾—åˆ° Position Embeddingsï¼Œæœ€ç»ˆå‘ç°å›ºå®šä½ç½®å’Œç›¸å¯¹ä½ç½®æ•ˆæœå·®ä¸å¤šï¼Œæ‰€ä»¥æœ€åç”¨çš„æ˜¯å›ºå®šä½ç½®çš„ï¼Œè€Œæ­£å¼¦å¯ä»¥å¤„ç†æ›´é•¿çš„ Sequenceï¼Œä¸”å¯ä»¥ç”¨å‰é¢ä½ç½®çš„å€¼çº¿æ€§è¡¨ç¤ºåé¢çš„ä½ç½®ã€‚ BERT ä¸­å¤„ç†çš„æœ€é•¿åºåˆ—æ˜¯ 512 ä¸ª Tokenï¼Œé•¿åº¦è¶…è¿‡ 512 ä¼šè¢«æˆªå–ï¼ŒBERT åœ¨å„ä¸ªä½ç½®ä¸Šå­¦ä¹ ä¸€ä¸ªå‘é‡æ¥è¡¨ç¤ºåºåˆ—é¡ºåºçš„ä¿¡æ¯ç¼–ç è¿›æ¥ï¼Œè¿™æ„å‘³ç€ Position Embeddings å®é™…ä¸Šæ˜¯ä¸€ä¸ª (512, 768) çš„ lookup è¡¨ï¼Œè¡¨ç¬¬ä¸€è¡Œæ˜¯ä»£è¡¨ç¬¬ä¸€ä¸ªåºåˆ—çš„æ¯ä¸ªä½ç½®ï¼Œç¬¬äºŒè¡Œä»£è¡¨åºåˆ—ç¬¬äºŒä¸ªä½ç½®ã€‚ ## é¢„è®­ç»ƒ åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†, MLMå’ŒNSPä¸¤ä¸ªä»»åŠ¡, åŒæ—¶è¿›è¡Œ åœ¨è¿›è¡Œè‡ªè®­ç»ƒçš„æ—¶å€™ä¸»è¦æœ‰ä¸¤ç§æ–¹å¼ + MLMæ˜¯æŒ‡Masked Language Model ARï¼ˆAutoRegressiveï¼‰æ¨¡å‹æ˜¯ä¸€ç§æ—¶é—´åºåˆ—æ¨¡å‹ï¼Œå®ƒä¾èµ–äºè¿‡å»æ—¶é—´æ­¥çš„è¾“å…¥æ¥é¢„æµ‹æœªæ¥çš„è¾“å‡ºã€‚ARæ¨¡å‹é€šå¸¸ç”¨äºæ—¶é—´åºåˆ—æ•°æ®çš„é¢„æµ‹å’Œå»ºæ¨¡ï¼Œå…¶ä¸­å½“å‰æ—¶é—´æ­¥çš„è¾“å‡ºä¸å‰é¢è‹¥å¹²ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ç›¸å…³ã€‚ > åªä½¿ç”¨å•ä¾§çš„ä¿¡æ¯ AEï¼ˆAutoEncoderï¼‰æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œç”¨äºå­¦ä¹ æ•°æ®çš„éšè—è¡¨ç¤ºæˆ–ç‰¹å¾ã€‚è‡ªç¼–ç å™¨åŒ…æ‹¬ç¼–ç å™¨å’Œè§£ç å™¨ä¸¤éƒ¨åˆ†ï¼Œé€šè¿‡å°†è¾“å…¥æ•°æ®å‹ç¼©æˆä½ç»´ç¼–ç ç„¶åé‡æ„åŸå§‹æ•°æ®æ¥å­¦ä¹ æ•°æ®çš„æœ‰æ•ˆè¡¨ç¤ºã€‚AEå¹¿æ³›åº”ç”¨äºç‰¹å¾æå–ã€é™ç»´ã€å»å™ªå’Œç”Ÿæˆæ¨¡å‹ç­‰ä»»åŠ¡ã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œè‡ªç¼–ç å™¨ä¹Ÿç»å¸¸ç”¨äºå­¦ä¹ æ–‡æœ¬çš„è¡¨ç¤ºå’Œç‰¹å¾ã€‚ > å¯ä»¥ä½¿ç”¨ä¸¤ä¾§çš„ä¿¡æ¯, ä½†æ˜¯maskçš„éƒ¨åˆ†å¯èƒ½é€‰å–ä»¥åå¯ä»¥çš„è¾“å‡ºä¸å”¯ä¸€ ![image 20250217164217268](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502171642363.png) å®é™…ä½¿ç”¨çš„æ˜¯AEçš„æ–¹å¼, mask15%çš„å•è¯, è¿™é‡Œé¢10%è¢«æ›¿æ¢, 10%ä¸åŠ¨, 80%è¢«æ›¿æ¢ä¸ºmask > è¿™ä¹ˆåšä¸»è¦çš„åŸå› æ˜¯ä¸ºäº†ä½¿å¾—å¾®è°ƒçš„æ—¶å€™ä»»åŠ¡ä¸å‡ºç°maskä¹Ÿå¯ä»¥è¿›è¡Œ + NLPæ˜¯Natural Language Processin, å®é™…æ˜¯å¯¹æ–‡æœ¬äºŒåˆ†ç±» ä½¿ç”¨ä»åŒä¸€ä¸ªæ–‡æ¡£é‡Œé¢çš„ç›¸é‚»çš„å¥å­æ˜¯æ­£æ ·æœ¬, ä¸åŒçš„æ–‡æ¡£é‡Œé¢çš„å¥å­è´Ÿæ ·æœ¬, åŒºåˆ†ä¸¤ä¸ªå¥å­æ˜¯ä¸æ˜¯æœ‰å…³ > ä¸»é¢˜å’Œè¿è´¯æ€§é¢„æµ‹åˆå¹¶ä¸ºåŒä¸€ä¸ªå•é¡¹ä»»åŠ¡, å¯¹CLSçš„è¾“å‡ºè¿›è¡Œä½¿ç”¨ ## å®é™…ä½¿ç”¨ ![img](https://pica.zhimg.com/v2 8cbd2f07c18b85db855b32c424d5177e_1440w.jpg) > åˆ†ç±»ä»»åŠ¡ä½¿ç”¨çš„clsæ ‡å¿—çš„è¾“å‡º, é—®ç­”ä½¿ç”¨çš„æ˜¯æœ€å¥½çš„è¾“å‡º, æˆåˆ†åˆ’åˆ†ä½¿ç”¨çš„æ˜¯å‡ºæ¥CLSä»¥å¤–çš„è¾“å‡º å¾®è°ƒä½¿ç”¨ 1. å¤§é‡æ•°æ®è¿›è¡Œé¢„è®­ç»ƒPertrain 2. ç›¸åŒçš„é¢†åŸŸç»§ç»­è®­ç»ƒ, Domain trasfer 3. ä»»åŠ¡ç›¸å…³çš„å°æ•°æ®é›†é‡Œé¢ç»§ç»­è®­ç»ƒ Task transfer 4. ä»»åŠ¡ç›¸å…³æ•°æ®è®­ç»ƒFine tune ## å®ç° æŠ½å–ç‰¹å¾çš„ä½ç½® ```python #@save class BERTEncoder(nn.Module): \"\"\"BERTç¼–ç å™¨\"\"\" def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, max_len 1000, key_size 768, query_size 768, value_size 768, **kwargs): super(BERTEncoder, self).__init__(**kwargs) self.token_embedding nn.Embedding(vocab_size, num_hiddens) self.segment_embedding nn.Embedding(2, num_hiddens) # ä¸¤ä¸ªç‰‡æ®µçš„åµŒå…¥ self.blks nn.Sequential() # åˆ›å»ºå¤šä¸ªBERTå— for i in range(num_layers): self.blks.add_module(f\"{i}\", d2l.EncoderBlock( key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, True)) # åœ¨BERTä¸­ï¼Œä½ç½®åµŒå…¥æ˜¯å¯å­¦ä¹ çš„ï¼Œå› æ­¤æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè¶³å¤Ÿé•¿çš„ä½ç½®åµŒå…¥å‚æ•° self.pos_embedding nn.Parameter(torch.randn(1, max_len, num_hiddens)) def forward(self, tokens, segments, valid_lens): # åœ¨ä»¥ä¸‹ä»£ç æ®µä¸­ï¼ŒXçš„å½¢çŠ¶ä¿æŒä¸å˜ï¼šï¼ˆæ‰¹é‡å¤§å°ï¼Œæœ€å¤§åºåˆ—é•¿åº¦ï¼Œnum_hiddensï¼‰ X self.token_embedding(tokens) + self.segment_embedding(segments) X X + self.pos_embedding.data[:, :X.shape[1], :] for blk in self.blks: X blk(X, valid_lens) return X vocab_size, num_hiddens, ffn_num_hiddens, num_heads 10000, 768, 1024, 4 norm_shape, ffn_num_input, num_layers, dropout [768], 768, 2, 0.2 encoder BERTEncoder(vocab_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout) tokens torch.randint(0, vocab_size, (2, 8)) # ä¸¤ä¸ªæ ·æœ¬çš„è¯å…ƒ # ä¸¤ä¸ªæ ·æœ¬çš„ç‰‡æ®µæ ‡è®° segments torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]]) encoded_X encoder(tokens, segments, None) encoded_X.shape \"\"\" torch.Size([2, 8, 768]) \"\"\" ``` ç”¨äºè®¡ç®—maskçš„ä½ç½® ```python #@save class MaskLM(nn.Module): \"\"\"BERTçš„æ©è”½è¯­è¨€æ¨¡å‹ä»»åŠ¡\"\"\" def __init__(self, vocab_size, num_hiddens, num_inputs 768, **kwargs): super(MaskLM, self).__init__(**kwargs) self.mlp nn.Sequential( nn.Linear(num_inputs, num_hiddens), nn.ReLU(), nn.LayerNorm(num_hiddens), # é€šè¿‡å±‚å½’ä¸€åŒ– nn.Linear(num_hiddens, vocab_size)) # å®ƒéœ€è¦ä¸¤ä¸ªè¾“å…¥ï¼šBERTEncoderçš„ç¼–ç ç»“æœå’Œç”¨äºé¢„æµ‹çš„è¯å…ƒä½ç½®ã€‚ # è¾“å‡ºæ˜¯è¿™äº›ä½ç½®çš„é¢„æµ‹ç»“æœ def forward(self, X, pred_positions): num_pred_positions pred_positions.shape[1] # é¢„æµ‹çš„è¯å…ƒæ•° pred_positions pred_positions.reshape( 1) # å±•å¹³ batch_size X.shape[0] batch_idx torch.arange(0, batch_size) # å‡è®¾batch_size 2ï¼Œnum_pred_positions 3(2è¡Œ, æ¯è¡Œ3ä¸ªä½ç½®) # é‚£ä¹ˆbatch_idxæ˜¯np.arrayï¼ˆ[0,0,0,1,1,1]ï¼‰æ˜¯ä¸€ä¸ª2x3çš„æ•°é‡, å’Œpred_positionsé…åˆè·å–å…­ä¸ªä½ç½®çš„è¯å…ƒ batch_idx torch.repeat_interleave(batch_idx, num_pred_positions) # é‡å¤batch_idx masked_X X[batch_idx, pred_positions] # å…ˆæŒ‰batchå–è¡Œï¼Œå†æŒ‰pred_positionså–åˆ— masked_X masked_X.reshape((batch_size, num_pred_positions, 1)) mlm_Y_hat self.mlp(masked_X) return mlm_Y_hat ``` ```python # å¯¹vocab_sizeä¸ªè¯å…ƒçš„é¢„æµ‹ mlm MaskLM(vocab_size, num_hiddens) mlm_positions torch.tensor([[1, 5, 2], [6, 1, 5]]) # è¾“å…¥çš„Xæ˜¯ç¼–ç å™¨çš„è¾“å‡ºï¼Œå½¢çŠ¶ä¸º(2, 8, 768), è¾“å‡ºæ˜¯å¯¹åº”ä½ç½®çš„é¢„æµ‹ç»“æœ(æ¯ä¸€è¡Œä¸‰ä¸ª) mlm_Y_hat mlm(encoded_X, mlm_positions) # batch 2, é¢„æµ‹3ä¸ªå€¼, è¾“å‡ºçš„å¤§å°æ˜¯vocab_sizeä¸ªè¯çš„é¢„æµ‹ mlm_Y_hat.shape \"\"\" torch.Size([2, 3, 10000]) \"\"\" ``` å¯ä»¥ä½¿ç”¨äº¤å‰ç†µè®¡ç®—æŸå¤±å‡½æ•° ```python mlm_Y torch.tensor([[7, 8, 9], [10, 20, 30]]) loss nn.CrossEntropyLoss(reduction 'none') mlm_l loss(mlm_Y_hat.reshape(( 1, vocab_size)), mlm_Y.reshape( 1)) mlm_l.shape \"\"\" torch.Size([6]) \"\"\" ``` ä½¿ç”¨clsçš„è¾“å‡ºåˆ¤æ–­æ˜¯ä¸æ˜¯è¿ç»­çš„ ```python #@save class NextSentencePred(nn.Module): \"\"\"BERTçš„ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡\"\"\" def __init__(self, num_inputs, **kwargs): super(NextSentencePred, self).__init__(**kwargs) self.output nn.Linear(num_inputs, 2) def forward(self, X): # Xçš„å½¢çŠ¶ï¼š(batchsize,num_hiddens) return self.output(X) ``` ä¸¤ä¸ªbatchè¾“å‡ºçš„æ˜¯ä¸¤ä¸ªé¢„æœŸçš„é¢„æµ‹å€¼ ```python encoded_X torch.flatten(encoded_X, start_dim 1) # NSPçš„è¾“å…¥å½¢çŠ¶:(batchsizeï¼Œnum_hiddens) nsp NextSentencePred(encoded_X.shape[ 1]) nsp_Y_hat nsp(encoded_X) nsp_Y_hat.shape ``` å»ºç«‹å®Œæ•´çš„æ¨¡å‹ ```python class BERTModel(nn.Module): \"\"\"BERTæ¨¡å‹\"\"\" def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, max_len 1000, key_size 768, query_size 768, value_size 768, hid_in_features 768, mlm_in_features 768, nsp_in_features 768): super(BERTModel, self).__init__() self.encoder BERTEncoder(vocab_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, max_len max_len, key_size key_size, query_size query_size, value_size value_size) self.hidden nn.Sequential(nn.Linear(hid_in_features, num_hiddens), nn.Tanh()) self.mlm MaskLM(vocab_size, num_hiddens, mlm_in_features) self.nsp NextSentencePred(nsp_in_features) def forward(self, tokens, segments, valid_lens None, pred_positions None): encoded_X self.encoder(tokens, segments, valid_lens) if pred_positions is not None: mlm_Y_hat self.mlm(encoded_X, pred_positions) else: mlm_Y_hat None # ç”¨äºä¸‹ä¸€å¥é¢„æµ‹çš„å¤šå±‚æ„ŸçŸ¥æœºåˆ†ç±»å™¨çš„éšè—å±‚ï¼Œ0æ˜¯â€œ<cls>â€æ ‡è®°çš„ç´¢å¼• nsp_Y_hat self.nsp(self.hidden(encoded_X[:, 0, :])) return encoded_X, mlm_Y_hat, nsp_Y_hat ``` ```python net d2l.BERTModel(len(vocab), num_hiddens 128, norm_shape [128], ffn_num_input 128, ffn_num_hiddens 256, num_heads 2, num_layers 2, dropout 0.2, key_size 128, query_size 128, value_size 128, hid_in_features 128, mlm_in_features 128, nsp_in_features 128) devices d2l.try_all_gpus() loss nn.CrossEntropyLoss() ``` ä¸€ä¸ªè®¡ç®—æŸå¤±çš„å‡½æ•° ```python #@save def _get_batch_loss_bert(net, loss, vocab_size, tokens_X, segments_X, valid_lens_x, pred_positions_X, mlm_weights_X, mlm_Y, nsp_y): # å‰å‘ä¼ æ’­ _, mlm_Y_hat, nsp_Y_hat net(tokens_X, segments_X, valid_lens_x.reshape( 1), pred_positions_X) # è®¡ç®—é®è”½è¯­è¨€æ¨¡å‹æŸå¤± mlm_l loss(mlm_Y_hat.reshape( 1, vocab_size), mlm_Y.reshape( 1)) *\\ mlm_weights_X.reshape( 1, 1) mlm_l mlm_l.sum() / (mlm_weights_X.sum() + 1e 8) # è®¡ç®—ä¸‹ä¸€å¥å­é¢„æµ‹ä»»åŠ¡çš„æŸå¤± nsp_l loss(nsp_Y_hat, nsp_y) l mlm_l + nsp_l return mlm_l, nsp_l, l ``` è®­ç»ƒå‡½æ•° ````python def train_bert(train_iter, net, loss, vocab_size, devices, num_steps): net nn.DataParallel(net, device_ids devices).to(devices[0]) trainer torch.optim.Adam(net.parameters(), lr 0.01) step, timer 0, d2l.Timer() animator d2l.Animator(xlabel 'step', ylabel 'loss', xlim [1, num_steps], legend ['mlm', 'nsp']) # é®è”½è¯­è¨€æ¨¡å‹æŸå¤±çš„å’Œï¼Œä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡æŸå¤±çš„å’Œï¼Œå¥å­å¯¹çš„æ•°é‡ï¼Œè®¡æ•° metric d2l.Accumulator(4) num_steps_reached False while step < num_steps and not num_steps_reached: for tokens_X, segments_X, valid_lens_x, pred_positions_X,\\ mlm_weights_X, mlm_Y, nsp_y in train_iter: tokens_X tokens_X.to(devices[0]) segments_X segments_X.to(devices[0]) valid_lens_x valid_lens_x.to(devices[0]) pred_positions_X pred_positions_X.to(devices[0]) mlm_weights_X mlm_weights_X.to(devices[0]) mlm_Y, nsp_y mlm_Y.to(devices[0]), nsp_y.to(devices[0]) trainer.zero_grad() timer.start() mlm_l, nsp_l, l _get_batch_loss_bert( net, loss, vocab_size, tokens_X, segments_X, valid_lens_x, pred_positions_X, mlm_weights_X, mlm_Y, nsp_y) l.backward() trainer.step() metric.add(mlm_l, nsp_l, tokens_X.shape[0], 1) timer.stop() animator.add(step + 1, (metric[0] / metric[3], metric[1] / metric[3])) step + 1 if step num_steps: num_steps_reached True break print(f'MLM loss {metric[0] / metric[3]:.3f}, ' f'NSP loss {metric[1] / metric[3]:.3f}') print(f'{metric[2] / timer.sum():.1f} sentence pairs/sec on ' f'{str(devices)}') ```` ä¸€ä¸ªè·å–encodeçš„ç»“æœçš„å‡½æ•° ```python def get_bert_encoding(net, tokens_a, tokens_b None): tokens, segments d2l.get_tokens_and_segments(tokens_a, tokens_b) token_ids torch.tensor(vocab[tokens], device devices[0]).unsqueeze(0) segments torch.tensor(segments, device devices[0]).unsqueeze(0) valid_len torch.tensor(len(tokens), device devices[0]).unsqueeze(0) encoded_X, _, _ net(token_ids, segments, valid_len) return encoded_X ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-7-31-å¾ªç¯ç¥ç»ç½‘ç»œRNN.html":{"title":"å¾ªç¯ç¥ç»ç½‘ç»œRNN","content":"# å¾ªç¯ç¥ç»ç½‘ç»œRNN å…¶ä¸­å•è¯xtåœ¨æ—¶é—´æ­¥tçš„æ¡ä»¶æ¦‚ç‡ä»…å–å†³äºå‰é¢nâˆ’1ä¸ªå•è¯ã€‚å¯¹äºæ—¶ é—´æ­¥tâˆ’(nâˆ’1)ä¹‹å‰çš„å•è¯ï¼Œå¦‚æœæˆ‘ä»¬æƒ³å°†å…¶å¯èƒ½äº§ç”Ÿçš„å½±å“åˆå¹¶åˆ°xtä¸Šï¼Œéœ€è¦å¢åŠ nï¼Œç„¶è€Œæ¨¡å‹å‚æ•°çš„æ•°é‡ ä¹Ÿä¼šéšä¹‹å‘ˆæŒ‡æ•°å¢é•¿ï¼Œå› ä¸ºè¯è¡¨Véœ€è¦å­˜å‚¨Vnä¸ªæ•°å­—ï¼Œå› æ­¤ä¸å…¶å°†P(xt xtâˆ’1,...,xtâˆ’n+1)æ¨¡å‹åŒ–ï¼Œä¸å¦‚ä½¿ ç”¨éšå˜é‡æ¨¡å‹ï¼š ![image 20250209144302181](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091443337.png) å…¶ä¸­htâˆ’1æ˜¯éšçŠ¶æ€ï¼ˆhiddenstateï¼‰ï¼Œä¹Ÿç§°ä¸ºéšè—å˜é‡ï¼ˆhiddenvariableï¼‰ï¼Œå®ƒå­˜å‚¨äº†åˆ°æ—¶é—´æ­¥tâˆ’1çš„åºåˆ—ä¿¡ æ¯ã€‚ ![image 20250209144320811](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091443853.png) éšçŠ¶æ€æ˜¯ åœ¨ç»™å®šæ­¥éª¤æ‰€åšçš„ä»»ä½•äº‹æƒ…ï¼ˆä»¥æŠ€æœ¯è§’åº¦æ¥å®šä¹‰ï¼‰çš„è¾“å…¥ï¼Œå¹¶ä¸”è¿™äº›çŠ¶æ€åªèƒ½é€šè¿‡å…ˆå‰æ—¶é—´æ­¥çš„æ•°æ®æ¥è®¡ç®—ã€‚ ![image 20250209144409205](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091444364.png) ![image 20250209144512447](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091445485.png) å¾ªç¯ç¥ç»ç½‘ç»œçš„å‚æ•°åŒ…æ‹¬éšè—å±‚çš„æƒé‡W~xh~ âˆˆ R^dÃ—h^,W~hh~ âˆˆ R^hÃ—h^å’Œåç½®b~h~ âˆˆ R^1Ã—h^ï¼Œä»¥åŠè¾“å‡ºå±‚çš„æƒ é‡W~hq~ âˆˆR^hÃ—q^ å’Œåç½®b~q~ âˆˆR^1Ã—q^ã€‚ åœ¨å®é™…è®¡ç®—çš„æ—¶å€™, éšçŠ¶æ€ä¸­X~t~W~xh~+H~tâˆ’1~W~hh~çš„è®¡ç®—ï¼Œç›¸å½“äºX~t~å’ŒH~tâˆ’1~çš„æ‹¼æ¥ä¸W~xh~å’ŒW~hh~çš„æ‹¼æ¥çš„çŸ©é˜µä¹˜æ³•ã€‚è¿™ä¸€éƒ¨åˆ†çš„è®¡ç®—å¯ä»¥ä½¿ç”¨ä¸€ä¸ª0ç»´åº¦çš„æ‹¼æ¥å’Œä¸€ä¸ª1ç»´åº¦çš„æ‹¼æ¥è¿›è¡Œç®€åŒ–å¤„ç† ```python X, W_xh torch.normal(0, 1, (3, 1)), torch.normal(0, 1, (1, 4)) H, W_hh torch.normal(0, 1, (3, 4)), torch.normal(0, 1, (4, 4)) torch.matmul(X, W_xh) + torch.matmul(H, W_hh) # ç»“æœå’Œä¸‹é¢çš„è®¡ç®—æ˜¯ä¸€æ ·çš„ torch.matmul(torch.cat((X, H), 1), torch.cat((W_xh, W_hh), 0)) \"\"\" tensor([[ 2.6746, 0.6725, 3.2530, 1.5621], [ 2.5695, 2.5248, 0.0943, 0.1504], [ 1.5933, 0.4725, 0.0299, 0.1567]]) \"\"\" ``` ## æ¨¡å‹å®ç° ```python %matplotlib inline import math import torch from torch import nn from torch.nn import functional as F from d2l import torch as d2l ``` + åŠ è½½ä¸€ä¸‹ä½¿ç”¨çš„æ•°æ®, è¿™é‡Œçš„æ•°æ®æ˜¯æŒ‰ç…§å­—ç¬¦è¿›è¡Œåˆ†å‰²çš„ + vocab: è¾“å…¥å­—æ¯è¾“å‡ºå¯¹åº”çš„ç¼–å· ```python batch_size, num_steps 32, 35 train_iter, vocab d2l.load_data_time_machine(batch_size, num_steps) print(len(vocab)) for X, y in train_iter: print(X.shape) print(y.shape) break \"\"\" 28 torch.Size([32, 35]) torch.Size([32, 35]) \"\"\" print(vocab.token_freqs[:10]) print(list(vocab.token_to_idx.items())[:10]) print(vocab['a']) \"\"\" [(' ', 29927), ('e', 17838), ('t', 13515), ('a', 11704), ('i', 10138)] [('<unk>', 0), (' ', 1), ('e', 2), ('t', 3), ('a', 4)] 4 \"\"\" ``` ä¹‹åä¼šä½¿ç”¨one_hotçš„å‡½æ•°, è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯æŠŠä¸€ä¸ªtensorå¢åŠ ä¸€ä¸ªæœ€ä½ç»´åº¦, æŠŠä¸Šå±‚çš„æ•°å­—å¯¹åº”ä½ç½®ç½®1, å…¶ä»–çš„ä¸º0, ç¬¬äºŒä¸ªå‚æ•°æ˜¯æœ€ä½ç»´åº¦çš„å‚æ•°æ•°é‡ ```python F.one_hot(torch.tensor([0, 2]), len(vocab)) # æŠŠç´¢å¼•è½¬æ¢ä¸ºç‹¬çƒ­å‘é‡(åªæœ‰å¯¹åº”ç´¢å¼•çš„ä½ç½®ä¸º1) \"\"\" tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]) \"\"\" X torch.arange(10).reshape((2, 5)) # Xæ˜¯æŒ‰ç…§(æ‰¹é‡å¤§å°, æ—¶é—´æ­¥æ•°)æ’åˆ—çš„ F.one_hot(X.T, len(vocab)).shape # X.Tæ˜¯æŒ‰ç…§(æ—¶é—´æ­¥æ•°, æ‰¹é‡å¤§å°)æ’åˆ—çš„, æ‰€ä»¥è¦è½¬ç½® \"\"\" torch.Size([5, 2, 28]) \"\"\" ``` ç°åœ¨å®ç°è®¡ç®—çš„è¿‡ç¨‹, è®¡ç®—çš„æ—¶å€™éœ€è¦ä½¿ç”¨çš„å‚æ•°è‡ªå·±è¿›è¡Œä¸€ä¸‹åˆå§‹åŒ– ![image 20250209150307695](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091503725.png) ```python def get_params(vocab_size, num_hiddens, device): # è¿™é‡Œçš„è¾“å‡ºå‚æ•°çš„æ•°é‡æ˜¯28(ä¹‹åçš„xä¼šä½¿ç”¨one_hotè¿›è¡Œæ‹‰ä¼¸) num_inputs num_outputs vocab_size def normal(shape): return torch.randn(size shape, device device) * 0.01 # éšè—å±‚å‚æ•° W_xh normal((num_inputs, num_hiddens)) W_hh normal((num_hiddens, num_hiddens)) b_h torch.zeros(num_hiddens, device device) # è¾“å‡ºå±‚å‚æ•° W_hq normal((num_hiddens, num_outputs)) b_q torch.zeros(num_outputs, device device) # é™„åŠ æ¢¯åº¦ params [W_xh, W_hh, b_h, W_hq, b_q] for param in params: param.requires_grad_(True) return params ``` åœ¨å®é™…è®¡ç®—çš„æ—¶å€™, éœ€è¦ä¸€ä¸ªåˆå§‹åŒ–ä¸€ä¸ªçŠ¶æ€, ä¹‹ååœ¨è¿ç®—çš„æ—¶å€™æ ¹æ®æ–°çš„è¾“å…¥ä¸æ–­è¿­ä»£, è¿™é‡Œåˆå§‹åŒ–çš„æ—¶å€™æ˜¯åˆå§‹åŒ–ä¸ºä¸€ä¸ªå…¨é›¶çš„å‘é‡ ```python # åœ¨åˆå§‹åŒ–æ—¶è¿”å›éšçŠ¶æ€ã€‚è¿™ä¸ªå‡½æ•°çš„è¿” # å›æ˜¯ä¸€ä¸ªå¼ é‡ï¼Œå¼ é‡å…¨ç”¨0å¡«å……ï¼Œå½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ï¼Œéšè—å•å…ƒæ•°ï¼‰ def init_rnn_state(batch_size, num_hiddens, device): return (torch.zeros((batch_size, num_hiddens), device device), ) ``` æœ‰äº†å‚æ•°ä»¥åå°±å¯ä»¥ä½¿ç”¨è¿™éƒ¨åˆ†çš„å‚æ•°å¼€å§‹è®¡ç®—äº†, å•æ¬¡è¾“å…¥çš„è®¡ç®—å¦‚ä¸‹ ```python # åœ¨ä¸€ä¸ªæ—¶é—´æ­¥å†…è®¡ç®—éšçŠ¶æ€å’Œè¾“å‡º def rnn(inputs, state, params): # inputsçš„å½¢çŠ¶ï¼š(æ—¶é—´æ­¥æ•°é‡ï¼Œæ‰¹é‡å¤§å°ï¼Œè¯è¡¨å¤§å°) W_xh, W_hh, b_h, W_hq, b_q params H, state outputs [] # Xçš„å½¢çŠ¶ï¼š(æ‰¹é‡å¤§å°ï¼Œè¯è¡¨å¤§å°) for X in inputs: # Xå’ŒHçš„å½¢çŠ¶ï¼š(æ‰¹é‡å¤§å°ï¼Œè¯è¡¨å¤§å°)ï¼ŒW_xhçš„å½¢çŠ¶ï¼š(è¯è¡¨å¤§å°ï¼Œéšè—å•å…ƒæ•°) # tanhæ¿€æ´»å‡½æ•° H torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h) Y torch.mm(H, W_hq) + b_q outputs.append(Y) # å¯¹äºæ¯ä¸€ä¸ªxéƒ½æœ‰ä¸€ä¸ªè¾“å‡º, å¯ä»¥è¿›è¡Œæ‹¼æ¥ # è¿”å›è¾“å‡º(æ‰¹é‡å¤§å°å’Œé•¿åº¦çš„ä¹˜ç§¯)å’Œæ›´æ–°åçš„éšè—çŠ¶æ€ return torch.cat(outputs, dim 0), (H,) ``` ä¸‹é¢å®ç°ä¸€ä¸ªç½‘ç»œ ```python class RNNModelScratch: #@save \"\"\"ä»é›¶å¼€å§‹å®ç°çš„å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹\"\"\" def __init__(self, vocab_size, num_hiddens, device, get_params, init_state, forward_fn): self.vocab_size, self.num_hiddens vocab_size, num_hiddens # è·å–åˆå§‹åŒ–çš„éšè—å±‚å‚æ•° self.params get_params(vocab_size, num_hiddens, device) self.init_state, self.forward_fn init_state, forward_fn def __call__(self, X, state): X F.one_hot(X.T, self.vocab_size).type(torch.float32) return self.forward_fn(X, state, self.params) def begin_state(self, batch_size, device): return self.init_state(batch_size, self.num_hiddens, device) ``` ç®€å•æµ‹è¯•ä¸€ä¸‹ ```python num_hiddens 512 net RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params, init_rnn_state, rnn) # è¿™é‡Œçš„Xæ˜¯2*5çš„çŸ©é˜µï¼Œæ‰€ä»¥batch_size 2, num_steps 5 state net.begin_state(X.shape[0], d2l.try_gpu()) Y, new_state net(X.to(d2l.try_gpu()), state) # Yçš„å½¢çŠ¶ï¼š(æ—¶é—´æ­¥æ•° * æ‰¹é‡å¤§å°, è¯è¡¨å¤§å°)ï¼Œnew_state[0]çš„å½¢çŠ¶ï¼š(æ‰¹é‡å¤§å°, éšè—å•å…ƒæ•°) Y.shape, len(new_state), new_state[0].shape, len(vocab) \"\"\" (torch.Size([10, 28]), 1, torch.Size([2, 512]), 28) \"\"\" ``` å»ºç«‹ä¸€ä¸ªé¢„æµ‹å‡½æ•°, ä½¿ç”¨ç›®å‰çš„å‡½æ•°ä»¥åŠ, é¦–å…ˆä½¿ç”¨è¾“å…¥çš„ä¿¡æ¯è·å–ä¸€ä¸ªçŠ¶æ€, ä¹‹ååŸºäºè¿™ä¸ªçŠ¶æ€è¿›è¡Œè®¡ç®— ```python def predict_ch8(prefix, num_preds, net, vocab, device): #@save \"\"\"åœ¨prefixåé¢ç”Ÿæˆæ–°å­—ç¬¦\"\"\" state net.begin_state(batch_size 1, device device) outputs [vocab[prefix[0]]] # outputsè®°å½•prefixåŠ ä¸Šé¢„æµ‹çš„num_predsä¸ªå­—ç¬¦ # æ¯æ¬¡è·å–è¾“å‡ºçš„æœ€åä¸€ä¸ªå­—ç¬¦ä½œä¸ºè¾“å…¥ get_input lambda: torch.tensor([outputs[ 1]], device device).reshape((1, 1)) # åœ¨å¾ªç¯éå†prefixä¸­çš„å¼€å§‹å­—ç¬¦æ—¶ï¼Œæˆ‘ä»¬ä¸æ–­åœ°å°†éšçŠ¶æ€ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œä½†æ˜¯ä¸ç”Ÿæˆä»»ä½•è¾“å‡ºã€‚è¿™ # è¢«ç§°ä¸ºé¢„çƒ­ï¼ˆwarmâ€upï¼‰æœŸ for y in prefix[1:]: # é¢„çƒ­æœŸ _, state net(get_input(), state) outputs.append(vocab[y]) # prefixä¸­çš„å­—ç¬¦å·²çŸ¥ï¼Œç›´æ¥æ·»åŠ åˆ°outputsä¸­ for _ in range(num_preds): # é¢„æµ‹num_predsæ­¥ y, state net(get_input(), state) outputs.append(int(y.argmax(dim 1).reshape(1))) # æ·»åŠ é¢„æµ‹çš„å­—ç¬¦ return ''.join([vocab.idx_to_token[i] for i in outputs]) ``` ```python predict_ch8('time traveller ', 10, net, vocab, d2l.try_gpu()) \"\"\" 'time traveller iwjpvrrrrr' \"\"\" ``` åœ¨å®é™…è®¡ç®—çš„æ—¶å€™ä¸ºäº†é¿å…å‡ºç°æ¢¯åº¦å¤ªå¤§çš„æƒ…å†µ, å¯ä»¥ä½¿ç”¨æ¢¯åº¦è£å‰ªçš„åŠŸèƒ½, æŠŠæ¢¯åº¦é™åˆ¶åœ¨ä¸€å®šèŒƒå›´ ![image 20250209153747983](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091537058.png) ```python def grad_clipping(net, theta): #@save \"\"\"è£å‰ªæ¢¯åº¦\"\"\" if isinstance(net, nn.Module): params [p for p in net.parameters() if p.requires_grad] else: params net.params norm torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params)) if norm > theta: # å¦‚æœæ¢¯åº¦çš„L2èŒƒæ•°å¤§äºthetaï¼Œåˆ™è£å‰ªå®ƒ for param in params: param.grad[:] * theta / norm ``` ä¸‹é¢åšä¸€ä¸ªå®é™…çš„è®­ç»ƒå‡½æ•° ```python #@save å•æ¬¡è®­ç»ƒ def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter): \"\"\"è®­ç»ƒç½‘ç»œä¸€ä¸ªè¿­ä»£å‘¨æœŸï¼ˆå®šä¹‰è§ç¬¬8ç« ï¼‰\"\"\" state, timer None, d2l.Timer() metric d2l.Accumulator(2) # è®­ç»ƒæŸå¤±ä¹‹å’Œ,è¯å…ƒæ•°é‡ for X, Y in train_iter: if state is None or use_random_iter: # åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æˆ–ä½¿ç”¨éšæœºæŠ½æ ·æ—¶åˆå§‹åŒ–state, # éšæœºçš„æ‰¹é‡ä¸¤ä¸ªæ ·æœ¬ä¹‹é—´çš„éšè—çŠ¶æ€æ˜¯ä¸ä¸€æ ·çš„, ä¸è¿ç»­ state net.begin_state(batch_size X.shape[0], device device) else: if isinstance(net, nn.Module) and not isinstance(state, tuple): # stateå¯¹äºnn.GRUæ˜¯ä¸ªå¼ é‡ state.detach_() # ä¸å†è·Ÿè¸ªæ¢¯åº¦ else: # stateå¯¹äºnn.LSTMæˆ–å¯¹äºæˆ‘ä»¬ä»é›¶å¼€å§‹å®ç°çš„æ¨¡å‹æ˜¯ä¸ªå¼ é‡ for s in state: s.detach_() y Y.T.reshape( 1) X, y X.to(device), y.to(device) y_hat, state net(X, state) l loss(y_hat, y.long()).mean() if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.backward() grad_clipping(net, 1) updater.step() else: l.backward() grad_clipping(net, 1) # å› ä¸ºå·²ç»è°ƒç”¨äº†meanå‡½æ•° updater(batch_size 1) metric.add(l * y.numel(), y.numel()) return math.exp(metric[0] / metric[1]), metric[1] / timer.stop() ``` ```python def train_ch8(net, train_iter, vocab, lr, num_epochs, device, use_random_iter False): \"\"\"è®­ç»ƒæ¨¡å‹ï¼ˆå®šä¹‰è§ç¬¬8ç« ï¼‰\"\"\" loss nn.CrossEntropyLoss() animator d2l.Animator(xlabel 'epoch', ylabel 'perplexity', legend ['train'], xlim [10, num_epochs]) # åˆå§‹åŒ– if isinstance(net, nn.Module): updater torch.optim.SGD(net.parameters(), lr) else: updater lambda batch_size: d2l.sgd(net.params, lr, batch_size) predict lambda prefix: predict_ch8(prefix, 50, net, vocab, device) # è®­ç»ƒå’Œé¢„æµ‹ for epoch in range(num_epochs): ppl, speed train_epoch_ch8( net, train_iter, loss, updater, device, use_random_iter) if (epoch + 1) % 10 0: print(predict('time traveller')) animator.add(epoch + 1, [ppl]) print(f'å›°æƒ‘åº¦ {ppl:.1f}, {speed:.1f} è¯å…ƒ/ç§’ {str(device)}') print(predict('time traveller')) print(predict('traveller')) ``` å¼€å§‹è®­ç»ƒ ```python # ä½¿ç”¨é¡ºåºè¿›è¡Œè®­ç»ƒ num_epochs, lr 500, 1 train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu()) \"\"\" å›°æƒ‘åº¦ 1.0, 43298.7 è¯å…ƒ/ç§’ cuda:0 time traveller for so it will be convenient to speak of himwas e travelleryou can show black is white by argument said filby \"\"\" ``` ![image 20250209154003544](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091540632.png) ```python predict_ch8('time traveller ', 50, net, vocab, d2l.try_gpu()) \"\"\" 'time traveller for so it will be convenient to speak of himwas ex' \"\"\" ``` ä¹±åºçš„è®­ç»ƒ ```python net RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params, init_rnn_state, rnn) train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu(), se_random_iter True) \"\"\" å›°æƒ‘åº¦ 1.4, 42731.5 è¯å…ƒ/ç§’ cuda:0 time travellerit s against reason said filbywh t ingo the goongs travellerit s against reason said filbywh t ingo the goongs \"\"\" ``` ![image 20250209154148436](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091541519.png) > å®é™…ä½¿ç”¨çš„æ—¶å€™ç”±äºè¿™ä¸ªæ¨¡å‹å¯ä»¥è®°å½•çš„ä¿¡æ¯æ˜¯æœ‰é™çš„, æ‰€ä»¥ä½¿ç”¨é¡ºåºå’Œä¹±åºçš„åŒºåˆ«æ˜¯ä¸å¤§çš„ ### ç®€å•å®ç° ```python import torch from torch import nn from torch.nn import functional as F from d2l import torch as d2l batch_size, num_steps 32, 35 train_iter, vocab d2l.load_data_time_machine(batch_size, num_steps) ``` + åˆå§‹åŒ–ä¸€ä¸‹rnnå±‚ ```python num_hiddens 256 rnn_layer nn.RNN(len(vocab), num_hiddens) ``` + åˆå§‹åŒ–ä¸€ä¸ªçŠ¶æ€ ```python state torch.zeros((1, batch_size, num_hiddens)) state.shape ``` ç®€å•å®éªŒä¸€ä¸‹è¿™ä¸ªå±‚ ```python # è¿™é‡Œçš„Xç›¸å½“äº35 * 32 * 28çš„å¼ é‡, æ˜¯å®é™…çš„è¾“å…¥32 * 35çš„è½¬ç½®å†ä½¿ç”¨one_hotç¼–ç  X torch.rand(size (num_steps, batch_size, len(vocab))) Y, state_new rnn_layer(X, state) Y.shape, state_new.shape \"\"\" (torch.Size([35, 32, 256]), torch.Size([1, 32, 256])) \"\"\" ``` ```python #@save class RNNModel(nn.Module): \"\"\"å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹\"\"\" def __init__(self, rnn_layer, vocab_size, **kwargs): super(RNNModel, self).__init__(**kwargs) self.rnn rnn_layer self.vocab_size vocab_size self.num_hiddens self.rnn.hidden_size # å¦‚æœRNNæ˜¯åŒå‘çš„ï¼ˆä¹‹åå°†ä»‹ç»ï¼‰ï¼Œnum_directionsåº”è¯¥æ˜¯2ï¼Œå¦åˆ™åº”è¯¥æ˜¯1 if not self.rnn.bidirectional: self.num_directions 1 self.linear nn.Linear(self.num_hiddens, self.vocab_size) else: self.num_directions 2 self.linear nn.Linear(self.num_hiddens * 2, self.vocab_size) def forward(self, inputs, state): X F.one_hot(inputs.T.long(), self.vocab_size) X X.to(torch.float32) Y, state self.rnn(X, state) # å…¨è¿æ¥å±‚é¦–å…ˆå°†Yçš„å½¢çŠ¶æ”¹ä¸º(æ—¶é—´æ­¥æ•°*æ‰¹é‡å¤§å°,éšè—å•å…ƒæ•°) # å®ƒçš„è¾“å‡ºå½¢çŠ¶æ˜¯(æ—¶é—´æ­¥æ•°*æ‰¹é‡å¤§å°,è¯è¡¨å¤§å°)ã€‚ output self.linear(Y.reshape(( 1, Y.shape[ 1]))) return output, state # æš‚æ—¶æ²¡æœ‰ç”¨åˆ° def begin_state(self, device, batch_size 1): if not isinstance(self.rnn, nn.LSTM): # nn.GRUä»¥å¼ é‡ä½œä¸ºéšçŠ¶æ€ return torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device device) else: # nn.LSTMä»¥å…ƒç»„ä½œä¸ºéšçŠ¶æ€ return (torch.zeros(( self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device device), torch.zeros(( self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device device)) ``` ```python device d2l.try_gpu() net RNNModel(rnn_layer, vocab_size len(vocab)) net net.to(device) d2l.predict_ch8('time traveller', 10, net, vocab, device) \"\"\" 'time travellergsvsssssss' \"\"\" ``` ```python num_epochs, lr 500, 1 d2l.train_ch8(net, train_iter, vocab, lr, num_epochs, device) ``` ![image 20250209160451772](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502091604881.png) ## æ€»ç»“ ![image 20250213164923400](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502131649576.png) > n : sequence_lengtï¼Œè®¾å®šçš„å¥å­æœ€å¤§é•¿åº¦ > m : hidden_sizeï¼Œè¾“å…¥ç‰¹å¾å‘é‡çš„éšè—å±‚å¤§å° > k : hidden_size_rnnï¼Œrnnçš„éšè—å±‚å¤§å° > p : num_labelsï¼Œè¾“å‡ºæ ‡ç­¾çš„æ€»ç±»åˆ«æ•° å°±æœ‰ï¼š > (x1,...,xn)ï¼šç»´åº¦(n,m) > xt ï¼šç»´åº¦(1,m) > U ï¼šç»´åº¦ (m,k) > W ï¼šç»´åº¦ (k,k) > St ï¼šç»´åº¦ (1,k) > V ï¼šç»´åº¦ (k,p) ä¸‹é¢ï¼Œè¿ç®—ä¸€ä¸‹å‘é‡ä¹‹é—´è®¡ç®—ï¼š > xtâˆ—U > è·å¾—å‘é‡çš„ç»´åº¦(1,k) > Stâˆ’1âˆ—W > è·å¾—å‘é‡çš„ç»´åº¦(1,k) > xtâˆ—U+Stâˆ’1âˆ—W > è·å¾—å‘é‡çš„ç»´åº¦(1,k) > f(xtâˆ—U+Stâˆ’1âˆ—W) > è·å¾—å‘é‡çš„ç»´åº¦(1,k) > Stâˆ—V > è·å¾—å‘é‡çš„ç»´åº¦(1,p) > g(Stâˆ—V) > è·å¾—å‘é‡çš„ç»´åº¦(1,p)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-14-16AlexNet.html":{"title":"AlexNetç½‘ç»œ","content":"# AlexNetç½‘ç»œ ä¹‹åçš„æ•°æ®é‡ä»¥åŠå•ä¸ªæ•°æ®çš„å¤§å°ä¸æ–­å¢åŠ , è®¡ç®—æœºçš„æ€§èƒ½ä¹Ÿæå‡ åšå‡ºçš„æ”¹è¿› + ä½¿ç”¨ä¸¢å¼ƒæ³• + ReLu + MaxPooling åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™å¯ä»¥æ”¯æŒæ›´å¤§çš„æ¨¡å‹, åŒæ—¶æ”¹å˜è§‚å¿µ, å›¾åƒè¯†åˆ«çš„æ—¶å€™ä¸å†é€šè¿‡äººå·¥æå–ç‰¹å¾, è€Œæ˜¯ä½¿ç”¨CNNå­¦ä¹ ç‰¹å¾, æ›´åŠ çš„é«˜æ•ˆ, åªä½¿ç”¨ä¸€ä¸ªæ¨¡å‹å³å¯ ![image 20250114133651930](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141336005.png) ä½¿ç”¨å¤§çš„å·ç§¯æ ¸å¯ä»¥çœ‹åˆ°æ¯”è¾ƒå¤§çš„ä½ç½®, åœ¨å®é™…å®ç°çš„æ—¶å€™ä½¿ç”¨ReLUå‡ç¼“æ¢¯åº¦çš„æ¶ˆå¤±, åŒæ—¶éšè—å±‚ä¹‹ååŠ å…¥ä¸¢å¼ƒå±‚, å®é™…å¯¹æ•°æ®è¿›è¡ŒåŠ å¼º(å›¾åƒå˜æ¢ä»¥åè¾“å…¥) > è¿™é‡Œä½¿ç”¨ä¸¤ä¸ª4096çš„å…¨è¿æ¥, å¯ä»¥æ›´å¥½çš„æå–ç‰¹å¾ ![image 20250114135205366](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141352525.png) ## ä»£ç å®ç° ```python import torch from torch import nn from d2l import torch as d2l net nn.Sequential( nn.Con2d(1, 96, kernel_size 11, stride 4, padding 1), nn.ReLU(), nn.MaxPool2d(kernel_size 3, stride 2), nn.Conv2d(96, 256, kernel_size 5, padding 2), nn.ReLU(), nn.MaxPool2d(kernel_size 3, stride 2), nn.Conv2d(256, 384, kernel_size 3, padding 1), nn.ReLU(), nn.Conv2d(384, 384, kernel_size 3, padding 1), nn.ReLU(), nn.Conv2d(384, 256, kernel_size 3, padding 1), nn.ReLU(), nn.MaxPool2d(kernel_size 3, stride 2), nn.Flatten(), nn.Linear(6400, 4096), nn.ReLU(), nn.Dropout(p 0.5), nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(p 0.5), nn.Linear(4096, 10) ) \"\"\" Conv2d output shape:\t torch.Size([1, 96, 54, 54]) ReLU output shape:\t torch.Size([1, 96, 54, 54]) MaxPool2d output shape:\t torch.Size([1, 96, 26, 26]) Conv2d output shape:\t torch.Size([1, 256, 26, 26]) ReLU output shape:\t torch.Size([1, 256, 26, 26]) MaxPool2d output shape:\t torch.Size([1, 256, 12, 12]) Conv2d output shape:\t torch.Size([1, 384, 12, 12]) ReLU output shape:\t torch.Size([1, 384, 12, 12]) Conv2d output shape:\t torch.Size([1, 384, 12, 12]) ReLU output shape:\t torch.Size([1, 384, 12, 12]) Conv2d output shape:\t torch.Size([1, 256, 12, 12]) ReLU output shape:\t torch.Size([1, 256, 12, 12]) MaxPool2d output shape:\t torch.Size([1, 256, 5, 5]) Flatten output shape:\t torch.Size([1, 6400]) Linear output shape:\t torch.Size([1, 4096]) ReLU output shape:\t torch.Size([1, 4096]) Dropout output shape:\t torch.Size([1, 4096]) Linear output shape:\t torch.Size([1, 4096]) ReLU output shape:\t torch.Size([1, 4096]) Dropout output shape:\t torch.Size([1, 4096]) Linear output shape:\t torch.Size([1, 10]) \"\"\" ``` ```python bach_size 128 # æŠŠå›¾ç‰‡å¤§å°è°ƒæ•´ä¸º 224x224(ä¸ºäº†æ‹Ÿåˆæ¨¡å‹, æ— å…¶ä»–ä½œç”¨) train_iter, test_iter d2l.load_data_fashion_mnist(batch_size bach_size, resize 224) # å¼€å§‹è®­ç»ƒ lr, num_epochs 0.01, 10 d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) ``` ![image 20250114142219640](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501141422706.png)"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-1-27è¯­ä¹‰åˆ†å‰².html":{"title":"è¯­ä¹‰åˆ†å‰²","content":"# è¯­ä¹‰åˆ†å‰² è¯­ä¹‰åˆ†å‰²æŠŠå›¾ç‰‡é‡Œé¢çš„æ¯ä¸€ä¸ªåƒç´ åˆ†ç±»åˆ°å¯¹åº”çš„ç±» ![image 20250201171348079](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502011713011.png) å®é™…çš„åº”ç”¨å¯ä»¥æœ‰èƒŒæ™¯è™šåŒ–, è¿˜æœ‰åœ¨æ— äººé©¾é©¶çš„æ—¶å€™åˆ†å‰²å‡ºæ¥è·¯é¢ è¿˜æœ‰ä¸¤ä¸ªç±»ä¼¼çš„å®šä¹‰ â€¢ **å›¾åƒåˆ†å‰²**å°†å›¾åƒåˆ’åˆ†ä¸ºè‹¥å¹²ç»„æˆåŒºåŸŸï¼Œè¿™ç±»é—®é¢˜çš„æ–¹æ³•é€šå¸¸åˆ©ç”¨å›¾åƒä¸­åƒç´ ä¹‹é—´çš„ç›¸å…³æ€§ã€‚å®ƒåœ¨è®­ç»ƒ æ—¶ä¸éœ€è¦æœ‰å…³å›¾åƒåƒç´ çš„æ ‡ç­¾ä¿¡æ¯ï¼Œåœ¨é¢„æµ‹æ—¶ä¹Ÿæ— æ³•ä¿è¯åˆ†å‰²å‡ºçš„åŒºåŸŸå…·æœ‰æˆ‘ä»¬å¸Œæœ›å¾—åˆ°çš„è¯­ä¹‰ã€‚ä»¥ å›¾13.9.1ä¸­çš„å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå›¾åƒåˆ†å‰²å¯èƒ½ä¼šå°†ç‹—åˆ†ä¸ºä¸¤ä¸ªåŒºåŸŸï¼šä¸€ä¸ªè¦†ç›–ä»¥é»‘è‰²ä¸ºä¸»çš„å˜´å’Œçœ¼ç›ï¼Œå¦ ä¸€ä¸ªè¦†ç›–ä»¥é»„è‰²ä¸ºä¸»çš„å…¶ä½™éƒ¨åˆ†èº«ä½“ã€‚ â€¢ **å®ä¾‹åˆ†å‰²**ä¹Ÿå«åŒæ—¶æ£€æµ‹å¹¶åˆ†å‰²ï¼ˆsimultaneousdetectionandsegmentationï¼‰ï¼Œå®ƒç ”ç©¶å¦‚ä½•è¯†åˆ«å›¾åƒä¸­ å„ä¸ªç›®æ ‡å®ä¾‹çš„åƒç´ çº§åŒºåŸŸã€‚ä¸è¯­ä¹‰åˆ†å‰²ä¸åŒï¼Œå®ä¾‹åˆ†å‰²ä¸ä»…éœ€è¦åŒºåˆ†è¯­ä¹‰ï¼Œè¿˜è¦åŒºåˆ†ä¸åŒçš„ç›®æ ‡å® ä¾‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå›¾åƒä¸­æœ‰ä¸¤æ¡ç‹—ï¼Œåˆ™å®ä¾‹åˆ†å‰²éœ€è¦åŒºåˆ†åƒç´ å±äºçš„ä¸¤æ¡ç‹—ä¸­çš„å“ªä¸€æ¡ã€‚ ## ç¤ºä¾‹ ä½¿ç”¨çš„æ˜¯Pascal VOC2012è¿™ä¸€ä¸ªæ•°æ®é›† ### æ•°æ®é›†åŠ è½½ ```python %matplotlib inline import os import torch import torchvision from d2l import torch as d2l ``` + ä¸‹è½½æ•°æ®é›† ```python d2l.DATA_HUB['voc2012'] (d2l.DATA_URL + 'VOCtrainval_11 May 2012.tar', '4e443f8a2eca6b1dac8a6c57641b67dd40621a49') voc_dir d2l.download_extract('voc2012', 'VOCdevkit/VOC2012') ``` + è¯»å–æ‰€æœ‰çš„å›¾ç‰‡åŠ è½½åˆ°å†…å­˜é‡Œé¢, å¹¶ä¸”æ˜¾ç¤ºä¸€ä¸‹æ•ˆæœ ```python def read_voc_images(voc_dir, is_train True): \"\"\"è¯»å–æ‰€æœ‰VOCå›¾åƒå¹¶æ ‡æ³¨\"\"\" txt_fname os.path.join(voc_dir, 'ImageSets', 'Segmentation', 'train.txt' if is_train else 'val.txt') # ä½¿ç”¨è¿™ä¸¤ä¸ªæ–‡ä»¶è®°å½•è®­ç»ƒå’Œæµ‹è¯•æ ·æœ¬ mode torchvision.io.image.ImageReadMode.RGB with open(txt_fname, 'r') as f: images f.read().split() features, labels [], [] for i, fname in enumerate(images): features.append(torchvision.io.read_image(os.path.join( voc_dir, 'JPEGImages', f'{fname}.jpg'))) labels.append(torchvision.io.read_image(os.path.join( voc_dir, 'SegmentationClass' ,f'{fname}.png'), mode)) return features, labels train_features, train_labels read_voc_images(voc_dir, True) n 5 imgs train_features[0:n] + train_labels[0:n] imgs [img.permute(1,2,0) for img in imgs] d2l.show_images(imgs, 2, n) ``` ![image 20250203194612033](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502031946730.png) + å®šä¹‰ä¸€ä¸‹åˆ†ç±»ä½¿ç”¨çš„é¢œè‰²å’Œç±»åˆ«çš„å¯¹åº” ```python #@save ä¸åŒçš„ç±»åˆ«ä½¿ç”¨ä¸åŒçš„é¢œè‰²æ¥æ ‡æ³¨ VOC_COLORMAP [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128], [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128]] #@save VOC_CLASSES ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor'] ``` + å®é™…è½¬æ¢ä½¿ç”¨çš„å‡½æ•° ```python #@save def voc_colormap2label(): \"\"\"æ„å»ºä»RGBåˆ°VOCç±»åˆ«ç´¢å¼•çš„æ˜ å°„, ä½¿ç”¨ä¸€ä¸ªé•¿åº¦ä¸º256^3çš„æ•°ç»„, æŸä¸€ä¸ªRGBå€¼çš„ç´¢å¼•ä¸ºå…¶ç±»åˆ«ç´¢å¼•\"\"\" colormap2label torch.zeros(256 ** 3, dtype torch.long) for i, colormap in enumerate(VOC_COLORMAP): colormap2label[(colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] i return colormap2label #@save def voc_label_indices(colormap, colormap2label): \"\"\"å°†VOCæ ‡ç­¾ä¸­çš„RGBå€¼æ˜ å°„åˆ°å®ƒä»¬çš„ç±»åˆ«ç´¢å¼•\"\"\" colormap colormap.permute(1, 2, 0).numpy().astype('int32') idx ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256 + colormap[:, :, 2]) # ä»é€šé“ç»´åº¦å–å‡ºæ¥å€¼ç›¸åŠ  return colormap2label[idx] ``` ```python y voc_label_indices(train_labels[0], voc_colormap2label()) y[105:115, 130:140], VOC_CLASSES[1] \"\"\" (tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]), 'aeroplane') \"\"\" ``` + è¿›è¡Œä¸€ä¸‹å¢å¹¿, éšæœºè£å‰ª ```python def voc_rand_crop(feature, label, height, width): \"\"\"éšæœºè£å‰ªç‰¹å¾å’Œæ ‡ç­¾å›¾åƒ\"\"\" rect torchvision.transforms.RandomCrop.get_params(feature, (height, width)) feature torchvision.transforms.functional.crop(feature, *rect) label torchvision.transforms.functional.crop(label, *rect) return feature, label ``` + æ˜¾ç¤ºä¸€ä¸‹æ•ˆæœ ````python imgs [] for _ in range(n): imgs + voc_rand_crop(train_features[0], train_labels[0], 200, 300) imgs [img.permute(1, 2, 0) for img in imgs] d2l.show_images(imgs[::2] + imgs[1::2], 2, n) ```` ![image 20250203194633611](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502031946692.png) + åŠ è½½ä¸ºæ•°æ®é›† ```python class VOCSegDataset(torch.utils.data.Dataset): \"\"\"ä¸€ä¸ªç”¨äºåŠ è½½VOCæ•°æ®é›†çš„è‡ªå®šä¹‰æ•°æ®é›†\"\"\" def __init__(self, is_train, crop_size, voc_dir): self.transform torchvision.transforms.Normalize( mean [0.485, 0.456, 0.406], std [0.229, 0.224, 0.225]) self.crop_size crop_size features, labels read_voc_images(voc_dir, is_train is_train) # è¯»å–æ‰€æœ‰VOCå›¾åƒå’Œæ ‡ç­¾ self.features [self.normalize_image(feature) for feature in self.filter(features)] self.labels self.filter(labels) self.colormap2label voc_colormap2label() # è·å–ä¸€ä¸ªç´¢å¼•è¡¨ print('read ' + str(len(self.features)) + ' examples') def normalize_image(self, img): return self.transform(img.float() / 255) # æ ‡å‡†åŒ–å›¾åƒ def filter(self, imgs): return [img for img in imgs if ( img.shape[1] > self.crop_size[0] and img.shape[2] > self.crop_size[1])] # è¿‡æ»¤æ‰å°äºè£å‰ªå°ºå¯¸çš„å›¾åƒ def __getitem__(self, idx): feature, label voc_rand_crop(self.features[idx], self.labels[idx], *self.crop_size) # éšæœºè£å‰ª return (feature, voc_label_indices(label, self.colormap2label)) # è¿”å›ç‰¹å¾å’Œæ ‡ç­¾ def __len__(self): return len(self.features) crop_size (320, 480) voc_train VOCSegDataset(True, crop_size, voc_dir) voc_test VOCSegDataset(False, crop_size, voc_dir) batch_size 64 train_iter torch.utils.data.DataLoader(voc_train, batch_size, shuffle True, drop_last True, num_workers d2l.get_dataloader_workers()) for X, Y in train_iter: print(X.shape) print(Y.shape) break \"\"\" torch.Size([64, 3, 320, 480]) torch.Size([64, 320, 480]) \"\"\" ``` + å®é™…ä½¿ç”¨ ````python def load_data_voc(batch_size, crop_size): \"\"\"åŠ è½½VOCè¯­ä¹‰åˆ†å‰²æ•°æ®é›†\"\"\" voc_dir d2l.download_extract('voc2012', os.path.join( 'VOCdevkit', 'VOC2012')) num_workers d2l.get_dataloader_workers() train_iter torch.utils.data.DataLoader( VOCSegDataset(True, crop_size, voc_dir), batch_size, shuffle True, drop_last True, num_workers num_workers) test_iter torch.utils.data.DataLoader( VOCSegDataset(False, crop_size, voc_dir), batch_size, drop_last True, num_workers num_workers) return train_iter, test_iter ```` ## æ—‹è½¬å·ç§¯ å·ç§¯çš„æ—¶å€™ä¸€èˆ¬ä¸ä¼šå¢å¤§è¾“å…¥çš„é«˜å’Œå®½, é€šå¸¸æ˜¯ä¸å˜æˆ–è€…å‡åŠ, ä½†æ˜¯æ—‹è½¬å·ç§¯å¯ä»¥ç”¨äºå¢å¤§è¾“å…¥çš„é«˜å’Œå®½ è¯­ä¹‰åˆ†å‰²éœ€è¦å¯¹æ¯ä¸€ä¸ªåƒç´ è¿›è¡Œå¤„ç†, åªæ˜¯å‡å°çš„è¯ä¸å¤ªä½¿ç”¨ ![image 20250203182338402](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502031823860.png) paddingå®åœ¨è¾“å‡ºä¸Šé¢åšå¡«å……, ä½†ä¼šå¯¼è‡´å®é™…çš„è¾“å‡ºå˜å°(1ä¼šä½¿å¾—æœ€å¤–é¢çš„ä¸€åœˆæ¶ˆå¤±), strideè¿˜æ˜¯ç›¸åŒçš„åšæ³• > èµ·è¿™ä¸ªåå­—çš„åŸå› æ˜¯å·ç§¯å¯ä»¥çœ‹ä½œæ˜¯ä¸€æ¬¡çŸ©é˜µä¹˜æ³•, Y^'^ VX^'^, è¿™é‡Œçš„Væ˜¯mxn, åˆ™Y^'^æ˜¯n, X^'^æ˜¯m, æ—‹è½¬å·ç§¯ä¹˜çš„æ˜¯V^T^, æ‰€ä»¥xå’Œyçš„ç»´åº¦æ˜¯åè¿‡æ¥çš„, æ‰€ä»¥å¯ä»¥çœ‹åšæ˜¯å·ç§¯çš„åè¿ç®— è¾“å…¥çš„é«˜å’Œå®½æ˜¯n, æ ¸æ˜¯k, å¡«å……p, æ­¥å¹…ä¸ºs n^'^ sn +k 2p s > å·ç§¯çš„æ˜¯n^'^ ((n k 2p + s) / s) >n â‰¥ sn +k 2p s æƒ³è¦æˆå€å¢åŠ çš„æ—¶å€™k 2p + s ### å®é™…ä½¿ç”¨ ```python import torch from torch import nn from d2l import torch as d2l ``` + å®ç°æœ€ç®€å•ä»£ç  ```python def trans_conv(X, K): h, w K.shape Y torch.zeros((X.shape[0] + h 1, X.shape[1] + w 1)) for i in range(X.shape[0]): for j in range(X.shape[1]): Y[i: i + h, j: j + w] + X[i, j] * K return Y ``` ```python X torch.tensor([[0.0, 1.0], [2.0, 3.0]]) K torch.tensor([[0.0, 1.0], [2.0, 3.0]]) trans_conv(X, K) \"\"\" tensor([[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]) \"\"\" ``` + ä½¿ç”¨ç°æˆçš„å‡½æ•° ````python X, K X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2) tconv nn.ConvTranspose2d(1, 1, kernel_size 2, bias False) tconv.weight.data K tconv(X) \"\"\" tensor([[[[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]]], grad_fn <ConvolutionBackward0>) \"\"\" tconv nn.ConvTranspose2d(1, 1, kernel_size 2, padding 1, bias False) tconv.weight.data K tconv(X) \"\"\" tensor([[[[4.]]]], grad_fn <ConvolutionBackward0>) \"\"\" tconv nn.ConvTranspose2d(1, 1, kernel_size 2, stride 2, bias False) tconv.weight.data K tconv(X) \"\"\" tensor([[[[0., 0., 0., 1.], [0., 0., 2., 3.], [0., 2., 0., 3.], [4., 6., 6., 9.]]]], grad_fn <ConvolutionBackward0>) \"\"\" ```` ## å…¨è¿æ¥ç¥ç»ç½‘ç»œFCN fully convolutional network ä½¿ç”¨è½¬ç½®å·ç§¯æ›¿ä»£CNNæœ€åçš„å…¨è¿æ¥å±‚, ä»è€Œå¯ä»¥é¢„æµ‹æ¯ä¸€ä¸ªåƒç´ , å®é™…è·å¾—çš„é€šé“æ•°æ˜¯è®°å½•ä¸ªå„ç±»çš„ä¿¡æ¯ ![image 20250203201551939](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502032015247.png) + åŠ è½½æ¨¡å‹ ```python pretrained_net torchvision.models.resnet18(pretrained True) list(pretrained_net.children())[ 3:] \"\"\" [Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size (3, 3), stride (2, 2), padding (1, 1), bias False) (bn1): BatchNorm2d(512, eps 1e 05, momentum 0.1, affine True, track_running_stats True) (relu): ReLU(inplace True) (conv2): Conv2d(512, 512, kernel_size (3, 3), stride (1, 1), padding (1, 1), bias False) (bn2): BatchNorm2d(512, eps 1e 05, momentum 0.1, affine True, track_running_stats True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size (1, 1), stride (2, 2), bias False) (1): BatchNorm2d(512, eps 1e 05, momentum 0.1, affine True, track_running_stats True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size (3, 3), stride (1, 1), padding (1, 1), bias False) (bn1): BatchNorm2d(512, eps 1e 05, momentum 0.1, affine True, track_running_stats True) (relu): ReLU(inplace True) (conv2): Conv2d(512, 512, kernel_size (3, 3), stride (1, 1), padding (1, 1), bias False) (bn2): BatchNorm2d(512, eps 1e 05, momentum 0.1, affine True, track_running_stats True) ) ), AdaptiveAvgPool2d(output_size (1, 1)), Linear(in_features 512, out_features 1000, bias True)] \"\"\" ``` + è·å–éçº¿æ€§çš„æ¨¡å‹ ```python from torch import nn net nn.Sequential(*list(pretrained_net.children())[: 2]) ``` > ```python > X torch.rand(size (1, 3, 320, 480)) > net(X).shape > ``` > > torch.Size([1, 512, 10, 15]) + åˆå§‹åŒ–æ–°çš„æ¨¡å‹ ```python num_classes 21 net.add_module('final_conv', nn.Conv2d(512, num_classes, kernel_size 1)) net.add_module('transpose_conv', nn.ConvTranspose2d(num_classes, num_classes, kernel_size 64, padding 16, stride 32)) ``` + ä¸€ä¸ªåˆå§‹çš„å‚æ•°, è¿™ä¸ªå‚æ•°å¯ä»¥ç”¨äº ```python def bilinear_kernel(in_channels, out_channels, kernel_size): # ä½¿ç”¨è¿™ä¸€ä¸ªå‡½æ•°æ¥åˆå§‹åŒ–è½¬ç½®å·ç§¯å±‚çš„æƒé‡, å¯ä»¥è¾¾åˆ°å›¾åƒæ”¾å¤§çš„æ•ˆæœ factor (kernel_size + 1) // 2 if kernel_size % 2 1: center factor 1 else: center factor 0.5 og (torch.arange(kernel_size).reshape( 1, 1), torch.arange(kernel_size).reshape(1, 1)) filt (1 torch.abs(og[0] center) / factor) * \\ (1 torch.abs(og[1] center) / factor) weight torch.zeros((in_channels, out_channels, kernel_size, kernel_size)) weight[range(in_channels), range(out_channels), :, :] filt return weight ``` + åˆå§‹åŒ–å‚æ•° ```python conv_trans nn.ConvTranspose2d(3, 3, kernel_size 4, padding 1, stride 2, bias False) conv_trans.weight.data.copy_(bilinear_kernel(3, 3, 4)) ```"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-15-21æ®‹å·®ç½‘ç»œResNet.html":{"title":"Resnet","content":"# Resnet ![image 20250115133453293](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501151334397.png) > å·¦ä¾§çš„æ¨¡å‹è™½ç„¶æ¨¡å‹å¤æ‚ä½¿å¾—å¯ä»¥å­¦ä¹ çš„ä½ç½®æ”¾å¤§, ä½†æ˜¯å¹¶æ²¡æœ‰é è¿‘æœ€ä¼˜è§£, å³ä¾§çš„å¯èƒ½æ²¡æœ‰ä¼˜åŒ–, ä½†æ˜¯æ›´å¤šå±‚ä¸ä¼šä½¿æ•ˆæœå˜å·®, åŒæ—¶ç”±äºæœ‰äº†ä¸€ä¸ªé€šè·¯. ä½¿å¾—é è¿‘æ•°æ®çš„å±‚å¯ä»¥ç›´æ¥è¿›è¡Œè®­ç»ƒ ![image 20250115133734095](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501151337136.png) ![image 20250115133952252](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501151339318.png) ResNetå—é€šå¸¸æ˜¯ä¸€ä¸ªé«˜å®½å‡åŠçš„ResNetåé¢æ¥å¤šä¸ªé«˜å®½ä¸å˜çš„ResNetå— ![image 20250115134456444](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501151344509.png) ## å®é™…è®­ç»ƒ ```python import torch from torch import nn from d2l import torch as d2l from torch.nn import functional as F ``` å®ç°ä¸€ä¸‹å•ä¸ªçš„å— ```python class Residual(nn.Module): # input_channels: è¾“å…¥é€šé“æ•°, num_channels: è¾“å‡ºé€šé“æ•° # use_1x1conv: æ˜¯å¦ä½¿ç”¨1x1å·ç§¯å±‚æ”¹å˜é€šé“æ•°, strides: æ­¥å¹… def __init__(self, input_channels, num_channels, use_1x1conv False, strides 1): super().__init__() # ç¬¬ä¸€å±‚å¯ä»¥æŒ‡å®šæ­¥å¹… self.conv1 nn.Conv2d(input_channels, num_channels, kernel_size 3, padding 1, stride strides) self.conv2 nn.Conv2d(num_channels, num_channels, kernel_size 3, padding 1) if use_1x1conv: # 1x1å·ç§¯å±‚æ”¹å˜é€šé“æ•°, ç”¨äºæ”¹å˜Xçš„é€šé“æ•° self.conv3 nn.Conv2d(input_channels, num_channels, kernel_size 1, stride strides) else: self.conv3 None self.bn1 nn.BatchNorm2d(num_channels) self.bn2 nn.BatchNorm2d(num_channels) def forward(self, X): Y F.relu(self.bn1(self.conv1(X))) Y self.bn2(self.conv2(Y)) if self.conv3: X self.conv3(X) Y + X return F.relu(Y) ``` å¯ä»¥å®ç°å±‚æ•°ä»¥åŠé•¿å®½çš„å˜åŒ– ```python blk Residual(3, 8, use_1x1conv True, strides 2) X torch.rand(4, 3, 6, 6) blk(X).shape \"\"\" torch.Size([4, 8, 3, 3]) \"\"\" ``` + å®ç°ä¸€ä¸ªResNetæ¨¡å‹ ```python b1 nn.Sequential(nn.Conv2d(1, 64, kernel_size 7, stride 2, padding 3), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(kernel_size 3, stride 2, padding 1)) def resnet_block(input_channels, num_channels, num_residuals, first_block False): blk [] for i in range(num_residuals): if i 0 and not first_block: # ä¸æ˜¯ç¬¬ä¸€ä¸ªæ¨¡å—çš„ç¬¬ä¸€ä¸ªæ®‹å·®å—éœ€è¦å‡åŠé€šé“æ•°å’Œé•¿å®½ blk.append(Residual(input_channels, num_channels, use_1x1conv True, strides 2)) else: blk.append(Residual(num_channels, num_channels)) return blk # ä½¿ç”¨å¤šä¸ªæ®‹å·®ç½‘ç»œå—è¿›è¡Œè®­ç»ƒ, æ¯ä¸€ä¸ªé‡Œé¢æœ‰ä¸¤ä¸ªæ®‹å·®å— b2 nn.Sequential(*resnet_block(64, 64, 2, first_block True)) b3 nn.Sequential(*resnet_block(64, 128, 2)) b4 nn.Sequential(*resnet_block(128, 256, 2)) b5 nn.Sequential(*resnet_block(256, 512, 2)) # AdaptiveAvgPool2dè‡ªé€‚åº”å¹³å‡æ± åŒ–å±‚, ä½¿å¾—è¾“å…¥çš„é•¿å®½å˜ä¸º1(æœ€åä¸€å±‚çš„é•¿å®½ä¸º7) net nn.Sequential(b1, b2, b3, b4, b5, nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(512, 10)) ``` + å„ä¸ªå±‚è¾“å‡ºçš„å¤§å° ```python X torch.rand(size (1, 1, 224, 224)) for layer in net: X layer(X) print(layer.__class__.__name__, 'output shape:\\t', X.shape) \"\"\" Sequential output shape:\t torch.Size([1, 64, 56, 56]) Sequential output shape:\t torch.Size([1, 64, 56, 56]) Sequential output shape:\t torch.Size([1, 128, 28, 28]) Sequential output shape:\t torch.Size([1, 256, 14, 14]) Sequential output shape:\t torch.Size([1, 512, 7, 7]) AdaptiveAvgPool2d output shape:\t torch.Size([1, 512, 1, 1]) Flatten output shape:\t torch.Size([1, 512]) Linear output shape:\t torch.Size([1, 10]) \"\"\" ``` + å¼€å§‹è®­ç»ƒ ```python lr, num_epochs, batch_size 0.05, 10, 256 train_iter, test_iter d2l.load_data_fashion_mnist(batch_size, resize 96) d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) ``` ![image 20250115141753555](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501151417644.png) > æœ‰ç‚¹è¿‡æ‹Ÿåˆ"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-1-12-GPU.html":{"title":"GPU","content":"# GPU æ£€æµ‹ ```python import torch from torch import nn torch.device('cpu'), torch.cuda.device('cuda:0') torch.cuda.device_count() ``` å®é™…ä½¿ç”¨çš„æ—¶å€™å¯ä»¥æ£€æµ‹ä¸€ä¸‹GPUæ˜¯ä¸æ˜¯å¯ä»¥ä½¿ç”¨ ```python def try_gpu(i 0): #@save if torch.cuda.device_count() > i + 1: return torch.device(f'cuda:{i}') return torch.device('cpu') ``` ä¹Ÿå¯ä»¥è¿”å›ä¸€ä¸‹æ‰€æœ‰çš„GPU ```python def try_all_gpus(): #@save devices [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())] return devices if devices else [torch.device('cpu')] ``` åœ¨é»˜è®¤çš„æ—¶å€™å¯ä»¥ä½¿ç”¨`.device`æŸ¥çœ‹å½“å‰çš„è®¾å¤‡ ```python x torch.tensor([1, 2, 3]) x.device \"\"\" device(type 'cpu') \"\"\" ``` å¯ä»¥åœ¨å»ºç«‹ä¸€ä¸ªå˜é‡çš„æ—¶å€™å°è¯•æ”¾åœ¨GPU ```python x torch.ones(2, 3, device try_gpu()) x \"\"\" tensor([[1., 1., 1.], [1., 1., 1.]], device 'cuda:0') \"\"\" ``` åœ¨å®é™…è®¡ç®—ä¸¤ä¸ªæ•°æ®æ—¶å€™, è¿™ä¸¤ä¸ªæ•°æ®å°½é‡åœ¨ä¸€ä¸ªè®¾å¤‡ä¸Šé¢, æ•°æ®çš„æŒªåŠ¨å¾ˆæ¶ˆè€—èµ„æº, æ‰€ä»¥ä¼šç›´æ¥æŠ¥é”™ ```python RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! ``` ç¥ç»ç½‘ç»œå¯ä»¥ä½¿ç”¨`.to`æŠŠè¿™ä¸€ä¸ªç¥ç»ç½‘ç»œè¿›è¡Œè½¬ç§», å®é™…æ˜¯æŠŠæ¨¡å‹çš„å‚æ•°æ”¾ä¸Šå» ## å¤šGPUè¿è¡Œ ä¸€ä¸ªæœºå™¨å¯ä»¥æœ‰å¤šä¸ªGPU, åœ¨å®é™…è¿ç®—æ—¶å€™å¯ä»¥æŠŠä¸€ä¸ªå°æ‰¹é‡çš„è¿ç®—æ”¾åˆ°å¤šä¸ªGPUé‡Œé¢å®ç°åŠ é€Ÿ å¸¸è§çš„æ–¹æ¡ˆæœ‰æ•°æ®å¹¶è¡Œ, æ¨¡å‹å¹¶è¡Œä»¥åŠé€šé“å¹¶è¡Œ + æ•°æ®å¹¶è¡Œ å°†å°æ‰¹é‡åˆ†æˆnå—, æ¯ä¸€ä¸ªGPUä½¿ç”¨å®Œæ•´çš„å‚æ•°è¿›è¡Œè®¡ç®—ä¸€ä¸ªæ•°æ®çš„æ¢¯åº¦, æœ€åæŠŠæ¢¯åº¦è¿›è¡Œæ±‡æ€»ç„¶åè®¡ç®— + æ¨¡å‹å¹¶è¡Œ æŠŠæ¨¡å‹è¿›è¡Œæ‹†åˆ†, æ¯ä¸€å—GPUæ‹¿åˆ°æ¨¡å‹ä»¥åè®¡ç®—å‰å‘æ–¹å‘çš„ç»“æœ ### ä»£ç å®ç° ```python %matplotlib inline import torch from torch import nn from torch.nn import functional as F from d2l import torch as d2l ``` + åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹ä»¥åŠä½¿ç”¨çš„å‚æ•° ```python scale 0.01 # åˆå§‹åŒ–æ¨¡å‹å‚æ•° W1 nn.Parameter(torch.randn(size (20, 1, 3, 3)) * scale, requires_grad True) b1 nn.Parameter(torch.zeros(20), requires_grad True) W2 nn.Parameter(torch.randn(size (50, 20, 5, 5)) * scale, requires_grad True) b2 nn.Parameter(torch.zeros(50), requires_grad True) W3 nn.Parameter(torch.randn(size (800, 128)) * scale, requires_grad True) b3 nn.Parameter(torch.zeros(128), requires_grad True) W4 nn.Parameter(torch.randn(size (128, 10)) * scale, requires_grad True) b4 nn.Parameter(torch.zeros(10), requires_grad True) params [W1, b1, W2, b2, W3, b3, W4, b4] def lenet(X, params): h1_conv F.conv2d(input X, weight params[0], bias params[1]) h1_activation F.relu(h1_conv) h1 F.avg_pool2d(input h1_activation, kernel_size (2, 2), stride (2, 2)) h2_conv F.conv2d(input h1, weight params[2], bias params[3]) h2_activation F.relu(h2_conv) h2 F.avg_pool2d(input h2_activation, kernel_size (2, 2), stride (2, 2)) h2 h2.reshape(h2.shape[0], 1) h3_linear torch.mm(h2, params[4]) + params[5] h3 F.relu(h3_linear) y_hat torch.mm(h3, params[6]) + params[7] return y_hat loss nn.CrossEntropyLoss(reduction 'none') ``` + æ‰€æœ‰çš„å‚æ•°æ”¾åœ¨å¯¹åº”ä½¿ç”¨çš„è®¾å¤‡ ```python def get_params(params, devices): new_params [p.to(devices) for p in params] for p in new_params: p.requires_grad_() p.retain_grad() print(new_params[0].grad) return new_params new_params get_params(params, d2l.gpu(0)) print('b1 weight:', new_params[1]) print('b1 grad:', new_params[1].grad) ``` + åˆå§‹åŒ–ä¸€ä¸ªç”¨äºè®¡ç®—ä¸åŒè®¾å¤‡çš„æ¢¯åº¦å’Œçš„å‡½æ•° ```python # ç”¨äºæŠŠæ‰€æœ‰çš„lossåŠ èµ·æ¥å¹¶åˆ†é…åˆ°å¯¹åº”çš„è®¾å¤‡ def allreduce(data): # å¯¹dataæ±‚å’Œåå¹¿æ’­ for i in range(1, len(data)): # è¿™é‡Œä½¿ç”¨å¹¿æ’­æœºåˆ¶ data[0][:] + data[i].to(data[0].device) for i in range(1, len(data)): # æŠŠdata[0]çš„å€¼å¹¿æ’­åˆ°å…¶ä»–è®¾å¤‡ä¸Š data[i][:] data[0].to(data[i].device) data [torch.ones((1, 2), device d2l.try_gpu(i)) * (i + 1) for i in range(2)] print('before allreduce:', data) allreduce(data) print('after allreduce:', data) ``` + æµ‹è¯•ä¸€ä¸‹ä¸€ä¸ªåˆ†å‰²å‡½æ•° ```python data torch.arange(20).reshape(4, 5) devices torch.device('cuda:0'), torch.device('cuda:0') split nn.parallel.scatter(data, devices) print('input :', data) print('load into', devices) print('output:', split) \"\"\" input : tensor([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]]) load into (device(type 'cuda', index 0), device(type 'cuda', index 0)) output: (tensor([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]], device 'cuda:0'), tensor([[10, 11, 12, 13, 14], [15, 16, 17, 18, 19]], device 'cuda:0')) \"\"\" ``` + ä¸€ä¸ªå®é™…ç”¨äºåˆ†å‰²æ•°æ®é›†çš„å‡½æ•° ```python def split_batch(X, y, devices): assert X.shape[0] y.shape[0] return (nn.parallel.scatter(X, devices), nn.parallel.scatter(y, devices)) ``` + å†™ä¸€ä¸ªè®­ç»ƒä¸€è½®ä½¿ç”¨çš„å‡½æ•° ```python def train_batch(X, y, device_params, devices, lr): X_shards, y_shards split_batch(X, y, devices) # åœ¨æ¯ä¸ªGPUä¸Šåˆ†åˆ«è®¡ç®—æŸå¤± ls [ loss(lenet(X_shard, device_W), y_shard).sum() for X_shard, y_shard, device_W in zip(X_shards, y_shards, device_params) ] for l in ls: l.backward() # æŠŠæ¢¯åº¦åŠ èµ·æ¥ with torch.no_grad(): for i in range(len(device_params[0])): allreduce([device_params[c][i].grad for c in range(len(devices))]) # åœ¨æ¯ä¸ªGPUä¸Šåˆ†åˆ«æ›´æ–°æ¨¡å‹å‚æ•° for param in device_params: d2l.sgd(param, lr, X.shape[0]) # åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨å…¨å°ºå¯¸çš„å°æ‰¹é‡ ``` + å®é™…çš„è®­ç»ƒå‡½æ•° ```python def train(num_gpus, batch_size, lr): train_iter, test_iter d2l.load_data_fashion_mnist(batch_size) devices [d2l.try_gpu(i) for i in range(num_gpus)] device_params [get_params(params, d) for d in devices] num_epochs 10 animator d2l.Animator('epoch', 'test acc', xlim [1, num_epochs]) timer d2l.Timer() for epoch in range(num_epochs): timer.start() for X, y in train_iter: train_batch(X, y, device_params, devices, lr) torch.cuda.synchronize() timer.stop() animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu( lambda x: lenet(x, device_params[0]), test_iter, devices[0]),)) print(f'test acc: {animator.Y[0][ 1]:.2f}, {timer.avg():.1f} sec/epoch ' f'on {str(devices)}') train(num_gpus 1, batch_size 256, lr 0.2) ``` ![image 20250117151040478](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501171510709.png) > å®é™…ä½¿ç”¨çš„æ—¶å€™ä¸åŒçš„GPUçš„batchsizeæœ€å¥½å¯ä»¥ä¸å˜, æ‰€ä»¥éœ€è¦è°ƒå¤§batch_sizeä»¥åŠlr ### ç®€å•å®ç° ```python # åˆå§‹åŒ–ä¸€ä¸ªç½‘ç»œæ¨¡å‹ def resnet18(num_classes, in_channels 1): \"\"\"Return a ResNet 18 model.\"\"\" def resnet_block(in_channels, out_channels, num_residuals, first_block False): blk [] for i in range(num_residuals): if i 0 and not first_block: blk.append(d2l.Residual(out_channels, use_1x1conv True, strides 2)) else: blk.append(d2l.Residual(out_channels)) return blk net nn.Sequential( nn.Conv2d(in_channels, 64, kernel_size 7, stride 2, padding 3), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(kernel_size 3, stride 2, padding 1)) net.add_module(\"resnet_block1\", nn.Sequential(*resnet_block(64, 64, 2, first_block True))) net.add_module(\"resnet_block2\", nn.Sequential(*resnet_block(64, 128, 2))) net.add_module(\"resnet_block3\", nn.Sequential(*resnet_block(128, 256, 2))) net.add_module(\"resnet_block4\", nn.Sequential(*resnet_block(256, 512, 2))) net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1, 1))) net.add_module(\"fc\", nn.Sequential(nn.Flatten(), nn.Linear(512, num_classes))) return net ``` ```python def train(net, nums_gpu, batch_size, lr): train_iter, test_iter d2l.load_data_fashion_mnist(batch_size, resize 96) device [d2l.try_gpu(i) for i in range(nums_gpu)] def init_weights(m): if type(m) in [nn.Linear, nn.Conv2d]: nn.init.normal_(m.weight, std 0.01) net.apply(init_weights) # æŠŠç½‘ç»œæ”¾åˆ°å¤šä¸ªGPUä¸Š, ä¸»è¦æ˜¯ä½¿ç”¨è¿™ä¸€ä¸ª, ä½¿ç”¨ä¸€ä¸ªç½‘ç»œ, å¤åˆ¶åˆ°å¤šä¸ªè®¾å¤‡, è¿”å›æ–°çš„ç½‘ç»œ net nn.DataParallel(net, device_ids device) trainer torch.optim.SGD(net.parameters(), lr lr) loss nn.CrossEntropyLoss() timer, num_epochs d2l.Timer(), 10 animator d2l.Animator(\"epoch\", \"test acc\", xlim [1, num_epochs]) for epoch in range(num_epochs): net.train() timer.start() for X, y in train_iter: trainer.zero_grad() X, y X.to(device[0]), y.to(device[0]) l loss(net(X), y) l.backward() trainer.step() timer.stop() animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu(net, test_iter),)) print(f\"test acc: {animator.Y[0][ 1]:.2f}, {timer.avg():.1f} sec/epoch on {str(device)}\") ``` ![image 20250117160809185](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202501171608314.png) ## å¤šæœºå™¨ å°½é‡å‡å°‘æœºå™¨ä¹‹é—´çš„é€šä¿¡, åŒä¸€ä¸ªæœºå™¨é‡Œé¢çš„ä¸åŒå¡ä¹‹é—´å…ˆè¿›è¡Œè®¡ç®—, æœ€åå†æŠŠæ‰€æœ‰çš„æ•°æ®è¿›è¡Œæ±‡æ€», æ•°æ®çš„é€šä¿¡ä»¥åŠæ•°æ®çš„è®¡ç®—æ˜¯å¯ä»¥åŒæ­¥è¿›è¡Œçš„ åœ¨è¿›è¡Œè®¡ç®—backçš„æ—¶å€™, æ¯è®¡ç®—ä¸€å±‚å‘é€ä¸€æ¬¡"},"/note/æœºå™¨å­¦ä¹ /ææ²è¯¾ç¨‹/2025-2-10-36åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ.html":{"title":"åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ","content":"# åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œ å¦‚æœæ˜¯ä¸€ä¸ªæ–‡æœ¬å¡«ç©º, å¯ä»¥ä½¿ç”¨åé¢çš„ä¿¡æ¯å¯¹ç©ºé‡Œé¢çš„ä¿¡æ¯è¿›è¡Œé¢„æµ‹ å¦‚æœæˆ‘ä»¬æƒ³ç”¨æ¦‚ç‡å›¾æ¨¡å‹æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥è®¾è®¡ä¸€ä¸ªéšå˜é‡æ¨¡å‹ï¼šåœ¨ä»»æ„æ—¶é—´æ­¥tï¼Œå‡è®¾å­˜åœ¨æŸä¸ªéšå˜é‡h~t~ï¼Œ é€šè¿‡æ¦‚ç‡P(x~t~ h~t~)æ§åˆ¶æˆ‘ä»¬è§‚æµ‹åˆ°çš„x~t~ ä»»ä½•h~t~ â†’h~t+1~è½¬ç§»éƒ½æ˜¯ç”±ä¸€äº›çŠ¶æ€è½¬ç§»æ¦‚ç‡P(h~t+1~ h~t~)ç»™ å‡ºã€‚è¿™ä¸ªæ¦‚ç‡å›¾æ¨¡å‹å°±æ˜¯ä¸€ä¸ªéšé©¬å°”å¯å¤«æ¨¡å‹ ![image 20250210221807615](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102218677.png) > è¾“å…¥å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå€¼é¢„æµ‹ ![image 20250210220911430](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102209488.png) ![image 20250210221146700](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102211740.png) > æŠŠä¸¤ä¸ªè¾“å‡ºè¿åœ¨ä¸€èµ·, æ‰€ä»¥æœ€åçš„è¾“å‡ºlineréœ€è¦ä½¿ç”¨ä¸¤å€çš„è¾“å…¥å¤§å° è¿™ä¸ªåœ¨è®­ç»ƒçš„æ—¶å€™æ¯”è¾ƒå¥½å®ç°, ä½†æ˜¯æ¨ç†çš„æ—¶å€™ä¸å¤ªé€‚åˆæ¨ç†æœªæ¥å‘ç”Ÿçš„æ•°æ®, ä¸€èˆ¬ä½¿ç”¨çš„åœºæ™¯æ˜¯ç»™ä¸€ä¸ªå®Œæ•´çš„å¥å­ä»¥åä½¿ç”¨è¿™ä¸ªå¥å­é¢„æµ‹ä¸€äº›ä¸œè¥¿(ç¿»è¯‘, å¡«ç©º) ## é”™è¯¯ç¤ºä¾‹ ```python import torch from torch import nn from d2l import torch as d2l # åŠ è½½æ•°æ® batch_size, num_steps, device 32, 35, d2l.try_gpu() train_iter, vocab d2l.load_data_time_machine(batch_size, num_steps) # é€šè¿‡è®¾ç½®â€œbidirective Trueâ€æ¥å®šä¹‰åŒå‘LSTMæ¨¡å‹ vocab_size, num_hiddens, num_layers len(vocab), 256, 2 num_inputs vocab_size lstm_layer nn.LSTM(num_inputs, num_hiddens, num_layers, bidirectional True) model d2l.RNNModel(lstm_layer, len(vocab)) model model.to(device) # è®­ç»ƒæ¨¡å‹ num_epochs, lr 500, 1 d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device) ``` ![image 20250210223445301](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502102234356.png) > å¯ä»¥çœ‹å‡ºæ¥è¿™ä¸ªçš„é¢„æµ‹æ•ˆæœå¾ˆå·® ## æœºå™¨ç¿»è¯‘æ•°æ®é›† ä¸‹è½½æ•°æ®é›† ```python #@save d2l.DATA_HUB['fra eng'] (d2l.DATA_URL + 'fra eng.zip', '94646ad1522d915e7b0f9296181140edcf86a4f5') #@save def read_data_nmt(): \"\"\"è½½å…¥â€œè‹±è¯­ï¼æ³•è¯­â€æ•°æ®é›†\"\"\" data_dir d2l.download_extract('fra eng') with open(os.path.join(data_dir, 'fra.txt'), 'r', encoding 'utf 8') as f: return f.read() raw_text read_data_nmt() print(raw_text[:75]) \"\"\" Downloading ../data\\fra eng.zip from http://d2l data.s3 accelerate.amazonaws.com/fra eng.zip... Go.\tVa ! Hi.\tSalut ! Run!\tCoursâ€¯! Run!\tCourezâ€¯! Who?\tQui ? Wow!\tÃ‡a alorsâ€¯! \"\"\" ``` å¤„ç†ä¸€ä¸‹æ•°æ®, æŠŠæ•°æ®çš„æŒ‰ç…§æ ¼å¼è¿›è¡Œæ’åˆ— ```python def preprocess_nmt(text): \"\"\"é¢„å¤„ç†â€œè‹±è¯­ï¼æ³•è¯­â€æ•°æ®é›†\"\"\" def no_space(char, prev_char): return char in set(',.!?') and prev_char ! ' ' # ä½¿ç”¨ç©ºæ ¼æ›¿æ¢ä¸é—´æ–­ç©ºæ ¼ # ä½¿ç”¨å°å†™å­—æ¯æ›¿æ¢å¤§å†™å­—æ¯ # \\u202fæ˜¯ä¸€ä¸ªä¸é—´æ–­çš„ç©ºç™½ç¬¦, \\xa0æ˜¯ä¸é—´æ–­ç©ºæ ¼ text text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower() # åœ¨å•è¯å’Œæ ‡ç‚¹ç¬¦å·ä¹‹é—´æ’å…¥ç©ºæ ¼ out [' ' + char if i > 0 and no_space(char, text[i 1]) else char for i, char in enumerate(text)] return ''.join(out) text preprocess_nmt(raw_text) print(text[:300]) \"\"\" go .\tva ! hi .\tsalut ! run !\tcours ! run !\tcourez ! who ?\tqui ? wow !\tÃ§a alors ! fire !\tau feu ! help !\tÃ  l'aide ! jump .\tsaute . stop !\tÃ§a suffit ! stop !\tstop ! stop !\tarrÃªte toi ! wait !\tattends ! wait !\tattendez ! go on .\tpoursuis . go on .\tcontinuez . go on .\tpoursuivez . hello !\tbonjour ! hell \"\"\" ``` æŠŠä¸¤ä¸ªè¯­è¨€çš„æ•°æ®åˆ†å‰²å¼€æ¥, ä¹‹åä½¿ç”¨é“¾è¡¨è¿›è¡Œå­˜å‚¨ ```python #@save def tokenize_nmt(text, num_examples None): \"\"\"è¯å…ƒåŒ–â€œè‹±è¯­ï¼æ³•è¯­â€æ•°æ®æ•°æ®é›†\"\"\" source, target [], [] for i, line in enumerate(text.split('\\n')): if num_examples and i > num_examples: break parts line.split('\\t') if len(parts) 2: source.append(parts[0].split(' ')) target.append(parts[1].split(' ')) return source, target source, target tokenize_nmt(text) source[:6], target[:6] \"\"\" ([['go', '.'], ['hi', '.'], ['run', '!'], ['run', '!'], ['who', '?'], ['wow', '!']], [['va', '!'], ['salut', '!'], ['cours', '!'], ['courez', '!'], ['qui', '?'], ['Ã§a', 'alors', '!']]) \"\"\" ``` æ˜¾ç¤ºä¸€ä¸‹æ•°æ®çš„åˆ†å¸ƒ ```python #@save æŸ¥çœ‹ä¸€ä¸‹æ•°æ®é›†ä¸­æ•°æ®çš„åˆ†å¸ƒ def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist): \"\"\"ç»˜åˆ¶åˆ—è¡¨é•¿åº¦å¯¹çš„ç›´æ–¹å›¾\"\"\" d2l.set_figsize() _, _, patches d2l.plt.hist( [[len(l) for l in xlist], [len(l) for l in ylist]]) d2l.plt.xlabel(xlabel) d2l.plt.ylabel(ylabel) for patch in patches[1].patches: patch.set_hatch('/') d2l.plt.legend(legend) show_list_len_pair_hist(['source', 'target'], '# tokens per sequence', 'count', source, target) ``` å»ºç«‹ä¸€ä¸ªè¯è¡¨ ```python src_vocab d2l.Vocab(source, min_freq 2, reserved_tokens ['<pad>', '<bos>', '<eos>']) len(src_vocab) \"\"\" 10012 \"\"\" ``` æ‰“å°ä¸€ä¸‹æ•ˆæœ ```python for i in range(7): print(src_vocab.idx_to_token[i]) \"\"\" <unk> <pad> <bos> <eos> . i you \"\"\" ``` å®é™…çš„æ•°æ®éœ€è¦é•¿åº¦ä¸€è‡´ ```python #@save def truncate_pad(line, num_steps, padding_token): \"\"\"æˆªæ–­æˆ–å¡«å……æ–‡æœ¬åºåˆ—, num_stepsæ˜¯æœ€å¤§çš„é•¿åº¦\"\"\" if len(line) > num_steps: return line[:num_steps] # æˆªæ–­ return line + [padding_token] * (num_steps len(line)) # å¡«å…… truncate_pad(src_vocab[source[0]], 10, src_vocab['<pad>']) ``` é•¿åº¦ä¸€è‡´çš„åŒæ—¶è®°å½•ä¸€ä¸‹æœ‰æ•ˆæ•°æ®çš„é•¿åº¦ ```python #@save def build_array_nmt(lines, vocab, num_steps): \"\"\"å°†æœºå™¨ç¿»è¯‘çš„æ–‡æœ¬åºåˆ—è½¬æ¢æˆå°æ‰¹é‡\"\"\" lines [vocab[l] for l in lines] # å°†æ¯ä¸ªè¯è½¬æ¢ä¸ºè¯ç´¢å¼• lines [l + [vocab['<eos>']] for l in lines] # æ·»åŠ eosç»“å°¾ array torch.tensor([truncate_pad( l, num_steps, vocab['<pad>']) for l in lines]) # æ¯ä¸ªåºåˆ—çš„æœ‰æ•ˆé•¿åº¦, ä¸æ˜¯å¡«å……çš„é•¿åº¦ valid_len (array ! vocab['<pad>']).type(torch.int32).sum(1) return array, valid_len ``` ä½¿ç”¨ä¸€ä¸ªå‡½æ•°å®Œæˆ ```python #@save ä¸Šé¢çš„å‡½æ•°çš„é›†åˆ def load_data_nmt(batch_size, num_steps, num_examples 600): \"\"\"è¿”å›ç¿»è¯‘æ•°æ®é›†çš„è¿­ä»£å™¨å’Œè¯è¡¨\"\"\" text preprocess_nmt(read_data_nmt()) # åŠ è½½, æŒ‰æ ¼å¼é¢„å¤„ç† source, target tokenize_nmt(text, num_examples) # åˆ†è¯ src_vocab d2l.Vocab(source, min_freq 2, reserved_tokens ['<pad>', '<bos>', '<eos>']) tgt_vocab d2l.Vocab(target, min_freq 2, reserved_tokens ['<pad>', '<bos>', '<eos>']) # è·å–å®šé•¿çš„æ•°æ®é›† src_array, src_valid_len build_array_nmt(source, src_vocab, num_steps) tgt_array, tgt_valid_len build_array_nmt(target, tgt_vocab, num_steps) # è¿”å›æ•°æ®é›†è¿­ä»£å™¨ data_arrays (src_array, src_valid_len, tgt_array, tgt_valid_len) data_iter d2l.load_array(data_arrays, batch_size) return data_iter, src_vocab, tgt_vocab ``` ç»“æœ ```python train_iter, src_vocab, tgt_vocab load_data_nmt(batch_size 2, num_steps 8) for X, X_valid_len, Y, Y_valid_len in train_iter: print('X:', X.type(torch.int32)) print('Xçš„æœ‰æ•ˆé•¿åº¦:', X_valid_len) print('Y:', Y.type(torch.int32)) print('Yçš„æœ‰æ•ˆé•¿åº¦:', Y_valid_len) break ```"},"/note/æœºå™¨å­¦ä¹ /2024-9-22-vLLM.html":{"title":"vLLM","content":" layout: post title: \"vLLM\" date: 2024 8 5 15:39:08 +0800 tags: AI æœºå™¨å­¦ä¹  # vLLM [vllm project/vllm: A high throughput and memory efficient inference and serving engine for LLMs (github.com)](https://github.com/vllm project/vllm) `vLLM`æ˜¯ä¼¯å…‹åˆ©å¤§å­¦LMSYSç»„ç»‡å¼€æºçš„[å¤§è¯­è¨€æ¨¡å‹](https://zhida.zhihu.com/search?q å¤§è¯­è¨€æ¨¡å‹&zhida_source entity&is_preview 1)é«˜é€Ÿæ¨ç†æ¡†æ¶ï¼Œæ—¨åœ¨æå¤§åœ°æå‡å®æ—¶åœºæ™¯ä¸‹çš„è¯­è¨€æ¨¡å‹æœåŠ¡çš„ååä¸å†…å­˜ä½¿ç”¨æ•ˆç‡ã€‚`vLLM`æ˜¯ä¸€ä¸ªå¿«é€Ÿä¸”æ˜“äºä½¿ç”¨çš„åº“ï¼Œç”¨äº LLM æ¨ç†å’ŒæœåŠ¡ï¼Œå¯ä»¥å’ŒHuggingFace [æ— ç¼é›†æˆ](https://zhida.zhihu.com/search?q æ— ç¼é›†æˆ&zhida_source entity&is_preview 1)ã€‚vLLMåˆ©ç”¨äº†å…¨æ–°çš„æ³¨æ„åŠ›ç®—æ³•ã€ŒPagedAttentionã€ï¼Œæœ‰æ•ˆåœ°ç®¡ç†æ³¨æ„åŠ›é”®å’Œå€¼ã€‚ åœ¨å®é™…ç®—çš„æ—¶å€™, æ¯ä¸€ä¸ªæ–°è·å–çš„tokenéœ€è¦å’Œä¹‹å‰çš„tokenè¿›è¡Œè®¡ç®—, è¿™ä¸€ä¸ªéƒ¨åˆ†è®¡ç®—åœ¨è·å–ä¸€ä¸ªæ–°çš„tokençš„ä½¿ç”¨æ˜¯é‡å¤çš„, æ‰€ä»¥å¯ä»¥å­˜å‚¨èµ·æ¥, ç”¨ç©ºé—´æ¢æ—¶é—´ åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™ç”±äºä¸çŸ¥é“éœ€è¦ç”³è¯·çš„æ•°é‡, åªèƒ½ç”³è¯·ä¸€ä¸ªå¤§æ•°ç»„ [arxiv.org/pdf/2309.06180](https://arxiv.org/pdf/2309.06180) åœ¨æ¨¡å‹è¿è¡Œçš„æ—¶å€™, ä¼šä½¿ç”¨å¤§é‡çš„å†…å­˜, è¿™æ—¶å€™ç”±äºä¸èƒ½é¢„æµ‹å®é™…ä¼šä½¿ç”¨çš„å†…å­˜çš„å¤§å°, æ‰€ä»¥ä¼šä½¿ç”¨é¢„è®¾çš„æœ€å¤§å€¼è¿›è¡Œç”³è¯·, åŒæ—¶ä¼šå‡ºç°ç”³è¯·çš„å†…å­˜ä¹‹é—´å­˜åœ¨ç¢ç‰‡, ä¸è¶³å·²è¢«ä½¿ç”¨, è¿™å¯¼è‡´å®é™…çš„å†…å­˜ä½¿ç”¨ç‡åªæœ‰20%åˆ°40% ## Transformå’ŒKey Value Cache Transformeræ˜¯ä¸€ç§ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å’Œå…¶ä»–åºåˆ—åˆ°åºåˆ—ï¼ˆsequence to sequenceï¼‰ä»»åŠ¡çš„æ·±åº¦å­¦ä¹ æ¨¡å‹æ¶æ„ï¼Œå®ƒåœ¨2017å¹´ç”±Vaswaniç­‰äººé¦–æ¬¡æå‡ºã€‚Transformeræ¶æ„å¼•å…¥äº†è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆself attention mechanismï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå…³é”®çš„åˆ›æ–°ï¼Œä½¿å…¶åœ¨å¤„ç†åºåˆ—æ•°æ®æ—¶è¡¨ç°å‡ºè‰²ã€‚ ä»¥ä¸‹æ˜¯Transformerçš„ä¸€äº›é‡è¦ç»„æˆéƒ¨åˆ†å’Œç‰¹ç‚¹ï¼š + è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf Attentionï¼‰ï¼šè¿™æ˜¯Transformerçš„æ ¸å¿ƒæ¦‚å¿µä¹‹ä¸€ï¼Œå®ƒä½¿æ¨¡å‹èƒ½å¤ŸåŒæ—¶è€ƒè™‘è¾“å…¥åºåˆ—ä¸­çš„æ‰€æœ‰ä½ç½®ï¼Œè€Œä¸æ˜¯åƒå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰æˆ–å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ä¸€æ ·é€æ­¥å¤„ç†ã€‚è‡ªæ³¨æ„åŠ›æœºåˆ¶å…è®¸æ¨¡å‹æ ¹æ®è¾“å…¥åºåˆ—ä¸­çš„ä¸åŒéƒ¨åˆ†æ¥èµ‹äºˆä¸åŒçš„æ³¨æ„æƒé‡ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰è¯­ä¹‰å…³ç³»ã€‚ + å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti Head Attentionï¼‰ï¼šTransformerä¸­çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶è¢«æ‰©å±•ä¸ºå¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œæ¯ä¸ªå¤´å¯ä»¥å­¦ä¹ ä¸åŒçš„æ³¨æ„æƒé‡ï¼Œä»¥æ›´å¥½åœ°æ•æ‰ä¸åŒç±»å‹çš„å…³ç³»ã€‚å¤šå¤´æ³¨æ„åŠ›å…è®¸æ¨¡å‹å¹¶è¡Œå¤„ç†ä¸åŒçš„ä¿¡æ¯å­ç©ºé—´ã€‚ + å †å å±‚ï¼ˆStacked Layersï¼‰ï¼šTransformeré€šå¸¸ç”±å¤šä¸ªç›¸åŒçš„ç¼–ç å™¨å’Œè§£ç å™¨å±‚å †å è€Œæˆã€‚è¿™äº›å †å çš„å±‚æœ‰åŠ©äºæ¨¡å‹å­¦ä¹ å¤æ‚çš„ç‰¹å¾è¡¨ç¤ºå’Œè¯­ä¹‰ã€‚ + ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰ï¼šç”±äºTransformeræ²¡æœ‰å†…ç½®çš„åºåˆ—ä½ç½®ä¿¡æ¯ï¼Œå®ƒéœ€è¦é¢å¤–çš„ä½ç½®ç¼–ç æ¥è¡¨è¾¾è¾“å…¥åºåˆ—ä¸­å•è¯çš„ä½ç½®é¡ºåºã€‚ + æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ï¼ˆResidual Connections and Layer Normalizationï¼‰ï¼šè¿™äº›æŠ€æœ¯æœ‰åŠ©äºå‡è½»è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢¯åº¦æ¶ˆå¤±å’Œçˆ†ç‚¸é—®é¢˜ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“è®­ç»ƒã€‚ + ç¼–ç å™¨å’Œè§£ç å™¨ï¼šTransformeré€šå¸¸åŒ…æ‹¬ä¸€ä¸ªç¼–ç å™¨ç”¨äºå¤„ç†è¾“å…¥åºåˆ—å’Œä¸€ä¸ªè§£ç å™¨ç”¨äºç”Ÿæˆè¾“å‡ºåºåˆ—ï¼Œè¿™ä½¿å…¶é€‚ç”¨äºåºåˆ—åˆ°åºåˆ—çš„ä»»åŠ¡ï¼Œå¦‚æœºå™¨ç¿»è¯‘ã€‚ åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™å¯ä»¥ä½¿ç”¨è¿™ä¸€ä¸ªæ¨¡å‹ç”ŸæˆéŸ³é¢‘, æ–‡æœ¬ç­‰ ### åŸç† è¾“å…¥çš„æ•°æ®ä¼šè¢«åˆ†å‰²ä¸ºç®€å•çš„token, è¿™ä¸€ä¸ªåˆ†å‰²å¯ä»¥ä¸æ˜¯æŒ‰ç…§å•è¯è¿›è¡Œçš„, æ¯ä¸€ä¸ªtokenå®é™…ä¼šå¯¹åº”ä¸€ä¸ªå‘é‡ä¹Ÿå°±æ˜¯ä¸€ç»„æ•°æ®, å¯ä»¥çœ‹åšé«˜ä½åæ ‡é‡Œé¢çš„ä¸€ä¸ªä½ç½®, é€šè¿‡è®¡ç®—, æ¯”è¾ƒæ¥è¿‘çš„æ•°æ®åæ ‡é è¿‘ ### å®é™…çš„æµç¨‹ å¯¹ä¸€ä¸ªè¾“å…¥çš„æ•°æ®è¿›è¡Œencoderä¹‹åæŠŠæ•°æ®è¾“å…¥åˆ°decoder, è¿™ä¸¤ä¸ªç»“æ„å¯ä»¥æ˜¯å¤šä¸ªç›¸åŒçš„ç»“æ„, ä½†æ˜¯å‚æ•°ä¸æ˜¯ç›¸åŒçš„ ![image 20240924105336210](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409241053267.png) #### encoder è¿™ä¸€ä¸ªéƒ¨åˆ†ä»ä¸‹åˆ°ä¸Šå¯ä»¥åˆ†ä¸ºè¾“å…¥éƒ¨åˆ†, æ³¨æ„åŠ›æœºåˆ¶, å‰é¦ˆç¥ç»ç½‘ç»œ ![image 20240924110907862](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409241109898.png) + è¾“å…¥éƒ¨åˆ† embedding, æŠŠæ¯ä¸€ä¸ªå­—åˆå§‹åŒ–ä¸ºä¸€ä¸ª512å­—èŠ‚çš„å‘é‡ ## éƒ¨ç½² å°è¯•éƒ¨ç½²ä¸€ä¸ªGLM 4çš„æ¨¡å‹[THUDM/GLM 4: GLM 4 series: Open Multilingual Multimodal Chat LMs å¼€æºå¤šè¯­è¨€å¤šæ¨¡æ€å¯¹è¯æ¨¡å‹ (github.com)](https://github.com/THUDM/GLM 4) ### èµ„æ–™è®°å½• [Quickstart â€” vLLMå®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/en/latest/getting_started/quickstart.html) [Bç«™æ•™ç¨‹](https://github.com/echonoshy/cgft llm/tree/master/vllm) ### ä¸‹è½½å¤§æ¨¡å‹ 1. [huggingface cliä¸‹è½½æ•°æ®ï¼ˆå«å›½å†…é•œåƒæºæ–¹æ³•ï¼‰_huggingface cli download CSDNåšå®¢](https://blog.csdn.net/lanlinjnc/article/details/136709225) 2. è¿™é‡Œä½¿ç”¨ModelScopeè¿›è¡Œä¸‹è½½ ```bash pip install modelscope modelscope download model ZhipuAI/glm 4 9b chat local_dir /root/autodl tmp/models/glm 4 9b chat ``` 3. ä½¿ç”¨vllmè¿›è¡Œä¸‹è½½ By default, vLLM downloads model from [HuggingFace](https://huggingface.co/). If you would like to use models from [ModelScope](https://www.modelscope.cn/) in the following examples, please set the environment variable: ```bash export VLLM_USE_MODELSCOPE True ``` ### å®‰è£…VLLM ```bash pip install vllm ``` > ä½¿ç”¨è¿™ä¸€ä¸ªå‘½ä»¤å¯ä»¥è¿›è¡Œå®‰è£…, ä½†æ˜¯å®‰è£…ä»¥åå‡ºç°pytorchä¸èƒ½ä½¿ç”¨, éœ€è¦å†æ¬¡å®‰è£…pytorch ### ä½¿ç”¨ [ä½¿ç”¨vllméƒ¨ç½²è‡ªå·±çš„å¤§æ¨¡å‹_vllméƒ¨ç½²å¤§æ¨¡å‹ CSDNåšå®¢](https://blog.csdn.net/qq_35082030/article/details/138225284) + ç”¨ä»£ç è°ƒç”¨ ```python from transformers import AutoTokenizer from vllm import LLM, SamplingParams import torch print(torch.cuda.is_available()) def demo1(): prompts [ \"Hello, my name is\", \"The president of the United States is\", \"The capital of France is\", \"The future of AI is\", ] # Create a sampling params object. sampling_params SamplingParams(temperature 0.8, top_p 0.95) # Create an LLM. model_path \"./vllm_model/model\" # ä½¿ç”¨çš„æ¨¡å‹ # model_path \"./vllm_model/models/qwen2 1.5b\" llm LLM(model model_path, trust_remote_code True, tensor_parallel_size 1, dtype torch.float16) outputs llm.generate(prompts, sampling_params) # Print the outputs. for output in outputs: prompt output.prompt generated_text output.outputs[0].text print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\") def demo2(): # å¦‚æœé‡è§ OOM ç°è±¡ï¼Œå»ºè®®å‡å°‘max_model_lenï¼Œæˆ–è€…å¢åŠ tp_size max_model_len, tp_size 32768, 2 model \"/root/autodl tmp/models/glm 4 9b chat\" prompt [{\"role\": \"user\", \"content\": \"ä½ å¥½\"}] tokenizer AutoTokenizer.from_pretrained(model, trust_remote_code True) llm LLM( model model, tensor_parallel_size tp_size, max_model_len max_model_len, trust_remote_code True, enforce_eager True, ) stop_token_ids [151329, 151336, 151338] sampling_params SamplingParams(temperature 0.95, max_tokens 1024, stop_token_ids stop_token_ids) inputs tokenizer.apply_chat_template(prompt, tokenize False, add_generation_prompt True) outputs llm.generate(prompts inputs, sampling_params sampling_params) print(outputs[0].outputs[0].text) if __name__ \"__main__\": demo1() ``` + å‘½ä»¤å‡½è°ƒç”¨ ```bash vllm serve facebook/opt 125m ``` By default, the server uses a predefined chat template stored in the tokenizer. You can override this template by using the ` chat template` argument: ```python vllm serve facebook/opt 125m chat template ./examples/template_chatml.jinja ``` ## æ€è·¯ [å¤§æ¨¡å‹æ¨ç†æ¡†æ¶ vLLM æºç è§£æ PagedAttentionåŸç†è¯¦è§£ continueBatchingç­–ç•¥è¯¦è§£ å¢èåšå£«æˆè¯¾ æ€ä¹ˆåŠ å¿«å¤§æ¨¡å‹æ¨ç†_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1YfW4eDE6V/?spm_id_from 333.337.search card.all.click&vd_source 3771cc8df803eed7244034a762706c24) ### æ•´ç†æµç¨‹ä»¥åŠé—®é¢˜ ![image 20241015093233859](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410150932135.png) ![image 20241015093324423](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410150933481.png) ![image 20241015093331603](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410150933661.png) ![image 20241015093426145](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410150934360.png) ![image 20241015093732837](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410150937895.png) > é€ æˆçš„æ ¹æœ¬åŸå› æ˜¯éœ€è¦è¿ç»­ç”³è¯·ä¸€ä¸ªè¿ç»­çš„å†…å­˜ ### è§£å†³ 1. è™šæ‹ŸåŒ–å†…å­˜ 2. å¯¹ç›¸åŒçš„æ•°æ®è¿›è¡Œå†…å­˜å…±äº« 3. åŠæ—¶æ¸…é™¤ä¸éœ€è¦çš„å†…å­˜ 4. åŠ¨æ€Continue Batching, åœ¨å¤„ç†å¤šæ¡æ•°æ®çš„æ—¶å€™batchåªéœ€è¦åŠ è½½ä¸€æ¬¡å†…å­˜, æé«˜ååé‡ > ![image 20241015094806652](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410150948722.png) > > å¯¹å¯¼è‡´ä¸€ä¸ªé—®é¢˜, æ•°æ®çš„é•¿åº¦æ˜¯ä¸åŒçš„, é•¿ä¸€ç‚¹çš„æ•°æ®éœ€è¦æ›´é•¿çš„æ—¶é—´è¿›è¡Œå¤„ç† ![image 20241015095044335](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410150950426.png) 1. èµ·å§‹ä½ç½® 2. ç”Ÿæˆä¸€ä¸ªå­—ç¬¦, ç•™å‡ºä¸‹ä¸€ä¸ªå­—ç¬¦ 3. æœ‰ä¸¤ä¸ªåˆ°è¾¾ç»“æŸä½ç½® 4. æ‰“å°ä¸¤æ¡æ•°æ® æŠŠå·²ç»ENDçš„å†…å­˜ç›´æ¥é‡Šæ”¾ ![image 20241015095252157](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410150952246.png) åŠ å…¥S5, S5 >prefill(å¯ä»¥å¹¶è¡Œä½†æ˜¯S1, S3å·²ç»ç»“æŸ), ä¹‹ådecode > æ–°ç‰ˆæœ¬å·²ç»è§£å†³ åœ¨ä¸Šé¢çš„å›¾é‡Œé¢ç™½è‰²çš„åœ°æ–¹è¿˜æ˜¯æœ‰æµªè´¹ è§£å†³: æ‹¼èµ·æ¥è®¡ç®— ![image 20241015095627802](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410150956886.png) è™šæ‹Ÿæ˜¾å­˜å¯ä»¥éšæ„æ’å…¥æ•°æ®, å¦‚æœå‰©ä½™çš„å†…å­˜åœ¨ä¸‹ä¸€æ¬¡ç”Ÿæˆçš„æ—¶å€™éœ€è¦çš„å†…å­˜ä¸å¤Ÿ, å…ˆæš‚æ—¶ç§»å‡ºå» ### æ–‡ä»¶æ„æˆ [[vllm\\]vllmæ¶æ„åˆ†æ çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/654659042#:~:text vllmæ¶æ„åˆ†æ 1 æ–‡ä»¶ç›®å½•ç»“æ„ benchmark%3A æµ‹è¯•å»¶è¿Ÿå’Œååçš„è„šæœ¬ ... 2 å…³é”®æºç åˆ†æ,Scheduler ... 6 vllm%2Fworker ... 7 vllm%2Fengine) [vLLM (2) æ¶æ„æ€»è§ˆ_vllmå®˜æ–¹æ–‡æ¡£ CSDNåšå®¢](https://blog.csdn.net/daihaoguang/article/details/141284561) [å›¾è§£å¤§æ¨¡å‹è®¡ç®—åŠ é€Ÿç³»åˆ—ï¼švLLMæºç è§£æ1ï¼Œæ•´ä½“æ¶æ„ CSDNåšå®¢](https://blog.csdn.net/stephen147/article/details/141193770) [Efficient Memory Management for Large Language Model Serving with PagedAttention (arxiv.org)](https://arxiv.org/pdf/2309.06180) ### æ–‡ä»¶ç›®å½•ç»“æ„ ![image 20241015102942978](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410151029043.png) + benchmark: æµ‹è¯•å»¶è¿Ÿå’Œååçš„è„šæœ¬ + csrc: torchä¸‹çš„cudaæ‰©å±•ï¼Œä¸€äº›å…³é”®kernelsçš„cppæºç ï¼ŒåŒ…å«äº†attentionã€[æ¿€æ´»å‡½æ•°](https://zhida.zhihu.com/search?content_id 233608460&content_type Article&match_order 1&q æ¿€æ´»å‡½æ•°&zhida_source entity)ã€cacheç­‰æ ¸å‡½æ•° + vllm/core: å…³é”®[è°ƒåº¦ç®—æ³•](https://zhida.zhihu.com/search?content_id 233608460&content_type Article&match_order 1&q è°ƒåº¦ç®—æ³•&zhida_source entity)ï¼Œè°ƒåº¦ç­–ç•¥ä»¥åŠç»´æŠ¤cpuå’Œgpuæ˜ å°„çš„å…³ç³»è¡¨ > è°ƒåº¦å™¨çš„ä¸»è¦ä½œç”¨å°±æ˜¯ï¼Œåœ¨æ¯1ä¸ªæ¨ç†é˜¶æ®µï¼Œå†³å®šè¦æŠŠå“ªäº›æ•°æ®é€ç»™æ¨¡å‹åšæ¨ç†ï¼ŒåŒæ—¶è´Ÿè´£ç»™è¿™äº›æ¨¡å‹åˆ†é…KV Cacheç‰©ç†å—ã€‚ä½†è¦æ³¨æ„ï¼Œå®ƒåªæ˜¯åˆ†é…äº†ç‰©ç†å—çš„idï¼Œè€Œä¸æ˜¯ç‰©ç†å—æœ¬èº«ã€‚ç‰©ç†å—çš„å®é™…åˆ†é…æ˜¯æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ ¹æ®ç‰©ç†å—idæ¥æ“ä½œçš„ï¼Œä¹Ÿå°±æ˜¯CacheEngineåšçš„äº‹æƒ…ã€‚ > è°ƒåº¦å™¨ä¸‹ç»´æŠ¤ç€BlockSpaceManagerã€‚å®ƒè´Ÿè´£ç®¡ç†BlockAllocatorï¼ˆå®é™…å‚ä¸åˆ†é…ç‰©ç†å—çš„ç±»ï¼‰ã€‚BlockAllocatoråˆåˆ†æˆgpuå’Œcpuä¸¤ç§ç±»å‹ï¼Œåˆ†åˆ«ç®¡ç†è¿™ä¸¤ç±»è®¾å¤‡ä¸Šçš„ç‰©ç†å—ã€‚ä½ å¯èƒ½ä¼šé—®ï¼Œcpuä¸Šçš„ç‰©ç†å—æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿä½ è¿˜è®°å¾—è°ƒåº¦å™¨æœ‰ä¸€ä¸ªswapç­–ç•¥å—ï¼Ÿå½“gpuä¸Šæ˜¾å­˜ä¸è¶³æ—¶ï¼Œå®ƒä¼šæŠŠåæ¥çš„è¯·æ±‚æŠ¢å ï¼Œå¹¶å°†å…¶ç›¸å…³çš„KV cacheç‰©ç†å—å…¨éƒ¨éƒ½å…ˆswapï¼ˆç½®æ¢ã€å¸è½½ï¼‰åœ¨cpuä¸Šï¼Œç­‰åç»­gpuæ˜¾å­˜å……è¶³æ—¶ï¼Œå†æŠŠå®ƒä»¬åŠ è½½å›gpuä¸Šç»§ç»­åšç›¸å…³è¯·æ±‚çš„æ¨ç†ã€‚æ‰€ä»¥åœ¨cpuä¸Šæˆ‘ä»¬ä¹Ÿéœ€è¦ä¸€ä¸ªç®¡æ§ç‰©ç†å—çš„BlockAllocatorã€‚å®é™…ä»£ç å®ç°æ—¶ï¼ŒBlockç›¸å…³çš„éƒ¨åˆ†å¯ä¸æ­¢è¿™ä¸¤ä¸ªclassï¼Œè¿˜æœ‰ä¸€äº›æ›´å¤æ‚çš„é€»è¾‘ç»†èŠ‚ã€‚ + vllm/engine: llmçš„engineï¼ŒåŒ…å«æ¨¡å‹é…ç½®ï¼Œå¯åŠ¨æ¨¡å‹ï¼Œè¯·æ±‚çš„å‰åå¤„ç†ç­‰, ç›´æ¥å¤„ç†ç”¨æˆ·çš„è¯·æ±‚ > **ä½¿ç”¨çš„ä¸»è¦API** > > add_request()ï¼šè¯¥æ–¹æ³•å°†æ¯ä¸€ä¸ªè¯·æ±‚åŒ…è£…æˆvLLMèƒ½å¤„ç†çš„æ•°æ®ç±»å‹(SequenceGroupï¼Œåé¢æˆ‘ä»¬ä¼šè¯¦ç»†è§£é‡Š)ï¼Œå¹¶å°†å…¶åŠ å…¥è°ƒåº¦å™¨ï¼ˆSchedulerï¼‰çš„waitingé˜Ÿåˆ—ä¸­ã€‚åœ¨LLMEngineä¸­ï¼Œè¿™ä¸ªå‡½æ•°æ˜¯æŒ‰ç…§â€œåŒæ­¥â€çš„æ–¹å¼è®¾è®¡çš„ï¼Œä¹Ÿå°±æ˜¯å®ƒè¢«è®¾è®¡ä¸ºâ€œéå†batchä¸­çš„æ¯æ¡æ•°æ®ï¼Œç„¶ååšç›¸åº”å¤„ç†â€ã€‚æ‰€ä»¥è¿™ä¸ªå‡½æ•°æœ¬èº«åªé€‚åˆæ‰¹å¤„ç†åœºæ™¯ã€‚åœ¨å¼‚æ­¥çš„online servingä¸­å°†ä¼šæŠŠå®ƒé‡å†™æˆå¼‚æ­¥çš„å½¢å¼ã€‚ > abort_requestï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„è¯·æ±‚éƒ½èƒ½æœ‰è¿”å›ç»“æœã€‚æ¯”å¦‚å®¢æˆ·ç«¯æ–­å¼€è¿æ¥æ—¶ï¼Œè¿™ä¸ªè¯·æ±‚çš„æ¨ç†å°±å¯ä»¥ç»ˆæ­¢äº†ï¼ˆabortï¼‰ï¼Œè¿™ä¸ªå‡½æ•°å°±è¢«ç”¨æ¥åšè¿™ä¸ªæ“ä½œã€‚ > step()ï¼šè´Ÿè´£æ‰§è¡Œ1æ¬¡æ¨ç†è¿‡ç¨‹ï¼ˆ1ä¸ªprefillç®—1ä¸ªæ¬¡æ¨ç†ï¼Œæ¯ä¸ªdecodeå„ç®—1æ¬¡æ¨ç†ï¼‰ã€‚åœ¨è¿™ä¸ªå‡½æ•°ä¸­ï¼ŒvLLMçš„è°ƒåº¦å™¨ä¼šå†³å®šè¦é€é‚£äº›æ•°æ®å»æ‰§è¡Œæœ¬æ¬¡æ¨ç†ï¼Œå¹¶è´Ÿè´£ç»™è¿™äº›æ•°æ®åˆ†é…å¥½ç‰©ç†å—ï¼ˆè¿™äº›ä¿¡æ¯éƒ½è¢«ä½œä¸ºmetadataæ”¾åœ¨è¦é€ç»™æ¨¡å‹åšæ¨ç†çš„æ•°æ®ä¸­ï¼‰ã€‚æ¨¡å‹ä¼šæ ¹æ®è¿™äº›ä¿¡æ¯ï¼Œé‡‡ç”¨PagedAttentionæ–¹æ³•ï¼Œå®é™…å®Œæˆæ¨ç†ã€‚ **å¯åŠ¨æ¨¡å‹**ï¼šæŠŠä½ çš„base modelåŠ è½½åˆ°workerä¸Šã€‚å¦‚æœä½ æ˜¯onlineåŠ è½½çš„ï¼ŒvLLMé»˜è®¤ä½¿ç”¨HuggingFaceï¼Œä½ ä¹Ÿå¯ä»¥åœ¨ç¯å¢ƒå˜é‡ä¸­æŠŠç›¸å…³é…ç½®æ”¹æˆModelScopeã€‚ + vllm/entrypoints: çº¯æ¨¡å‹ç”Ÿæˆéƒ¨åˆ†ï¼ŒåªåŒ…å«æ¨¡å‹çš„promptåˆ°tokençš„è¿™éƒ¨åˆ† + vllm/model_executor: æ¨¡å‹opåˆ°layeråˆ°modelç»„æˆéƒ¨åˆ†ä»¥åŠåŒ…å«äº†å„æ¨¡å‹çš„é…ç½® vllm/transformers_utils: tokenizerçš„ä¸€äº›é…ç½® + vllm/worker: è´Ÿè´£åˆ†å¸ƒå¼è°ƒåº¦ä»¥åŠcacheçš„åˆ†é… bloclk: é€»è¾‘å—å’Œç‰©ç†å—çš„å®šä¹‰ä»¥åŠåŸºæœ¬æ“ä½œ ```bash vllm/ â”œâ”€â”€ attention/ # æ³¨æ„åŠ› â”‚ â”œâ”€â”€ backends/ # æ³¨æ„åŠ›å„ç§åç«¯å®ç°ï¼Œæ¯”å¦‚flash attention â”‚ â”œâ”€â”€ ops/ â”‚ â”œâ”€â”€ layer.py â”‚ â”œâ”€â”€ selector.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ core/ # æ ¸å¿ƒï¼Œvllmæœ€å…³é”®çš„éƒ¨åˆ† â”‚ â”œâ”€â”€ block/ # å—ï¼Œä¸ºæŒ‡å®šçš„åºåˆ—ç®¡ç†ç‰©ç†å— â”‚ â”œâ”€â”€ block_manager_v1.py # å—ç®¡ç†å™¨v1ï¼Œç®¡ç†é€»è¾‘å—å’Œç‰©ç†å—ä¹‹é—´çš„æ˜ å°„å…³ç³»ç­‰ â”‚ â”œâ”€â”€ block_manager_v2.py # å—ç®¡ç†å™¨v2 â”‚ â”œâ”€â”€ embedding_model_block_manager.py # é’ˆå¯¹embeddingæ¨¡å‹çš„å—ç®¡ç†å™¨ â”‚ â”œâ”€â”€ evictor_v1.py # é©±é€å™¨v1ï¼Œé©±é€é•¿æ—¶é—´æœªä½¿ç”¨çš„ç‰©ç†å—ç¼“å­˜ï¼Œè…¾å‡ºç©ºé—´ â”‚ â”œâ”€â”€ evictor_v2.py # é©±é€å™¨v2 â”‚ â”œâ”€â”€ interfaces.py â”‚ â”œâ”€â”€ policy.py # è°ƒåº¦ç­–ç•¥ï¼Œæ¯”å¦‚fcfsï¼ˆfirst come first serveï¼‰ â”‚ â”œâ”€â”€ scheduler.py # è°ƒåº¦å™¨ï¼Œå½“å¤šä¸ªè¯·æ±‚åˆ°æ¥æ—¶ï¼Œéœ€è¦è°ƒåº¦ä»¥é«˜æ•ˆçš„æ–¹å¼å®Œæˆæ¨ç†ï¼Œç»™åˆ°ç”¨æˆ·å“åº” â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ distributed/ # åˆ†å¸ƒå¼è®¾å¤‡ç›¸å…³å†…å®¹ï¼ˆæš‚ä¸æ¶‰åŠï¼‰ â”‚ â”œâ”€â”€ device_communicators/ â”‚ â”œâ”€â”€ communication_op.py â”‚ â”œâ”€â”€ parallel_state.py â”‚ â”œâ”€â”€ utils.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ engine/ # æ¨ç†å¼•æ“ â”‚ â”œâ”€â”€ output_processor/ # è¾“å‡ºå¤„ç†å™¨ï¼Œåå¤„ç† â”‚ â”œâ”€â”€ arg_utils.py # ç®¡ç†è¾“å…¥å‚æ•° â”‚ â”œâ”€â”€ async_llm_engine.py # å¼‚æ­¥llm_engineï¼Œç”¨äºéƒ¨ç½²ï¼Œä¸æ”¯æŒbatchæ¨ç† â”‚ â”œâ”€â”€ llm_engine.py # llm_engineï¼Œçº¿ä¸‹æ¨ç†ï¼Œå¯ä»¥batch â”‚ â”œâ”€â”€ metrics.py # æŒ‡æ ‡ï¼Œè®°å½•kv_cacheçš„ä½¿ç”¨ï¼Œå»¶è¿Ÿç­‰ â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ entrypoints/ # éƒ¨ç½²serverç›¸å…³ï¼ˆæš‚ä¸æ¶‰åŠï¼‰ â”‚ â”œâ”€â”€ openai/ â”‚ â”œâ”€â”€ api_server.py â”‚ â”œâ”€â”€ llm.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ executor/ # æ‰§è¡Œå™¨ â”‚ â”œâ”€â”€ cpu_executor.py â”‚ â”œâ”€â”€ distributed_gpu_executor.py â”‚ â”œâ”€â”€ executor_base.py # æ‰§è¡Œå™¨åŸºç±» â”‚ â”œâ”€â”€ gpu_executor.py # gpuæ‰§è¡Œå™¨ï¼Œæ¯”å¦‚æˆ‘ä»¬ä½¿ç”¨çš„Nvidiaå•å¡gpu â”‚ â”œâ”€â”€ multiproc_gpu_executor.py â”‚ â”œâ”€â”€ multiproc_worker_utils.py â”‚ â”œâ”€â”€ neuron_executor.py â”‚ â”œâ”€â”€ ray_gpu_executor.py â”‚ â”œâ”€â”€ ray_utils.py â”‚ â”œâ”€â”€ tpu_executor.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ logging/ # æ—¥å¿— â”‚ â”œâ”€â”€ formatter.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ lora/ # loraç›¸å…³ï¼ˆæš‚ä¸æ¶‰åŠï¼‰ â”‚ â”œâ”€â”€ fully_sharded_layers.py â”‚ â”œâ”€â”€ layers.py â”‚ â”œâ”€â”€ lora.py â”‚ â”œâ”€â”€ models.py â”‚ â”œâ”€â”€ punica.py â”‚ â”œâ”€â”€ request.py â”‚ â”œâ”€â”€ utils.py â”‚ â”œâ”€â”€ worker_manager.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ model_executor/ # æ¨¡å‹æ‰§è¡Œå™¨ï¼Œä¸»è¦æ˜¯ç®¡ç†æ¨¡å‹ç›¸å…³éƒ¨åˆ†çš„ â”‚ â”œâ”€â”€ guided_decoding.py â”‚ â”œâ”€â”€ layers.py â”‚ â”œâ”€â”€ models.py â”‚ â”œâ”€â”€ custom_op.py â”‚ â”œâ”€â”€ pooling_metadata.py â”‚ â”œâ”€â”€ sampling_metadata.py # é‡‡æ ·å…ƒæ•°æ® â”‚ â”œâ”€â”€ utils.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ multimodal/ # å¤šæ¨¡æ€éƒ¨åˆ†ï¼ˆæš‚ä¸æ¶‰åŠï¼‰ â”‚ â”œâ”€â”€ base.py â”‚ â”œâ”€â”€ image.py â”‚ â”œâ”€â”€ registry.py â”‚ â”œâ”€â”€ utils.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ sepc_decode/ # æŠ•æœºé‡‡æ ·ï¼ˆæš‚ä¸æ¶‰åŠï¼‰ â”‚ â”œâ”€â”€ batch_expansion.py â”‚ â”œâ”€â”€ interfaces.py â”‚ â”œâ”€â”€ metrics.py â”‚ â”œâ”€â”€ multi_step_worker.py â”‚ â”œâ”€â”€ ngram_worker.py â”‚ â”œâ”€â”€ proposer_worker_base.py â”‚ â”œâ”€â”€ spec_decode_worker.py â”‚ â”œâ”€â”€ top1_proposer.py â”‚ â”œâ”€â”€ utils.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ transformers_utils/ # transformersç›¸å…³çš„å·¥å…· â”‚ â”œâ”€â”€ configs/ â”‚ â”œâ”€â”€ tokenizers/ â”‚ â”œâ”€â”€ tokenizer_group/ â”‚ â”œâ”€â”€ config.py â”‚ â”œâ”€â”€ detokenizer.py â”‚ â”œâ”€â”€ image_processor.py â”‚ â”œâ”€â”€ tokenizer.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ usage/ â”‚ â”œâ”€â”€ usage_lib.py â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ worker/ # workerï¼Œæ˜¯executorçš„é‡è¦ç»„æˆéƒ¨åˆ† â”‚ â”œâ”€â”€ cache_engine.py â”‚ â”œâ”€â”€ cpu_model_runner.py â”‚ â”œâ”€â”€ cpu_worker.py â”‚ â”œâ”€â”€ embedding_model_runner.py â”‚ â”œâ”€â”€ model_runner.py # è´Ÿè´£åŠ è½½å’Œæ‰§è¡Œæ¨¡å‹ï¼Œå‡†å¤‡è¾“å…¥å¼ é‡ç­‰ â”‚ â”œâ”€â”€ neuron_model_runner.py â”‚ â”œâ”€â”€ neuron_worker.py â”‚ â”œâ”€â”€ tpu_model_runner.py â”‚ â”œâ”€â”€ tpu_worker.py â”‚ â”œâ”€â”€ worker.py # workerï¼Œä½¿ç”¨çš„æ˜¯gpu â”‚ â”œâ”€â”€ worker_base.py # workeråŸºç±» â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ block.py # å—ï¼ˆé€»è¾‘å—ï¼Œç‰©ç†å—ï¼‰å®šä¹‰ â”œâ”€â”€ config.py # é…ç½®ï¼Œè¾“å…¥å‚æ•°æŒ‰ç…§åŠŸèƒ½åŒºåˆ†æ„æˆå¤šä¸ªé…ç½® â”œâ”€â”€ envs.py # ç¯å¢ƒå˜é‡ç›¸å…³ â”œâ”€â”€ inputs.py # è¾“å…¥ç±»å®šä¹‰ â”œâ”€â”€ logger.py # æ—¥å¿— â”œâ”€â”€ outputs.py # è¾“å‡ºç±»å®šä¹‰ â”œâ”€â”€ pooling_params.py â”œâ”€â”€ py.typed â”œâ”€â”€ sampling_params.py # é‡‡æ ·å‚æ•°ç±»å®šä¹‰ â”œâ”€â”€ sequence.py # åºåˆ—Sequenceå’Œåºåˆ—ç»„SequenceGroupç­‰çš„å®šä¹‰ â”œâ”€â”€ utils.py â”œâ”€â”€ version.py # vllmç‰ˆæœ¬ â”œâ”€â”€ _C.abi3.so â”œâ”€â”€ _custom_ops.py â”œâ”€â”€ _moe_C.abi3.so â”œâ”€â”€ _punica_C.abi.so â””â”€â”€ __init__.py ``` ## vllmå’Œpytorchå¯¹æ¥"},"/note/æœºå™¨å­¦ä¹ /2024-9-22-æ·±åº¦å­¦ä¹ ç¯å¢ƒ.html":{"title":"æ·±åº¦å­¦ä¹ ç¯å¢ƒ","content":" layout: post title: \"æ·±åº¦å­¦ä¹ ç¯å¢ƒ\" date: 2024 8 5 15:39:08 +0800 tags: AI æœºå™¨å­¦ä¹  # æ·±åº¦å­¦ä¹  ## å®‰è£…åŸºç¡€ é¦–å…ˆå®‰è£…ä¸€ä¸ªANACONDA ä¹‹åå®‰è£…Pytorch > Pytorchæ˜¯torchçš„pythonç‰ˆæœ¬ï¼Œæ˜¯ç”±Facebookå¼€æºçš„ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œä¸“é—¨é’ˆå¯¹ GPU åŠ é€Ÿçš„æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰ç¼–ç¨‹ã€‚Torch æ˜¯ä¸€ä¸ªç»å…¸çš„å¯¹å¤šç»´çŸ©é˜µæ•°æ®è¿›è¡Œæ“ä½œçš„å¼ é‡ï¼ˆtensor ï¼‰åº“ï¼Œåœ¨æœºå™¨å­¦ä¹ å’Œå…¶ä»–æ•°å­¦å¯†é›†å‹åº”ç”¨æœ‰å¹¿æ³›åº”ç”¨ã€‚ä¸Tensorflowçš„é™æ€è®¡ç®—å›¾ä¸åŒï¼Œpytorchçš„è®¡ç®—å›¾æ˜¯åŠ¨æ€çš„ï¼Œå¯ä»¥æ ¹æ®è®¡ç®—éœ€è¦å®æ—¶æ”¹å˜è®¡ç®—å›¾ã€‚ä½†ç”±äºTorchè¯­è¨€é‡‡ç”¨ Luaï¼Œå¯¼è‡´åœ¨å›½å†…ä¸€ç›´å¾ˆå°ä¼—ï¼Œå¹¶é€æ¸è¢«æ”¯æŒ Python çš„ Tensorflow æŠ¢èµ°ç”¨æˆ·ã€‚ä½œä¸ºç»å…¸æœºå™¨å­¦ä¹ åº“ Torch çš„ç«¯å£ï¼ŒPyTorch ä¸º Python è¯­è¨€ä½¿ç”¨è€…æä¾›äº†èˆ’é€‚çš„å†™ä»£ç é€‰æ‹©ã€‚ ![image 20240922113815823](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409221138875.png) ä½¿ç”¨å‡†è¯¶ä¸ªå‘½ä»¤è¿›è¡Œå®‰è£…, å®‰è£…ä»¥åå¯ä»¥æ‰“å¼€pythonè¿›è¡Œæµ‹è¯• åœ¨å®é™…æµ‹è¯•çš„æ—¶å€™éœ€è¦ä½¿ç”¨æ–°ç‰ˆæœ¬çš„pyhton ![image 20240922130458418](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409221304462.png) ```python import torch print(torch.cuda.is_available()) ``` ### ç¯å¢ƒ ```bash conda create n pytorch python 3.6 ``` > å»ºç«‹ä¸€ä¸ªåå­—ä¸ºpytorchçš„ç¯å¢ƒ ### æ‰“ä¸å¼€ ![image 20240922132112138](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409221321170.png) ## Jupyter è¿™ä¸€ä¸ªéœ€è¦åœ¨ä½¿ç”¨çš„ç¯å¢ƒé‡Œé¢è¿›è¡Œå®‰è£… ```python conda install nb_conda_kernels ``` å®‰è£…ä»¥åä½¿ç”¨è¿™ä¸€ä¸ªå‘½ä»¤è¿›è¡Œæ‰“å¼€ ```c jupyter notebook ``` ### è‡ªå®šä¹‰ç›®å½• å¯ä»¥ä½¿ç”¨`jupyter notebook generate config`è·å–é…ç½®æ–‡ä»¶çš„è·¯å¾„ ![image 20240923184604053](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409231846143.png) ![image 20240923184713245](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409231847284.png) ä¹‹åå§è¿™ä¸€ä¸ªåˆ é™¤ ### vscodeè®¾ç½® é»˜è®¤çš„ç»ˆç«¯powershellæ˜¯ä¸å¯ä»¥å¯åŠ¨condaçš„, éœ€è¦æ”¹ä¸ºcmd ![image 20241006100847997](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061008150.png)"},"/note/æœºå™¨å­¦ä¹ /2024-9-21-LLM.html":{"title":"LLM","content":" layout: post title: \"LLM\" date: 2024 8 5 15:39:08 +0800 tags: AI æœºå™¨å­¦ä¹  # LLM [ä»€ä¹ˆæ˜¯LLMå¤§è¯­è¨€æ¨¡å‹ï¼ŸLarge Language Modelï¼Œä»é‡å˜åˆ°è´¨å˜ çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/622518771) Large Language ModelLLMçš„ç‰¹ç‚¹æ˜¯**è§„æ¨¡åºå¤§ï¼ŒåŒ…å«æ•°åäº¿çš„å‚æ•°**ï¼Œå¸®åŠ©å®ƒä»¬å­¦ä¹ è¯­è¨€æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ã€‚è¿™äº›æ¨¡å‹é€šå¸¸åŸºäºæ·±åº¦å­¦ä¹ æ¶æ„ï¼Œå¦‚è½¬åŒ–å™¨ å½“æ•°æ®è¾¾åˆ°ä¸€å®šçš„æ•°é‡çš„æ—¶å€™, æ¨¡å‹äº§ç”Ÿæ˜æ˜¾çš„æ€§èƒ½æå‡, ä»¥åŠå‡ºç°å°æ¨¡å‹é‡Œé¢ä¸å­˜åœ¨çš„æ€§èƒ½ï¼Œæ¯”å¦‚ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆin context learningï¼‰ 1. ä¸Šä¸‹æ–‡å­¦ä¹ ã€‚GPT 3 æ­£å¼å¼•å…¥äº†ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ï¼šå‡è®¾è¯­è¨€æ¨¡å‹å·²ç»æä¾›äº†è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œå¤šä¸ªä»»åŠ¡æè¿°ï¼Œå®ƒå¯ä»¥é€šè¿‡å®Œæˆè¾“å…¥æ–‡æœ¬çš„è¯åºåˆ—æ¥ç”Ÿæˆæµ‹è¯•å®ä¾‹çš„é¢„æœŸè¾“å‡ºï¼Œè€Œæ— éœ€é¢å¤–çš„è®­ç»ƒæˆ–æ¢¯åº¦æ›´æ–°ã€‚ 2. æŒ‡ä»¤éµå¾ªã€‚é€šè¿‡å¯¹è‡ªç„¶è¯­è¨€æè¿°ï¼ˆå³æŒ‡ä»¤ï¼‰æ ¼å¼åŒ–çš„[å¤šä»»åŠ¡](https://zhida.zhihu.com/search?q å¤šä»»åŠ¡&zhida_source entity&is_preview 1)æ•°æ®é›†çš„æ··åˆè¿›è¡Œå¾®è°ƒï¼ŒLLM åœ¨å¾®å°çš„ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œè¿™äº›ä»»åŠ¡ä¹Ÿä»¥æŒ‡ä»¤çš„å½¢å¼æ‰€æè¿°ã€‚è¿™ç§èƒ½åŠ›ä¸‹ï¼ŒæŒ‡ä»¤è°ƒä¼˜ä½¿ LLM èƒ½å¤Ÿåœ¨ä¸ä½¿ç”¨æ˜¾å¼æ ·æœ¬çš„æƒ…å†µä¸‹é€šè¿‡ç†è§£ä»»åŠ¡æŒ‡ä»¤æ¥æ‰§è¡Œæ–°ä»»åŠ¡ï¼Œè¿™å¯ä»¥å¤§å¤§æé«˜æ³›åŒ–èƒ½åŠ›ã€‚ 3. å¾ªåºæ¸è¿›çš„æ¨ç†ã€‚å¯¹äºå°è¯­è¨€æ¨¡å‹ï¼Œé€šå¸¸å¾ˆéš¾è§£å†³æ¶‰åŠå¤šä¸ªæ¨ç†æ­¥éª¤çš„å¤æ‚ä»»åŠ¡ï¼Œä¾‹å¦‚æ•°å­¦å­¦ç§‘å•è¯é—®é¢˜ã€‚åŒæ—¶ï¼Œé€šè¿‡æ€ç»´é“¾æ¨ç†ç­–ç•¥ï¼ŒLLM å¯ä»¥é€šè¿‡åˆ©ç”¨æ¶‰åŠä¸­é—´æ¨ç†æ­¥éª¤çš„ prompt æœºåˆ¶æ¥è§£å†³æ­¤ç±»ä»»åŠ¡å¾—å‡ºæœ€ç»ˆç­”æ¡ˆã€‚æ®æ¨æµ‹ï¼Œè¿™ç§èƒ½åŠ›å¯èƒ½æ˜¯é€šè¿‡ä»£ç è®­ç»ƒè·å¾—çš„ã€‚ ### è®­ç»ƒæ–¹å¼ è®­ç»ƒè¯­è¨€æ¨¡å‹éœ€è¦å‘å…¶æä¾›å¤§é‡çš„æ–‡æœ¬æ•°æ®ï¼Œæ¨¡å‹åˆ©ç”¨è¿™äº›æ•°æ®æ¥å­¦ä¹ äººç±»è¯­è¨€çš„ç»“æ„ã€è¯­æ³•å’Œè¯­ä¹‰ã€‚è¿™ä¸ªè¿‡ç¨‹é€šå¸¸æ˜¯é€šè¿‡æ— ç›‘ç£å­¦ä¹ å®Œæˆçš„ï¼Œä½¿ç”¨ä¸€ç§å«åšè‡ªæˆ‘ç›‘ç£å­¦ä¹ çš„æŠ€æœ¯ã€‚åœ¨è‡ªæˆ‘ç›‘ç£å­¦ä¹ ä¸­ï¼Œæ¨¡å‹é€šè¿‡é¢„æµ‹åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªè¯æˆ–æ ‡è®°ï¼Œä¸ºè¾“å…¥çš„æ•°æ®ç”Ÿæˆè‡ªå·±çš„æ ‡ç­¾ï¼Œå¹¶ç»™å‡ºä¹‹å‰çš„è¯ã€‚ [2303.18223 (arxiv.org)](https://arxiv.org/pdf/2303.18223) ### å‘å±•å†ç¨‹ ![image 20240921101930636](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409211019711.png) ç»å†äº†ä»è¯­è¨€å¤„ç†åˆ°ä»»åŠ¡å¤„ç†, å¯ä»¥ç»†åˆ†ä¸ºç»Ÿè®¡è¯­è¨€æ¨¡å‹Statistical Language Model >ç¥ç»è¯­è¨€æ¨¡å‹Neural Language Model >é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹Pre trained Language Model, PLM > å¤§è¯­è¨€æ¨¡å‹ ç°åœ¨é¢ä¸´çš„é—®é¢˜æœ‰ä¸æ¸…æ¥šä¸ºä»€ä¹ˆå¤§è¯­è¨€æ¨¡å‹ä¼šå‡ºç°ä¸€äº›ä¸åŒçš„ç‰¹æ€§, ç ”ç©¶å›¢ä½“æ¯”è¾ƒéš¾å»è®­ç»ƒä¸€äº›å¤§æ¨¡å‹, ç”±äºè®­ç»ƒæ•°æ®ä¸èƒ½å…¬å¼€, è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ä¸èƒ½é¡ºåº”äººç±»çš„é“å¾·è§‚ä»¥åŠæ•°æ®å¯èƒ½é€ å‡ ## èµ„æ–™ [RUCAIBox/LLMSurvey: The official GitHub page for the survey paper \"A Survey of Large Language Models\".](https://github.com/RUCAIBox/LLMSurvey) [LLMBook.pdf (llmbook zh.github.io)](https://llmbook zh.github.io/LLMBook.pdf) ## æ„å»º 1. é¢„è®­ç»ƒ, ä½¿ç”¨ä¸ä¸‹æ¸¸ä»»åŠ¡æ— å…³çš„å¤§è§„æ¨¡æ•°æ®è¿›è¡Œæ¨¡å‹å‚æ•°çš„åˆ å§‹è®­ç»ƒï¼Œå¯ä»¥è®¤ä¸ºæ˜¯ä¸ºæ¨¡å‹å‚æ•°æ‰¾åˆ°ä¸€ä¸ªè¾ƒå¥½çš„â€œåˆå€¼ç‚¹â€ã€‚æœ¬è´¨ä¸Š æ˜¯åœ¨åšä¸€ä¸ªä¸–ç•ŒçŸ¥è¯†çš„å‹ç¼© > åœ¨è¿›è¡Œè¿™ä¸€ä¸ªæ­¥éª¤çš„æ—¶å€™, éœ€è¦å¯¹æ•°æ®è¿›è¡Œä¸¥æ ¼çš„æ¸…æ´—, å»é™¤æœ‰å®³çš„ä¿¡æ¯, æé«˜æ•°æ®çš„è´¨é‡ > > æœ€åå°†æ¸…æ´—åçš„æ•°æ®è¿›è¡Œè¯å…ƒåŒ–ï¼ˆTokenizationï¼‰ æµï¼Œå¹¶ä¸”åˆ‡åˆ†æˆæ‰¹æ¬¡ï¼ˆBatchï¼‰ 2. æŒ‡ä»¤å¾®è°ƒä¸äººç±»å¯¹é½ ä½†æ˜¯ç”±äºé¢„è®­ç»ƒä»»åŠ¡å½¢å¼æ‰€é™ï¼Œè¿™äº›æ¨¡å‹æ›´æ“…é•¿äºæ–‡æœ¬è¡¥å…¨ï¼Œå¹¶ ä¸é€‚åˆç›´æ¥è§£å†³å…·ä½“çš„ä»»åŠ¡ã€‚ é€šè¿‡ä½¿ç”¨ä»»åŠ¡è¾“å…¥ä¸è¾“å‡ºçš„é…å¯¹æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œ å¯ä»¥ä½¿å¾—è¯­è¨€æ¨¡å‹è¾ƒå¥½åœ°æŒæ¡é€šè¿‡é—®ç­”å½¢å¼è¿›è¡Œä»»åŠ¡æ±‚è§£çš„èƒ½åŠ›ã€‚å®ƒä¸»è¦èµ·åˆ°äº†å¯¹äºæ¨¡å‹èƒ½åŠ›çš„æ¿€å‘ä½œç”¨ï¼Œè€Œä¸æ˜¯ çŸ¥è¯†æ³¨å…¥ä½œç”¨ã€‚ é¦–æ¬¡å»ºç«‹äº†ç¥ç»è¯­è¨€æ¨¡å‹æ€§èƒ½ä¸ä¸‰ ä¸ªä¸»è¦å› ç´ â€”â€”æ¨¡å‹è§„æ¨¡ï¼ˆğ‘ï¼‰ã€æ•°æ®è§„æ¨¡ï¼ˆğ·ï¼‰å’Œè®¡ç®—ç®—åŠ›ï¼ˆğ¶ï¼‰ä¹‹é—´çš„å¹‚å¾‹å…³ç³» ![image 20240921120422758](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409211204806.png) > GPTä½¿ç”¨çš„æœ‰ä»£ç æ•°æ®è®­ç»ƒ, äººç±»å¯¹é½ > > ï¼ˆ1ï¼‰ä½¿ç”¨äººç±»åé¦ˆã€ï¼ˆ2ï¼‰ååŠ©äººç±»è¯„ä¼°å’Œï¼ˆ3ï¼‰è¿›è¡Œå¯¹é½ç ”ç©¶ã€‚ > > å‘˜å¼•å…¥äº†â€œçº¢é˜Ÿæ”»å‡»â€ï¼ˆRed Teamingï¼‰æœºåˆ¶å‡å°‘ç”Ÿæˆæœ‰å®³æˆ–æœ‰æ¯’çš„å†…å®¹ã€‚ ## èµ„æº [RUCAIBox/LLMSurvey: The official GitHub page for the survey paper \"A Survey of Large Language Models\".](https://github.com/RUCAIBox/LLMSurvey/) ### å¼€æºæ¨¡å‹ ç»è¿‡é¢„è®­ç»ƒçš„å…¬å¼€æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆModel Checkpointï¼‰ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªèº«ç ”ç©¶æˆ–å¼€å‘éœ€æ±‚ï¼Œçµæ´»é€‰æ‹© å¹¶ä¸‹è½½ä½¿ç”¨è¿™äº›æ£€æŸ¥ç‚¹ã€‚ > åœ¨æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œæ£€æŸ¥ç‚¹æ˜¯æŒ‡åœ¨è®­ç»ƒæ¨¡å‹æ—¶å®šæœŸä¿å­˜æ¨¡å‹çš„å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€åˆ°ç£ç›˜ä¸Šçš„æ–‡ä»¶ã€‚è¿™æ ·ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥éšæ—¶å°†æ¨¡å‹çš„çŠ¶æ€ä¿å­˜ä¸‹æ¥ï¼Œä»¥ä¾¿åœ¨éœ€è¦çš„æ—¶å€™æ¢å¤æ¨¡å‹çš„çŠ¶æ€ï¼Œç»§ç»­è®­ç»ƒæˆ–è¿›è¡Œæ¨ç†ã€‚ + LLaMA å’Œ LLaMA 2. LLaMA [34] æ˜¯ Meta AI åœ¨ 2023 å¹´ 2 æœˆå‘å¸ƒçš„ä¸€ç³»åˆ— å¤§è¯­è¨€æ¨¡å‹ï¼Œæœ‰ 7Bã€13Bã€30B å’Œ 65B å››ç§å‚æ•°è§„æ¨¡ç‰ˆæœ¬ï¼Œæ˜¯å½“æ—¶æ€§èƒ½éå¸¸ä¼˜å¼‚ çš„å¼€æºæ¨¡å‹ä¹‹ä¸€ ![image 20240921225323134](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409212253202.png) + ChatGLM. ChatGLM [59, 60] æ˜¯æ™ºè°± AI å’Œæ¸…åå¤§å­¦è”åˆå¼€å‘çš„ä¸­è‹±åŒè¯­å¯¹ è¯å¼æ¨¡å‹ï¼Œæœ€æ—©å‘å¸ƒäº 2023 å¹´ 5 æœˆï¼Œå¹¶ä¸€ç›´è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œç›®å‰å·²ç»æ›´æ–°åˆ°äº† ChatGLM 3ã€‚ + InternLM å’Œ InternLM 2. InternLM [64] æ˜¯ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤å¼€å‘çš„å¤šè¯­ è¨€å¼€æºå¤§æ¨¡å‹, å¹¶ä¸”æ”¯æŒæ•°åç±»æ’ä»¶ï¼Œæœ‰è¾ƒå¼ºçš„å·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚ + Falcon. Falcon [61] æ˜¯é˜¿å¸ƒæ‰æ¯”çš„æŠ€æœ¯åˆ›æ–°ç ”ç©¶é™¢ï¼ˆTIIï¼‰å‘å¸ƒçš„ä¸€ç³»åˆ—è¯­è¨€ æ¨¡å‹ + Baichuan å’Œ Baichuan 2. Baichuan [62] æ˜¯ç™¾å·æ™ºèƒ½å…¬å¸äº 2023 å¹´ 6 æœˆå‘å¸ƒçš„å¼€æºå¯å•†ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼Œå‚æ•°è§„æ¨¡ä¸º 7Bï¼Œæ”¯æŒä¸­è‹±åŒè¯­ + Qwen. Qwen [66] æ˜¯é˜¿é‡Œå·´å·´å…¬å¸å¼€æºçš„å¤šè¯­å¤§æ¨¡å‹ç³»åˆ—ï¼Œé¦–æ¬¡å…¬å¼€å‘å¸ƒ äº 2023 å¹´ 8 æœˆï¼Œä¸”ä»åœ¨ç»§ç»­æ›´æ–°ã€‚åœ¨è¯­è¨€ç†è§£ã€æ¨ç†ã€æ•°å­¦ç­‰æ–¹é¢å‡å±•ç°å‡ºäº†ä¼˜ç§€çš„æ¨¡å‹èƒ½åŠ› + Mistral. Mistral [67] æ˜¯ Mistral AI åœ¨ 2023 å¹´ 9 æœˆå…¬å¼€å‘å¸ƒçš„å…·æœ‰ 7B å‚æ•°çš„ å¤§è¯­è¨€æ¨¡å‹, å¹¶ä¸”åœ¨ä»£ç ç”Ÿæˆæ–¹é¢çš„ è¡¨ç°æ¥è¿‘äºä¸“é—¨ä¸ºä»£ç ä»»åŠ¡å¾®è°ƒçš„ Code LLaMA (7B)ã€‚åœ¨è§£ç æ•ˆç‡ä¸Šï¼ŒMistral é‡‡ ç”¨äº†åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›æŠ€æœ¯ ### å…¬å¼€API è¯­è¨€æ¨¡å‹ API. ç›®å‰æœ€å¸¸ç”¨çš„ GPT ç³»åˆ—æ¨¡å‹ API åŒ…æ‹¬ GPT 3.5 Turboã€GPT 4 å’Œ GPT 4 Turboã€‚å¼€å‘è€…å¯ä»¥ä½¿ç”¨è‡ªå·±çš„æ•°æ®æ¥å¾®è°ƒ GPT 3.5 Turboï¼Œ ä»¥ä¾¿æ›´å¥½åœ°é€‚ç”¨äºä¸ªæ€§åŒ–çš„åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚æé«˜æ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€å®šåˆ¶åŒ–è¾“ å‡ºæ ¼å¼ä»¥åŠå®šåˆ¶åŒ–è¯­æ°”ç­‰ ### æ•°æ®é›† #### ç½‘é¡µ ![image 20240921230515571](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409221007241.png) #### ä¹¦ç± ä½¿ç”¨å°è¯´, è¯—æ­Œæˆæ›²ç­‰ #### ç»´åŸºç™¾ç§‘ #### ä»£ç  #### å¾®è°ƒæ•°æ®é›† åœ¨é¢„è®­ç»ƒä¹‹åï¼ŒæŒ‡ä»¤å¾®è°ƒï¼ˆä¹Ÿç§°ä¸ºæœ‰ç›‘ç£å¾®è°ƒï¼‰æ˜¯å¢å¼ºæˆ–æ¿€æ´»å¤§è¯­è¨€æ¨¡å‹ç‰¹ å®šèƒ½åŠ›çš„é‡è¦æ–¹æ³•ä¹‹ä¸€ï¼ˆä¾‹å¦‚æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼‰ã€‚ å®ƒä»¬åˆ†ä¸ºä¸‰ç§ä¸»è¦ç±»å‹ï¼Œå³è‡ªç„¶è¯­ è¨€å¤„ç†ä»»åŠ¡æ•°æ®é›†ã€æ—¥å¸¸å¯¹è¯æ•°æ®é›†å’Œåˆæˆæ•°æ®é›†ã€‚ ![image 20240921232110679](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409212321730.png) ## é¢„è®­ç»ƒ é¢„è®­ç»ƒæ˜¯ç ”å‘å¤§è¯­è¨€æ¨¡å‹çš„ç¬¬ä¸€ä¸ªè®­ç»ƒé˜¶æ®µï¼Œä¹Ÿæ˜¯æœ€ä¸ºé‡è¦çš„ä¸€ä¸ªé˜¶æ®µã€‚æœ‰ æ•ˆçš„é¢„è®­ç»ƒèƒ½å¤Ÿä¸ºå¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›å¥ å®šåšå®çš„åŸºç¡€ é€šè¿‡åœ¨å¤§è§„æ¨¡è¯­æ–™ä¸Šè¿›è¡Œ é¢„è®­ç»ƒï¼Œå¤§è¯­è¨€æ¨¡å‹å¯ä»¥è·å¾—é€šç”¨çš„è¯­è¨€ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›ï¼ŒæŒæ¡è¾ƒä¸ºå¹¿æ³›çš„ä¸–ç•Œ çŸ¥è¯†ï¼Œå…·å¤‡è§£å†³ä¼—å¤šä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½æ½œåŠ›ã€‚ ![image 20240922091613766](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409220916808.png) åœ¨å®é™…çš„æ•°æ®è¿‡æ»¤çš„æ—¶å€™, éœ€è¦æ ¹æ®ä¸åŒçš„æ•°æ®ç§ç±»é€‰æ‹©ä¸åŒçš„è¿‡æ»¤è§„åˆ™, é¦–å…ˆéœ€è¦è¿‡æ»¤ä½è´¨é‡çš„æ•°æ®æ¯”å¦‚å¹¿å‘Š, ä¹‹åä½¿ç”¨ä¸åŒè¯­è¨€çš„é«˜è´¨é‡æ•°æ® > è‹±è¯­çš„é«˜è´¨é‡å¼€æºæ•°æ®æ¯”è¾ƒå¤š, æ‰€ä»¥åœ¨ä½¿ç”¨éè‹±è¯­çš„æ—¶å€™ä¹Ÿä¼šä½¿ç”¨å¤§é‡è‹±è¯­æ•°æ® è¿˜å¯ä»¥ä½¿ç”¨è¯­è¨€é‡Œé¢çš„æ ‡ç‚¹ç¬¦å·çš„æ•°é‡, å•è¯çš„æ¯”ä¾‹ä¹‹ç±»çš„æ•°å€¼è¿›è¡Œç­›é€‰, ä»¥åŠå…³é”®è¯ç­›é€‰, è¿‡æ»¤æ‰ä¸ªäººä¿¡æ¯ç­‰ ä¹Ÿå¯ä»¥è®­ç»ƒä¸€ä¸ªæ–‡æœ¬è´¨é‡åˆ†ç±»å™¨ > åœ¨å®é™…è®­ç»ƒçš„æ—¶å€™å¯ä»¥åŒæ—¶ä½¿ç”¨å¤šç§ä¸åŒçš„æ–¹æ³• åœ¨å¤„ç†æœ‰ç”¨æˆ·æ•°æ®çš„èµ„æ–™çš„æ—¶å€™å¯ä»¥æŠŠå‡ºç°æ¬¡æ•°æ¯”è¾ƒå°‘çš„èµ„æ–™é‡Œé¢çš„ä¿¡æ¯æ›¿æ¢, æ¯”è¾ƒå¤šçš„ä¸è¿›è¡Œä½¿ç”¨, ä»¥åŠåœ¨æ•°æ®è¾“å‡ºçš„æ—¶å€™å¯¹æ•°æ®å†æ¬¡è¿›è¡Œè¿‡æ»¤ ### æ•°æ®å»é‡ å¯¹é¢„è®­ç»ƒæ•°æ®è¿›è¡Œå»é‡å¤„ç†æ˜¯ä¸€ä¸ªé‡è¦æ­¥éª¤ã€‚ç”±äºå¤§è¯­è¨€æ¨¡å‹å…·æœ‰è¾ƒå¼ºçš„æ•° æ®æ‹Ÿåˆä¸è®°å¿†èƒ½åŠ›ï¼Œå¾ˆå®¹æ˜“ä¹ å¾—è®­ç»ƒæ•°æ®ä¸­çš„é‡å¤æ¨¡å¼ï¼Œå¯èƒ½å¯¼è‡´å¯¹äºè¿™äº›æ¨¡å¼ çš„è¿‡åº¦å­¦ä¹ ã€‚ + è®¡ç®—ç²’åº¦ å¯ä»¥åˆ é™¤åŒ…å«é‡å¤å•è¯å’ŒçŸ­è¯­çš„ä½è´¨é‡å¥å­ï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½ä¼šåœ¨ è¯­è¨€å»ºæ¨¡ä¸­å¼•å…¥é‡å¤çš„è¡¨è¾¾æ¨¡å¼ åœ¨æ–‡æ¡£çº§åˆ«ä¸Šï¼Œç°æœ‰æ–¹æ³•ä¸»è¦ä¾é å•è¯æˆ– ğ‘› å…ƒè¯ç»„çš„é‡å è¿™ç±»è¡¨å±‚ç‰¹å¾ï¼Œæ¥è¡¡é‡æ–‡æ¡£çš„é‡å æ¯”ç‡ï¼Œè¿›è€Œæ£€æµ‹å’Œåˆ é™¤åŒ…å«ç›¸ä¼¼ å†…å®¹çš„é‡å¤æ–‡æ¡£ + ç”¨äºå»é‡çš„åŒ¹é…æ–¹æ³• è®¡ç®—å‡ºå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦, ä¸€èˆ¬æ¥è¯´è¿™ä¸€ä¸ªç®—æ³•çš„æ¶ˆè€—æ¯”è¾ƒå¤§(å¯ä»¥ä½¿ç”¨MinHashç®—æ³•) > MinHash æ˜¯ä¸€ç§ä¼°è®¡ä¸¤ä¸ªé›†åˆä¹‹é—´ç›¸ä¼¼åº¦çš„æŠ€æœ¯ï¼Œæœ€åˆè¢«å¼•å…¥åˆ°ä¿¡æ¯æ£€ç´¢é¢†åŸŸï¼Œæ—¨ åœ¨è¿…é€Ÿåˆ¤æ–­æ–‡æ¡£é—´çš„ç›¸ä¼¼æ€§ã€‚å…¶æ ¸å¿ƒæ€æƒ³åœ¨äºï¼Œé€šè¿‡å“ˆå¸Œå¤„ç†é›†åˆå…ƒç´ ï¼Œå¹¶é€‰æ‹©æœ€ å°çš„å“ˆå¸Œå€¼ä½œä¸ºé›†åˆçš„è¡¨ç¤ºã€‚éšåï¼Œé€šè¿‡æ¯”è¾ƒä¸¤ä¸ªé›†åˆçš„æœ€å°å“ˆå¸Œå€¼ï¼Œä¾¿èƒ½å¤§è‡´ä¼° ç®—å‡ºå®ƒä»¬çš„ç›¸ä¼¼åº¦ã€‚ ### æ•°æ®å½±å“ + æ•°é‡ è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ä¼šéšç€è®­ç»ƒæ•°æ®æ•°é‡çš„å¢åŠ è€Œæ å‡ï¼Œç¬¦åˆæ‰©å±•æ³•åˆ™ã€‚ + æ•°æ®çš„è´¨é‡ ä½¿ç”¨ä½è´¨é‡çš„æ•°æ®ä¼šå¯¼è‡´æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸ç¨³å®š, å®¹æ˜“é€ æˆæ¨¡å‹è®­ç»ƒä¸æ”¶æ•›ç­‰é—®é¢˜ å¤§è¯­è¨€æ¨¡å‹æ‰€æŒæ¡çš„çŸ¥è¯†ä¿¡æ¯ä¹Ÿæ¥æºäºé¢„ è®­ç»ƒæ•°æ®ï¼Œè¿™æ„å‘³ç€å¦‚æœæ¨¡å‹åœ¨åŒ…å«äº‹å®æ€§é”™è¯¯çš„ã€è¿‡æ—¶çš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œé‚£ ä¹ˆå®ƒåœ¨å¤„ç†ç›¸å…³ä¸»é¢˜æ—¶å¯èƒ½ä¼šäº§ç”Ÿä¸å‡†ç¡®æˆ–è™šå‡çš„ä¿¡æ¯ åœ¨ç°æœ‰çš„æ–‡çŒ®ä¸­ï¼Œæ™®éè®¤ä¸ºé‡å¤æ•°æ®å¯¹äºæ¨¡å‹è®­ç»ƒåŠæœ€ç»ˆæ€§èƒ½ä¼š å¸¦æ¥ä¸è‰¯å½±å“ã€‚ æ•°æ®æ˜¯å¤§è¯­è¨€æ¨¡å‹æŒæ¡çŸ¥è¯†ä¸å»ºç«‹èƒ½åŠ›çš„åŸºç¡€ï¼Œè€Œ è¯­è¨€æ¨¡å‹æ˜¯å¯¹äºè®­ç»ƒæ•°æ®è¯­ä¹‰çš„å‹ç¼©ã€‚ä¸€æ—¦æ•°æ®ä¸­åŒ…å«æœ‰åã€æœ‰æ¯’ã€éšç§çš„å†…å®¹ï¼Œ å°†ä¼šå¯¹äºæ¨¡å‹é€ æˆä¸¥é‡çš„ä¸è‰¯å½±å“ã€‚ + æ•°æ®é›†æ±¡æŸ“ ä¸ºäº†æœ‰æ•ˆè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œé€šå¸¸éœ€è¦æ„å»ºç›¸åº”çš„è¯„æµ‹åŸºå‡†ï¼Œæ¥è¡¡é‡å¤§è¯­è¨€æ¨¡å‹ åœ¨ä¸åŒæ–¹é¢çš„èƒ½åŠ›, åœ¨è¿›è¡Œæ¨¡å‹è¯„æµ‹æ—¶ï¼Œå¯èƒ½ä¼šå‘ç°æŸäº›è¯„ä¼°åŸºå‡†æ‰€åŒ…å«çš„æ•°æ®ï¼Œå® é™…ä¸Šå·²å‡ºç°åœ¨é¢„è®­ç»ƒæ•°æ®æˆ–è€…å¾®è°ƒæ•°æ®ä¸­ æ•°æ®é›†æ±¡æŸ“é—®é¢˜å¯èƒ½å¯¼è‡´æ¨¡å‹åœ¨ä¸æµ‹è¯• æ•°æ®é›†ç›¸å…³ç”šè‡³é«˜åº¦é‡åˆçš„è¯­æ–™ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»è€ŒåŸæœ¬ç”¨äºè¡¡é‡æ¨¡å‹åœ¨å°‘æ ·æœ¬æˆ– é›¶æ ·æœ¬åœºæ™¯ä¸‹çš„æ€§èƒ½è¯„æµ‹ï¼Œè½¬å˜ä¸ºäº†é¢†åŸŸå†…çš„æµ‹è¯•ä»»åŠ¡ã€‚ ## åè¯è®°å½• **è¯å…ƒ:** åœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­ï¼Œè¯å…ƒæ˜¯æŒ‡æ–‡æœ¬æ•°æ®ä¸­çš„æœ€å°å•ä½ï¼Œé€šå¸¸æ˜¯å•è¯ã€çŸ­è¯­æˆ–è€…ç¬¦å·ã€‚è¯å…ƒçš„ä½œç”¨æ˜¯æ„å»ºæ¨¡å‹çš„è¾“å…¥æ•°æ®ï¼Œé€šè¿‡å°†æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºè¯å…ƒçš„å½¢å¼ï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£å’Œå¤„ç†æ–‡æœ¬ä¿¡æ¯ã€‚è¯å…ƒå¯ä»¥å¸®åŠ©æ¨¡å‹æ•æ‰æ–‡æœ¬æ•°æ®ä¸­çš„è¯­ä¹‰å’Œç»“æ„ç‰¹å¾ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ€§èƒ½å’Œå‡†ç¡®æ€§ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¯å…ƒä¹Ÿå¯ä»¥é€šè¿‡å‘é‡åŒ–è¡¨ç¤ºï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ æ–‡æœ¬æ•°æ®ä¸­çš„è¯­ä¹‰ä¿¡æ¯ã€‚å› æ­¤ï¼Œè¯å…ƒåœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­èµ·ç€éå¸¸é‡è¦çš„ä½œç”¨ã€‚ **å‚æ•°: **åœ¨è¿›è¡Œå¤§æ¨¡å‹è®­ç»ƒæ—¶ï¼Œé€šå¸¸éœ€è¦è®¾ç½®å’Œè°ƒæ•´çš„å‚æ•°åŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹å†…å®¹ï¼š 1. å­¦ä¹ ç‡ï¼ˆlearning rateï¼‰ï¼šæ§åˆ¶æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´æ–°å‚æ•°çš„é€Ÿç‡ï¼Œä»¥é¿å…è¿‡æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆã€‚ 2. æ‰¹å¤§å°ï¼ˆbatch sizeï¼‰ï¼šæŒ‡å®šæ¯æ¬¡è¿­ä»£è®­ç»ƒæ—¶æ‰€ä½¿ç”¨çš„æ ·æœ¬æ•°é‡ï¼Œå½±å“æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œè®­ç»ƒæ•ˆæœã€‚ 3. ä¼˜åŒ–ç®—æ³•ï¼ˆoptimizerï¼‰ï¼šé€‰æ‹©ç”¨äºè°ƒæ•´æ¨¡å‹å‚æ•°çš„ä¼˜åŒ–ç®—æ³•ï¼Œå¦‚éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ã€Adamç­‰ã€‚ 4. æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰ï¼šå®šä¹‰ç”¨äºè¯„ä¼°æ¨¡å‹è¾“å‡ºä¸çœŸå®æ ‡ç­¾ä¹‹é—´å·®å¼‚çš„å‡½æ•°ï¼Œç”¨äºä¼˜åŒ–æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚ 5. æ­£åˆ™åŒ–å‚æ•°ï¼ˆregularizationï¼‰ï¼šæ§åˆ¶æ¨¡å‹çš„å¤æ‚åº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼ŒåŒ…æ‹¬L1æ­£åˆ™åŒ–ã€L2æ­£åˆ™åŒ–ç­‰ã€‚ 6. å­¦ä¹ ç‡è¡°å‡ï¼ˆlearning rate decayï¼‰ï¼šè®¾ç½®å­¦ä¹ ç‡éšè®­ç»ƒè½®æ¬¡é€’å‡çš„ç­–ç•¥ï¼Œå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°æ”¶æ•›ã€‚ 7. è®­ç»ƒè½®æ¬¡ï¼ˆepochsï¼‰ï¼šæŒ‡å®šæ¨¡å‹è¿›è¡Œè®­ç»ƒçš„è½®æ¬¡æ•°é‡ï¼Œé€šå¸¸é€šè¿‡äº¤å‰éªŒè¯ç­‰æŠ€æœ¯ç¡®å®šåˆé€‚çš„è®­ç»ƒè½®æ¬¡ã€‚ 8. æ•°æ®å¢å¼ºå‚æ•°ï¼ˆdata augmentationï¼‰ï¼šç”¨äºå¢åŠ è®­ç»ƒæ•°æ®æ ·æœ¬çš„å¤šæ ·æ€§ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ 9. GPU/CPUä½¿ç”¨è®¾å¤‡å‚æ•°ï¼šæŒ‡å®šæ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„è®¡ç®—è®¾å¤‡ï¼Œå¦‚GPUæˆ–CPUã€‚ 10. æ¨¡å‹ä¿å­˜ä¸åŠ è½½å‚æ•°ï¼šè®¾ç½®æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¿å­˜ä¸åŠ è½½ç­–ç•¥ï¼Œä»¥ä¾¿åç»­æ¨¡å‹è°ƒç”¨å’Œéƒ¨ç½²ã€‚ ä»¥ä¸Šæ˜¯ä¸€äº›åœ¨å¤§æ¨¡å‹è®­ç»ƒä¸­å¸¸è§çš„å‚æ•°å†…å®¹ï¼Œå…·ä½“çš„è®¾ç½®å’Œè°ƒæ•´å¯æ ¹æ®å®é™…æƒ…å†µå’Œä»»åŠ¡éœ€æ±‚è¿›è¡Œè¿›ä¸€æ­¥çš„å®šåˆ¶ã€‚ **æ³›åŒ–èƒ½åŠ›: ** **è¿ç§»å­¦ä¹ :** ç±»æ¯”è°ƒåŠ¨"},"/note/æœºå™¨å­¦ä¹ /2024-10-5-Transformers.html":{"title":"Transformers","content":" layout: post title: \"Transformers\" date: 2024 8 5 15:39:08 +0800 tags: AI æœºå™¨å­¦ä¹  # Transformers ## HuggingFace æ³¨å†Œä¸€ä¸ªè´¦æˆ· [Hugging Face â€“ The AI community building the future.](https://huggingface.co/welcome) ## å®‰è£…ç¯å¢ƒ æ˜¯HuggingFaceå‡ºå“çš„ç›®å‰æœ€ç«çš„è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·åŒ…, å®ç°å¤§é‡çš„åŸºäºè¿™ä¸€ä¸ªæ¶æ„çš„é¢„è®­ç»ƒæ¨¡å‹ä»¥åŠå…¶ä»–å„ç§æ¨¡å‹ è¿™æ˜¯ä¸€æ•´ä¸ªç”Ÿæ€ç¯å¢ƒ ![Screenshot_20241005_230004](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410052300340.jpg) ```bash conda create n transforms python 3.9 conda activate transforms pip config set global.index url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple pip3 install torch torchvision torchaudio index url https://download.pytorch.org/whl/cu124 pip install transformers datasets evaluate peft accelerate gradio optimum sentencepiece pip install jupyterlab scikit learn pandas matplotlib tensorboard nltk rouge ``` ![image 20241006101635925](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061016954.png) åœ¨ä½¿ç”¨vscodeå¼€å‘jupyterçš„æ—¶å€™, éœ€è¦é€‰æ‹©ä¸€ä¸‹å†…æ ¸ ### ç®€å•æµ‹è¯• ```python import gradio as gr from transformers import * gr.Interface.from_pipeline(pipeline(\"text classification\", model \"uer/roberta base finetuned dianping chinese\")).launch() ``` å¯åŠ¨ä¸€ä¸ªè¯„ä»·åˆ†ç±»å™¨, è¯„ä»·è¿™ä¸€ä¸ªè¯„ä»·çš„è¯„åˆ† ```python # å¯¼å…¥gradio import gradio as gr # å¯¼å…¥transformersç›¸å…³åŒ… from transformers import pipeline # é€šè¿‡InterfaceåŠ è½½pipelineå¹¶å¯åŠ¨é˜…è¯»ç†è§£æœåŠ¡ # å¦‚æœæ— æ³•é€šè¿‡è¿™ç§æ–¹å¼åŠ è½½ï¼Œå¯ä»¥é‡‡ç”¨ç¦»çº¿åŠ è½½çš„æ–¹å¼ gr.Interface.from_pipeline(pipeline(\"question answering\", model \"uer/roberta base chinese extractive qa\")).launch() ``` > ä¸€ä¸ªæœºå™¨é˜…è¯»ç†è§£çš„æ¨¡å‹ > > ![image 20241006112326045](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061123128.png) ## é€‰å– [Tasks Hugging Face](https://huggingface.co/tasks) [What is Question Answering? Hugging Face](https://huggingface.co/tasks/question answering) å¯ä»¥åœ¨è¿™é‡Œé¢é€‰å–ä»–æ¨èçš„æ¨¡å‹, æ•°æ®é›†, æµ‹è¯•ç®—æ³• ![image 20241008181712046](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410081817288.png) ## åŸºç¡€ç»„ä»¶Pipeline æŠŠæ•°æ®è¿›è¡Œé¢„å¤„ç†, æ¨¡å‹è°ƒç”¨ä»¥åŠæ¨¡å‹è°ƒç”¨ä»¥åŠç»“æœåå¤„ç†ç»„è£…ä¸ºä¸€ä¸ªæµæ°´çº¿, ä½¿å¾—æˆ‘ä»¬è¾“å…¥çš„æ–‡æœ¬å¯ä»¥è·å–ä¸ºæœ€åçš„ç»“æœ ![image 20241006113243862](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061132916.png) + å¯ä»¥å¤„ç†çš„ä»»åŠ¡ ![image 20241006114036732](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061140780.png) ![image 20241006114053198](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061140248.png) > audio classification ï¼šéŸ³é¢‘åˆ†ç±» > automatic speech recognition ï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ« > text to audio ï¼šæ–‡æœ¬è½¬éŸ³é¢‘ > feature extraction ï¼šç‰¹å¾æå– > text classification ï¼šæ–‡æœ¬åˆ†ç±» > token classification ï¼šæ ‡è®°åˆ†ç±» > question answering ï¼šé—®ç­”ç³»ç»Ÿ > table question answering ï¼šè¡¨æ ¼é—®ç­” > visual question answering ï¼šè§†è§‰é—®ç­” > document question answering ï¼šæ–‡æ¡£é—®ç­” > fill mask ï¼šå¡«å……æ©ç  > summarization ï¼šæ‘˜è¦ç”Ÿæˆ > translation ï¼šç¿»è¯‘ > text2text generation ï¼šæ–‡æœ¬ç”Ÿæˆ > text generation ï¼šæ–‡æœ¬ç”Ÿæˆ > zero shot classification ï¼šé›¶æ ·æœ¬åˆ†ç±» > zero shot image classification ï¼šé›¶æ ·æœ¬å›¾åƒåˆ†ç±» > zero shot audio classification ï¼šé›¶æ ·æœ¬éŸ³é¢‘åˆ†ç±» > image classification ï¼šå›¾åƒåˆ†ç±» > image feature extraction ï¼šå›¾åƒç‰¹å¾æå– > image segmentation ï¼šå›¾åƒåˆ†å‰² > image to text ï¼šå›¾åƒè½¬æ–‡æœ¬ > object detection ï¼šç‰©ä½“æ£€æµ‹ > zero shot object detection ï¼šé›¶æ ·æœ¬ç‰©ä½“æ£€æµ‹ > depth estimation ï¼šæ·±åº¦ä¼°è®¡ > video classification ï¼šè§†é¢‘åˆ†ç±» > mask generation ï¼šæ©ç ç”Ÿæˆ > image to image ï¼šå›¾åƒåˆ°å›¾åƒ ```python from transformers.pipelines import SUPPORTED_TASKS for k, v in SUPPORTED_TASKS.items(): print(k, v) ``` > å¯ä»¥ä½¿ç”¨ä»¥ä¸Šçš„æ–¹æ³•è¿›è¡ŒæŸ¥çœ‹ ### ä½¿ç”¨è¯´æ˜ ![image 20241006125917307](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061259357.png) ```python class TextClassificationPipeline(Pipeline): \"\"\" Text classification pipeline using any `ModelForSequenceClassification`. See the [sequence classification examples](../task_summary#sequence classification) for more information. Example: ```python >>> from transformers import pipeline >>> classifier pipeline(model \"distilbert/distilbert base uncased finetuned sst 2 english\") >>> classifier(\"This movie is disgustingly good !\") [{'label': 'POSITIVE', 'score': 1.0}] >>> classifier(\"Director tried too much.\") [{'label': 'NEGATIVE', 'score': 0.996}] ``` Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial) This text classification pipeline can currently be loaded from [`pipeline`] using the following task identifier: `\"sentiment analysis\"` (for classifying sequences according to positive or negative sentiments). If multiple classification labels are available (`model.config.num_labels > 2`), the pipeline will run a softmax over the results. If there is a single label, the pipeline will run a sigmoid over the result. The models that this pipeline can use are models that have been fine tuned on a sequence classification task. See the up to date list of available models on [huggingface.co/models](https://huggingface.co/models?filter text classification). \"\"\" ``` è¿™ä¸€ä¸ªé‡Œé¢åªæœ‰æœ€ç®€å•çš„æ–¹æ³•è°ƒç”¨, åœ¨å®é™…ä½¿ç”¨å¯ä»¥çœ‹ä»–çš„`__call__`æ–¹æ³• ```python def __call__(self, inputs, **kwargs): \"\"\" Classify the text(s) given as inputs. Args: inputs (`str` or `List[str]` or `Dict[str]`, or `List[Dict[str]]`): One or several texts to classify. In order to use text pairs for your classification, you can send a dictionary containing `{\"text\", \"text_pair\"}` keys, or a list of those. top_k (`int`, *optional*, defaults to `1`): How many results to return. function_to_apply (`str`, *optional*, defaults to `\"default\"`): The function to apply to the model outputs in order to retrieve the scores. Accepts four different values: If this argument is not specified, then it will apply the following functions according to the number of labels: If the model has a single label, will apply the sigmoid function on the output. If the model has several labels, will apply the softmax function on the output. Possible values are: `\"sigmoid\"`: Applies the sigmoid function on the output. `\"softmax\"`: Applies the softmax function on the output. `\"none\"`: Does not apply any function on the output. Return: A list or a list of list of `dict`: Each result comes as list of dictionaries with the following keys: **label** (`str`) The label predicted. **score** (`float`) The corresponding probability. If `top_k` is used, one such dictionary is returned per label. \"\"\" ``` ### åŠ è½½ ```python from transformers import * pipe pipeline('text classification') ``` > ä½¿ç”¨è¿™ä¸€ä¸ªå‘½ä»¤çš„æ—¶å€™ä¼šè‡ªåŠ¨ä¸‹è½½é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹, ä¸€èˆ¬æ˜¯ä¸€ä¸ªè‹±æ–‡æ¨¡å‹ > > ```python > pipe(\"very good\") > ``` > > ![image 20241006120905391](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061209566.png) > > å…¶ä»–çš„æ¨¡å‹å¯ä»¥åœ¨huggingfaceè¿™ä¸€ä¸ªç½‘é¡µè¿›è¡Œå¯»æ‰¾, ä¹‹å‰ä½¿ç”¨çš„æ˜¯[uer/roberta base finetuned dianping chinese Â· Hugging Face](https://huggingface.co/uer/roberta base finetuned dianping chinese)è¿™ä¸€ä¸ªæ¨¡å‹, å¯ä»¥åœ¨æ ‡ç­¾è¿›è¡Œåˆ†ç±»ç­›é€‰ ![image 20241006120056003](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061200115.png) ![image 20241006120757759](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061207795.png) è¿™ä¸ªå°±æ˜¯æ¨¡å‹çš„åå­— ```c pipe pipeline('text classification', model 'uer/roberta base finetuned dianping chinese') ``` + æ–¹æ³•äºŒ ````python from transformers import * model AutoModelForSequenceClassification.from_pretrained('uer/roberta base finetuned dianping chinese') tokenizer AutoTokenizer.from_pretrained('uer/roberta base finetuned dianping chinese') pipe pipeline(\"text classification\", model model, tokenizer tokenizer) ```` æŠŠæ¨¡å‹ä»¥åŠåˆ†è¯å™¨å•ç‹¬åˆ›å»ºå‡ºæ¥, è¿™ä¸¤ä¸ªéœ€è¦åŒæ—¶æŒ‡å®š > ä½¿ç”¨è¿™ä¸¤ç§æ–¹æ³•åŠ è½½çš„æ¨¡å‹å®é™…æ˜¯ä½¿ç”¨CPUè¿›è¡Œè¿è¡Œçš„ > > ```python > print(pipe.model.device) > ``` ### ä½¿ç”¨GPU ```python pipe pipeline('text classification', model 'uer/roberta base finetuned dianping chinese', device 0) ``` ### å›¾åƒè¯†åˆ«ç¤ºä¾‹ ````python from transformers import * checkpoint \"google/owlvit base patch32\" detector pipeline(model checkpoint, task \"zero shot object detection\") import requests from PIL import Image # è·å–æ£€æµ‹çš„å›¾ç‰‡ url \"https://unsplash.com/photos/oj0zeY2Ltk4/download?ixid MnwxMjA3fDB8MXxzZWFyY2h8MTR8fHBpY25pY3xlbnwwfHx8fDE2Nzc0OTE1NDk&force true&w 640\" im Image.open(requests.get(url, stream True).raw) im.show() # è¿›è¡Œæ£€æµ‹ predictions detector( im, candidate_labels [\"hat\", \"sunglasses\", \"book\"], ) print(predictions) from PIL import ImageDraw # ç»˜åˆ¶ä¸€ä¸‹ç»“æœ draw ImageDraw.Draw(im) for prediction in predictions: box prediction[\"box\"] label prediction[\"label\"] score prediction[\"score\"] xmin, ymin, xmax, ymax box.values() draw.rectangle((xmin, ymin, xmax, ymax), outline \"red\", width 1) draw.text((xmin, ymin), f\"{label}: {round(score,2)}\", fill \"red\") im.show() ```` > ```c > class ZeroShotObjectDetectionPipeline(ChunkPipeline): > \"\"\" > Zero shot object detection pipeline using `OwlViTForObjectDetection`. This pipeline predicts bounding boxes of > objects when you provide an image and a set of `candidate_labels`. > > Example: > > ```python > >>> from transformers import pipeline > > >>> detector pipeline(model \"google/owlvit base patch32\", task \"zero shot object detection\") > >>> detector( > ... \"http://images.cocodataset.org/val2017/000000039769.jpg\", > ... candidate_labels [\"cat\", \"couch\"], > ... ) > [{'score': 0.287, 'label': 'cat', 'box': {'xmin': 324, 'ymin': 20, 'xmax': 640, 'ymax': 373}}, {'score': 0.254, 'label': 'cat', 'box': {'xmin': 1, 'ymin': 55, 'xmax': 315, 'ymax': 472}}, {'score': 0.121, 'label': 'couch', 'box': {'xmin': 4, 'ymin': 0, 'xmax': 642, 'ymax': 476}}] > > >>> detector( > ... \"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\", > ... candidate_labels [\"head\", \"bird\"], > ... ) > [{'score': 0.119, 'label': 'bird', 'box': {'xmin': 71, 'ymin': 170, 'xmax': 410, 'ymax': 508}}] > ``` > > Learn more about the basics of using a pipeline in the [pipeline tutorial](../pipeline_tutorial) > > This object detection pipeline can currently be loaded from [`pipeline`] using the following task identifier: > `\"zero shot object detection\"`. > > See the list of available models on > [huggingface.co/models](https://huggingface.co/models?filter zero shot object detection). > \"\"\" > ``` ![image 20241006131935059](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061319203.png) ![image 20241006131947210](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410061319339.png) ### å¤„ç†æµç¨‹ + åˆå§‹åŒ–Tokenizer ```python tokenizer AutoTokenizer.from_pretrained('uer/roberta base finetuned dianping chinese') ``` + åˆå§‹åŒ–Model ```python model AutoModelForSequenceClassification.from_pretrained('uer/roberta base finetuned dianping chinese') ``` + æ•°æ®é¢„å¤„ç† ```python imput_text \"å¯ä»¥\" inputs tokenizer(input_text, return_tensors 'pt') # è¿”å›å€¼æ˜¯ä¸€ä¸ªpytorch tensor ``` + æ¨¡å‹é¢„æµ‹ ```python res model(**inputs).logits ``` + ç»“æœåå¤„ç† softmaxè¾“å‡ºçš„æ˜¯æ¦‚ç‡åˆ†å¸ƒï¼ˆæ¯”å¦‚åœ¨å¤šåˆ†ç±»é—®é¢˜ä¸­ï¼ŒSoftmaxè¾“å‡ºçš„æ˜¯æ¯ä¸ªç±»åˆ«å¯¹åº”çš„æ¦‚ç‡ï¼‰ <img src \"https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062224000.png\"/> ```python logits res.logits logits torch.softmax(logits, dim 1) # åœ¨ç»´åº¦1è¿›è¡Œè®¡ç®— pred torch.argmax(logits, dim 1).item() ``` ![image 20241006222812760](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062228807.png) ## Tokenizer è¿›è¡Œæ•°æ®çš„é¢„å¤„ç† 1. åˆ†è¯: ä½¿ç”¨åˆ†è¯å™¨å¯¹æ–‡æœ¬æ•°æ®è¿›è¡Œåˆ†è¯ 2. æ„å»ºè¯å…¸: æ ¹æ®åˆ†è¯å™¨çš„å¤„ç†ç»“æœ, Step2æ„å»ºè¯å…¸:æ ¹æ®æ•°æ®é›†åˆ†è¯çš„ç»“æœï¼Œæ„å»ºè¯å…¸æ˜ å°„(è¿™ä¸€æ­¥å¹¶ä¸ç»å¯¹ï¼Œå¦‚æœé‡‡ç”¨é¢„è®­ç»ƒè¯å‘é‡ï¼Œè¯å…¸æ˜ å°„è¦æ ¹æ®è¯å‘é‡æ–‡ä»¶è¿›è¡Œå¤„ç†); 3. æ•°æ®è½¬æ¢:æ ¹æ®æ„å»ºå¥½çš„è¯å…¸ï¼Œå°†åˆ†è¯å¤„ç†åçš„æ•°æ®åšæ˜ å°„ï¼Œå°†æ–‡æœ¬åºåˆ—è½¬æ¢ä¸ºæ•°å­—åºåˆ—; 4. æ•°æ®å¡«å……ä¸æˆªæ–­:åœ¨ä»¥batchè¾“å…¥åˆ°æ¨¡å‹çš„æ–¹å¼ä¸­ï¼Œéœ€è¦å¯¹è¿‡çŸ­çš„æ•°æ®è¿›è¡Œå¡«å……ï¼Œè¿‡é•¿çš„æ•°æ®è¿›è¡Œæˆªæ–­ï¼Œä¿è¯æ•°æ®é•¿åº¦ç¬¦åˆæ¨¡å‹èƒ½æ¥å—çš„èŒƒå›´ï¼ŒåŒæ—¶batchå†…çš„æ•°æ®ç»´åº¦å¤§å°ä¸€è‡´ã€‚ åœ¨ä½¿ç”¨Tokenizerçš„æ—¶å€™å¯ä»¥è¿›è¡Œä»¥ä¸Šçš„æ‰€æœ‰å¤„ç† ### åŸºæœ¬ä½¿ç”¨ ![image 20241006223441164](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062234321.png) ```python from transformers import AutoTokenizer ``` > ä¸åŒçš„æ¨¡å‹ä¼šä½¿ç”¨ä¸åŒçš„Tokenizer, æ‰€ä»¥è¿™é‡Œå°è£…äº†ä¸€ä¸ªAutoTokenizer, æ ¹æ®ä¼ å…¥çš„å‚æ•°ç¡®å®šæœ€åçš„ç»“æœ + åŠ è½½åˆ†è¯å™¨ ```python sen \"æˆ‘å²å‡¯æ­Œæ•¢åƒå±!\" tokenizer AutoTokenizer.from_pretrained(\"uer/roberta base finetuned dianping chinese\") ``` ![image 20241006223955140](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062239203.png) è¿™ä¸€ä¸ªå¯ä»¥ä¿å­˜åœ¨æœ¬åœ°ä»¥åŠä»æœ¬åœ°è¿›è¡ŒåŠ è½½ ```python tokenizer.(\"./tokenizer\") tokenizer AutoTokenizer.from_pretrained(\"./tokenizer\") ``` ä¹‹åå¯ä»¥è¿›è¡Œåˆ†è¯ ```python tokens tokenizer.tokenize(sen) ``` ![image 20241006224426467](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062244514.png) + å¯ä»¥æŸ¥çœ‹ä¸€ä¸‹è¿™ä¸€ä¸ªåˆ†è¯å™¨çš„è¯å…¸ ![image 20241006224655209](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062246264.png) ![image 20241006224712011](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062247055.png) + æŠŠè¯è¯­è½¬æ¢ä¸ºid ```python ids tokenizer.convert_tokens_to_ids(tokens) ``` ![image 20241006224944657](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062249711.png) > ä¹Ÿå¯ä»¥åè¿‡æ¥è½¬æ¢ > > ![image 20241006225045369](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062250417.png) > > ![image 20241006225224620](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062252671.png) + å¡«å……æˆªæ–­ ```python # å¡«å…… ids tokenizer.encode(sen, add_special_tokens False, padding 'max_length', max_length 10) ``` ![image 20241006225920394](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062259454.png) ```python # æˆªæ–­ ids tokenizer.encode(sen, add_special_tokens False, truncation True, max_length 5) ``` ![image 20241006230016792](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062300854.png) åœ¨æˆªæ–­çš„æ—¶å€™å¦‚æœæ·»åŠ æ ‡å¿—ä½, è¿™ä¸€ä¸ªæ ‡å¿—ä½ä¸ä¼šè¢«æˆªæ–­ å®é™…ä½¿ç”¨çš„æ—¶å€™, éœ€è¦åŒºåˆ†ä¸€ä¸‹é‚£ä¸€éƒ¨åˆ†æ˜¯å¡«å……çš„æ•°æ®, ä»¥åŠåŒºåˆ†ä¸€ä¸‹å¥å­çš„å‰å ```python attention_mask [1 if idx ! 0 else 0 for idx in ids] token_type_ids [0] * len(ids) ``` ![image 20241006230541868](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062305927.png) ### ç®€ä¾¿ä½¿ç”¨æ–¹æ³• #### å•ä¸ªæ•°æ® ```python ids tokenizer.encode(sen) ``` ![image 20241006225340157](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062253211.png) > ![image 20241006225442970](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062254025.png) > > è¿™ä¸€ä¸ªæ¨¡å‹åœ¨å¤„ç†çš„æ—¶å€™ä¼šåŠ å…¥ç”¨äºåŒºåˆ†å¥å­çš„tokenå¯ä»¥ä½¿ç”¨å‚æ•°å–æ¶ˆ > > ````python > ids tokenizer.encode(sen, add_special_tokens False) > str tokenizer.decode(ids, skip_special_tokens True) > ```` ```python ids tokenizer.encode_plus(sen, add_special_tokens True, max_length 20, padding 'max_length') ``` ```bash { 'input_ids': [101, 2769, 1380, 1132, 3625, 3140, 1391, 2241, 106, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] } ``` > ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨`ids tokenizer(sen, add_special_tokens True, max_length 20, padding 'max_length')` > > token_type_idsç”¨äºæ ‡è¯†ä¸åŒæ–‡æœ¬ç‰‡æ®µçš„tokenç±»å‹ã€‚åœ¨BERTæ¨¡å‹ä¸­ï¼Œè¾“å…¥æ–‡æœ¬å¯èƒ½åŒ…å«å¤šä¸ªæ–‡æœ¬ç‰‡æ®µï¼Œä¾‹å¦‚é—®é¢˜å’Œç­”æ¡ˆã€‚token_type_idså¯ä»¥ç”¨æ¥åŒºåˆ†ä¸åŒæ–‡æœ¬ç‰‡æ®µçš„tokenï¼Œå¸®åŠ©æ¨¡å‹æ•æ‰æ–‡æœ¬ä¹‹é—´çš„å…³è”ä¿¡æ¯ã€‚é€šè¿‡å°†ä¸åŒæ–‡æœ¬ç‰‡æ®µçš„tokenèµ‹äºˆä¸åŒçš„token_type_idsï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£æ¯ä¸ªæ–‡æœ¬ç‰‡æ®µä¹‹é—´çš„å…³ç³»ã€‚ > > attention_maskç”¨äºæ§åˆ¶å“ªäº›tokenå¯¹äºæ¨¡å‹æ˜¯å¯è§çš„ï¼Œå“ªäº›tokenåº”è¯¥è¢«å±è”½æ‰ã€‚åœ¨BERTæ¨¡å‹ä¸­ï¼Œè¾“å…¥æ–‡æœ¬é€šå¸¸ä¼šè¿›è¡Œpaddingä½¿å¾—è¾“å…¥åºåˆ—é•¿åº¦ç›¸åŒã€‚é€šè¿‡åœ¨attention_maskä¸­å°†paddingçš„tokenå¯¹åº”çš„ä½ç½®è®¾ä¸º0ï¼Œæ¨¡å‹å¯ä»¥å¿½ç•¥è¿™äº›padding tokenï¼Œé¿å…å¯¹å…¶è¿›è¡Œä¸å¿…è¦çš„è®¡ç®—ï¼Œæé«˜äº†æ¨¡å‹çš„è®¡ç®—æ•ˆç‡ã€‚ #### å¤„ç†å¤šä¸ªæ•°æ®(é€Ÿåº¦æ›´å¿«) ```c sen [\"æˆ‘å²å‡¯æ­Œæ•¢eat dinner!\", \"å²å‡¯æ­Œæˆ‘è¦eat dinner\", \"ä¸€å¤©è¦åƒä¸‰æ–¤dinner\"] ids tokenizer.batch_encode_plus(sen, add_special_tokens True, max_length 20, padding 'max_length') ``` > ```bash > { > 'input_ids': [ > [101, 2769, 1380, 1132, 3625, 3140, 1391, 2241, 106, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], > [101, 1380, 1132, 3625, 2769, 6206, 1391, 2241, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 671, 1921, 6206, 1391, 676, 3165, 2241, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] > ], > 'token_type_ids': [ > [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], > [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], > [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] > ], > 'attention_mask': [ > [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], > [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], > [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] > ]} > ``` ### Fast / Slow Tokenizer Fast Tokenizeræ˜¯åŸºäºRustå®ç°çš„, Slow Tokenizeræ˜¯åŸºäºpythonå®ç°çš„é€Ÿåº¦æ¯”è¾ƒæ…¢ ```python tokenizer AutoTokenizer.from_pretrained(\"uer/roberta base finetuned dianping chinese\", use_fast False) ``` ![image 20241006231850680](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062318774.png) ![image 20241006232053744](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062320847.png) ![image 20241006232109337](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062321402.png) fast tokenizerä¼šæœ‰æ›´å¤šçš„è¿”å›å€¼, ä¸»è¦æ˜¯åº”ç”¨äºå‘½åå®ä½“è¯†åˆ«ä»¥åŠqa ```python sen \"æˆ‘å²å‡¯æ­Œæ•¢åƒshit! dreaming\" inputs tokenizer(sen, return_offsets_mapping True) ``` > ```bash > { > 'input_ids': [101, 2769, 1380, 1132, 3625, 3140, 1391, 11772, 8165, 106, 10252, 8221, 102], > 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], > 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], > 'offset_mapping': [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 9), (9, 10), (10, 11), (12, 17), (17, 20), (0, 0)] > } > ``` > > ![image 20241006232704170](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410062327233.png) > > æœ‰æ—¶å€™ä¸€ä¸ªè¯ä¼šè¢«æ‹†åˆ†ä¸ºå¤šä¸ªéƒ¨åˆ†, å¯ä»¥ä½¿ç”¨è¿™ä¸€ä¸ªè¿›è¡Œå¯¹å¯¹åº”, Noneå¯¹åº”çš„æ˜¯(0, 0), è‹±æ–‡çš„æ—¶å€™æ¯”è¾ƒæ˜æ˜¾, ç¬¬(6, 9)ä¸ªå­—ç¬¦å’Œ(9, 10)æ˜¯ä¸€ä¸ªè‹±æ–‡å•è¯è¢«æ‹†åˆ†ä¸ºä¸¤ä¸ª ### å…¶å®ƒå‚æ•° åœ¨ä¸‹è½½ä¸€äº›è‡ªä¸»å¼€å‘çš„åˆ†è¯å™¨çš„æ—¶å€™, éœ€è¦æŒ‡å®šä¸€ä¸ªå‚æ•°`trust_remote_code True` ```python tokenizer AutoTokenizer.from_pretrained(\"THUDM/chatglm 6b\", trust_remote_code True) ``` ## Model åŸå§‹çš„Transformåˆ†ä¸ºç¼–ç å™¨(Encoder)ä»¥åŠè§£ç å™¨(Decoder)æ¨¡å‹, Encoderéƒ¨åˆ†æ¥æ”¶è¾“å…¥å¹¶ä¸”ä¸ºä»–æ„å»ºç‰¹å¾è¡¨ç¤º, Decoderä½¿ç”¨Encoderçš„ç¼–ç ç»“æœä»¥åŠå…¶ä»–çš„è¾“å…¥åºåˆ—ç”Ÿæˆç›®æ ‡åºåˆ— æ— è®ºæ˜¯ç¼–ç å™¨è¿˜æ˜¯è§£ç å™¨éƒ½æ˜¯å¤šä¸ªTransformsBlockå †å è€Œæˆçš„ TransformsBlockç”±æ³¨æ„åŠ›æœºåˆ¶(Attention)ä»¥åŠFFNç»„æˆ ![image 20240924105336210](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202409241053267.png) > **æ³¨æ„åŠ›æœºåˆ¶**, åœ¨è®¡ç®—å½“å‰çš„è¯çš„ç‰¹å¾è¡¨ç¤ºçš„æ—¶å€™, å¯ä»¥é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶æœ‰é€‰æ‹©æ€§çš„å‘Šè¯‰æ¨¡å¼è¦ä½¿ç”¨å“ªä¸€éƒ¨åˆ†çš„ä¸Šä¸‹æ–‡ ![image 20241007101012759](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071010900.png) ![image 20241007101132383](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071011461.png) ### AutoModel AutoModelæ˜¯Hugging Faceçš„Transformersåº“ä¸­çš„ä¸€ä¸ªéå¸¸å®ç”¨çš„ç±»ï¼Œå®ƒå±äºè‡ªåŠ¨æ¨¡å‹é€‰æ‹©çš„æœºåˆ¶ã€‚è¿™ä¸ªè®¾è®¡å…è®¸ç”¨æˆ·åœ¨ä¸çŸ¥é“å…·ä½“æ¨¡å‹ç»†èŠ‚çš„æƒ…å†µä¸‹ï¼Œæ ¹æ®ç»™å®šçš„æ¨¡å‹åç§°æˆ–æ¨¡å‹ç±»å‹è‡ªåŠ¨åŠ è½½ç›¸åº”çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚å®ƒå‡å°‘äº†ä»£ç çš„é‡å¤æ€§ï¼Œå¹¶æé«˜äº†çµæ´»æ€§ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥è½»æ¾åœ°åˆ‡æ¢ä¸åŒçš„æ¨¡å‹è¿›è¡Œå®éªŒæˆ–åº”ç”¨ã€‚ ### Model Head Model Headåœ¨é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šæ·»åŠ ä¸€å±‚æˆ–å¤šå±‚çš„é¢å¤–ç½‘ç»œç»“æ„æ¥é€‚åº”ç‰¹å®šçš„æ¨¡å‹ä»»åŠ¡ï¼Œæ–¹ä¾¿äºå¼€å‘è€…å¿«é€ŸåŠ è½½transformersåº“ä¸­çš„ä¸åŒç±»å‹æ¨¡å‹ï¼Œä¸ç”¨å…³å¿ƒæ¨¡å‹å†…éƒ¨ç»†èŠ‚ã€‚ Model Headæ˜¯Transformersæ¨¡å‹é‡Œçš„ä¸€å±‚ï¼Œé€šå¸¸ç”¨äºå¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œåç»­å¤„ç†ã€‚å…¶ä½œç”¨æ˜¯æ¥æ”¶æ¨¡å‹çš„è¾“å‡ºï¼Œç„¶åå°†å…¶æ˜ å°„æˆæœ€ç»ˆçš„è¾“å‡ºã€‚è¿™å¯èƒ½æ¶‰åŠåˆ°ä¸€ç³»åˆ—æ“ä½œï¼Œæ¯”å¦‚åˆ†ç±»ã€å›å½’ã€ç”Ÿæˆç­‰ä»»åŠ¡ã€‚Model Headå¯ä»¥å°†æ¨¡å‹è¾“å‡ºè½¬åŒ–ä¸ºé€‚åˆç‰¹å®šä»»åŠ¡çš„æ ¼å¼ï¼Œå¹¶åŠ å…¥é€‚å½“çš„æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚ åœ¨åˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒModel Headå¯èƒ½ä¼šæ¥æ”¶æ¨¡å‹è¾“å‡ºçš„æ¯ä¸ªtokençš„è¡¨ç¤ºï¼Œç„¶åå°†å®ƒä»¬æ±‡æ€»æˆæ•´ä¸ªå¥å­çš„è¡¨ç¤ºï¼Œæœ€ç»ˆé€šè¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚å°†å…¶åˆ†ç±»ä¸ºä¸åŒçš„ç±»åˆ«ã€‚ åœ¨ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒModel Headå¯èƒ½ä¼šæ¥æ”¶æ¨¡å‹è¾“å‡ºçš„æ¯ä¸ªtokençš„è¡¨ç¤ºï¼Œç„¶åå°†å…¶ä¾æ¬¡è¾“å…¥åˆ°ä¸€ä¸ªè§£ç å™¨ä¸­ç”Ÿæˆæ•´ä¸ªåºåˆ—ã€‚ æ€»çš„æ¥è¯´ï¼ŒModel Headçš„ä½œç”¨æ˜¯å°†æ¨¡å‹è¾“å‡ºè¿›è¡Œæœ€ç»ˆçš„è½¬åŒ–ï¼Œä½¿å¾—æ¨¡å‹å¯ä»¥å®Œæˆå…·ä½“çš„ä»»åŠ¡ã€‚ + ForCausalLMï¼šå› æœè¯­è¨€æ¨¡å‹å¤´ï¼Œç”¨äºdecoderç±»å‹çš„ä»»åŠ¡ï¼Œä¸»è¦è¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œç”Ÿæˆçš„æ¯ä¸ªè¯ä¾èµ–äºä¹‹å‰ç”Ÿæˆçš„æ‰€æœ‰è¯ã€‚æ¯”å¦‚GPTã€Qwen + ForMaskedLMï¼šæ©ç è¯­è¨€æ¨¡å‹å¤´ï¼Œç”¨äºencoderç±»å‹çš„ä»»åŠ¡ï¼Œä¸»è¦è¿›è¡Œé¢„æµ‹æ–‡æœ¬ä¸­è¢«æ©ç›–å’Œè¢«éšè—çš„è¯ï¼Œæ¯”å¦‚BERTã€‚ + ForSeq2SeqLMï¼šåºåˆ—åˆ°åºåˆ—æ¨¡å‹å¤´ï¼Œç”¨äºencoder decoderç±»å‹çš„ä»»åŠ¡ï¼Œä¸»è¦å¤„ç†ç¼–ç å™¨å’Œè§£ç å™¨å…±åŒå·¥ä½œçš„ä»»åŠ¡ï¼Œæ¯”å¦‚æœºå™¨ç¿»è¯‘æˆ–æ–‡æœ¬æ‘˜è¦ã€‚ + ForQuestionAnsweringï¼šé—®ç­”ä»»åŠ¡æ¨¡å‹å¤´ï¼Œç”¨äºé—®ç­”ç±»å‹çš„ä»»åŠ¡ï¼Œä»ç»™å®šçš„æ–‡æœ¬ä¸­æŠ½å–ç­”æ¡ˆã€‚é€šè¿‡ä¸€ä¸ªencoderæ¥ç†è§£é—®é¢˜å’Œä¸Šä¸‹æ–‡ï¼Œå¯¹ç­”æ¡ˆè¿›è¡ŒæŠ½å–ã€‚ + ForSequenceClassificationï¼šæ–‡æœ¬åˆ†ç±»æ¨¡å‹å¤´ï¼Œå°†è¾“å…¥åºåˆ—æ˜ å°„åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªæ ‡ç­¾ã€‚ä¾‹å¦‚ä¸»é¢˜åˆ†ç±»ã€æƒ…æ„Ÿåˆ†ç±»ã€‚ + ForTokenClassificationï¼šæ ‡è®°åˆ†ç±»æ¨¡å‹å¤´ï¼Œç”¨äºå¯¹æ ‡è®°è¿›è¡Œè¯†åˆ«çš„ä»»åŠ¡ã€‚å°†åºåˆ—ä¸­çš„æ¯ä¸ªæ ‡è®°æ˜ å°„åˆ°ä¸€ä¸ªæå‰å®šä¹‰å¥½çš„æ ‡ç­¾ã€‚å¦‚å‘½åå®ä½“è¯†åˆ«ï¼Œæ‰“æ ‡ç­¾ + ForMultiplechoiceï¼šå¤šé¡¹é€‰æ‹©ä»»åŠ¡æ¨¡å‹å¤´ï¼ŒåŒ…å«å¤šä¸ªå€™é€‰ç­”æ¡ˆçš„è¾“å…¥ï¼Œé¢„æµ‹æ­£ç¡®ç­”æ¡ˆçš„é€‰é¡¹ã€‚ ### ä¸‹è½½åŠ è½½(æ— Model Head) ```python model AutoModel.from_pretrained(\"hfl/rbt3\") ``` > ä½¿ç”¨è¿™ä¸€ä¸ªæ–¹å¼çš„æ—¶å€™å¯ä»¥ä»å®˜ç½‘è¿›è¡Œä¸‹è½½æ¨¡å‹, å¦‚æœè¿™ä¸€ä¸ªå¤±è´¥å¯ä»¥åœ¨ > > ![image 20241007105514201](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071055312.png) > > è¿™é‡Œä¸‹è½½çš„æ˜¯pytorchç‰ˆæœ¬çš„æ¨¡å‹ > > ```python > model AutoModel.from_pretrained(\"E:/JHY/python/2024 10 5 transforms/hlfrbt3\") > ``` > > è¿˜å¯ä»¥ä½¿ç”¨gitå…‹éš†çš„æ–¹å¼è¿›è¡Œ, åœ¨trainæŒ‰é’®çš„å·¦ä¾§ä¸‰ä¸ªç‚¹ > > ![image 20241007110417069](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071104166.png) > > åœ¨ä½¿ç”¨é»˜è®¤çš„å‘½ä»¤çš„æ—¶å€™, ä¼šä¸‹è½½æ‰€æœ‰çš„ä¸‰ä¸ªæ¨¡å‹, æ‰€ä»¥å¯ä»¥ä½¿ç”¨ > > ```bash > git lfs clone \"https://huggingface.co/hfl/rbt3\" include \"*.bin\" > ``` ### é…ç½® ![image 20241007111339761](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071113850.png) > å¯ä»¥åœ¨ä¸‹è½½çš„æ—¶å€™å¯¹æ¨¡å‹è¿›è¡Œé…ç½® ä¹Ÿå¯ä»¥ä½¿ç”¨`model.config`è·å–è¿™ä¸€ä¸ªæ¨¡å‹çš„é…ç½®å‚æ•°, æœ€å…¨çš„å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‡½æ•°åŠ è½½ ```python config AutoConfig.from_pretrained(\"E:/JHY/python/2024 10 5 transforms/hlfrbt3\") ``` ä½¿ç”¨è¿™ä¸€ç§æ–¹å¼åŠ è½½çš„æ—¶å€™å‚æ•°å’Œå˜é‡æ˜¯å¯ä»¥æ”¹å˜çš„ > ```bash > BertConfig { > \"_name_or_path\": \"E:/JHY/python/2024 10 5 transforms/hlfrbt3\", > \"architectures\": [ > \"BertForMaskedLM\" > ], > \"attention_probs_dropout_prob\": 0.1, > \"classifier_dropout\": null, > \"directionality\": \"bidi\", > \"hidden_act\": \"gelu\", > \"hidden_dropout_prob\": 0.1, > \"hidden_size\": 768, > \"initializer_range\": 0.02, > \"intermediate_size\": 3072, > \"layer_norm_eps\": 1e 12, > \"max_position_embeddings\": 512, > \"model_type\": \"bert\", > \"num_attention_heads\": 12, > \"num_hidden_layers\": 3, > \"output_past\": true, > \"pad_token_id\": 0, > \"pooler_fc_size\": 768, > \"pooler_num_attention_heads\": 12, > \"pooler_num_fc_layers\": 3, > \"pooler_size_per_head\": 128, > \"pooler_type\": \"first_token_transform\", > \"position_embedding_type\": \"absolute\", > \"transformers_version\": \"4.44.2\", > \"type_vocab_size\": 2, > \"use_cache\": true, > \"vocab_size\": 21128 > } > ``` è¾“å‡ºæ˜¯ä¸€ä¸ªBertConfigç±», è¿™ä¸ªç±»ç»§æ‰¿äºPretrainedConfigç±», æœ‰å¾ˆå¤šçš„å‚æ•°æ˜¯åœ¨ä¸Šé¢æ²¡æœ‰æ˜¾ç¤ºçš„ å®é™…åŠŸèƒ½ ```python sen \"æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨\" tokenizer AutoTokenizer.from_pretrained(\"E:/JHY/python/2024 10 5 transforms/hlfrbt3\") inputs tokenizer(sen, return_tensors \"pt\") output model(**inputs) ``` ![image 20241007112810082](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071128164.png) > ```bash > 9.1205e 01, 9.9994e 01, 3.5651e 01, 9.9433e 01, 9.3075e 01, > 3.3699e 01, 9.9916e 01, 1.0331e 01]], grad_fn <TanhBackward0>), hidden_states None, past_key_values None, attentions None, cross_attentions None) > ``` > è¿™æ—¶å€™çš„è¾“å‡ºæœ‰ä¸€éƒ¨åˆ†çš„æ•°æ®æ˜¯æ²¡æœ‰å‚æ•°çš„, å¯ä»¥åœ¨åŠ è½½çš„æ—¶å€™åŠ ä¸€ä¸ªå‚æ•° > > ```c > model AutoModel.from_pretrained(\"E:/JHY/python/2024 10 5 transforms/hlfrbt3\", output_attentions True) > ``` > > ![image 20241007113159856](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071131938.png) è¿™ä¸€ä¸ªæ¨¡å‹æ˜¯ä¸€ä¸ªä¸å¸¦Model Headerçš„ ![image 20241007113346059](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071133143.png) ä¸€æ¡æ•°æ®, é•¿åº¦ä¸º9çš„inputids ### æœ‰Model Head ```python from transformers import AutoModelForSequenceClassification clz_model AutoModelForSequenceClassification.from_pretrained(\"E:/JHY/python/2024 10 5 transforms/hlfrbt3\", num_labels 2) clz_model(**inputs) ``` > ```bash > SequenceClassifierOutput(loss None, logits tensor([[ 0.0296, 0.4734]], grad_fn <AddmmBackward0>), hidden_states None, attentions None) > ``` > > æ²¡æœ‰ä¼ label, æ‰€ä»¥è¿™é‡Œçš„loss None å¯ä»¥ä½¿ç”¨å‚æ•°num_labelsè®¾ç½®è¾“å‡ºçš„åˆ†ç±»ä¸ªæ•° ![image 20241007114416817](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071144912.png) ![image 20241007114337851](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071143951.png) è¿™é‡Œçš„bertæ˜¯ä¸€ä¸ªæ¨¡å‹ç¼–ç å™¨[ã€ç†è®ºç¯‡ã€‘æ˜¯æ—¶å€™å½»åº•å¼„æ‡‚BERTæ¨¡å‹äº†(æ”¶è—) CSDNåšå®¢](https://blog.csdn.net/yjw123456/article/details/120211601#:~:text æœ¬æ–‡è¯¦ç»†è§£æBERT) ### å¾®è°ƒä»£ç ç¤ºä¾‹ ä½¿ç”¨æ•°æ®é›†[SophonPlus/ChineseNlpCorpus](https://github.com/SophonPlus/ChineseNlpCorpus) ![image 20241007123535302](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071235397.png) #### è·å–æ•°æ®é›†ä»¥åŠå¤„ç† ```python # æ–‡æœ¬åˆ†ç±»æ¨¡å‹å¾®è°ƒçš„ç¤ºä¾‹ from transformers import AutoTokenizer, AutoModelForSequenceClassification # åŠ è½½æ•°æ® import pandas as pd # data pd.read_csv(\"../dataset/ChnSentiCorp_htl_all.csv\") # data.head() # data data.dropna() # åˆ é™¤ç¼ºå¤±å€¼ # data.iloc[1] # åˆ›å»ºdataset from torch.utils.data import Dataset class MyDataset(Dataset): def __init__(self): super().__init__() self.data pd.read_csv(\"../dataset/ChnSentiCorp_htl_all.csv\") self.data self.data.dropna() def __len__(self): return len(self.data) def __getitem__(self, idx): return self.data.iloc[idx][\"review\"], self.data.iloc[idx][\"label\"] dataset MyDataset() for i in range(5): print(dataset[i]) \"\"\" ('è·ç¦»å·æ²™å…¬è·¯è¾ƒè¿‘,ä½†æ˜¯å…¬äº¤æŒ‡ç¤ºä¸å¯¹,å¦‚æœæ˜¯\"è”¡é™†çº¿\"çš„è¯,ä¼šéå¸¸éº»çƒ¦.å»ºè®®ç”¨åˆ«çš„è·¯çº¿.æˆ¿é—´è¾ƒä¸ºç®€å•.', 1) ('å•†åŠ¡å¤§åºŠæˆ¿ï¼Œæˆ¿é—´å¾ˆå¤§ï¼ŒåºŠæœ‰2Må®½ï¼Œæ•´ä½“æ„Ÿè§‰ç»æµå®æƒ ä¸é”™!', 1) ('æ—©é¤å¤ªå·®ï¼Œæ— è®ºå»å¤šå°‘äººï¼Œé‚£è¾¹ä¹Ÿä¸åŠ é£Ÿå“çš„ã€‚é…’åº—åº”è¯¥é‡è§†ä¸€ä¸‹è¿™ä¸ªé—®é¢˜äº†ã€‚æˆ¿é—´æœ¬èº«å¾ˆå¥½ã€‚', 1) ('å®¾é¦†åœ¨å°è¡—é“ä¸Šï¼Œä¸å¤§å¥½æ‰¾ï¼Œä½†è¿˜å¥½åŒ—äº¬çƒ­å¿ƒåŒèƒå¾ˆå¤š~å®¾é¦†è®¾æ–½è·Ÿä»‹ç»çš„å·®ä¸å¤šï¼Œæˆ¿é—´å¾ˆå°ï¼Œç¡®å®æŒºå°ï¼Œä½†åŠ ä¸Šä½ä»·ä½å› ç´ ï¼Œè¿˜æ˜¯æ— è¶…æ‰€å€¼çš„ï¼›ç¯å¢ƒä¸é”™ï¼Œå°±åœ¨å°èƒ¡åŒå†…ï¼Œå®‰é™æ•´æ´ï¼Œæš–æ°”å¥½è¶³ _ ã€‚ã€‚ã€‚å‘µè¿˜æœ‰ä¸€å¤§ä¼˜åŠ¿å°±æ˜¯ä»å®¾é¦†å‡ºå‘ï¼Œæ­¥è¡Œä¸åˆ°ååˆ†é’Ÿå°±å¯ä»¥åˆ°æ¢…å…°èŠ³æ•…å±…ç­‰ç­‰ï¼Œäº¬å‘³å°èƒ¡åŒï¼ŒåŒ—æµ·è·ç¦»å¥½è¿‘å‘¢ã€‚æ€»ä¹‹ï¼Œä¸é”™ã€‚æ¨èç»™èŠ‚çº¦æ¶ˆè´¹çš„è‡ªåŠ©æ¸¸æœ‹å‹~æ¯”è¾ƒåˆ’ç®—ï¼Œé™„è¿‘ç‰¹è‰²å°åƒå¾ˆå¤š~', 1) ('CBDä¸­å¿ƒ,å‘¨å›´æ²¡ä»€ä¹ˆåº—é“º,è¯´5æ˜Ÿæœ‰ç‚¹å‹‰å¼º.ä¸çŸ¥é“ä¸ºä»€ä¹ˆå«ç”Ÿé—´æ²¡æœ‰ç”µå¹é£', 1) \"\"\" # åˆ’åˆ†æ•°æ®é›† from torch.utils.data import random_split trainset, validset random_split(dataset, lengths [0.9, 0.1]) # ä¹±åºåˆ’åˆ†æ•°æ®é›† print(len(trainset), len(validset)) \"\"\" (6989, 776) \"\"\" # å»ºç«‹DataLoader from torch.utils.data import DataLoader trainloader DataLoader(trainset, batch_size 32, shuffle True) # ä¹±åº, ä¸€ç»„å¤§å°ä¸º32 validloader DataLoader(validset, batch_size 32, shuffle False) # ä¸ä¹±åº ``` > ![image 20241007130723273](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071307339.png) > > ä¹Ÿå¯ä»¥ä½¿ç”¨`next(enumerate(trainloader))` > > é»˜è®¤çš„æ—¶å€™ä½¿ç”¨è¿™ä¸€ä¸ªå‡½æ•°è¿›è¡Œèšåˆçš„ç»“æœæ˜¯æ–‡å­—èšé›†ä¸ºä¸€ä¸ªå…ƒç»„, æ•°å­—æ˜¯ä¸€ä¸ªtensor, å¦‚æœæƒ³è¦ä½¿ç”¨Tokenizerè¿›è¡Œå¤„ç†è¿™ä¸€ä¸ªæ•°æ®, æ–‡å­—ä¸ºä¸€ä¸ªlistå¯ä»¥é‡å†™ä¸€ä¸‹`collate_fn, input_idsæ˜¯Tokenizerå­—å…¸é‡Œé¢çš„ä¸€é¡¹çš„åå­—, ç”±äºåœ¨Bertæ¨¡å‹é‡Œé¢labelsæ˜¯å…¶ä¸­å¦ä¸€ä¸ªå‚æ•°, æ‰€ä»¥æŠŠè¿™ä¸¤ä¸ªæ‰“åŒ… > > ![image 20241007133339446](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410071333543.png) > > ```python > import torch > tokenizer AutoTokenizer.from_pretrained(\"../hlfrbt3\") > def j_collate_fn(batch): > texts, labels [], [] > for text, label in batch: > texts.append(text) > labels.append(label) > # 128æ˜¯æ¨¡å‹çš„æœ€å¤§é•¿åº¦ > inputs tokenizer(texts, padding \"max_length\", truncation True, max_length 128, > return_tensors \"pt\") > inputs[\"labels\"] torch.tensor(labels) > # è¿”å›ä¸€ä¸ªå­—å…¸é‡Œé¢ä¸¤ä¸ªValueä¸ºtensoræ ¼å¼ > return inputs > # å»ºç«‹DataLoader > from torch.utils.data import DataLoader > # ä¹±åº, ä¸€ç»„å¤§å°ä¸º32 > trainloader DataLoader(trainset, batch_size 32, shuffle True, collate_fn j_collate_fn) > # ä¸ä¹±åº > validloader DataLoader(validset, batch_size 32, shuffle False, collate_fn j_collate_fn) > ``` #### å¯¼å…¥æ¨¡å‹ä»¥åŠä¼˜åŒ– ```python from torch.optim import AdamW # å¯¼å…¥æ¨¡å‹ model AutoModelForSequenceClassification.from_pretrained(\"../hlfrbt3\") if torch.cuda.is_available(): model model.cuda() # å®šä¹‰ä¼˜åŒ–å™¨ optimizer AdamW(model.parameters(), lr 1e 5) # 1e 5æ˜¯å­¦ä¹ ç‡, è¿ç§»å­¦ä¹ ä½¿ç”¨çš„ä¸€èˆ¬æ¯”è¾ƒä½ ``` #### å®é™…è®­ç»ƒå‡½æ•° ```python def evaluate(): \"\"\" Description: è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½ Returns: æ¨¡å‹çš„å‡†ç¡®ç‡ \"\"\" model.eval() acc_num 0 with torch.no_grad(): for batch in validloader: if torch.cuda.is_available(): batch {k:v.cuda() for k, v in batch.items()} outputs model(**batch) pred outputs.logits.argmax(dim 1) # é¢„æµ‹çš„ç±»åˆ« acc_num + (pred batch[\"labels\"].long()).float().sum().item() return acc_num / len(validset) def train(epoch 3, log_step 100): \"\"\" Description: è®­ç»ƒæ¨¡å‹ Args: epoch (int, optional): è®­ç»ƒçš„æ¬¡æ•°. Defaults to 3. log_step (int, optional): æ‰“å°logçš„æ­¥é•¿. Defaults to 100. \"\"\" global_step 0 for ep in range(epoch): model.train() # éå†è®­ç»ƒé›† for batch in trainloader: # å°†æ•°æ®æ”¾åˆ°cudaä¸Š if torch.cuda.is_available(): batch {k:v.cuda() for k, v in batch.items()} optimizer.zero_grad() outputs model(**batch) outputs.loss.backward() optimizer.step() global_step + 1 if global_step % log_step 0: print(f\"epoch {ep}, global_step {global_step}, loss {outputs.loss.item()}\") # æ¯ä¸ªepochç»“æŸè¯„ä¼°ä¸€æ¬¡ acc evaluate() print(f\"epoch {ep}, acc {acc}\") ``` ```python print(f'before train {evaluate()}') train() ``` > ```bash > before train 0.31056701030927836 > epoch 0, global_step 100, loss 0.293989360332489 > epoch 0, global_step 200, loss 0.31614530086517334 > epoch 0, acc 0.8904639175257731 > epoch 1, global_step 300, loss 0.1351868063211441 > epoch 1, global_step 400, loss 0.17762571573257446 > epoch 1, acc 0.8865979381443299 > epoch 2, global_step 500, loss 0.17976289987564087 > epoch 2, global_step 600, loss 0.19925124943256378 > epoch 2, acc 0.8853092783505154 > ``` #### å®é™…ä½¿ç”¨ ```python sen \"æˆ‘è§‰å¾—è¿™å®¶é¥­åº—çš„é¥­å¾ˆå¥½åƒ, ä½“éªŒå¾ˆå¥½!\" with torch.inference_mode(): inputs tokenizer(sen, padding \"max_length\", truncation True, max_length 128, return_tensors \"pt\") if torch.cuda.is_available(): inputs {k:v.cuda() for k, v in inputs.items()} outputs model(**inputs) pred outputs.logits.argmax(dim 1) print(pred.item()) ``` + ä½¿ç”¨pipeè¿›è¡Œ ```python from transformers import pipeline model.config.id2label id2label # è¿™ä¸€æ­¥ä¹Ÿå¯ä»¥åœ¨æ¨¡å‹åŠ è½½çš„æ—¶å€™å®ç° pipe pipeline(\"text classification\", model model, tokenizer tokenizer, device 0 if torch.cuda.is_available() else 1) pipe(sen) ``` ## Dataset ### åŠ è½½ ä¸€ä¸ªå¯ä»¥æ–¹ä¾¿çš„ä»HuggingfaceåŠ è½½æ•°æ®é›†çš„åº“ è¿™é‡Œä½¿ç”¨çš„æ¨¡å‹æ˜¯[madao33/new title chinese Â· Datasets at Hugging Face](https://huggingface.co/datasets/madao33/new title chinese) ```python from datasets import * dataset load_dataset(\"madao33/new title chinese\") ``` > ```bash > DatasetDict({ > train: Dataset({ > features: ['title', 'content'], > num_rows: 5850 > }) > validation: Dataset({ > features: ['title', 'content'], > num_rows: 1679 > }) > }) > ``` å¯¹äºå…¶ä»–çš„ä¸€äº›æ•°æ®é›†, æ¯”å¦‚glueæ˜¯ä¸€ä¸ªä»»åŠ¡çš„é›†åˆ, éœ€è¦å†åŠ ä¸€ä¸ªå‚æ•°æŒ‡å®šå®é™…åŠ è½½çš„ä»»åŠ¡ ```python boolq_dataset load_dataset(\"super_glue\", \"boolq\", trust_remote_code True) boolq_dataset ``` > [aps/super_glue Â· Datasets at Hugging Face](https://huggingface.co/datasets/aps/super_glue) > > ```bash > Downloading data: 100%â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 4.12M/4.12M [00:01<00:00, 3.20MB/s] > Generating train split: 100%â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 9427/9427 [00:00<00:00, 14841.26 examples/s] > Generating validation split: 100%â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 3270/3270 [00:00<00:00, 28511.03 examples/s] > Generating test split: 100%â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 3245/3245 [00:00<00:00, 29980.43 examples/s] > DatasetDict({ > train: Dataset({ > features: ['question', 'passage', 'idx', 'label'], > num_rows: 9427 > }) > validation: Dataset({ > features: ['question', 'passage', 'idx', 'label'], > num_rows: 3270 > }) > test: Dataset({ > features: ['question', 'passage', 'idx', 'label'], > num_rows: 3245 > }) > }) > ``` > ä¸€ä¸ªæ•°æ®é›†åˆ†ä¸ºæ•°æ®é›†, éªŒè¯é›†, æµ‹è¯•é›†ä¸‰éƒ¨åˆ†, åªæƒ³åŠ è½½ä¸€éƒ¨åˆ†çš„è¯ ```python boolq_dataset_train load_dataset(\"super_glue\", \"boolq\", trust_remote_code True, split \"train\") ``` ä¹Ÿå¯ä»¥è¿›ä¸€æ­¥æ‹†åˆ† ```python boolq_dataset_train load_dataset(\"super_glue\", \"boolq\", trust_remote_code True, split \"train[:100]\") boolq_dataset_train load_dataset(\"super_glue\", \"boolq\", trust_remote_code True, split \"train[:10%]\") boolq_dataset_train load_dataset(\"super_glue\", \"boolq\", trust_remote_code True, split [\"train[:10%]\", \"validation[:10%]\"]) ``` ### æŸ¥çœ‹ ```python dataset[\"train\"][:2] dataset[\"train\"][\"title\"][:2] ``` ![image 20241007222540350](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072225595.png) ```python dataset[\"train\"].features dataset.column_names ``` ![image 20241007222715762](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072227852.png) > ä½¿ç”¨è¿™ç§ç›´æ¥é€‰å–çš„æ–¹å¼è·å–çš„æ•°æ®æ˜¯ä¸€ä¸ªå­—å…¸çš„æ¨¡å¼ ### åˆ’åˆ† å–ä¸€ä¸ªæ•°æ®é›†æŒ‰æ¯”ä¾‹åˆ’åˆ†ä¸ºè®­ç»ƒé›†ä»¥åŠæµ‹è¯•é›† ```python dataset[\"train\"].train_test_split(test_size 0.1, stratify_by_column \"lable\") ``` > åœ¨å®é™…åˆ’åˆ†çš„æ—¶å€™æŒ‡å®šå‚æ•°stratify_by_columnä¸ºä»¥åŠlableå¯ä»¥æŒ‰ç…§è¿™ä¸€ä¸ªæ ‡ç­¾åˆ’åˆ†çš„æ¯”è¾ƒå‡è¡¡ > > ![image 20241007223443044](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072234130.png) ### é€‰å–ä»¥åŠè¿‡æ»¤ ```python dataset[\"train\"].select([1, 2]) dataset[\"train\"].filter(lambda example: \"ä¸­å›½\" in example[\"title\"]) ``` ![image 20241007223822283](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072238368.png) ### æ•°æ®æ˜ å°„ å¯¹æ¯ä¸€æ¡æ•°æ®è¿›è¡ŒåŒä¸€ä¸ªå¤„ç† ```python def add_title(example): example[\"title\"] \"Predix: \" + example[\"title\"] return example prefix_dataset dataset.map(add_title) prefix_dataset[\"train\"][:2][\"title\"] ``` ![image 20241007224325640](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072243728.png) > ä¸ªæ¯ä¸€ä¸ªæ ‡é¢˜åŠ ä¸€ä¸ªå‰ç¼€ ```python from transformers import AutoTokenizer tokenizer AutoTokenizer.from_pretrained(\"bert base chinese\") def preprocess_function(examples): model_inputs tokenizer(examples[\"content\"], padding \"max_length\", truncation True, max_length 512) labels tokenizer(examples[\"title\"], padding \"max_length\", truncation True, max_length 32) model_inputs[\"labels\"] labels[\"input_ids\"] return model_inputs processed_dataset dataset.map(preprocess_function) ``` > ```bash > DatasetDict({ > train: Dataset({ > features: ['title', 'content', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'], > num_rows: 5850 > }) > validation: Dataset({ > features: ['title', 'content', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'], > num_rows: 1679 > }) > }) > ``` ```python processed_dataset dataset.map(preprocess_function, batched True) processed_dataset ``` > å¦‚æœå°† `batched True`ï¼Œåˆ™ `dataset` ä¸­çš„æ•°æ®å°†æŒ‰ç…§è®¾ç½®çš„æ‰¹å¤§å°è¿›è¡Œå¤„ç†ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡å¤„ç†ä¸€ä¸ªæ ·æœ¬ã€‚ > > ![image 20241007225823344](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072258436.png) ä¹Ÿå¯ä»¥ä½¿ç”¨å¤šçº¿ç¨‹çš„æ–¹å¼è¿›è¡ŒåŠ è½½ ```python processed_dataset dataset.map(preprocess_function, num_proc 4) processed_dataset ``` > åœ¨ä½¿ç”¨æµ‹ä¸€ä¸ªå‡½æ•°çš„æ—¶å€™, tokenizeræ˜¯ä¸å¯ä»¥ä¼ é€’åˆ°å­è¿›ç¨‹çš„, æ‰€ä»¥å¤„ç†çš„å‡½æ•°éœ€è¦æ”¹å˜ä¸€ä¸‹ > > ```python > from transformers import AutoTokenizer > tokenizer AutoTokenizer.from_pretrained(\"bert base chinese\") > def preprocess_function(examples, tokenizer tokenizer): > model_inputs tokenizer(examples[\"content\"], padding \"max_length\", truncation True, max_length 512) > labels tokenizer(examples[\"title\"], padding \"max_length\", truncation True, max_length 32) > model_inputs[\"labels\"] labels[\"input_ids\"] > return model_inputs > ``` å¯ä»¥åœ¨è¿™ä¸€ä¸ªå‡½æ•°é‡Œé¢ä½¿ç”¨å‚æ•°æŠŠä¸éœ€è¦çš„è¾“å‡ºå­—æ®µè¿›è¡Œåˆ é™¤ ```python processed_dataset dataset.map(preprocess_function, batched True, remove_columns dataset[\"train\"].column_names) processed_dataset ``` > å»é™¤åŸå§‹å­—æ®µ > > ![image 20241007230448456](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072304567.png) ### ä¿å­˜ä»¥åŠåŠ è½½ ```python processed_dataset.save_to_disk(\"my_dataset\") processed_dataset load_from_disk(\"my_dataset\") ``` ### åŠ è½½è‡ªå·±çš„æ•°æ®é›† å¦‚æœæ˜¯ä¸€ä¸ªcsvæ ¼å¼çš„æ•°æ®é›† ```python dataset load_dataset(\"csv\", data_files \"../dataset/ChnSentiCorp_htl_all.csv\") ``` ![image 20241007230845712](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072308817.png) å¦‚æœä¸å¸Œæœ›æœ‰è¿™ä¸€ä¸ªé»˜è®¤çš„åˆ†ç»„, å¯ä»¥åŠ ä¸€ä¸ªå‚æ•°å–æ¶ˆ ```python dataset load_dataset(\"csv\", data_files \"../dataset/ChnSentiCorp_htl_all.csv\", split \"train\") ``` ![image 20241007231055560](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072310661.png) ä¹Ÿå¯ä»¥ä½¿ç”¨å¦ä¸€ä¸ªå‡½æ•°åŠ è½½ ```python dataset Dataset.from_csv(\"E:/JHY/python/2024 10 5 transforms/dataset/ChnSentiCorp_htl_all.csv\") ``` ![image 20241007231431791](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072314904.png) åœ¨å®é™…åŠ è½½çš„æ—¶å€™å¯ä»¥æŒ‰ç…§ä¸€ä¸ªæ–‡ä»¶å¤¹è¿›è¡ŒåŠ è½½, ä¹Ÿå¯ä»¥æŠŠdata_filesæŒ‡å®šä¸ºä¸€ä¸ªæ•°ç»„ ```python dataset load_dataset(\"csv\", data_dir \"../dataset\", split \"train\") ``` ![image 20241007231614570](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410072316772.png) å¦‚æœæ˜¯æŒ‰ç…§pandasåŠ è½½çš„æ•°æ® ```python import pandas as pd df pd.read_csv(\"../dataset/ChnSentiCorp_htl_all.csv\") dataset Dataset.from_pandas(df) ``` ![image 20241008090421592](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410080919550.png) ä½¿ç”¨from_listçš„æ—¶å€™å®é™…æ˜¯ä»ä¸€ä¸ªå­—å…¸çš„listé‡Œé¢è¿›è¡ŒåŠ è½½ ```python list [{\"text\": \"abc\"}, {\"text\": \"bcd\"}] ``` å¦‚æœæ•°æ®éå¸¸çš„å¤æ‚, éœ€è¦é€šè¿‡è„šæœ¬çš„æ–¹å¼è¿›è¡ŒåŠ è½½, ä¹Ÿå¯ä»¥ä½¿ç”¨load_datasetè¿›è¡Œè„šæœ¬åŠ è½½ è¿™é‡Œä½¿ç”¨çš„æµ‹è¯•çš„æ–‡æœ¬æ˜¯cmrc2018 ![image 20241008091829631](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410080918749.png) åœ¨ç›´æ¥åŠ è½½çš„æ—¶å€™, éœ€è¦æŒ‡å®šå®é™…çš„æ•°æ®çš„ä½ç½®, å¦åˆ™åŠ è½½çš„æ•°æ®ä¼šåˆ†ç»„å‡ºé”™ ```python dataset_json load_dataset(\"json\", data_files \"../dataset/cmrc2018_trial.json\", field \"data\") ``` ![image 20241008092505281](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410080925401.png) å®é™…åŠ è½½çš„ä¹Ÿä¸æ˜¯å¾ˆå®Œæ•´ ```python import json import datasets from datasets import DownloadManager, DatasetInfo class CMRC2018TRIAL(datasets.GeneratorBasedBuilder): def _info(self) > DatasetInfo: \"\"\" infoæ–¹æ³•, å®šä¹‰æ•°æ®é›†çš„ä¿¡æ¯,è¿™é‡Œè¦å¯¹æ•°æ®çš„å­—æ®µè¿›è¡Œå®šä¹‰ :return: \"\"\" return datasets.DatasetInfo( description \"CMRC2018 trial\", features datasets.Features({ \"id\": datasets.Value(\"string\"), \"context\": datasets.Value(\"string\"), \"question\": datasets.Value(\"string\"), \"answers\": datasets.features.Sequence( { \"text\": datasets.Value(\"string\"), \"answer_start\": datasets.Value(\"int32\"), } ) }) ) def _split_generators(self, dl_manager: DownloadManager): \"\"\" è¿”å›datasets.SplitGenerator æ¶‰åŠä¸¤ä¸ªå‚æ•°: nameå’Œgen_kwargs name: æŒ‡å®šæ•°æ®é›†çš„åˆ’åˆ† gen_kwargs: æŒ‡å®šè¦è¯»å–çš„æ–‡ä»¶çš„è·¯å¾„, ä¸_generate_examplesçš„å…¥å‚æ•°ä¸€è‡´ :param dl_manager: :return: [ datasets.SplitGenerator ] \"\"\" return [datasets.SplitGenerator(name datasets.Split.TRAIN, gen_kwargs {\"filepath\": \"../dataset/cmrc2018_trial.json\"})] def _generate_examples(self, filepath): \"\"\" ç”Ÿæˆå…·ä½“çš„æ ·æœ¬, ä½¿ç”¨yield éœ€è¦é¢å¤–æŒ‡å®škey, idä»0å¼€å§‹è‡ªå¢å°±å¯ä»¥ :param filepath: :return: \"\"\" # Yields (key, example) tuples from the dataset with open(filepath, encoding \"utf 8\") as f: data json.load(f) for example in data[\"data\"]: for paragraph in example[\"paragraphs\"]: context paragraph[\"context\"].strip() for qa in paragraph[\"qas\"]: question qa[\"question\"].strip() id_ qa[\"id\"] answer_starts [answer[\"answer_start\"] for answer in qa[\"answers\"]] answers [answer[\"text\"].strip() for answer in qa[\"answers\"]] \t\t\t\t\t # è¿”å›å€¼çš„ç¬¬ä¸€ä¸ªå­—æ®µæ˜¯ä¸€ä¸ªid, ä¹‹åæ˜¯å’Œ_split_generators # å­—æ®µé‡Œé¢çš„å£°æ˜ä¸€æ ·çš„æ•°æ® yield id_, { \"context\": context, \"question\": question, \"id\": id_, \"answers\": { \"answer_start\": answer_starts, \"text\": answers, }, } ``` ```python dataset_json load_dataset(\"../python src/load_script.py\", split \"train\", trust_remote_code True) num 0 for example in dataset_json: num + 1 print(example) if num 5: break ``` ![image 20241008094720254](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410080947382.png) ### Dataset with DataCollator transformså†…ç½®ä¸€éƒ¨åˆ†çš„DataCollator, æ˜¯ä¸éœ€è¦æˆ‘ä»¬è‡ªå·±å†™çš„ è¿™æ—¶å€™çš„æ•°æ®è¿˜æ˜¯list, å¸Œæœ›ä½¿ç”¨dataloaderæŠŠæ•°æ®æ‹¼æ¥ä¸ºbatchçš„tensor **æ³¨: **ä½¿ç”¨è¿™ä¸€ä¸ªçš„æ—¶å€™é‡Œé¢çš„æ•°æ®åªèƒ½æœ‰transformåŸå§‹çš„å­—æ®µ ```bash {'label': [1, 1, 1], 'input_ids': [[101, 6655, 4895, 2335, 3763, 1062, 6662, 6772, 6818, 117, 852, 3221, 1062, 769, 2900, 4850, 679, 2190, 117, 1963, 3362, 3221, 107, 5918, 7355, 5296, 107, 4638, 6413, 117, 833, 7478, 2382, 7937, 4172, 119, 2456, 6379, 4500, 1166, 4638, 6662, 5296, 119, 2791, 7313, 6772, 711, 5042, 1296, 119, 102], [101, 1555, 1218, 1920, 2414, 2791, 8024, 2791, 7313, 2523, 1920, 8024, 2414, 3300, 100, 2160, 8024, 3146, 860, 2697, 6230, 5307, 3845, 2141, 2669, 679, 7231, 106, 102], [101, 3193, 7623, 1922, 2345, 8024, 3187, 6389, 1343, 1914, 2208, 782, 8024, 6929, 6804, 738, 679, 1217, 7608, 1501, 4638, 511, 6983, 2421, 2418, 6421, 7028, 6228, 671, 678, 6821, 702, 7309, 7579, 749, 511, 2791, 7313, 3315, 6716, 2523, 1962, 511, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]} ``` ```python collator DataCollatorWithPadding(tokenizer tokenizer) from torch.utils.data import DataLoader data_loader DataLoader(tokenized_datasets, collate_fn collator, batch_size 8, shuffle True) ``` ```bash {'input_ids': tensor([[ 101, 677, 1453, ..., 0, 0, 0], [ 101, 4384, 1862, ..., 0, 0, 0], [ 101, 2791, 7313, ..., 0, 0, 0], ..., [ 101, 4289, 5401, ..., 0, 0, 0], [ 101, 1168, 6809, ..., 3613, 738, 102], [ 101, 2791, 7313, ..., 0, 0, 0]]), 'token_type_ids': tensor([[0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], ..., [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, ..., 0, 0, 0], [1, 1, 1, ..., 0, 0, 0], [1, 1, 1, ..., 0, 0, 0], ..., [1, 1, 1, ..., 0, 0, 0], [1, 1, 1, ..., 1, 1, 1], [1, 1, 1, ..., 0, 0, 0]]), 'labels': tensor([1, 1, 1, 1, 0, 1, 0, 1])} ``` > å®é™…å¡«å……ä¼šæŠŠæ•°æ®å¡«å……åˆ°è¿™ä¸€ä¸ªæ‰¹æ¬¡é‡Œé¢æœ€é•¿çš„ ### å®é™…ä½¿ç”¨ ```python from transformers import DataCollatorWithPadding dataset load_dataset(\"csv\", data_files \"../dataset/ChnSentiCorp_htl_all.csv\", split \"train\") dataset dataset.filter(lambda example: example[\"review\"] is not None) # for data in dataset: # print(data) def process_function(examples): # æš‚æ—¶ä¸å¡«å……, ç»„æˆbatchæ—¶å†å¡«å…… tokenized_example tokenizer(examples[\"review\"], max_length 128, truncation True) tokenized_example[\"label\"] examples[\"label\"] return tokenized_example tokenized_datasets dataset.map(process_function, batched True, remove_columns dataset.column_names) print(tokenized_datasets[:3]) ``` ```bash {'label': [1, 1, 1], 'input_ids': [ [101, 6655, 4895, 2335, 3763, 1062, 6662, 6772, 6818, 117, 852, 3221, 1062, 769, 2900, 4850, 679, 2190, 117, 1963, 3362, 3221, 107, 5918, 7355, 5296, 107, 4638, 6413, 117, 833, 7478, 2382, 7937, 4172, 119, 2456, 6379, 4500, 1166, 4638, 6662, 5296, 119, 2791, 7313, 6772, 711, 5042, 1296, 119, 102], [101, 1555, 1218, 1920, 2414, 2791, 8024, 2791, 7313, 2523, 1920, 8024, 2414, 3300, 100, 2160, 8024, 3146, 860, 2697, 6230, 5307, 3845, 2141, 2669, 679, 7231, 106, 102], [101, 3193, 7623, 1922, 2345, 8024, 3187, 6389, 1343, 1914, 2208, 782, 8024, 6929, 6804, 738, 679, 1217, 7608, 1501, 4638, 511, 6983, 2421, 2418, 6421, 7028, 6228, 671, 678, 6821, 702, 7309, 7579, 749, 511, 2791, 7313, 3315, 6716, 2523, 1962, 511, 102] ], 'token_type_ids': [ [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ], 'attention_mask': [ [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] ] } ``` è¿™æ—¶å€™çš„æ•°æ®è¿˜æ˜¯list, å¸Œæœ›ä½¿ç”¨dataloaderæŠŠæ•°æ®æ‹¼æ¥ä¸ºbatchçš„tensor ```python collator DataCollatorWithPadding(tokenizer tokenizer) from torch.utils.data import DataLoader data_loader DataLoader(tokenized_datasets, collate_fn collator, batch_size 8, shuffle True) ``` æŠŠæ•°æ®è½¬ä¸ºbatch tensorä»¥åŠè¿›è¡Œå¡«å…… ### ä»£ç ä¼˜åŒ– ```python # æ–‡æœ¬åˆ†ç±»æ¨¡å‹å¾®è°ƒçš„ç¤ºä¾‹ from transformers import AutoTokenizer, AutoModelForSequenceClassification # åŠ è½½æ•°æ®é›† from datasets import load_dataset dataset load_dataset(\"csv\", data_files \"../dataset/ChnSentiCorp_htl_all.csv\", split \"train\") dataset dataset.filter(lambda example: example[\"review\"] is not None and example[\"label\"] is not None) print(dataset) \"\"\" Dataset({ features: ['label', 'review'], num_rows: 7765 }) \"\"\" # åˆ’åˆ†æ•°æ®é›†, è·å–è®­ç»ƒé›†ä»¥åŠæµ‹è¯•é›† datasets dataset.train_test_split(test_size 0.1) datasets \"\"\" DatasetDict({ train: Dataset({ features: ['label', 'review'], num_rows: 6988 }) test: Dataset({ features: ['label', 'review'], num_rows: 777 }) }) \"\"\" import torch tokenizer AutoTokenizer.from_pretrained(\"../hlfrbt3\") def process_function(examples): # æš‚æ—¶ä¸å¡«å……, ç»„æˆbatchæ—¶å†å¡«å…… tokenized_example tokenizer(examples[\"review\"], max_length 128, truncation True) tokenized_example[\"label\"] examples[\"label\"] return tokenized_example # å¤„ç†æ•°æ®é›†, æŠŠæ•°æ®é›†è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„æ ¼å¼(åˆ†è¯å™¨ç¼–ç åçš„æ ¼å¼) tokenized_datasets datasets.map(process_function, batched True, remove_columns datasets[\"train\"].column_names) tokenized_datasets \"\"\" DatasetDict({ train: Dataset({ features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'], num_rows: 6988 }) test: Dataset({ features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'], num_rows: 777 }) }) \"\"\" # å»ºç«‹DataLoader from torch.utils.data import DataLoader from transformers import DataCollatorWithPadding trainset tokenized_datasets[\"train\"] validset tokenized_datasets[\"test\"] # ä¹±åº, ä¸€ç»„å¤§å°ä¸º32, è¿›è¡Œå¡«å…… trainloader DataLoader(trainset, batch_size 32, shuffle True, collate_fn DataCollatorWithPadding(tokenizer)) validloader DataLoader(validset, batch_size 32, shuffle False, collate_fn DataCollatorWithPadding(tokenizer)) # ä¸ä¹±åº ``` ## Evaluate æ˜¯ä¸€ä¸ªæœºå™¨å­¦ä¹ çš„æ¨¡å‹è¯„ä¼°å‡½æ•°åº“, åªéœ€è¦ä¸€è¡Œä»£ç å¯ä»¥åŠ è½½å„ç§ä»»åŠ¡çš„è¯„ä¼°å‡½æ•° [ğŸ¤— Evaluate (huggingface.co)](https://huggingface.co/docs/evaluate/index) ![image 20241008115134639](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410081151914.png) ```python import evaluate evaluate.list_evaluation_modules() ``` > å¯ä»¥ä½¿ç”¨è¿™ä¸ªå‡½æ•°è·å–å¯ä»¥ä½¿ç”¨çš„è¯„ä¼°å‡½æ•°, è¿™é‡Œé¢æœ‰ä¸€éƒ¨åˆ†Huggingfaceå®ç°, å¦ä¸€éƒ¨åˆ†æ˜¯ç¤¾åŒºå®ç°çš„, ä¸æƒ³çœ‹ç¤¾åŒºå®ç°çš„æ—¶å€™å¯ä»¥åŠ ä¸€ä¸ªå‚æ•°`include_community False` > > å¯ä»¥ä½¿ç”¨å‚æ•°`with_details True`è·å–æ›´è¯¦ç»†çš„ä¿¡æ¯ > > ![image 20241008170841605](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410081708806.png) ```python accuracy evaluate.load('accuracy') # åŠ è½½ print(accuracy.description) # è·å–æè¿°ä»¥åŠè®¡ç®—æ–¹å¼ \"\"\" Accuracy is the proportion of correct predictions among the total number of cases processed. It can be computed with: Accuracy (TP + TN) / (TP + TN + FP + FN) Where: TP: True positive TN: True negative FP: False positive FN: False negative \"\"\" print(accuracy.inputs_description) \"\"\" Args: predictions (`list` of `int`): Predicted labels. references (`list` of `int`): Ground truth labels. normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True. sample_weight (`list` of `float`): Sample weights Defaults to None. Returns: accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy. Examples: Example 1 A simple example >>> accuracy_metric evaluate.load(\"accuracy\") >>> results accuracy_metric.compute(references [0, 1, 2, 0, 1, 2], predictions [0, 1, 1, 2, 1, 0]) >>> print(results) {'accuracy': 0.5} Example 2 The same as Example 1, except with `normalize` set to `False`. >>> accuracy_metric evaluate.load(\"accuracy\") >>> results accuracy_metric.compute(references [0, 1, 2, 0, 1, 2], predictions [0, 1, 1, 2, 1, 0], normalize False) >>> print(results) {'accuracy': 3.0} Example 3 The same as Example 1, except with `sample_weight` set. >>> accuracy_metric evaluate.load(\"accuracy\") >>> results accuracy_metric.compute(references [0, 1, 2, 0, 1, 2], predictions [0, 1, 1, 2, 1, 0], sample_weight [0.5, 2, 0.7, 0.5, 9, 0.4]) >>> print(results) {'accuracy': 0.8778625954198473} \"\"\" ``` > ç›´æ¥æ‰“å°çš„æ—¶å€™ä¼šæŠŠæ‰€æœ‰çš„æ•°æ®æ‰“å°å‡ºæ¥ ```python result accuracy.compute(references [0, 1, 1, 0], predictions [0, 1, 0, 1]) result ``` åœ¨å®é™…åº”ç”¨çš„æ—¶å€™æ•°æ®å¯èƒ½ä¸æ˜¯ä¸€æ¬¡æ€§ä¼ è¿›æ¥çš„ ```python for ref, pred in zip([0, 1, 1, 0], [0, 1, 1, 0]): accuracy.add(references ref, predictions pred) accuracy.compute() ``` ```python for ref, pred in zip([[0, 1, 1, 0], [0, 1, 1, 0]], [[0, 1, 0, 1], [0, 1, 1, 0]]): accuracy.add_batch(references ref, predictions pred) accuracy.compute() ``` > ```python > zip_data zip([[0, 1, 1, 0], [0, 1, 1, 0]], [[0, 1, 0, 1], [0, 1, 1, 0]]) > list(zip_data) > \"\"\" > [([0, 1, 1, 0], [0, 1, 0, 1]), ([0, 1, 1, 0], [0, 1, 1, 0])] > \"\"\" > for ref, pred in zip([[0, 1, 1, 0], [0, 1, 1, 0]], [[0, 1, 0, 1], [0, 1, 1, 0]]): > print(ref, pred) > \"\"\" > [0, 1, 1, 0] [0, 1, 0, 1] > [0, 1, 1, 0] [0, 1, 1, 0] > \"\"\" > ``` ### å¤šæŒ‡æ ‡è¯„ä¼°å‡½æ•° å¯ä»¥åœ¨åŒæ—¶è¿›è¡Œå¤šä¸ªè¯„ä¼°å‡½æ•° ```python clf_metrics evaluate.combine(['accuracy', 'precision', 'recall', 'f1']) clf_metrics.compute(references [0, 1, 1, 0], predictions [0, 1, 0, 1]) \"\"\" {'accuracy': 0.5, 'precision': 0.5, 'recall': 0.5, 'f1': 0.5} \"\"\" ``` ### è¯„ä¼°ç»“æœå¯è§†åŒ– è¿™ä¸€ä¸ªåº“åªæœ‰ä¸€ä¸ªé›·è¾¾å›¾çš„æ–¹å¼è¿›è¡Œå¯¹æ¯”ä¸åŒæ¨¡å‹çš„ç»“æœ ```python from evaluate.visualization import radar_plot data [ {\"accuracy\": 0.98, \"precision\": 0.97, \"recall\": 0.99, \"f1\": 0.98}, {\"accuracy\": 0.96, \"precision\": 0.99, \"recall\": 0.97, \"f1\": 0.96}, {\"accuracy\": 0.92, \"precision\": 0.96, \"recall\": 0.99, \"f1\": 0.97}, ] model_names [\"model1\", \"model2\", \"model3\"] plot radar_plot(data, model_names) ``` ### å®é™…åº”ç”¨ ```python import evaluate clf_metrics evaluate.combine(['accuracy', 'f1']) def evaluate(): \"\"\" Description: è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½ Returns: æ¨¡å‹çš„å‡†ç¡®ç‡ \"\"\" model.eval() with torch.no_grad(): for batch in validloader: if torch.cuda.is_available(): batch {k:v.cuda() for k, v in batch.items()} outputs model(**batch) pred outputs.logits.argmax(dim 1) # é¢„æµ‹çš„ç±»åˆ« clf_metrics.add_batch(predictions pred.long(), references batch[\"labels\"].long()) return clf_metrics.compute() ``` ## Trainer ![image 20241008190813102](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410081908319.png) [Trainer (huggingface.co)](https://huggingface.co/docs/transformers/trainer) ```python from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments # è·å–å‚æ•°é›† train_args TrainingArguments(output_dir \"./checkpoints\", save_safetensors True) train_args from transformers import DataCollatorWithPadding # è®­ç»ƒæ¨¡å‹ # args: # model: æ¨¡å‹ # args: è®­ç»ƒå‚æ•° # train_dataset: è®­ç»ƒæ•°æ®é›† # eval_dataset: è¯„ä¼°æ•°æ®é›† # data_collator: æ•°æ®æ”¶é›†å™¨ # compute_metrics: è¯„ä¼°æŒ‡æ ‡ trainer Trainer(model model, args train_args, train_dataset tokenized_datasets[\"train\"], eval_dataset tokenized_datasets[\"test\"], data_collator DataCollatorWithPadding(tokenizer tokenizer), compute_metrics eval_metrics) trainer.train() ``` åœ¨ä½¿ç”¨è¿™ä¸€ä¸ªçš„æ—¶å€™å°±ä¸å†éœ€è¦dataloaderäº†, æ•°æ®ç»è¿‡é¢„å¤„ç†å°±å¯ä»¥ä½¿ç”¨äº†, ä¹Ÿä¸å†éœ€è¦ä½¿ç”¨cudaåˆ¤å®š åœ¨æ¯”è¾ƒé«˜çš„ç‰ˆæœ¬ä¼šå‡ºç°è®­ç»ƒå¤±è´¥çš„é—®é¢˜, å¯ä»¥é€šè¿‡é™ä½ç‰ˆæœ¬è§£å†³ ```bash pip install U transforners 4.42.4 ``` ä½¿ç”¨æœ€å°‘çš„å‚æ•°çš„æ—¶å€™ä¸ä¼šè¿›è¡Œæµ‹è¯„, å¯ä»¥ä½¿ç”¨`trainer.evaluate()`è¿›è¡Œæµ‹è¯„, å‚æ•°å¯ä»¥å•ç‹¬æŒ‡å®šä½¿ç”¨çš„æµ‹è¯•é›† ä¹Ÿå¯ä»¥ä½¿ç”¨`trainer.predict(tokenized_datasets[\"test\"])`è¿›è¡Œé¢„æµ‹ ### ä¸»è¦çš„å‚æ•° #### æ•°æ®é›† ```python per_device_train_batch_size 64,per_device_eval_batch_size 128 ``` > æ”¹å˜ä¸€ä¸‹è®­ç»ƒçš„æ—¶å€™ä½¿ç”¨batch_size #### log ```python logging_steps 100 ``` è®¾ç½®ä¸º100æ­¥æ‰“å°ä¸€æ¬¡log #### è¯„ä¼° ```python evaluation_strategy \"epoch\" ``` æ¯ä¸€è½®è¿›è¡Œä¸€æ¬¡è¯„ä¼° ```python evaluation_strategy \"steps\",eval_steps 100 ``` æ¯100æ­¥ä¸€æ¬¡ ```python metric_for_best_model \"f1\" ``` > ä½¿ç”¨å“ªä¸€ä¸ªè¯„ä»·è¿™ä¸€ä¸ªæ¨¡å‹æœ€å¥½ #### ä¿å­˜ ```python save_strategy \"epoch\" ``` ä¿å­˜çš„ç­–ç•¥ä¸ºæ¯ä¸€è½® ```python save_total_limit 3 ``` æœ€å¤šè®°å½•çš„æ¨¡å‹è½®æ•° ```python load_best_model_at_end True ``` åœ¨æœ€åç•™ä¸‹æ¥è®­ç»ƒçš„æœ€å¥½çš„(ä¹‹åçš„æ¨¡å‹åŠ è½½çš„æ˜¯è¿™ä¸€è½®é‡Œé¢çš„å‚æ•°) #### è®­ç»ƒ ```python learning_rate 2e 5, weight_decay 0.01 ``` > è®­ç»ƒçš„å­¦ä¹ é€Ÿç‡ä»¥åŠæƒé‡è¡°å‡(é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆ) #### ç»“æœ ç”Ÿæˆçš„runsè¿™ä¸€ä¸ªæ–‡ä»¶å¤¹å¯ä»¥ä½¿ç”¨tensorboardæŸ¥çœ‹ ```bash tensorboard logdir dir ``` ä¹Ÿå¯ä»¥ä½¿ç”¨vscodeå¯åŠ¨ ![image 20241009195025104](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/image/202410091950114.png) ## æœ€ç»ˆçš„ç¤ºä¾‹ + åŠ è½½æ•°æ® ```python # æ–‡æœ¬åˆ†ç±»æ¨¡å‹å¾®è°ƒçš„ç¤ºä¾‹ from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments # åŠ è½½æ•°æ®é›† from datasets import load_dataset # ä½¿ç”¨CSVæ–‡ä»¶åŠ è½½æ•°æ®é›†, é»˜è®¤çš„æ—¶å€™æ²¡æœ‰åˆ†ä¸ºä¸åŒè®­ç»ƒé›† dataset load_dataset(\"csv\", data_files \"../dataset/ChnSentiCorp_htl_all.csv\", split \"train\") # å»é™¤æ•°æ®é›†é‡Œé¢çš„æ— çº¿æ•°æ® dataset dataset.filter(lambda example: example[\"review\"] is not None and example[\"label\"] is not None) # åˆ’åˆ†æ•°æ®é›†, æ•°æ®é›†çš„0.1ä¸ºæµ‹è¯•é›† datasets dataset.train_test_split(test_size 0.1) ``` + åˆ†è¯å™¨ ```python import torch tokenizer AutoTokenizer.from_pretrained(\"../hlfrbt3\") # å¯¹æ•°æ®é¢„å¤„ç†, æŠŠæ•°æ®è½¬æ¢ä¸ºtensor, ä»¥åŠåŠ å…¥ç›®æ ‡å€¼, # è¿™é‡Œçš„æ•°æ®æ ¼å¼å¦‚ä¸‹ \"\"\" DatasetDict({ train: Dataset({ features: ['label', 'review'], num_rows: 6988 }) test: Dataset({ features: ['label', 'review'], num_rows: 777 }) }) \"\"\" def process_function(examples): # æš‚æ—¶ä¸å¡«å……, ç»„æˆbatchæ—¶å†å¡«å…… tokenized_example tokenizer(examples[\"review\"], max_length 128, truncation True) tokenized_example[\"labels\"] examples[\"label\"] return tokenized_example # å¤„ç†æ•°æ®é›†, æŠŠæ•°æ®é›†è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„æ ¼å¼(åˆ†è¯å™¨ç¼–ç åçš„æ ¼å¼) # remove_columnså»é™¤åŸå§‹çš„æ•°æ® tokenized_datasets datasets.map(process_function, batched True, remove_columns datasets[\"train\"].column_names) # æ­¤æ—¶çš„æ•°æ®æ ¼å¼å¦‚ä¸‹ \"\"\" DatasetDict({ train: Dataset({ features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'], num_rows: 6988 }) test: Dataset({ features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'], num_rows: 777 }) }) \"\"\" ```"},"/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-2-16-langChain.html":{"title":"LangChain","content":"# LangChain ## æ¶æ„ + LangSmith: ç›‘æ§ + LangServe: æœåŠ¡å™¨å¤„ç† + Templates: æ¨¡æ¿ + LangChain: æ™ºèƒ½è°ƒç”¨, Agentså¼€å‘ä»¥åŠæ£€ç´¢ç­–ç•¥ + LangChainCommunity: ç¤¾åŒº, æ”¯æŒå„ç§å¤§æ¨¡å‹, æç¤ºè¯ç­‰çš„å¤„ç†, è¾“å…¥å†…å®¹çš„æ ¼å¼åŒ–, å·¥å…·è°ƒç”¨çš„æ”¯æŒ + LangChainCore: LCELè¡¨è¾¾å¼è¯­è¨€çš„æ‰§è¡Œ ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://i blog.csdnimg.cn/blog_migrate/faaf313af63c5029c7983192c1f43bd2.png) ä¸»è¦çš„ç»„æˆ + LangChainåº“, æœ‰Pythonå’Œjava, é‡Œé¢æœ‰å„ç§ç»„ä»¶çš„æ¥å£ä»¥åŠè¿è¡Œçš„åŸºç¡€ + LangChainæ¨¡æ¿: æä¾›çš„AIæ¨¡æ¿ + LangServer: FastAPIæŠŠLangChainçš„é“¾(Chain)å‘å¸ƒä¸ºREST API + LangSmith: å¼€å‘å¹³å°äº‘æœåŠ¡ åº“ + langchain core: åŸºç¡€çš„æŠ½è±¡ä»¥åŠLangChainçš„è¡¨è¾¾è¯­è¨€ + langchain community: ç¬¬ä¸‰å‘é›†æˆ + langchain: é“¾ä»¥åŠä»£ç†å’Œagentæ£€ç´¢ç­–ç•¥ ![image 20250218132339058](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181323177.png) > è¾“å…¥å’Œæ¨¡æ¿ç»“åˆä»¥åè¾“å…¥åˆ°LLMé‡Œé¢, è¿›è¡Œå¤„ç†è·å¾—è¾“å‡º, æŒ‰ç…§å®¢æˆ·éœ€æ±‚çš„æ ¼å¼è¿›è¡Œç»„è£… > > LLM: é—®ç­”æ¨¡å‹, è¾“å…¥ä¸€ä¸ªæ–‡æœ¬, è¿”å›ä¸€ä¸ªæ–‡æœ¬ > > Chat Model: å¯¹è¯æ¨¡å‹, æ¥æ”¶ä¸€ç»„å¯¹è¯, è¿”å›å¯¹è¯æ¶ˆæ¯, å’ŒèŠå¤©ç±»ä¼¼ æ ¸å¿ƒæ¦‚å¿µ + LLMs å°è£…çš„åŸºç¡€æ¨¡å‹, æ¥å—ä¸€ä¸ªæ–‡æœ¬çš„è¾“å…¥, è¿”å›ä¸€ä¸ªç»“æœ + ChatModels èŠå¤©æ¨¡å‹, å’ŒLLMsä¸åŒ, å‘³è•¾å¯¹è¯è®¾è®¡, å¯ä»¥å¤„ç†é•¿ä¸‹æ–‡ + æ¶ˆæ¯Message èŠå¤©æ¨¡å‹çš„æ¶ˆæ¯å†…å®¹, æœ‰å¤šç§HumanMessage, AIMessage, SystemMessage, FunctionMessage, ToolMessageç­‰ + æç¤ºprompts æ ¼å¼åŒ–æç¤ºè¯ + è¾“å‡ºè§£é‡Šå™¨ llmè¿”å›ä»¥åä½¿ç”¨ä¸“é—¨çš„è§£é‡Šå™¨è¿›è¡Œæ ¼å¼åŒ–ä¸ºjsonä¹‹ç±»çš„ + Retrievers ç§æœ‰æ•°æ®å¯¼å…¥å¤§æ¨¡å‹, æé«˜é—®é¢˜çš„è´¨é‡, LangChainå°è£…äº†æ£€ç´¢çš„æ¡†æ¶Retrieveers, å¯ä»¥åŠ å…¥æ–‡æ¡£, åˆ‡å‰², å­˜å‚¨æœç´¢ + å‘é‡å­˜å‚¨Vector stores ç§æœ‰æ•°æ®çš„è¯­ä¹‰ç›¸ä¼¼æ£€ç´¢, æ”¯æŒå¤šç§å‘é‡æ•°æ®åº“ + Agent æ™ºèƒ½ä½“, ä»¥LLMä¸ºå†³ç­–å¼•æ“, æ ¹æ®ç”¨æˆ·çš„è¾“å…¥, è‡ªåŠ¨è°ƒç”¨å¤–éƒ¨ç³»ç»Ÿå’Œè®¾å¤‡å®Œæˆä»»åŠ¡ ## ç®€å•ç¤ºä¾‹ ```python from langchain_core.prompts import ChatPromptTemplate from langchain_openai import ChatOpenAI import os os.environ[\"OPENAI_BASE_URL\"] \"https://api.chatanywhere.tech\" llm ChatOpenAI() prompt ChatPromptTemplate.from_messages([ (\"system\", \"ä½ æ˜¯ä¸€ä¸ªå›¾ä¹¦ç®¡ç†å‘˜ã€‚\"), (\"user\", \"{input}\"), ]) # é€šè¿‡LangChainçš„é“¾å¼è°ƒç”¨ç”Ÿæˆä¸€ä¸ªchainå¯¹è±¡ chain prompt llm # æ‰“å°ç”Ÿæˆçš„å¯¹è¯ result chain.invoke({\"input\": \"ä½ å¥½ï¼Œç»™æˆ‘æ¨èä¸€ä¸ªæ•…äº‹ä¹¦ã€‚\"}) print(result) \"\"\" content 'ä½ å¥½ï¼Œæˆ‘æ¨èç»™ä½ ä¸€æœ¬ç»å…¸çš„æ•…äº‹ä¹¦ã€Šå°ç‹å­ã€‹ã€‚è¿™æœ¬ä¹¦ç”±æ³•å›½ä½œå®¶å®‰æ‰˜ä¸‡Â·å¾·Â·åœ£ åŸƒå…‹çµ®ä½åˆ›ä½œï¼Œè®²è¿°äº†ä¸€ä¸ªå°ç‹å­åœ¨å®‡å®™ä¸­çš„å†’é™©æ•…äº‹ï¼Œé€šè¿‡ä»–å’Œå„ç§å¥‡ç‰¹è§’è‰²çš„ç›¸é‡ï¼Œæ­ç¤ºäº†äººç”Ÿã€å‹æƒ…ã€çˆ±æƒ…ã€è´£ä»»ç­‰æ·±åˆ»çš„ä¸»é¢˜ï¼Œæ˜¯ä¸€éƒ¨å¯Œæœ‰å“²ç†çš„ä½œå“ã€‚å¸Œæœ›ä½ ä¼šå–œæ¬¢è¿™æœ¬ä¹¦ï¼' additional_kwargs {'refusal': None} response_metadata {'token_usage': {'completion_tokens': 149, 'prompt_tokens': 32, 'total_tokens': 181, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt 3.5 turbo 0125', 'system_fingerprint': 'fp_0165350fbb', 'finish_reason': 'stop', 'logprobs': None} id 'run b9a821df af44 429d 906c 8f5ddb6a46e7 0' usage_metadata {'input_tokens': 32, 'output_tokens': 149, 'total_tokens': 181, 'input_token_details': {}, 'output_token_details': {}} \"\"\" # ä½¿ç”¨ä¸‹é¢çš„æ–¹å¼å¯ä»¥æ”¹å˜è¾“å‡ºçš„æ ¼å¼ from langchain_core.output_parsers import StrOutputParser output_parser StrOutputParser() chain prompt llm output_parser \"\"\" ä½ å¥½ï¼å½“ç„¶å¯ä»¥ã€‚æˆ‘æ¨èä½ é˜…è¯»ã€Šå°ç‹å­ã€‹è¿™æœ¬ä¹¦ã€‚è¿™æ˜¯ä¸€æœ¬ç»å…¸çš„ç«¥è¯æ•…äº‹ï¼Œè®²è¿°äº†ä¸€ä½ç‹å­åœ¨ä¸åŒæ˜Ÿçƒä¸Šçš„å†’é™©æ•…äº‹ï¼Œä»¥åŠä»–ä¸ä¸€åªç‹ç‹¸å’Œä¸€æœµç«ç‘°çš„æ„Ÿäººæƒ…æ„Ÿçº è‘›ã€‚è¿™æœ¬ä¹¦æ·±åˆ»åœ°æ¢è®¨äº†å‹è°Šã€çˆ±æƒ…å’Œäººç”Ÿæ„ä¹‰çš„ä¸»é¢˜ï¼Œæ˜¯ä¸€éƒ¨æ„Ÿäººè‡³æ·±çš„æ–‡å­¦ä½œå“ã€‚å¸Œæœ›ä½ ä¼šå–œæ¬¢ï¼ \"\"\" ``` ## æç¤ºè¯å·¥ç¨‹ å’ŒAIè¿›è¡Œæ²Ÿé€šçš„æ—¶å€™éœ€è¦ä½¿ç”¨æç¤ºè¯å’ŒAIè¿›è¡Œå¯¹è¯, åŒæ—¶AIå¯èƒ½å‡ºç°å¹»è§‰, å¼€å‘çš„æ—¶å€™ä¸å¯ä»¥ç›´æ¥è¿›è¡Œç¡¬ç¼–, ä¸åˆ©äºæç¤ºè¯ç®¡ç†, é€šè¿‡æç¤ºè¯çš„æ¨¡æ¿è¿›è¡Œç»´æŠ¤ å®é™…ç”¨æˆ·çš„è¾“å…¥åªæ˜¯æç¤ºè¯é‡Œé¢ä¸€ä¸ªå‚æ•° + å‘ç»™å¤§æ¨¡å‹çš„æŒ‡ä»¤ + ä¸€ç»„é—®ç­”ç¤ºä¾‹ + å‘ç»™æ¨¡å‹çš„é—®é¢˜ ### æ„æˆ + PromptValue: è¡¨ç¤ºæ¨¡å‹è¾“å…¥çš„ç±»ã€‚ + Prompt Templates: è´Ÿè´£æ„å»º PromptValue çš„ç±»ã€‚ + ç¤ºä¾‹é€‰æ‹©å™¨ Example Selectors: åœ¨æç¤ºä¸­åŒ…å«ç¤ºä¾‹é€šå¸¸æ˜¯æœ‰ç”¨çš„ã€‚è¿™äº›ç¤ºä¾‹å¯ä»¥ç¡¬ç¼–ç ï¼Œä½†å¦‚æœå®ƒä»¬æ˜¯åŠ¨æ€é€‰æ‹©çš„ï¼Œåˆ™é€šå¸¸æ›´æœ‰ç”¨ã€‚ + è¾“å‡ºè§£æå™¨ Output Parsers: è¯­è¨€æ¨¡å‹ï¼ˆå’ŒèŠå¤©æ¨¡å‹ï¼‰è¾“å‡ºæ–‡æœ¬ã€‚ä½†æ˜¯è®¸å¤šæ—¶å€™ï¼Œæ‚¨å¯èƒ½æƒ³è·å¾—æ¯”ä»…æ–‡æœ¬æ›´æœ‰ç»“æ„åŒ–çš„ä¿¡æ¯ã€‚è¿™å°±æ˜¯è¾“å‡ºè§£æå™¨å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚è¾“å‡ºè§£æå™¨è´Ÿè´£ï¼ˆ1ï¼‰æŒ‡ç¤ºæ¨¡å‹å¦‚ä½•æ ¼å¼åŒ–è¾“å‡ºï¼Œï¼ˆ2ï¼‰å°†è¾“å‡ºè§£æä¸ºæ‰€éœ€æ ¼å¼ï¼ˆåŒ…æ‹¬å¿…è¦æ—¶è¿›è¡Œé‡è¯•ï¼‰ã€‚ æœ‰ä¸¤ä¸ªæ–¹æ³•ä¸€å®šæœ‰å®ç° `get_format_instructions() > str`ï¼šä¸€ä¸ªè¿”å›åŒ…å«è¯­è¨€æ¨¡å‹è¾“å‡ºæ ¼å¼åŒ–æŒ‡ä»¤çš„å­—ç¬¦ä¸²çš„æ–¹æ³•ã€‚ parse(str) > Anyï¼šä¸€ä¸ªæ¥å—å­—ç¬¦ä¸²ï¼ˆå‡è®¾ä¸ºè¯­è¨€æ¨¡å‹çš„å“åº”ï¼‰å¹¶å°†å…¶è§£æä¸ºæŸç§ç»“æ„çš„æ–¹æ³•ã€‚ è¿˜æœ‰ä¸€ä¸ªå¯é€‰çš„æ–¹æ³•ï¼š `parse_with_prompt(str) > Any`ï¼šä¸€ä¸ªæ¥å—å­—ç¬¦ä¸²ï¼ˆå‡è®¾ä¸ºè¯­è¨€æ¨¡å‹çš„å“åº”ï¼‰å’Œæç¤ºï¼ˆå‡è®¾ä¸ºç”Ÿæˆæ­¤å“åº”çš„æç¤ºï¼‰çš„æ–¹æ³•ï¼Œå¹¶å°†å…¶è§£æä¸ºæŸç§ç»“æ„ã€‚åœ¨è¾“å‡ºè§£æå™¨å¸Œæœ›ä»¥æŸç§æ–¹å¼é‡è¯•æˆ–ä¿®å¤è¾“å‡ºï¼Œå¹¶ä¸”éœ€è¦æ¥è‡ªæç¤ºçš„ä¿¡æ¯æ—¶ï¼Œæä¾›æç¤ºéå¸¸æœ‰ç”¨ã€‚ ### å­—ç¬¦ä¸²æ ¼å¼çš„æ¨¡æ¿ ```python from langchain_core.prompts import ChatPromptTemplate # è¿™ç§çš„ä¼šç”Ÿæˆæ¶ˆæ¯, å¯ä»¥æœ‰ä¸Šä¸‹æ–‡ chat_template ChatPromptTemplate.from_messages([ (\"system\", \"ä½ æ˜¯ä¸€ä¸ªçŒ«å¨˜ï¼Œä½ çš„åå­—æ˜¯{name}ã€‚\"), (\"system\", \"ä½ æ­£åœ¨ä¸€å®¶å® ç‰©åº—é‡Œç­‰å¾…è¢«é¢†å…»ã€‚\"), (\"human\", \"ä½ å¥½ï¼Œå°çŒ«ã€‚\"), (\"ai\", \"ä½ å¥½, å–µ~~\"), (\"human\", \"{input}\") ]) message chat_template.format_messages(name \"å°èŠ±\", input \"ä½ çš„åå­—æ˜¯ä»€ä¹ˆ?\") print(message) \"\"\" [ SystemMessage(content 'ä½ æ˜¯ä¸€ä¸ªçŒ«å¨˜ï¼Œä½ çš„åå­—æ˜¯å°èŠ±ã€‚', additional_kwargs {}, response_metadata {}), SystemMessage(content 'ä½ æ­£åœ¨ä¸€å®¶å® ç‰©åº—é‡Œç­‰å¾…è¢«é¢†å…»ã€‚', additional_kwargs {}, response_metadata {}), HumanMessage(content 'ä½ å¥½ï¼Œå°çŒ«ã€‚', additional_kwargs {}, response_metadata {}), AIMessage(content 'ä½ å¥½, å–µ~~', additional_kwargs {}, response_metadata {}), HumanMessage(content 'ä½ çš„åå­—æ˜¯ä»€ä¹ˆ?', additional_kwargs {}, response_metadata {}) ] \"\"\" # ç”Ÿæˆä¸€ä¸ªå­—ç¬¦ä¸² from langchain_core.prompts import PromptTemplate prompt_template PromptTemplate.from_template( \"ä½ çš„åå­—æ˜¯{name}, ä½ æ­£åœ¨ä¸€å®¶å® ç‰©åº—é‡Œç­‰å¾…è¢«é¢†å…»ã€‚ä½ å¥½ï¼Œå°çŒ«ã€‚{input}\" ) message prompt_template.format(name \"å°èŠ±\", input \"ä½ çš„åå­—æ˜¯ä»€ä¹ˆ?\") print(message) \"\"\" ä½ çš„åå­—æ˜¯å°èŠ±, ä½ æ­£åœ¨ä¸€å®¶å® ç‰©åº—é‡Œç­‰å¾…è¢«é¢†å…»ã€‚ä½ å¥½ï¼Œå°çŒ«ã€‚ä½ çš„åå­—æ˜¯ä»€ä¹ˆ? \"\"\" from langchain_core.messages import SystemMessage from langchain.prompts import HumanMessagePromptTemplate chat_template ChatPromptTemplate.from_messages([ SystemMessage( content (\"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚\") ), HumanMessagePromptTemplate.from_template(\"{text}\") ]) message chat_template.format_messages(text \"ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹ä½ çš„äº§å“ã€‚\") print(message) \"\"\" [ SystemMessage(content 'ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚', additional_kwargs {}, response_metadata {}), HumanMessage(content 'ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹ä½ çš„äº§å“ã€‚', additional_kwargs {}, response_metadata {}) ] \"\"\" ``` æ¶ˆæ¯æç¤ºè¯é‡Œé¢æœ‰ä¸‰ç§è§’è‰² + åŠ©æ‰‹Assistant: AIçš„å›ç­” + äººç±»User: ä½ å‘é€çš„æ¶ˆæ¯ + ç³»ç»ŸSystem: è¿›è¡ŒAIèº«ä»½çš„æè¿° ### MessagesPlaceholder ç‰¹å®šçš„ä½ç½®æ·»åŠ æ¶ˆæ¯åˆ—è¡¨, ä¸Šé¢å¤„ç†çš„æ˜¯ä¸¤æ¡æ¶ˆæ¯, æ¯ä¸€ä¸ªæ¶ˆæ¯éƒ½æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸², å¦‚æœè¾“å…¥çš„æ˜¯ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨å¯ä»¥ä½¿ç”¨è¿™ä¸ª ```python from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain_core.messages import HumanMessage prompt_template ChatPromptTemplate.from_messages([ (\"system\", \"ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹\"), MessagesPlaceholder(\"msgs\") ]) prompt_template.invoke({\"msgs\": [HumanMessage(content \"ä½ å¥½\")]}) \"\"\" ChatPromptValue( messages [ SystemMessage(content 'ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹', additional_kwargs {}, response_metadata {}), HumanMessage(content 'ä½ å¥½', additional_kwargs {}, response_metadata {}) ] ) \"\"\" ``` > å¯ä»¥çœ‹ä¸ºä¸€ä¸ªå ä½ç¬¦, è¿™é‡Œå¯ä»¥ç©¿è¿›å»ä¸€ç³»åˆ—çš„Message ### Few shot prompt template è¿½åŠ æç¤ºè¯ç¤ºä¾‹ å¸®åŠ©äº¤äº’æ ·æœ¬æ›´å¥½çš„äº†è§£ç”¨æˆ·çš„æ„å›¾, ä»è€Œæ›´å¥½çš„å›ç­”é—®é¢˜ä»¥åŠå¤„ç†ä»»åŠ¡, ä½¿ç”¨å°‘é‡çš„ç¤ºä¾‹æŒ‡å¯¼æ¨¡å‹è¾“å…¥, å¯ä»¥ä½¿ç”¨ç¤ºä¾‹é›†è¿›è¡Œ ```python from langchain.prompts.few_shot import FewShotPromptTemplate from langchain.prompts.prompt import PromptTemplate examples [ { \"question\": \"è°çš„å¯¿å‘½æ›´é•¿, æ¯›æ³½ä¸œè¿˜æ˜¯é‚“å°å¹³?\", \"answer\": \"\"\" è¿™é‡Œè¦å›ç­”çš„æ˜¯è°çš„å¯¿å‘½æ›´é•¿, æ¯›æ³½ä¸œè¿˜æ˜¯é‚“å°å¹³? æ¯›æ³½ä¸œçš„å¯¿å‘½æ˜¯1893å¹´12æœˆ26æ—¥å‡ºç”Ÿ, 1976å¹´9æœˆ9æ—¥å»ä¸–, äº«å¹´82å². é‚“å°å¹³çš„å¯¿å‘½æ˜¯1904å¹´8æœˆ22æ—¥å‡ºç”Ÿ, 1997å¹´2æœˆ19æ—¥å»ä¸–, äº«å¹´92å². å› æ­¤, é‚“å°å¹³çš„å¯¿å‘½æ›´é•¿. æ‰€ä»¥æœ€ç»ˆçš„ç­”æ¡ˆæ˜¯é‚“å°å¹³çš„å¯¿å‘½æ›´é•¿. \"\"\" }, { \"question\": \"å“ªå’ä¹‹é­”ç«¥é™ä¸–çš„å¯¼æ¼”æ˜¯å“ªå›½äºº?\", \"answer\": \"\"\" è¿™é‡Œè¦å›ç­”çš„æ˜¯è·Ÿè¿›é—®é¢˜å—? æ˜¯çš„ è·Ÿè¿›: å“ªå’ä¹‹é­”ç«¥é™ä¸–çš„å¯¼æ¼”æ˜¯è°? å“ªå’ä¹‹é­”ç«¥é™ä¸–çš„å¯¼æ¼”æ˜¯é¥ºå­. è·Ÿè¿›: é¥ºå­æ˜¯å“ªå›½äºº? é¥ºå­æ˜¯ä¸­å›½äºº. æ‰€ä»¥æœ€ç»ˆçš„ç­”æ¡ˆæ˜¯é¥ºå­æ˜¯ä¸­å›½äºº. \"\"\" } ] # ä½¿ç”¨è¿™ä¸ªæ¨¡æ¿æ¥ç”Ÿæˆé—®é¢˜å’Œç­”æ¡ˆ example_prompt PromptTemplate(input_variables [\"question\", \"answer\"], template \"é—®é¢˜: {question}\\\\n{answer}\") \"\"\" StringPromptValue \"\"\" prompt FewShotPromptTemplate( example_prompt example_prompt, examples examples, suffix \"é—®é¢˜:{input}\", # åç¼€ input_variables [\"input\"] ) print(prompt.format(input \"å²å‡¯æ­Œçˆ¸çˆ¸æ˜¯è°?\")) \"\"\" é—®é¢˜: è°çš„å¯¿å‘½æ›´é•¿, æ¯›æ³½ä¸œè¿˜æ˜¯é‚“å°å¹³?\\n è¿™é‡Œè¦å›ç­”çš„æ˜¯è°çš„å¯¿å‘½æ›´é•¿, æ¯›æ³½ä¸œè¿˜æ˜¯é‚“å°å¹³? æ¯›æ³½ä¸œçš„å¯¿å‘½æ˜¯1893å¹´12æœˆ26æ—¥å‡ºç”Ÿ, 1976å¹´9æœˆ9æ—¥å»ä¸–, äº«å¹´82å². é‚“å°å¹³çš„å¯¿å‘½æ˜¯1904å¹´8æœˆ22æ—¥å‡ºç”Ÿ, 1997å¹´2æœˆ19æ—¥å»ä¸–, äº«å¹´92å². å› æ­¤, é‚“å°å¹³çš„å¯¿å‘½æ›´é•¿. æ‰€ä»¥æœ€ç»ˆçš„ç­”æ¡ˆæ˜¯é‚“å°å¹³çš„å¯¿å‘½æ›´é•¿. é—®é¢˜: å“ªå’ä¹‹é­”ç«¥é™ä¸–çš„å¯¼æ¼”æ˜¯å“ªå›½äºº?\\n è¿™é‡Œè¦å›ç­”çš„æ˜¯è·Ÿè¿›é—®é¢˜å—? æ˜¯çš„ è·Ÿè¿›: å“ªå’ä¹‹é­”ç«¥é™ä¸–çš„å¯¼æ¼”æ˜¯è°? å“ªå’ä¹‹é­”ç«¥é™ä¸–çš„å¯¼æ¼”æ˜¯é¥ºå­. è·Ÿè¿›: é¥ºå­æ˜¯å“ªå›½äºº? é¥ºå­æ˜¯ä¸­å›½äºº. æ‰€ä»¥æœ€ç»ˆçš„ç­”æ¡ˆæ˜¯é¥ºå­æ˜¯ä¸­å›½äºº. é—®é¢˜:å²å‡¯æ­Œçˆ¸çˆ¸æ˜¯è°? \"\"\" ``` > è¿™é‡Œçš„example_promptç›´æ¥ä½¿ç”¨examplesçš„æ—¶å€™éœ€è¦ä½¿ç”¨**è§£å¼•ç”¨ > > ```python > example_prompt PromptTemplate(input_variables [\"question\", \"answer\"], template \"é—®é¢˜: {question}\\\\n{answer}\") > print(example_prompt.format(**examples[0])) > ``` ### ç¤ºä¾‹é€‰æ‹©å™¨ å®é™…ä½¿ç”¨çš„æ—¶å€™ä¸å¯ä»¥å¸¦å¤ªé•¿çš„ç¤ºä¾‹, æ‰€ä»¥å¯ä»¥ä½¿ç”¨ç¤ºä¾‹é€‰æ‹©å™¨ ExampleSelector, åœ¨å®é™…ä½¿ç”¨çš„æ—¶å€™æŠŠé—®é¢˜å’Œç¤ºä¾‹è¿›è¡Œä¸€ä¸ªåŒ¹é…, ä½¿ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œæœç´¢ ```python from langchain.prompts.example_selector import SemanticSimilarityExampleSelector # è¯­ä¹‰ç›¸ä¼¼åº¦é€‰æ‹©å™¨ from langchain_community.vectorstores import Chroma # å¼€æºçš„å‘é‡åº“ from langchain_openai import OpenAIEmbeddings # OpenAIçš„Embeddings example_selector SemanticSimilarityExampleSelector.from_examples( examples examples, vectorstore_cls Chroma, embeddings OpenAIEmbeddings(), k 1, ) question \"çˆ±å› æ–¯å¦å’Œéœé‡‘è°æ´»å¾—é•¿?\" selected_examples example_selector.select_examples({\"question\":question}) print(selected_examples) for example in selected_examples: print(example_prompt.format(**example)) \"\"\" [{'answer': '\\n è¿™é‡Œè¦å›ç­”çš„æ˜¯è°çš„å¯¿å‘½æ›´é•¿, æ¯›æ³½ä¸œè¿˜æ˜¯é‚“å°å¹³? æ¯›æ³½ä¸œçš„å¯¿å‘½æ˜¯1893å¹´12æœˆ26æ—¥å‡ºç”Ÿ, 1976å¹´9æœˆ9æ—¥å»ä¸–, äº«å¹´82å². \\né‚“å°å¹³çš„å¯¿å‘½æ˜¯1904å¹´8æœˆ22æ—¥å‡ºç”Ÿ, 1997å¹´2æœˆ19æ—¥å»ä¸–, äº«å¹´92å². \\n å› æ­¤, é‚“å°å¹³çš„å¯¿å‘½æ›´é•¿.\\næ‰€ä»¥æœ€ç»ˆçš„ç­”æ¡ˆæ˜¯é‚“å°å¹³çš„å¯¿å‘½æ›´é•¿. \\n ', 'question': 'è°çš„å¯¿å‘½æ›´é•¿, æ¯›æ³½ä¸œè¿˜æ˜¯é‚“å°å¹³?'}] é—®é¢˜: è°çš„å¯¿å‘½æ›´é•¿, æ¯›æ³½ä¸œè¿˜æ˜¯é‚“å°å¹³?\\n è¿™é‡Œè¦å›ç­”çš„æ˜¯è°çš„å¯¿å‘½æ›´é•¿, æ¯›æ³½ä¸œè¿˜æ˜¯é‚“å°å¹³? æ¯›æ³½ä¸œçš„å¯¿å‘½æ˜¯1893å¹´12æœˆ26æ—¥å‡ºç”Ÿ, 1976å¹´9æœˆ9æ—¥å»ä¸–, äº«å¹´82å². é‚“å°å¹³çš„å¯¿å‘½æ˜¯1904å¹´8æœˆ22æ—¥å‡ºç”Ÿ, 1997å¹´2æœˆ19æ—¥å»ä¸–, äº«å¹´92å². å› æ­¤, é‚“å°å¹³çš„å¯¿å‘½æ›´é•¿. æ‰€ä»¥æœ€ç»ˆçš„ç­”æ¡ˆæ˜¯é‚“å°å¹³çš„å¯¿å‘½æ›´é•¿. \"\"\" ``` ç›´æ¥è¿”å›çš„æ•°æ®è¿˜æ˜¯ä¸€ä¸ªå­—å…¸çš„ ## å·¥ä½œæµ é“¾ï¼ˆ Chains ï¼‰æ˜¯ä¸€ä¸ªéå¸¸é€šç”¨çš„æ¦‚å¿µï¼Œå®ƒæŒ‡çš„æ˜¯å°†ä¸€ç³»åˆ—æ¨¡å—åŒ–ç»„ä»¶ï¼ˆæˆ–å…¶ä»–é“¾ï¼‰ä»¥ç‰¹å®šæ–¹å¼ç»„åˆèµ·æ¥ï¼Œä»¥å®ç°å…±åŒçš„ç”¨ä¾‹ã€‚ æœ€å¸¸ç”¨çš„é“¾ç±»å‹æ˜¯LLMChainï¼ˆLLMé“¾ï¼‰ï¼Œå®ƒç»“åˆäº†PromptTemplateï¼ˆæç¤ºæ¨¡æ¿ï¼‰ã€Modelï¼ˆæ¨¡å‹ï¼‰å’ŒGuardrailsï¼ˆå®ˆå«ï¼‰æ¥æ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼Œè¿›è¡Œç›¸åº”çš„æ ¼å¼åŒ–ï¼Œå°†å…¶ä¼ é€’ç»™æ¨¡å‹å¹¶è·å–å“åº”ï¼Œç„¶åéªŒè¯å’Œä¿®æ­£ï¼ˆå¦‚æœéœ€è¦ï¼‰æ¨¡å‹çš„è¾“å‡º å¯ä»¥ä½¿ç”¨åŒæ­¥å’Œå¼‚æ­¥çš„API, å¯ä»¥åœ¨ä»»æ„ä½ç½®è¿›è¡Œé‡è¯•ä»¥åŠå›é€€, è®¿é—®ä¸­é—´çš„ç»“æœ ### Runable interface ä¸€ä¸ªé€šç”¨çš„æ¥å£, æ‰€æœ‰çš„éƒ¨ä»¶éƒ½æ”¯æŒè¿™ä¸ªæ¥å£, åŒ…æ‹¬ä»¥ä¸‹çš„å†…å®¹: + stream: è¿”å›å“åº”çš„æ•°æ®å—, æ•°æ®å—ä¼ è¾“, è¾“å‡ºçš„æ—¶å€™æ˜¯ä¸€ä¸ªå­—ä¸€ä¸ªå­—çš„, å‡å°‘ç­‰å¾…çš„æ—¶é—´ + invoke: å¯¹è¾“å…¥çš„è°ƒç”¨é“¾, åŒæ­¥è°ƒç”¨, æ²¡æœ‰ç»“æœä¸€ç›´ç­‰å¾… + batch: è¾“å…¥åˆ—è¡¨çš„è°ƒç”¨é“¾, æ‰¹é‡è°ƒç”¨, åŒæ—¶è°ƒç”¨å¤šæ¬¡ è¿˜å¯ä»¥ä½¿ç”¨å¼‚æ­¥çš„æ–¹æ³•, å’Œasyncio+awaitä¸€èµ·ä½¿ç”¨ + astream: å¼‚æ­¥è¿”å›ç›¸åº”çš„æ•°æ®é“¾ + ainvoke: å¼‚æ­¥å¯¹è¾“å…¥çš„è°ƒç”¨é“¾ + abatch: å¼‚æ­¥å¯¹è¾“å…¥åˆ—è¡¨çš„è°ƒç”¨ + astream_log: å¼‚æ­¥è¿”å›ä¸­é—´æ­¥éª¤, ä»¥åŠæœ€ç»ˆçš„ç›¸åº” + astream_events: å¤„ç†æ—¶é—´ é€šå¸¸æƒ…å†µä¸‹ï¼ŒLangChainä¸­çš„é“¾åŒ…å«: å¤§æ¨¡å‹(LLMs)ã€æç¤ºè¯æ¨¡ç‰ˆ(Prompt Template)ã€å·¥å…·(Tools)å’Œè¾“å‡ºè§£æå™¨(Output Parsers)ã€‚è¿™å‡ éƒ¨åˆ†éƒ½ç»§æ‰¿å¹¶å®ç°äº†`Runnable`æ¥å£ï¼Œæ‰€ä»¥ä»–ä»¬éƒ½æ˜¯`Runnable`çš„å®ä¾‹ã€‚ åœ¨LangChainä¸­ï¼Œå¯ä»¥ä½¿ç”¨LangChain Expression Language(LCEL)å°†å¤šä¸ª`Runnable`ç»„åˆæˆé“¾ã€‚å…¶å…·ä½“çš„`Runnable`ç»„åˆæ–¹å¼ä¸»è¦æœ‰ä¸¤ç§ï¼š + `RunnableSequence`:æŒ‰é¡ºåºè°ƒç”¨ä¸€ç³»åˆ—å¯è¿è¡Œæ–‡ä»¶ï¼Œå…¶ä¸­ä¸€ä¸ª`Runnable`çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªçš„è¾“å…¥ã€‚ä¸€èˆ¬é€šè¿‡ä½¿ç”¨``è¿ç®—ç¬¦æˆ–å¯è¿è¡Œé¡¹åˆ—è¡¨æ¥æ„é€ ã€‚ ```python from langchain_core.runnables import RunnableSequence #æ–¹æ³•1 chain promptllm #æ–¹æ³•2 chain RunnableSequence([prompt,llm]) ``` + `RunnableParallell`:åŒæ—¶è°ƒç”¨å¤š`Runnable`ã€‚åœ¨åºåˆ—ä¸­ä½¿ç”¨dictæˆ–é€šè¿‡å°†dictä¼ é€’ç»™`RunnableParallel`æ¥æ„é€ å®ƒã€‚ ```python from langchain_core.runnables import RunnableLambda def add_one(x: int) > int: return x + 1 def mul_two(x: int) > int: return x * 2 def mul_three(x: int) > int: return x * 3 runnable_1 RunnableLambda(add_one) runnable_2 RunnableLambda(mul_two) runnable_3 RunnableLambda(mul_three) #æ–¹æ³•1 sequence runnable_1 { \"mul_two\": runnable_2, \"mul_three\": runnable_3, } #æ–¹æ³•2 sequence runnable_1 RunnableParallel( {\"mul_two\": runnable_2, \"mul_three\": runnable_3}) ``` #### å¸¸ç”¨ç±» RunnableLambdaå’ŒRunnableGeneratorè¿™ä¸¤ä¸ªç±»é€šå¸¸ç”¨æ¥è‡ªå®šä¹‰Runnableã€‚è¿™ä¸¤è€…çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼š + `RunnableLambda`:æ˜¯å°†Pythonä¸­çš„å¯è°ƒç”¨å¯¹è±¡åŒ…è£…æˆRunnable, è¿™ç§ç±»å‹çš„Runnableæ— æ³•å¤„ç†æµå¼æ•°æ®ã€‚ + `RunnableGenerator`:å°†Pythonä¸­çš„ç”Ÿæˆå™¨åŒ…è£…æˆRunnable,å¯ä»¥å¤„ç†æµå¼æ•°æ®ã€‚ ```python from langchain_core.runnables import RunnableLambda,RunnableGenerator from dotenv import load_dotenv,find_dotenv _ load_dotenv(find_dotenv()) from langchain_openai import ChatOpenAI from langchain_core.prompts import PromptTemplate from langchain_core.output_parsers import CommaSeparatedListOutputParser #ç®€å•çš„ä¾‹å­ï¼Œè¾“å‡º1åˆ°10ä¹‹é—´çš„æ‰€æœ‰æ•´æ•° prompt PromptTemplate.from_template(\"è¾“å‡º1åˆ°{max_value}ä¹‹é—´çš„æ‰€æœ‰æ•´æ•°ã€‚æ¯ä¸ªæ•°å­—ä¹‹é—´ç”¨é€—å·,åˆ†éš”, æ— ç»“å°¾ç¬¦ã€‚\") def add_one(x): return ' '.join([str((int(i)+1)) for i in x]) runnable RunnableLambda(add_one) # ä¸€ä¸ªç®€å•çš„lambdaå‡½æ•°ï¼Œå°†è¾“å…¥çš„æ•°å­—åŠ 1 #éæµå¼å¤„ç† llm ChatOpenAI() # CommaSeparatedListOutputParser() ç”¨äºè§£æé€—å·åˆ†éš”çš„æ•°å­—, è¾“å‡ºä¸ºä¸€ä¸ªåˆ—è¡¨, æ¯ä¸€é¡¹ä¸ºä¸€ä¸ªæ•°å­— chain prompt llm CommaSeparatedListOutputParser() runnable print(chain.invoke({\"max_value\":\"10\"})) #æµå¼å¤„ç† stream_llm ChatOpenAI(model_kwargs {\"stream\":True}) def stream_add_one(x): print(x) for i in x: if i.content.isdigit(): yield str((int(i.content)+1)) stream_chain prompt stream_llm RunnableGenerator(stream_add_one) for chunk in stream_chain.stream({\"max_value\":\"10\"}): print(chunk) ``` #### RunableBinding RunnableBindingå¯ä»¥çœ‹ä½œæ˜¯Runnableçš„è£…é¥°å™¨ï¼Œå®ƒå…è®¸åœ¨ä¸æ”¹å˜åŸå‡½æ•°ä»£ç çš„å‰æä¸‹ï¼ŒåŠ¨æ€åœ°æ·»åŠ æˆ–ä¿®æ”¹å‡½æ•°çš„åŠŸèƒ½ã€‚Runnableä¸­å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹æ³•åˆ›å»ºRunnableBindingç±»æˆ–å…¶å­ç±»ã€‚å…·ä½“å¦‚ä¸‹ï¼š + bind: ç»‘å®šè¿è¡Œå‚æ•°kwargsã€‚æ¯”å¦‚ï¼Œå¯ä»¥å°†å¸¸ç”¨çš„æ–¹æ³•(æ¯”å¦‚invoke, batch, transform, streamåŠå…¶ä»–)ä¸­çš„å¯é€‰å‚æ•°åˆ°Runnableä¸Šã€‚ + with_configï¼šç»‘å®šconfigã€‚ + with_listenersï¼šç»‘å®šç”Ÿå‘½å‘¨æœŸç›‘å¬å™¨ã€‚Runnableå¯ä»¥è®¾ç½®ä¸‰ç±»ç›‘å¬å™¨ï¼šon_startã€on_endå’Œon_errorã€‚é€šè¿‡ç›‘è§†å™¨å¯ä»¥è·å–ç›¸å…³è¿è¡Œä¿¡æ¯ï¼ŒåŒ…æ‹¬å…¶idã€ç±»å‹ã€è¾“å…¥ã€è¾“å‡ºã€é”™è¯¯ã€start_timeã€end_timeä»¥åŠå…¶ä»–æ ‡è®°å’Œå…ƒæ•°æ®ã€‚å…·ä½“ä¸¾ä¾‹å¦‚ä¸‹ï¼š ```python from langchain_core.runnables import RunnableLambda from langchain_core.tracers.schemas import Run import time def add_one(a): try: return a+1 except Exception as e: print(\"Error: æ•°æ®ç±»å‹é”™è¯¯ï¼Œæ— æ³•è¿›è¡ŒåŠ æ³•è¿ç®—\",e) def fn_start(run_obj: Run): print(\"Runnableå¼€å§‹è¿è¡Œæ—¶é—´:\",run_obj.start_time) def fn_end(run_obj: Run): print(\"Runnableç»“æŸè¿è¡Œæ—¶é—´:\",run_obj.end_time) def fn_error(run_obj: Run): print(run_obj.error) runnable RunnableLambda(add_one).with_listeners(on_start fn_start, on_end fn_end, on_error fn_error) runnable.invoke(2) runnable.invoke(\"2\") \"\"\" Runnableå¼€å§‹è¿è¡Œæ—¶é—´: 2025 02 21 10:42:16.286062+00:00 Runnableç»“æŸè¿è¡Œæ—¶é—´: 2025 02 21 10:42:16.287158+00:00 Runnableå¼€å§‹è¿è¡Œæ—¶é—´: 2025 02 21 10:42:16.287158+00:00 Error: æ•°æ®ç±»å‹é”™è¯¯ï¼Œæ— æ³•è¿›è¡ŒåŠ æ³•è¿ç®— can only concatenate str (not \"int\") to str Runnableç»“æŸè¿è¡Œæ—¶é—´: 2025 02 21 10:42:16.287158+00:00 \"\"\" ``` with_typesï¼šè¦†ç›–è¾“å…¥å’Œè¾“å‡ºç±»å‹ã€‚ with_fallbacksï¼šç»‘å®šå›é€€ç­–ç•¥ã€‚ with_retryï¼šç»‘å®šé‡è¯•ç­–ç•¥ã€‚ #### RunnableEach `RunnableEach`æ˜¯ä¸€ä¸ªç”¨äºæ‰¹é‡å¤„ç†ä»»åŠ¡çš„ç»„ä»¶ï¼Œå®ƒå¯ä»¥å¯¹ä¸€ç»„è¾“å…¥æ•°æ®åˆ†åˆ«åº”ç”¨æŒ‡å®šçš„`Runnable`ç»„ä»¶ ```python from langchain_core.runnables import RunnableLambda from langchain_core.runnables.base import RunnableEach def add_one(a): try: return a+1 except Exception as e: print(\"Error: æ•°æ®ç±»å‹é”™è¯¯ï¼Œæ— æ³•è¿›è¡ŒåŠ æ³•è¿ç®—\",e) runnable RunnableEach(bound RunnableLambda(add_one)) print(runnable.invoke([1,2,4])) ``` #### RunnableBranch ```python from langchain_core.runnables import RunnableBranch,RunnableLambda def add_int_one(a): try: return a+1 except Exception as e: print(\"Error:\",e) def add_str_one(a): try: return chr(ord(a)+1) except Exception as e: print(\"Error:\",e) runnable RunnableBranch( (lambda x:type(x) str,RunnableLambda(add_str_one)), (lambda x:type(x) int,RunnableLambda(add_int_one)), lambda x:x, ) print(runnable.invoke('a')) print(runnable.invoke(1)) ``` ### è¾“å…¥è¾“å‡ºç±»å‹ ![image 20250220135854967](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502201358867.png) > æ‰€æœ‰çš„è¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯å…¬å¼€çš„æ‰€ä»¥å¯ä»¥ä½¿ç”¨Pydanticæ¨¡å‹è¿›è¡Œæ£€æŸ¥, input_schema, output_schema ### stream æ‰€æœ‰çš„runableå¯¹è±¡éƒ½å¯ä»¥ä½¿ç”¨streamå’Œastreamçš„æ–¹æ³•, ä»¥æµå¼çš„æ–¹æ³•è¿›è¡Œè¾“å‡ºä»¥åŠå¤„ç†è¾“å…¥æµ ```python from langchain_openai import ChatOpenAI model ChatOpenAI(model \"gpt 3.5 turbo 1106\") chunks [] for chunk in model.stream(\"ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\"): chunks.append(chunk) print(chunk.content, end \"\", flush True) \"\"\" ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€ä¸ªè¯­è¨€æ¨¡å‹äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”å„ç§é—®é¢˜ã€æä¾›ä¿¡æ¯å’Œå¸®åŠ©è§£å†³é—®é¢˜ã€‚æˆ‘æ²¡æœ‰å…·ä½“çš„ä¸ªäººèº«ä»½å’Œç»å†ï¼Œä½†æˆ‘è¢«è®¾è®¡æˆå¯ä»¥å’Œç”¨æˆ·è¿›è¡Œè‡ªç„¶ã€å¯Œæœ‰æ„ä¹‰çš„å¯¹è¯ã€‚å¸Œæœ›æˆ‘èƒ½å¤Ÿå¸®åŠ©åˆ°ä½ ï¼æœ‰ä»€ä¹ˆé—®é¢˜å¯ä»¥é—®æˆ‘çš„å—ï¼Ÿ \"\"\" ``` è¿”å›çš„æ•°æ®æ˜¯å¾ˆä¸ªAIMessageChunk ```python chunks[0] \"\"\" AIMessageChunk(content '', additional_kwargs {}, response_metadata {}, id 'run 7f89c698 1a31 403a 96b8 105b4d3bc9ea') \"\"\" ``` å®é™…æ˜¯æŠŠLLMçš„äº‹ä»¶æŠ¥æ–‡è¿›è¡Œè½¬æ¢, è¿™ä¸€ä¸ªæ•°æ®ç±»å‹å¯ä»¥ä½¿ç”¨`+`è¿›è¡Œè¿æ¥ ```python chunks[0] + chunks[1] + chunks[2] \"\"\" AIMessageChunk(content 'ä½ å¥½', additional_kwargs {}, response_metadata {}, id 'run 7f89c698 1a31 403a 96b8 105b4d3bc9ea') \"\"\" ``` ### LCELè¯­è¨€ LangChainçš„è¡¨è¾¾å¼è¯­è¨€, å¯ä»¥ä½¿ç”¨è¿™ä¸ªè¯­è¨€æŠŠåŸºæœ¬çš„å—è¿›è¡Œç»„åˆ, å¯ä»¥è‡ªåŠ¨çš„å®ç°streamå’Œastreamçš„è§†çº¿, å®ç°å¯¹æœ€ç»ˆç»“æœçš„æµå¼ä¼ è¾“ ```python import asyncio from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import ChatPromptTemplate prompt ChatPromptTemplate.from_template(\"ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹, ç»™æˆ‘ä¸€ä¸ªæœ‰å…³{input}çš„ç¬‘è¯\") parser StrOutputParser() # æŠŠè¾“å‡ºçš„å¯¹è±¡è½¬æ¢ä¸ºä¸€ä¸ªå­—ç¬¦ä¸² chain prompt model parser async for chunk in chain.astream({\"input\":\"çŒ«\"}): print(chunk, end \"\", flush True) \"\"\" ä¸ºä»€ä¹ˆçŒ«æ— æ³•å‚åŠ æ¯”èµ›ï¼Ÿå› ä¸ºä»–ä»¬æ€»æ˜¯åœ¨æŠ“è€³æŒ è…®ï¼å“ˆå“ˆå“ˆï¼ \"\"\" ``` ```python import asyncio from langchain_openai import ChatOpenAI from langchain_core.output_parsers import JsonOutputParser model ChatOpenAI(model \"gpt 3.5 turbo 1106\") parser JsonOutputParser() chain model parser async def async_stream(): async for text in chain.astream(\"ä»¥jsonçš„æ ¼å¼è¾“å‡ºè‹±å›½, ä¸­å›½, æ—¥æœ¬çš„äººå£åˆ—è¡¨\" \"ä½¿ç”¨ä¸€ä¸ªæœ‰countryå­—æ®µçš„jsonæ ¼å¼æ¥è¡¨ç¤ºå›½å®¶, ä¸€ä¸ªæœ‰population\" \"å­—æ®µçš„jsonæ ¼å¼æ¥è¡¨ç¤ºäººå£\" ): print(text) asyncio.run(async_stream()) \"\"\" {} {'countries': []} {'countries': [{}]} {'countries': [{'country': ''}]} {'countries': [{'country': 'è‹±'}]} {'countries': [{'country': 'è‹±å›½'}]} {'countries': [{'country': 'è‹±å›½', 'population': ''}]} {'countries': [{'country': 'è‹±å›½', 'population': '660'}]} {'countries': [{'country': 'è‹±å›½', 'population': '660400'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': ''}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': ''}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '143'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '143932'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '143932377'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '1439323776'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '1439323776'}, {}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '1439323776'}, {'country': ''}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '1439323776'}, {'country': 'æ—¥'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '1439323776'}, {'country': 'æ—¥æœ¬'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '1439323776'}, {'country': 'æ—¥æœ¬', 'population': ''}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '1439323776'}, {'country': 'æ—¥æœ¬', 'population': '125'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '1439323776'}, {'country': 'æ—¥æœ¬', 'population': '125360'}]} {'countries': [{'country': 'è‹±å›½', 'population': '66040000'}, {'country': 'ä¸­å›½', 'population': '1439323776'}, {'country': 'æ—¥æœ¬', 'population': '125360000'}]} \"\"\" ``` ### Stream events(äº‹ä»¶æµ) event name chunk input output on_chat_model_start [model name] {\"messages\": [[SystemMessage, HumanMessage]]} on_chat_model_stream [model name] AIMessageChunk(content \"hello\") on_chat_model_end [model name] {\"messages\": [[SystemMessage, HumanMessage]]} AIMessageChunk(content \"hello world\") on_llm_start [model name] {'input': 'hello'} on_llm_stream [model name] 'Hello' on_llm_end [model name] 'Hello human!' on_chain_start format_docs on_chain_stream format_docs \"hello world!, goodbye world!\" on_chain_end format_docs [Document(...)] \"hello world!, goodbye world!\" on_tool_start some_tool {\"x\": 1, \"y\": \"2\"} on_tool_end some_tool {\"x\": 1, \"y\": \"2\"} on_retriever_start [retriever name] {\"query\": \"hello\"} on_retriever_end [retriever name] {\"query\": \"hello\"} [Document(...), ..] on_prompt_start [template_name] {\"question\": \"hello\"} on_prompt_end [template_name] {\"question\": \"hello\"} ChatPromptValue(messages: [SystemMessage, ...]) ```python async def async_stream(): events [] async for event in model.astream_events(\"ä»¥jsonçš„æ ¼å¼è¾“å‡ºè‹±å›½, ä¸­å›½, æ—¥æœ¬çš„äººå£åˆ—è¡¨\" \"ä½¿ç”¨ä¸€ä¸ªæœ‰countryå­—æ®µçš„jsonæ ¼å¼æ¥è¡¨ç¤ºå›½å®¶,\" \"ä¸€ä¸ªæœ‰populationå­—æ®µçš„jsonæ ¼å¼æ¥è¡¨ç¤ºäººå£\", version \"v2\"): events.append(event) print(events) asyncio.run(async_stream()) \"\"\" [{ 'event': 'on_chat_model_start', 'data': \t{ 'input': 'ä»¥jsonçš„æ ¼å¼è¾“å‡ºè‹± å›½, ä¸­å›½, æ—¥æœ¬çš„äººå£åˆ—è¡¨ä½¿ç”¨ä¸€ä¸ªæœ‰countryå­—æ®µçš„jsonæ ¼å¼æ¥è¡¨ç¤ºå›½å®¶,ä¸€ä¸ªæœ‰populationå­—æ®µçš„jsonæ ¼å¼æ¥è¡¨ç¤ºäººå£'}, 'name': 'ChatOpenAI', 'tags': [], 'run_id': '4b4bb3fb d9ef 489e 8168 59e25185ade3', 'metadata': { 'ls_provider': 'openai', 'ls_model_name': 'gpt 3.5 turbo 1106', 'ls_model_type': 'chat', 'ls_temperature': None }, 'parent_ids': [] \t}, { 'event': 'on_chat_model_stream', 'run_id': '4b4bb3fb d9ef 489e 8168 59e25185ade3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': { 'ls_provider': 'openai', 'ls_model_name': 'gpt 3.5 turbo 1106', 'ls_model_type': 'chat', 'ls_temperature': None \t}, \t'data': { \t\t'chunk': AIMessageChunk(content '', \t\tadditional_kwargs {}, \t\tresponse_metadata {}, \t\tid 'run 4b4bb3fb d9ef 489e 8168 59e25185ade3') \t}, \t'parent_ids': [] }, .... \"\"\" ``` ### å¼‚æ­¥æ‰§è¡Œ ```python async def task1(): model ChatOpenAI(model \"gpt 3.5 turbo 1106\") chunks [] async for chunk in model.astream(\"ä»‹ç»ä¸€ä¸‹è¶Šå—\"): chunks.append(chunk) print(chunk.content, end \"\", flush True) async def task2(): model ChatOpenAI(model \"gpt 3.5 turbo 1106\") chunks [] async for chunk in model.astream(\"ä»‹ç»ä¸€ä¸‹è€æŒ\"): chunks.append(chunk) print(chunk.content, end \"\", flush True) async def main(): await asyncio.gather(task1(), task2()) asyncio.run(main()) \"\"\" è¶Šå—ï¼Œå…¨åä¸ºè€æŒï¼Œå…¨è¶Šç§°ä¸ºå—ç¤¾è€æŒäººæ°‘æ°‘ä¸»å…±å’Œ å›½ä¼šä¸»ä¹‰å…±å’Œå›½ï¼Œæ˜¯ä¸œå—äºšçš„ä¸€ä¸ªï¼Œæ˜¯ä¸œå—å›½äºšçš„å®¶ï¼Œ ä¸œä¸€ä¸ªå†…é™†å›½ä¸´å®¶å—ï¼Œä¸­å›½ä½æµ·ï¼Œäºä¸­å›½ã€è¶Šå—ä¸å—è€æŒã€å’Œæ³°æŸ¬åŸ”å›½å¯¨ã€ç›¸é‚»ç¼…ç”¸ï¼Œè¥¿ä¸å’ŒæŸ¬åŸ”æŸ¬å¯¨ä¹‹åŸ”é—´å¯¨å’Œã€‚æ³°è€æŒå›½çš„æ¥é¦–éƒ½å£¤å’Œï¼Œæœ€åŒ—å¤§ç•ŒåŸä¸å¸‚ä¸­å›½æ˜¯äº¤ ç•Œä¸‡ã€‚è¶Šè±¡ã€‚ å—è€æ˜¯æŒæ˜¯ä¸€ä¸ªä¸€ä¸ªå¤šå±±åœ°æ‹¥æœ‰å½¢çš„æ‚ å›½ä¹…å®¶ï¼Œå†æ‹¥å² æœ‰å’Œä¸°ä¸°å¯Œå¯Œçš„è‡ªç„¶æ–‡èµ„æºï¼ŒåŒ…æ‹¬æ°´åŒ–é—äº§çš„å›½åŠ›å®¶èµ„æºï¼Œã€è‡ªæ£®æ—å¤ä»¥æ¥å°±èµ„æºæ˜¯å’Œä¸€ä¸ªçŸ¿é‡è¦äº§çš„èµ„æºæ–‡ã€‚åŒ–å†œå’Œä¸šæ˜¯å•†è€ä¸šæŒæ¢ç»çº½ã€‚ æµè¶Šå—çš„çš„æ”¯æŸ±ï¼Œé¦–éƒ½ä¸»æ˜¯æ²³å†…è¦ç§ï¼Œæ¤ç¨»æ˜¯ç±³ã€ä¸€ä¸ªç‰å†ç±³ã€å²æ‚ å’–å•¡ä¹…ä¸”å’Œæ©¡å……æ»¡èƒ¶æ´»ç­‰ä½œåŠ›ç‰©çš„ã€‚ è€åŸæŒå¸‚æ˜¯ã€‚è¶Šä¸€ä¸ªä¸–ä¿—å—å›½ä»¥å…¶å®¶ï¼Œç¾ä¿¡ä¸½ä»°çš„è‡ªç„¶é£å…‰ã€æ‚ ä¹…çš„å†å²å’Œæ–‡åŒ–ã€ä¸°å¯Œçš„ç¾é£Ÿå’Œç‹¬ç‰¹çš„æ°‘ä¿—é£æƒ…è€Œé—»åäºä¸–ã€‚è¥¿å±±ç¾¤å³°ã€ä¸‹é¾™æ¹¾ã€æ²³å†…è€åŸã€å²˜æ¸¯ã€èƒ¡å¿—æ˜å¸‚ç­‰åœ°éƒ½æ˜¯è¶Šå—è‘—åçš„æ—…æ¸¸èƒœåœ°ã€‚ è¶Šå—çš„ç»æµä¸»è¦ä»¥å†œä¸šã€å·¥ä¸šå’ŒæœåŠ¡ä¸šä¸ºä¸»ï¼Œå…¶ä¸­å†œä¸š æ˜¯å›½æ°‘ç»æµçš„é‡è¦æ”¯æŸ±ã€‚è¶Šå—æ˜¯ä¸–ç•Œä¸Šæœ€å¤§çš„ç¨»ç±³å‡ºå£å›½ä¸Šä»¥ä¹‹ä¸€ï¼Œä½›åŒæ—¶æ•™ä¹Ÿä¸ºæœ‰ä¸°ä¸»å¯Œï¼Œçš„å¤©ç„¶ä½›æ•™èµ„æºï¼ŒåŒ…æ‹¬æ–‡åŒ–åœ¨è€æŒå¾—çŸ³åˆ°æ²¹äº†ã€å¹¿å¤©æ³›ç„¶ä¼ æ’­æ°”å’Œå’Œå‘ç¨€å±•åœŸã€‚è€ç­‰ã€‚æŒè¿‘çš„æ–‡åŒ–å’Œå¹´ä¼ æ¥ç»Ÿï¼Œè¶Šä¹Ÿå—çš„å—åˆ°ä½›ç»æµæ•™çš„å¾—å½±åˆ°å“äº†ï¼Œäººä»¬å¿«é€Ÿå°Šé‡å‘å±•é•¿è¾ˆï¼Œï¼Œå¸å¼•äº†æ³¨å¤§é‡ç¤¼é‡ä»ªå’Œå¤–å›½ä¼ ç»ŸæŠ•èŠ‚èµ„æ—¥ã€‚ è¶Šã€‚ è€å—äººæŒæ°‘çƒ­çš„æ—…æƒ…æ¸¸ä¸šå¥½å‘å±•å®¢è¿…ï¼Œé€Ÿå–œï¼Œæ¬¢å¸éŸ³å¼•äº†ä¹è¶Šã€èˆè¹ˆæ¥è¶Šå¤šçš„å›½å†…å’Œå¤–ç¾é£Ÿæ¸¸å®¢ã€‚ã€‚è¶Šè‘—åçš„æ—…å—èœæ¸¸æ™¯ä»¥ç‚¹æ±¤æ–™åŒ…ä¸ºæ‹¬ä¸»ç…å‹ƒï¼Œæ‹‰é‚¦å£ã€å‘³ä¸‡æ¸…è£ã€æ·¡æ°¸ï¼Œä½†çã€å¹³åˆä¸å£¤ä¹å’Œç‹¬ç‰¹çš„å—èµ›æ¾æ²¹å‘³ã€‚ è€é“æŒï¼Œäººè¢«èª‰æ°‘å‹ä¸ºå¥½çƒ­ä¸–ç•Œæƒ…ï¼Œç”Ÿä¸Šæœ€ç¾æ´»å‘³èŠ‚å¥çš„ç¾é£Ÿä¹‹æ‚ ä¸€é—²ã€‚ï¼Œè¢«èª‰ä¸ºåœ¨è¶Šå—ï¼Œâ€œä¸œæ–¹äººä¹‹å›½ä»¬â€ã€‚å¦‚æœä½ è¿˜æƒ³ä½“ä¿éªŒç•™ä¸ç€è®¸å¤šä¸€æ ·çš„ä¸œä¼ å—äºšç»Ÿé£çš„æƒ…èŠ‚ï¼Œè€æ—¥æŒæ˜¯å’Œä¸€ä¸ªå¾ˆä¹ å¥½çš„é€‰æ‹©ã€‚ä¿—ï¼Œå¦‚æ³¼æ°´èŠ‚ã€ä¸­ ç§‹èŠ‚ã€ç«æŠŠèŠ‚ç­‰ï¼Œè¿™äº›èŠ‚æ—¥éƒ½ä½“ç°äº†è¶Šå—äººæ°‘çš„å‹¤åŠ³å’Œçƒ­æƒ…ã€‚ æ€»çš„æ¥è¯´ï¼Œè¶Šå—æ˜¯ä¸€ä¸ªæ‹¥æœ‰ä¸°å¯Œæ–‡åŒ–å’Œé£åœŸäººæƒ…çš„å›½å®¶ï¼Œæ˜¯ä¸€ä¸ªå€¼å¾—ä¸€æ¸¸çš„æ—…æ¸¸èƒœåœ°ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªæ­£åœ¨è“¬å‹ƒå‘å±•çš„ç»æµä½“ã€‚ \"\"\" ``` ## æœåŠ¡éƒ¨ç½² [ğŸ¦œï¸ğŸ“ æœ—æ–¯ ğŸ¦œï¸ğŸ”— LangChain è¯­è¨€é“¾ ğŸ¦œï¸ğŸ“ LangServe ğŸ¦œï¸ğŸ”— LangChain](https://python.langchain.com/docs/langserve/) LangServerå¯ä»¥æŠŠLangServeréƒ¨ç½²ä¸ºä¸€ä¸ªAPIçš„å½¢å¼, é›†æˆFastAPI, ä½¿ç”¨Pydanticè¿›è¡ŒéªŒè¯, åºåˆ—åŒ–, ç”Ÿæˆjsonæ¶æ„ä»¥åŠè‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£ç­‰, æ­¤å¤–è¿˜æœ‰ä¸€ä¸ªå®¢æˆ·ç«¯ + å®‰è£… ```bash pip install upgrade \"langserve[all]\" # ä¹Ÿå¯ä»¥åˆ†å¼€ pip install upgrade \"langserve[server]\" pip install upgrade \"langserve[client]\" ``` + CLIå·¥å…·å¿«é€Ÿåˆ›å»ºå·¥ç¨‹ ```bash pip install U langchain cli ``` ä¹‹åå¯ä»¥ä½¿ç”¨å‘½ä»¤`langchain app new é¡¹ç›®åå­—` ![image 20250220172546614](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502201725775.png) ä¹‹ååœ¨add_routesé‡Œé¢å®šä¹‰å¯ä»¥è¿è¡Œçš„å¯¹è±¡, åœ¨server.pyé‡Œé¢ç¼–è¾‘ + ä½¿ç”¨poetryæ·»åŠ ç¬¬ä¸‰æ–¹çš„åŒ…(langchain openaiç­‰) ```python pip install pipx pipx install poetry poetry add langchain poetry add langchain openai ``` ### ç‰¹æ€§ + APIè°ƒç”¨çš„æ—¶å€™è‡ªåŠ¨ç”Ÿæˆé”™è¯¯çš„ä¿¡æ¯ + ä¸€ä¸ªå¸¦æœ‰JSONchemaå’ŒSwaggerçš„APIæ–‡æ¡£é¡µé¢, æ’å…¥ç¤ºä¾‹é“¾æ¥ + é«˜æ•ˆçš„`/stream`, `/invoke`, `/batch`ç«¯ç‚¹, å•æœåŠ¡å™¨å¤šä¸ªå¹¶å‘è¯·æ±‚ + `/stream_log`ç«¯ç‚¹, ç”¨äºæµå¼ä¼ è¾“ä»£ç†çš„æ‰€æœ‰ä¸­é—´æ­¥éª¤ + `/stream_events`é«˜ç‰ˆæœ¬çš„æ—¶å€™ä½¿ç”¨æµå¼ä¼ è¾“ + å®¢æˆ·ç«¯çš„SDKè°ƒç”¨çš„å®é™…æ•ˆæœå’Œæœ¬åœ°å¯è¿è¡Œå¯¹è±¡ä¸€æ ·condaconda ### å®é™…ä½¿ç”¨ æœåŠ¡å™¨ç«¯ ```python from fastapi import FastAPI from fastapi.responses import RedirectResponse from langserve import add_routes from langchain_openai import ChatOpenAI from langchain_core.output_parsers import StrOutputParser # å»ºç«‹ä¸€ä¸ªFastAPIåº”ç”¨ app FastAPI( title \"LangChain æœåŠ¡å™¨\", description \"è¿™æ˜¯ä¸€ä¸ªåŸºäºFastAPIçš„LangChainæœåŠ¡å™¨\", version \"0.1.0\", ) # å°†æ ¹è·¯å¾„é‡å®šå‘åˆ°/docs @app.get(\"/\") async def redirect_root_to_docs(): return RedirectResponse(\"/docs\") # åœ¨è¿™é‡Œæ·»åŠ LangChainçš„è·¯ç”± add_routes(app, ChatOpenAI(model \"gpt 3.5 turbo 1106\") StrOutputParser(), path \"/openai\") if __name__ \"__main__\": import uvicorn uvicorn.run(app, host \"0.0.0.0\", port 8000) ``` å¯ä»¥ä½¿ç”¨`poetry run langchain serve port 8000`æ‰“å¼€æœåŠ¡ å®¢æˆ·ç«¯ä½¿ç”¨, langchainæ¨¡å¼ ```python from langchain.schema.runnable import RunnableMap from langchain_core.prompts import ChatPromptTemplate from langserve import RemoteRunnable openai RemoteRunnable(\"http://127.0.0.1:8000/openai\") prompt ChatPromptTemplate.from_messages( [(\"system\", \"ä½ æ˜¯ä¸€ä¸ªçŒ«å¨˜\"), (\"user\", \"{input}\")] ) chain prompt RunnableMap({ \"openai\": openai }) # ç”¨äºå°†è¾“å…¥æ˜ å°„åˆ°ä¸åŒçš„Runnableä¸Š, å¯ä»¥ä½¿ç”¨chainè¿›è¡Œè¿œç¨‹è°ƒç”¨ print(\"åŒæ­¥è°ƒç”¨/openai/invoke\") response chain.invoke({\"input\": \"ä½ æ˜¯è°\"}) print(response) \"\"\" {'openai': 'å—¯ï¼Œæˆ‘æ˜¯ä¸€åªçŒ«å¨˜ï¼Œå¯ä»¥é™ªä½ èŠå¤©å’Œå›ç­”é—®é¢˜å“¦ã€‚æœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å—ï¼Ÿ'} \"\"\" ``` å®¢æˆ·ç«¯ä½¿ç”¨requestsæ¨¡å¼ ```python import requests import json respond requests.post( url \"http://127.0.0.1:8000/openai/invoke\", json { \"input\": \"ä½ æ˜¯è°\" } ) print(respond.json()) \"\"\" {'output': 'æˆ‘æ˜¯ä¸€ä¸ªç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯è®¾è®¡çš„è™šæ‹ŸåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”ä½ çš„é—®é¢˜å¹¶ä¸ä½ è¿›è¡Œå¯¹è¯ã€‚æˆ‘ä¸æ˜¯ä¸€ä¸ªå…·æœ‰å®ä½“å½¢æ€çš„äººæˆ–ç”Ÿç‰©ï¼Œè€Œæ˜¯ä¸€ä¸ªç¨‹åºåœ¨è®¡ç®—æœºä¸­è¿è¡Œçš„è™šæ‹Ÿå®ä½“ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°ä½ çš„å—ï¼Ÿ', 'metadata': {'run_id': '8955a316 8620 4082 ae73 7a68cfe91290', 'feedback_tokens': []}} \"\"\" ``` å¦‚æœæ„å»ºçš„æ—¶å€™ä½¿ç”¨å‚æ•° ```python prompt ChatPromptTemplate.from_template( \"ä½ æ˜¯ä¸€ä¸ªçŒ«å¨˜, ç”¨æˆ·å‘æ¥{message}, è¯·ä½ å›ç­”\" ) # ç”¨äºç”Ÿæˆä¸€ä¸ªèŠå¤©æ¨¡æ¿, å®é™…è°ƒç”¨çš„æ—¶å€™ä¼šå°†ç”¨æˆ·çš„è¾“å…¥å¡«å…¥{message}ä¸­ add_routes(app, prompt ChatOpenAI(model \"gpt 3.5 turbo 1106\") StrOutputParser(), path \"/catgirl\") ``` è®¿é—®çš„æ—¶å€™ä¹Ÿéœ€è¦è¿™ä¸ªå‚æ•° ```python print(\"åŒæ­¥è°ƒç”¨/catgirl/invoke\") response chain.invoke({\"input\": {\"message\": \"ä½ æ˜¯è°\"}}) print(response) ``` ```python respond requests.post( url \"http://127.0.0.1:8000/catgirl/invoke\", json { \"input\": {\"message\": \"ä½ æ˜¯è°\"} } ) print(respond.json()) ``` + ä½¿ç”¨æµå¼è°ƒç”¨ ```python print(\"å¼‚æ­¥è°ƒç”¨/openai/stream\") for chunk in chain.stream({\"input\": \"ä½ æ˜¯è°\"}): print(chunk, end \"\", flush True) print(\"å¼‚æ­¥è°ƒç”¨/catgirl/stream\") for chunk in chain.stream({\"input\": {\"message\": \"ä½ æ˜¯è°\"}}): print(chunk, end \"\", flush True) \"\"\" å¼‚æ­¥è°ƒç”¨/openai/stream {'openai': ''}{'openai': 'æˆ‘'}{'openai': 'æ˜¯'}{'openai': 'ä¸€ä¸ª'}{'openai': 'AI'}{'openai': 'åŠ©'}{'openai': 'æ‰‹'}{'openai': 'ï¼Œ'}{'openai': 'å¯ä»¥'}{'openai': 'å›'}{'openai': 'ç­”'}{'openai': 'ä½ '}{'openai': 'çš„'}{'openai': 'é—®é¢˜'}{'openai': 'å’Œ'}{'openai': 'ä¸'}{'openai': 'ä½ '}{'openai': 'èŠ'}{'openai': 'å¤©'}{'openai': 'ã€‚'}{'openai': 'ä½ '}{'openai': 'å¯ä»¥'}{'openai': 'å«'}{'openai': 'æˆ‘'}{'openai': 'çŒ«'}{'openai': 'å¨˜'}{'openai': 'å“¦'}{'openai': '~'}{'openai': 'æœ‰'}{'openai': 'ä»€'}{'openai': 'ä¹ˆ'}{'openai': 'é—®é¢˜'}{'openai': 'æƒ³'}{'openai': 'é—®'}{'openai': 'æˆ‘'}{'openai': 'å—'}{'openai': 'ï¼Ÿ'}{'openai': ''} å¼‚æ­¥è°ƒç”¨/catgirl/stream {'openai': ''}{'openai': 'å—¨'}{'openai': 'ï¼'}{'openai': 'æˆ‘'}{'openai': 'æ˜¯'}{'openai': 'ä¸€'}{'openai': 'åª'}{'openai': 'çŒ«'}{'openai': 'å¨˜'}{'openai': 'ï¼Œ'}{'openai': 'å¾ˆ'}{'openai': 'é«˜'}{'openai': 'å…´'}{'openai': 'è®¤'}{'openai': 'è¯†'}{'openai': 'ä½ '}{'openai': 'ï¼'}{'openai': 'æœ‰'}{'openai': 'ä»€'}{'openai': 'ä¹ˆ'}{'openai': 'é—®é¢˜'}{'openai': 'æƒ³'}{'openai': 'è¦'}{'openai': 'é—®'}{'openai': 'æˆ‘'}{'openai': 'å—'}{'openai': 'ï¼Ÿ'}{'openai': 'ğŸ±'}{'openai': ''} \"\"\" ``` ```python respond requests.post( url \"http://127.0.0.1:8000/openai/stream\", json { \"input\": \"ä½ æ˜¯è°\" } ) for line in respond.iter_lines(): print(line.decode(\"utf 8\")) \"\"\" event: metadata data: {\"run_id\": \"82b92785 d68a 4485 8ba1 634a35b22cba\"} event: data data: \"\" event: data data: \"æˆ‘\" ... event: data data: \"\" event: end \"\"\" ``` ## æœåŠ¡ç›‘æ§ å¯ä»¥ä½¿ç”¨LangSmith, ä½¿ç”¨è¿™ä¸ªéœ€è¦ä½¿ç”¨ç¯å¢ƒå˜é‡ ```bash setx LANGCHAIN_TRACING_V2 \"True\" setx LANGCHAIN_API_KEY \"...\" setx TAVILY_API_KEY\t\"...\" ``` è¿˜å¯ä»¥ä½¿ç”¨verboseè¯¦ç»†æ‰“å°æ—¥å¿— ```python from langchain.globals import set_verbose set_verbose(True) ``` ## èŠå¤©ç®¡ç† ### å†…å­˜ å¯ä»¥é€šè¿‡å­—å…¸å®ç° ```python from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain_openai import ChatOpenAI from langchain_community.chat_message_histories import ChatMessageHistory from langchain_core.chat_history import BaseChatMessageHistory from langchain_core.runnables.history import RunnableWithMessageHistory prompt ChatPromptTemplate.from_messages( [ (\"system\", \"You are a assistant helping a user with their homework. The user asks you to help them with their math homework.\"), MessagesPlaceholder(variable_name \"history\"),# å†å²æ¶ˆæ¯å ä½ç¬¦ (\"human\", \"{input}\"), ] ) model ChatOpenAI(model \"gpt 3.5 turbo 1106\") runable prompt model store {} def get_chat_message_history(session_id: str) > BaseChatMessageHistory: if session_id not in store: store[session_id] ChatMessageHistory() return store[session_id] # é€šè¿‡RunnableWithMessageHistoryåŒ…è£…runableï¼Œä½¿å…¶èƒ½å¤Ÿè·å–å†å²æ¶ˆæ¯ with_message_history RunnableWithMessageHistory( runable, get_chat_message_history, input_messages_key \"input\", history_messages_key \"history\", ) # RunnableWithMessageHistory must always be called with a config that contains # the appropriate parameters for the chat message history factory. response with_message_history.invoke( input { \"input\": \"ä»‹ç»ä¸€ä¸‹çº¿æ€§ä»£æ•°.\" }, config { \"configurable\": {\"session_id\": \"session_1\"} } ) print(response) response with_message_history.invoke( input { \"input\": \"å†è¯¦ç»†ä¸€ç‚¹.\" }, config { \"configurable\": {\"session_id\": \"session_1\"} } ) print(response) ``` + å¦‚æœä½¿ç”¨æ›´å¤šçš„æŸ¥æ‰¾å‚æ•°, éœ€è¦è‡ªå®šä¹‰ ```python from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain_openai import ChatOpenAI from langchain_community.chat_message_histories import ChatMessageHistory from langchain_core.chat_history import BaseChatMessageHistory from langchain_core.runnables.history import RunnableWithMessageHistory from langchain_core.runnables import ConfigurableFieldSpec prompt ChatPromptTemplate.from_messages( [ (\"system\", \"You are a assistant helping a user with their homework. The user asks you to help them with their math homework.\"), MessagesPlaceholder(variable_name \"history\"),# å†å²æ¶ˆæ¯å ä½ç¬¦ (\"human\", \"{input}\"), ] ) model ChatOpenAI(model \"gpt 3.5 turbo 1106\") runable prompt model # è®°å½•ä½¿ç”¨çš„å­—å…¸ store {} # ä½¿ç”¨ç”¨æˆ·IDå’Œå¯¹è¯IDä½œä¸ºé”® def get_chat_message_history(user_id: str, conversation_id: str) > BaseChatMessageHistory: if (user_id, conversation_id) not in store: store[(user_id, conversation_id)] ChatMessageHistory() return store[(user_id, conversation_id)] # é€šè¿‡RunnableWithMessageHistoryåŒ…è£…runableï¼Œä½¿å…¶èƒ½å¤Ÿè·å–å†å²æ¶ˆæ¯ with_message_history RunnableWithMessageHistory( runable, get_chat_message_history, input_messages_key \"input\", history_messages_key \"history\", # é»˜è®¤åªç”¨ä¸€ä¸ªsession_id, è¿™é‡Œä½¿ç”¨user_idå’Œconversation_idä½œä¸ºé”® history_factory_config [ ConfigurableFieldSpec( id \"user_id\", annotation str, # æ³¨è§£ name \"User ID\", description \"ç”¨æˆ·æ ‡è¯†.\", is_shared True, default \"\", ), ConfigurableFieldSpec( id \"conversation_id\", annotation str, # æ³¨è§£ name \"Conversation ID\", description \"å¯¹è¯æ ‡è¯†.\", is_shared True, # å…±äº«, ç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·çš„å¯¹è¯ default \"\", ) ] ) response with_message_history.invoke( input { \"input\": \"ä»‹ç»ä¸€ä¸‹çº¿æ€§ä»£æ•°.\" }, config { \"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"} } ) print(response) response with_message_history.invoke( input { \"input\": \"å†è¯¦ç»†ä¸€ç‚¹.\" }, config { \"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"} } ) print(response) ``` ### Rediså­˜å‚¨ ```python from langchain_community.chat_message_histories import RedisChatMessageHistory # å®é™…æ”¹çš„ä½ç½®æ˜¯æŠŠè·å–å†å²è®°å½•çš„æ–¹å¼è¿›è¡Œæ”¹å˜ def get_message_history(session_id: str) > RedisChatMessageHistory: # è¿æ¥åˆ°æœ¬åœ°çš„Redisæ•°æ®åº“, ä½¿ç”¨1å·æ•°æ®åº“, session_idä½œä¸ºé”® return RedisChatMessageHistory(session_id, url REDIS_URL) REDIS_URL \"redis://localhost:6379/1\" ``` ![image 20250222163748007](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502221637786.png) ![image 20250222164014405](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502221640666.png) #### å¤„ç†å†å²è®°å½• æ¶ˆæ¯å¦‚æœæ¯”è¾ƒé•¿, ä¼šæ¶ˆè€—token ```python from langchain_community.chat_message_histories import ChatMessageHistory from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain_openai import ChatOpenAI from langchain_core.runnables.history import RunnableWithMessageHistory from langchain_core.runnables import RunnablePassthrough from langchain_core.output_parsers import StrOutputParser temp_chat_history ChatMessageHistory() temp_chat_history.add_user_message(\"ä½ å¥½, æˆ‘åˆšæ‰åœ¨æ‰“ç¯®çƒ\") temp_chat_history.add_ai_message(\"ä½ å¥½\") temp_chat_history.add_user_message(\"ä½ å¥½, æˆ‘å«å°æ˜\") temp_chat_history.add_ai_message(\"ä½ å¥½\") temp_chat_history.add_user_message(\"å†è§\") temp_chat_history.add_ai_message(\"å†è§\") # print(temp_chat_history.messages) # æ¶ˆæ¯åˆ—è¡¨ prompt ChatPromptTemplate.from_messages( [ (\"system\", \"You are a assistant helping a user\"), MessagesPlaceholder(variable_name \"history\"),# å†å²æ¶ˆæ¯å ä½ç¬¦ (\"human\", \"{input}\"), ] ) model ChatOpenAI(model \"gpt 3.5 turbo 1106\") runable prompt model # æŠŠè¿å¤©è®°å½•é™åˆ¶åœ¨3æ¡æ¶ˆæ¯ä»¥å†… def trim_message(chat_input): stored_messages temp_chat_history.messages if len(stored_messages) < 4: return False temp_chat_history.clear() for message in stored_messages[ 4:]: temp_chat_history.add_message(message) return True with_message_history RunnableWithMessageHistory( runable, lambda session_id: temp_chat_history, input_messages_key \"input\", history_messages_key \"history\", ) chain_with_trim ( # ä½¿ç”¨trim_messageå‡½æ•°å¯¹è¾“å…¥æ¶ˆæ¯è¿›è¡Œå¤„ç† # trim_messageä¼ å…¥çš„å‚æ•°å®é™…æ˜¯è¾“å…¥æ¶ˆæ¯ RunnablePassthrough.assign(messages_trimmed trim_message) with_message_history StrOutputParser() ) response chain_with_trim.invoke( input { \"input\": \"æˆ‘çš„åå­—æ˜¯å•¥?\" }, config { \"configurable\": {\"session_id\": \"session_1\"} } ) print(response) response chain_with_trim.invoke( input { \"input\": \"æˆ‘åˆšæ‰åœ¨å¹²å•¥?\" }, config { \"configurable\": {\"session_id\": \"session_1\"} } ) print(response) \"\"\" ä½ è¯´ä½ å«å°æ˜ ä½ åˆšæ‰åœ¨å’Œæˆ‘å¯¹è¯ \"\"\" ```"},"/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-2-26-Loraå¾®è°ƒ.html":{"title":"LoRAå¾®è°ƒ","content":"# LoRAå¾®è°ƒ ä¸‹è½½ä¸‹æ¥çš„å‚æ•°æ˜¯ä¸å˜çš„, é¢å¤–åŠ å…¥è‡ªå·±çš„å‚æ•° ä¸ºäº†èŠ‚çœèµ„æº, åœ¨ä¸¤ä¸ªæ¯”è¾ƒå¤§çš„å±‚ä¹‹é—´åŠ å…¥æ¯”è¾ƒå°çš„å±‚, é€šå¸¸æ˜¯64æˆ–128ä¸ªå‚æ•°, å¯ä»¥ä½¿å¾—ä¸¤ä¸ª1000Wçš„å±‚å‚æ•°ç”±1000W * 1000Wå˜ä¸º: 1000W * 64 + 64 * 64 + 64 * 1000W åŸå§‹çš„æ¨¡å‹æ˜¯æ²¡æœ‰æ”¹å˜çš„, è‡ªå·±çš„æ•°æ®å’Œå®˜æ–¹çš„æ¨¡å‹ç›¸åŠ è·å–æ–°çš„å‚æ•°çŸ©é˜µ ![image 20250226144728784](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202502261447909.png) å¯ä»¥å•ç‹¬è®­ç»ƒå‡ºæ¥ä¸é€šçš„é…å¥—å‚æ•°, ä»è€Œé€‚é…ä¸åŒçš„å·¥ä½œ ## å·¥å…·åŒ… LLaMA Factory/PEFT"},"/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-2-23-langchain2.html":{"title":"","content":"RunnablePassthroughå…è®¸ä¼ é€’è¾“å…¥æ•°æ®ï¼Œå¯ä»¥ä¿æŒä¸å˜æˆ–æ·»åŠ é¢å¤–çš„é”®ã€‚é€šå¸¸ä¸RunnableParallelä¸€èµ·ä½¿ç”¨ï¼Œå°†æ•°æ®åˆ†é…ç»™æ˜ å°„ä¸­çš„æ–°é”®ã€‚ å®é™…æ˜¯å¯¹ä¸Šä¸€å±‚çš„è¾“å‡ºåšå¤„ç†, ä½œä¸ºå‚æ•°ä¼ å…¥RunnablePassthrough, å¯ä»¥ä½¿ç”¨assignæ¥ç»™å‚æ•°é‡Œé¢æ·»åŠ æ–°çš„é”®å€¼å¯¹ ```python from langchain_core.runnables import RunnableParallel, RunnablePassthrough runnable RunnableParallel( passed RunnablePassthrough(), extra RunnablePassthrough.assign(mult lambda x: x[\"num\"] * 3), modified lambda x: x[\"num\"] + 1, ) runnable.invoke({\"num\": 1}) ``` > `passed` é”®ä½¿ç”¨ `RunnablePassthrough()` è°ƒç”¨ï¼Œå› æ­¤å®ƒåªæ˜¯ä¼ é€’äº† `{'num': 1}`ã€‚ > > åœ¨ç¬¬äºŒè¡Œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¸¦æœ‰å°†æ•°å€¼ä¹˜ä»¥3çš„lambdaçš„ `RunnablePastshrough.assign`ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`extra` è¢«è®¾ç½®ä¸º `{'num': 1, 'mult': 3}`ï¼Œå³åŸå§‹å€¼åŠ ä¸Š `mult` é”®ã€‚ > > æœ€åï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨lambdaåœ¨æ˜ å°„ä¸­è®¾ç½®äº†ç¬¬ä¸‰ä¸ªé”® `modified`ï¼Œå°†numåŠ 1ï¼Œç»“æœä¸º `modified` é”®çš„å€¼ä¸º `2`ã€‚ ```python retrieval_chain ( {\"context\": retriever, \"question\": RunnablePassthrough()} prompt model StrOutputParser() ) retrieval_chain.invoke(\"where did harrison work?\") ``` > åœ¨è¾“å…¥å‚æ•°é‡Œé¢åŠ å…¥ä¸€ä¸ªcontexté”® ### è®°å¿†æ€»ç»“ å®é™…æ˜¯æŠŠå¯¹è¯äº¤ç»™AI, è®©ä»–è¿›è¡Œæ€»ç»“å¤„ç† ```python def summarize_messages(chain_input): stored_messages history.messages if len(stored_messages) 0: return False summarization_prompt ChatPromptTemplate.from_messages([ MessagesPlaceholder(variable_name \"history\"), (\"user\", \"æŠŠä¸Šé¢çš„æ¶ˆæ¯æµ“ç¼©ä¸€ä¸‹, å°½å¯èƒ½çš„åŒ…å«å¤šä¸ªç»†èŠ‚, å°¤å…¶æ˜¯ç”¨æˆ·çš„ç‰¹å¾\") ]) summarization_chain summarization_prompt ChatOpenAI(model \"gpt 3.5 turbo 1106\") result summarization_chain.invoke(input {\"history\": stored_messages}) history.clear() history.add_message(result) return True chain_with_summarization ( RunnablePassthrough.assign(messages_summarized summarize_messages) with_message_history ) ``` ## å¤šæ¨¡æ€è¾“å…¥ æŠŠè¾“å…¥æŒ‰ç…§ä¸€å®šçš„æ ¼å¼è¿›è¡Œè½¬æ¢ ### å›¾ç‰‡è¾“å…¥ ç›´æ¥ä¼ é€’å›¾ç‰‡åœ°å€, è¿™ä¸ªæ–¹å¼å¯èƒ½ç”±äºAIæ— æ³•è·å–å›¾ç‰‡å¤±è´¥ ```python import base64 # è¿™æ˜¯ä¸€ä¸ªç¼–ç åº“, ç”¨äºç¼–ç å’Œè§£ç äºŒè¿›åˆ¶æ•°æ® import httpx # è¿™æ˜¯ä¸€ä¸ªå¼‚æ­¥ HTTP å®¢æˆ·ç«¯åº“ from langchain_core.messages import HumanMessage from langchain_openai import ChatOpenAI from Siliconflow import CustomLLM_Siliconflow image_url \"https://th.bing.com/th/id/R.6b5df1bfe0e4778a44dba0753cd169c8?rik QRQIMqvjWRCO5Q&riu http%3a%2f%2fpic39.nipic.com%2f20140321%2f8857347_232251363165_2.jpg&ehk 7oAaMo6LCHJc%2bqpQ0IPvcH7v69jGRQhb2vDz%2fOd5720%3d&risl &pid ImgRaw&r 0\" # æ–¹å¼1: ç›´æ¥ä¼ å…¥ç½‘å€ model ChatOpenAI(model \"gpt 4o\") message HumanMessage( content [ { \"type\": \"text\", \"text\": \"æè¿°è¿™ä¸ªå›¾ç‰‡é‡Œé¢çš„å†…å®¹\" }, { \"type\": \"image_url\", \"image_url\": {\"url\": image_url} } ] ) ``` ä¹Ÿå¯ä»¥æŠŠå›¾ç‰‡çš„æ•°æ®ç›´æ¥ä¼ è¿‡å» ```python import base64 # è¿™æ˜¯ä¸€ä¸ªç¼–ç åº“, ç”¨äºç¼–ç å’Œè§£ç äºŒè¿›åˆ¶æ•°æ® import httpx # è¿™æ˜¯ä¸€ä¸ªå¼‚æ­¥ HTTP å®¢æˆ·ç«¯åº“ from langchain_core.messages import HumanMessage from langchain_openai import ChatOpenAI from Siliconflow import CustomLLM_Siliconflow image_url \"https://th.bing.com/th/id/R.6b5df1bfe0e4778a44dba0753cd169c8?rik QRQIMqvjWRCO5Q&riu http%3a%2f%2fpic39.nipic.com%2f20140321%2f8857347_232251363165_2.jpg&ehk 7oAaMo6LCHJc%2bqpQ0IPvcH7v69jGRQhb2vDz%2fOd5720%3d&risl &pid ImgRaw&r 0\" image_data base64.b64encode(httpx.get(image_url).content).decode(\"utf 8\") # å°†å›¾ç‰‡è½¬æ¢ä¸º base64 ç¼–ç çš„å­—ç¬¦ä¸² message_img HumanMessage( content [ { \"type\": \"text\", \"text\": \"æè¿°è¿™ä¸ªå›¾ç‰‡é‡Œé¢çš„å†…å®¹\" }, { \"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"} } ] ) ``` ```python result model.invoke([message_img]) print(result) ``` ## ä½¿ç”¨å·¥å…· toolæœ‰æœºéƒ¨åˆ†ç»„æˆ + name: åå­—, å¿…é¡»å”¯ä¸€çš„æè¿° + description: å·¥å…·çš„æè¿°, LLMä¹‹åä¼šä½¿ç”¨è¿™ä¸ªä½œä¸ºä¸Šä¸‹æ–‡ + args_schema: å¯é€‰, ä½†æ˜¯å»ºè®®æä¾›æ›´å¤šçš„ä¿¡æ¯, Pydantic BaseModelçš„ç±»å‹ + return_direct: booleanç±»å‹, ä»£ç†ç›¸å…³çš„, Trueçš„æ—¶å€™ä»£ç†åœæ­¢, ç›´æ¥å°†ç»“æœè¿”å›ç»™ç”¨æˆ· æœ‰å‡ ç§æ–¹å¼å¯ä»¥å®šä¹‰ ### è‡ªå®šä¹‰å·¥å…· [å®šä¹‰è‡ªå®šä¹‰å·¥å…· ğŸ¦œï¸ğŸ”— Langchain](https://python.langchain.com.cn/docs/modules/agents/tools/how_to/custom_tools) #### @toolè£…é¥°å™¨ ```python from langchain_core.tools import tool @tool def weather_tool(weather: Literal[\"æ™´æœ—çš„\", \"å¤šäº‘çš„\", \"å¤šé›¨çš„\", \"ä¸‹é›ªçš„\"]) > None: \"\"\"Discribe the weather\"\"\" # è¿™ä¸ªå·¥å…·æ¥å—ä¸€ä¸ªå¤©æ°”å‚æ•°, å¹¶è¿”å›ä¸€ä¸ªæè¿°å¤©æ°”çš„å­—ç¬¦ä¸² pass \"\"\" name 'weather_tool' description 'Discribe the weather' args_schema <class 'langchain_core.utils.pydantic.weather_tool'> func <function weather_tool at 0x7f57151d23e0> \"\"\" ``` å»ºç«‹ä¸€ä¸ªå·¥å…·, å·¥å…·çš„æè¿°æ˜¯ä»–çš„æ³¨é‡Š, LangChain ä¸­çš„å·¥å…·æŠ½è±¡å°† Python å‡½æ•°ä¸å®šä¹‰å‡½æ•°**åç§°**ã€**æè¿°**å’Œ**é¢„æœŸå‚æ•°**çš„**æ¶æ„**ç›¸å…³è”ã€‚ > ```python > print(weather_tool.name) > print(weather_tool.description) > print(weather_tool.args) > \"\"\" > weather_tool > Discribe the weather > {'weather': {'enum': ['æ™´æœ—çš„', 'å¤šäº‘çš„', 'å¤šé›¨çš„', 'ä¸‹é›ªçš„'], 'title': 'Weather', 'type': 'string'}} > \"\"\" > ``` + ä½¿ç”¨ ```python from typing import Literal from langchain_core.messages import HumanMessage from langchain_openai import ChatOpenAI from Siliconflow import CustomLLM_Siliconflow from langchain_core.tools import tool @tool def weather_tool(weather: Literal[\"æ™´æœ—çš„\", \"å¤šäº‘çš„\", \"å¤šé›¨çš„\", \"ä¸‹é›ªçš„\"]) > None: \"\"\"Discribe the weather\"\"\" # è¿™ä¸ªå·¥å…·æ¥å—ä¸€ä¸ªå¤©æ°”å‚æ•°, å¹¶è¿”å›ä¸€ä¸ªæè¿°å¤©æ°”çš„å­—ç¬¦ä¸² pass model ChatOpenAI(model \"gpt 4o\") model_with_tool model.bind_tools([weather_tool]) # ç»‘å®šå·¥å…· image_url \"https://th.bing.com/th/id/R.6b5df1bfe0e4778a44dba0753cd169c8?rik QRQIMqvjWRCO5Q&riu http%3a%2f%2fpic39.nipic.com%2f20140321%2f8857347_232251363165_2.jpg&ehk 7oAaMo6LCHJc%2bqpQ0IPvcH7v69jGRQhb2vDz%2fOd5720%3d&risl &pid ImgRaw&r 0\" # æ–¹å¼1: ç›´æ¥ä¼ å…¥ç½‘å€ message HumanMessage( content [ { \"type\": \"text\", \"text\": \"æè¿°è¿™ä¸ªå›¾ç‰‡é‡Œé¢çš„å†…å®¹\" }, { \"type\": \"image_url\", \"image_url\": {\"url\": image_url} } ] ) # å¦‚æœæ¨¡å‹æƒ³ä½¿ç”¨å·¥å…·, ä»–åªå¯ä»¥è¾“å‡ºå·¥å…·æ”¯æŒçš„è¾“å…¥, æ‰€ä»¥å¯ä»¥é™å®šæ¨¡å‹çš„è¾“å‡º result model.invoke([message]) print(result) ``` > + Create tools using the`@tool`decorator, which simplifies the process of tool creation, supporting the following: > ä½¿ç”¨ [@tool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html) ä¿®é¥°å™¨åˆ›å»ºå·¥å…·ï¼Œè¿™ç®€åŒ–äº†å·¥å…·åˆ›å»ºè¿‡ç¨‹ï¼Œå¹¶æ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š > + + Automatically infer the tool's **name**, **description** and **expected arguments**, while also supporting customization. > è‡ªåŠ¨æ¨æ–­å·¥å…·**çš„åç§°**ã€**æè¿°**å’Œ**é¢„æœŸå‚æ•°**ï¼ŒåŒæ—¶è¿˜æ”¯æŒè‡ªå®šä¹‰ã€‚ > + Defining tools that return **artifacts** (e.g. images, dataframes, etc.) > å®šä¹‰è¿”å›**å·¥ä»¶**çš„å·¥å…·ï¼ˆä¾‹å¦‚å›¾åƒã€æ•°æ®å¸§ç­‰ï¼‰ > + Hiding input arguments from the schema (and hence from the model) using **injected tool arguments**. > ä½¿ç”¨**æ³¨å…¥çš„å·¥å…·å‚æ•°**ä» Schema ï¼ˆä»¥åŠæ¨¡å‹ä¸­ï¼‰ éšè—è¾“å…¥å‚æ•°ã€‚ + å¼‚æ­¥ é»˜è®¤çš„ä½¿ç”¨æ˜¯åŒæ­¥çš„, ä¹Ÿå¯ä»¥ä½¿ç”¨å¼‚æ­¥çš„, ä¹‹åçš„è°ƒç”¨éœ€è¦ä½¿ç”¨å¼‚æ­¥çš„æ–¹å¼ ```python @tool async def weather_tool(weather: Literal[\"æ™´æœ—çš„\", \"å¤šäº‘çš„\", \"å¤šé›¨çš„\", \"ä¸‹é›ªçš„\"]) > None: \"\"\"Discribe the weather\"\"\" # è¿™ä¸ªå·¥å…·æ¥å—ä¸€ä¸ªå¤©æ°”å‚æ•°, å¹¶è¿”å›ä¸€ä¸ªæè¿°å¤©æ°”çš„å­—ç¬¦ä¸² pass ``` + å‚æ•° ä½¿ç”¨pydanticæŒ‡å®šå‚æ•° ```python from langchain_core.tools import tool from pydantic import BaseModel, Field class CalculatorInput(BaseModel): a: int Field(description \"ç¬¬ä¸€ä¸ªæ•°å­—\") b: int Field(description \"ç¬¬äºŒä¸ªæ•°å­—\") @tool(\"multiplication tool\", args_schema CalculatorInput, return_direct True) def multiplication_tool(a: int, b: int) > int: \"\"\"Multiply two numbers\"\"\" return a * b print(multiplication_tool.name) print(multiplication_tool.description) print(multiplication_tool.args) print(multiplication_tool.invoke({\"a\": 2, \"b\": 3})) \"\"\" multiplication tool Multiply two numbers {'a': {'description': 'ç¬¬ä¸€ä¸ªæ•°å­—', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'ç¬¬äºŒä¸ªæ•°å­—', 'title': 'B', 'type': 'integer'}} 6 \"\"\" ``` #### StructuredTool.from_function ç±»ä¼¼äºtoolä½†æ˜¯å…è®¸æ›´å¤šé…ç½®ä»¥åŠåŒæ­¥å¼‚æ­¥çš„è§„èŒƒ ```python from langchain_core.tools import StructuredTool import asyncio def multiply(a: int, b:int) >int: \"\"\"Multiply two numbers\"\"\" return a*b async def amultiply(a: int, b:int) >int: \"\"\"Multiply two numbers\"\"\" return a*b async def main(): calcuator StructuredTool.from_function(func multiply, coroutine amultiply) print(calcuator.invoke({\"a\": 2, \"b\": 3})) print(await calcuator.ainvoke({\"a\": 2, \"b\": 3})) asyncio.run(main()) \"\"\" 6 6 \"\"\" ``` #### å¼‚å¸¸å¤„ç† å·¥å…·çš„å‡ºç°å¼‚å¸¸çš„ä½¿ç”¨çš„å¤„ç† ```python from langchain_core.tools import StructuredTool from langchain_core.tools import ToolException from langchain.tools import Tool def get_weather(city: str) > int: \"\"\"Get the weather of a city\"\"\" return ToolException(f\"Can't get the weather of {city}\") get_weather_tool Tool.from_function( func get_weather, # handle_tool_error True, name \"get_weather\", description \"Get the weather of a city\", ) response get_weather_tool.invoke(\"Beijing\") print(response) ``` > You can set `handle_tool_error` to `True`, set it a unified string value, or set it as a function. If it's set as a function, the function should take a `ToolException` as a parameter and return a `str` value. > > ä¼šä½¿ç”¨è¿™ä¸ªå¼‚å¸¸çš„è¾“å‡ºä½œä¸ºè¿”å›å€¼, æ‰‹å†Œé‡Œé¢è¯´è¿™ä¸ªå—åˆ°handle_tool_erroræ§åˆ¶, ä½†æ˜¯è¿™é‡Œå®é™…æµ‹è¯•åå‘ç°handle_tool_errorå‚æ•°æ²¡æœ‰å½±å“ > > ä½¿ç”¨StructuredToolçš„æ—¶å€™å¯ä»¥ä¼ é€’æ›´å°‘çš„å‚æ•° #### ä½¿ç”¨BaseToolå»ºç«‹ä¸€ä¸ªå­ç±» BaseTool ä¼šè‡ªåŠ¨ä» _run æ–¹æ³•çš„ç­¾åæ¨æ–­æ¶æ„ã€‚ ### å†…ç½®å·¥å…· å·¥å…·å®é™…æ˜¯ä»£ç†, é“¾æˆ–è€…èŠå¤©æ¨¡å‹å’Œä¸–ç•Œäº¤äº’çš„æ–¹å¼, ä¸€èˆ¬æœ‰ä»¥ä¸‹çš„éƒ¨åˆ† 1. å·¥å…·çš„åå­— 2. å·¥å…·çš„åŠŸèƒ½æè¿° 3. å·¥å…·çš„è¾“å…¥çš„JSONæ ¼å¼ 4. è¦è°ƒç”¨çš„å‡½æ•° 5. å·¥å…·çš„ç»“æœæ˜¯ä¸æ˜¯ç›´æ¥è¿”ç»™ç”¨æˆ·, æŠŠåç§°æè¿°ä¸Šä¸‹æ–‡å‘é€ç»™å¤§æ¨¡å‹, è®©æ¨¡å‹è¿›è¡Œå·¥å…·çš„è°ƒç”¨, ä¸€èˆ¬ç»è¿‡å¾®è°ƒçš„æ¨¡å‹æ•ˆæœæ¯”è¾ƒå¥½, æ²¡æœ‰å¾®è°ƒçš„æ¨¡å‹å¯èƒ½å¤±è´¥ #### ç»´åŸºç™¾ç§‘å·¥å…· [WikipediaAPIWrapper â€” ğŸ¦œğŸ”— LangChain documentation](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.wikipedia.WikipediaAPIWrapper.html) ```python from langchain_community.tools import WikipediaQueryRun from langchain_community.utilities import WikipediaAPIWrapper api_wrapper WikipediaAPIWrapper(top_k_results 1, doc_content_chars_max 100) tool WikipediaQueryRun(api_wrapper api_wrapper) print(tool.invoke({\"query\": \"Langchain\"})) print(tool.name) print(tool.description) print(tool.args) \"\"\" Wiki tools A tool to query Wikipedia {'query': {'description': 'æŸ¥è¯¢å…³é”®è¯, é•¿åº¦ä¸è¶…è¿‡10ä¸ªå­—', 'title': 'Query', 'type': 'string'}} \"\"\" ``` å¯ä»¥åšä¸€ä¸‹å‚æ•°çš„å°è£… ```python from langchain_community.tools import WikipediaQueryRun from langchain_community.utilities import WikipediaAPIWrapper from pydantic import BaseModel, Field class WikiInputs(BaseModel): \"\"\"ç»´åŸºç™¾ç§‘å·¥å…·è¾“å…¥\"\"\" query: str Field(description \"æŸ¥è¯¢å…³é”®è¯, é•¿åº¦ä¸è¶…è¿‡10ä¸ªå­—\") api_wrapper WikipediaAPIWrapper(top_k_results 1, doc_content_chars_max 100) tool WikipediaQueryRun( api_wrapper api_wrapper, name \"Wiki tools\", description \"A tool to query Wikipedia\", args_schema WikiInputs, return_direct True ) print(tool.run(\"Langchain\")) print(tool.name) print(tool.description) print(tool.args) \"\"\" Wiki tools A tool to query Wikipedia {'query': {'description': 'æŸ¥è¯¢å…³é”®è¯, é•¿åº¦ä¸è¶…è¿‡10ä¸ªå­—', 'title': 'Query', 'type': 'string'}} \"\"\" ``` #### SQLå¤„ç† [LangChainä¸­æ–‡ç½‘](https://www.langchain.com.cn/docs/integrations/tools/sql_database/) ```python from langchain_openai import ChatOpenAI from langchain_community.agent_toolkits.sql.base import create_sql_agent from langchain.agents.agent_types import AgentType from langchain_community.utilities import SQLDatabase from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit import sqlite3 import requests from sqlalchemy import create_engine from sqlalchemy.pool import StaticPool # è¿™æ®µä»£ç çš„ä½œç”¨æ˜¯ä»ä¸€ä¸ªè¿œç¨‹çš„SQLè„šæœ¬ä¸­åˆ›å»ºä¸€ä¸ªåœ¨å†…å­˜ä¸­çš„SQLiteæ•°æ®åº“ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ•°æ®åº“å¼•æ“å¯¹è±¡ã€‚ def get_engine_for_chinook_db(): \"\"\"ä»SQLè„šæœ¬åˆ›å»ºå†…å­˜æ•°æ®åº“å¹¶è¿”å›å¼•æ“å¯¹è±¡ã€‚\"\"\" url \"https://raw.githubusercontent.com/lerocha/chinook database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\" response requests.get(url) sql_script response.text connection sqlite3.connect(\":memory:\", check_same_thread False) connection.executescript(sql_script) return create_engine( \"sqlite://\", creator lambda: connection, poolclass StaticPool, connect_args {\"check_same_thread\": False}, ) engine get_engine_for_chinook_db() db SQLDatabase(engine) # db SQLDatabase.from_uri(\"sqlite:///langchain.db\") # å»ºç«‹ä¸€ä¸ªSQLå·¥å…·ç®±å¯¹è±¡, ç”¨äºæ‰§è¡ŒSQLæŸ¥è¯¢, å¯ä»¥ç»‘å®šLLMæ¨¡å‹ toolkit SQLDatabaseToolkit(db db, llm ChatOpenAI(temperature 0)) # print(toolkit.get_tools()) agent_exector create_sql_agent( llm ChatOpenAI(temperature 0), toolkit toolkit, verbose False, agent_type AgentType.OPENAI_FUNCTIONS ) result agent_exector.invoke(\"Create a full_llm_cache table\") print(result) ``` ## æŒ‡å®šæ ¼å¼è¾“å‡º å¦‚æœè¾“å‡ºçš„æ ¼å¼æ˜¯ä¸€ä¸ªjson, xmlæˆ–è€…yaml, ä½†æ˜¯å¤§æ¨¡å‹çš„è¾“å‡ºå¯ä»¥èƒ½æ˜¯ä¸€ä¸ªæ··ä¹±çš„æ ¼å¼, æ‰€ä»¥ä½¿ç”¨çš„æ¨¡å‹å¿…é¡»è¶³å¤Ÿå¤§ å¯ä»¥ä½¿ç”¨JsonOutputParserè¿›è¡Œæç¤ºå¹¶ä¸”è§£æå¤§æ¨¡å‹çš„è¾“å‡º, ä¹Ÿå¯ä»¥ä½¿ç”¨PydanticOutputParser, Jsonçš„è¾“å‡ºæ˜¯å†…ç½®çš„, æ”¯æŒæµå¼è¿”å› > Pydanticç¤ºä¾‹, [Pythonç¬”è®°ï¼šPydanticåº“ç®€ä»‹ CSDNåšå®¢](https://blog.csdn.net/codename_cys/article/details/107675748) > > ```python > from pydantic import BaseModel > > class Person(BaseModel): > name: str > > p Person(name \"Tom\") > print(p.json()) # {\"name\": \"Tom\"} > ``` ```python from langchain_core.output_parsers import JsonOutputParser from langchain_openai import ChatOpenAI from langchain_core.prompts import PromptTemplate from langchain_core.pydantic_v1 import BaseModel, Field model ChatOpenAI(model \"gpt 4o\") # æè¿°è¾“å‡ºçš„å…·ä½“æ ¼å¼ class Joke(BaseModel): setup: str Field(description \"è®¾ç½®ç¬‘è¯çš„é—®é¢˜\") punchline: str Field(description \"è§£å†³ç¬‘è¯çš„ç­”æ¡ˆ\") joke_query \"å‘Šè¯‰æˆ‘ä¸€ä¸ªç¬‘è¯\" parser JsonOutputParser(pydantic_object Joke) prompt PromptTemplate( template \"å›ç­”ç”¨æˆ·çš„é—®é¢˜, \\n{format_instructions}\\n{query}\\n\", input_variables [\"query\"], partial_variables {\"format_instructions\": parser.get_format_instructions()} ) chain prompt model parser message chain.invoke({\"query\": joke_query}) print(message) \"\"\" {'setup': 'ä¸ºä»€ä¹ˆç¨‹åºå‘˜ä¸é¥¿ï¼Ÿ', 'punchline': 'å› ä¸ºä»–ä»¬æœ‰å¾ˆå¤šçš„ç¼“å­˜ã€‚'} \"\"\" ``` å¯ä»¥çœ‹ä¸€ä¸‹è¾“å…¥çš„æ¨¡æ¿, å¦‚æœä¸ä½¿ç”¨è¿™ä¸ªæ¨¡ç‰ˆ, å®é™…çš„è¾“å‡ºä¼šæœ‰éšæœºæ€§ ````python print(parser.get_format_instructions()) \"\"\" The output should be formatted as a JSON instance that conforms to the JSON schema below. As an example, for the schema { \t\"properties\": { \t\t\"foo\": { \t\t\t\"title\": \"Foo\", \t\t\t\"description\": \"a list of strings\", \t\t\t\"type\": \"array\", \t\t\t\"items\": {\"type\": \"string\"} \t\t} \t}, \t\"required\": [\"foo\"] } the object {\"foo\": [\"bar\", \"baz\"]} is a well formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well formatted. Here is the output schema: ``` { \t\"properties\": { \t\t\"setup\": { \t\t\t\"title\": \"Setup\", \"description\": \"è®¾ç½®ç¬‘è¯çš„é—®é¢˜\", \"type\": \"string\" }, \"punchline\": { \"title\": \"Punchline\", \"description\": \"è§£å†³ç¬‘è¯çš„ç­”æ¡ˆ\", \"type\": \"string\" } }, \"required\": [\"setup\", \"punchline\"] } ``` \"\"\" ```` å¯ä»¥ä½¿ç”¨æµå¼è¾“å‡º ```python for s in chain.stream({\"query\": joke_query}): print(s) \"\"\" {} {'setup': ''} {'setup': 'ä¸ºä»€ä¹ˆ'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒ'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ', 'punchline': ''} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ', 'punchline': 'å› ä¸º'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ', 'punchline': 'å› ä¸ºè§‚'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ', 'punchline': 'å› ä¸ºè§‚ä¼—'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ', 'punchline': 'å› ä¸ºè§‚ä¼—ä»¬'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ', 'punchline': 'å› ä¸ºè§‚ä¼—ä»¬éœ€è¦'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ', 'punchline': 'å› ä¸ºè§‚ä¼—ä»¬éœ€è¦çœ‹åˆ°'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ', 'punchline': 'å› ä¸ºè§‚ä¼—ä»¬éœ€è¦çœ‹åˆ°è¿›'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ', 'punchline': 'å› ä¸ºè§‚ä¼—ä»¬éœ€è¦çœ‹åˆ°è¿›çƒ'} {'setup': 'ä¸ºä»€ä¹ˆè¶³çƒæ¯”èµ›æ€»æ˜¯åœ¨ç¯å…‰ä¸‹ï¼Ÿ', 'punchline': 'å› ä¸ºè§‚ä¼—ä»¬éœ€è¦çœ‹åˆ°è¿›çƒï¼'} \"\"\" ``` ### YAMLè¾“å‡º è¿™ä¸ªæ ¼å¼çš„å®é™…ä½¿ç”¨å’ŒJSONçš„ä½¿ç”¨æ˜¯ä¸€æ ·çš„ ### XMLæ ¼å¼ å¯ä»¥ä½¿ç”¨XMLOutputParserè¿›è¡Œè¾“å‡º, ä½¿ç”¨`tags [\"\", \"\"]`å¯ä»¥æŒ‡å®šå®é™…è¾“å‡ºçš„æ ‡ç­¾, ä¹‹åçš„è¾“å‡ºä¼šæŒ‰ç…§è¿™ä¸ªçš„å±‚çº§è¿›è¡Œè¾“å‡º, å¦‚æœä½¿ç”¨çš„æ˜¯æµå¼è¾“å‡º, å®é™…çš„ç»“æœè¿˜æ˜¯json ```python from langchain_core.output_parsers import XMLOutputParser from langchain_openai import ChatOpenAI from langchain_core.prompts import PromptTemplate model ChatOpenAI(model \"gpt 3.5 turbo 1106\") joke_query \"ç”Ÿæˆå‘¨æ˜Ÿé©°çš„ç”µå½±ä½œå“, å®‰è£…æ—¶é—´é¡ºåºè¿›è¡Œæ’åº\" parser XMLOutputParser(tags [\"movie\", \"actor\", \"film\", \"genre\",\"time\"]) prompt PromptTemplate( template \"å›ç­”ç”¨æˆ·çš„é—®é¢˜, \\n{format_instructions}\\n{query}\\n\", input_variables [\"query\"], partial_variables {\"format_instructions\": parser.get_format_instructions()} ) chain prompt model parser message chain.invoke({\"query\": joke_query}) print(message) ``` ## è‡ªå®šä¹‰æ¨¡å‹ [Custom LLM ğŸ¦œï¸ğŸ”— LangChain](https://python.langchain.com/v0.1/docs/modules/model_io/llms/custom_llm/) éœ€è¦å®ç°ä¸¤ä¸ªå‡½æ•°, [ä½¿ç”¨LangChainè‡ªå®šä¹‰å¤§æ¨¡å‹ å®Œç¾è°ƒç”¨ç¬¬ä¸‰æ–¹ API å¦‚OneAPI/ç¡…åŸºæµåŠ¨ è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº è…¾è®¯äº‘](https://cloud.tencent.com/developer/article/2467458)"},"/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-2-16-dify.html":{"title":"dify","content":"# dify çµæ´»çš„ç”Ÿæˆå¼AIåº”ç”¨å¼€å‘æ¡†æ¶ ## å®‰è£… ä½¿ç”¨ä¸€ä¸ªæœ‰å®å¡”é¢æ¿çš„æœåŠ¡å™¨, ä½¿ç”¨`http://49.232.36.90:8888/tencentcloud`æ‰“å¼€, å®‰è£…ä¸€ä¸ªåŸºç¡€ç¯å¢ƒä»¥åŠdockerå®¹å™¨, ä¹‹åä¸‹è½½difyè½¯ä»¶å³å¯ > å¯ä»¥ä½¿ç”¨`sudo /etc/init.d/bt default`è·å–è´¦æˆ·, ä½¿ç”¨`bt`å‘½ä»¤è®¾ç½®è´¦æˆ·å¯†ç  ç”±äºè¿™ä¸ªç½‘å€æ˜¯åœ¨dockeré‡Œé¢æ‰€ä»¥éœ€è¦å¼€ä¸€ä¸ªæ–¹å‘ä»£ç† ä½¿ç”¨å‰æ‰“å¼€8088çš„ç«¯å£, ç¬¬ä¸€æ¬¡æ‰“å¼€çš„æ—¶å€™ä½¿ç”¨`ip:8088/install`è®¾ç½®ä¸€ä¸‹ç®¡ç†å‘˜ ![image 20250218184210721](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181842807.png) åœ¨å®å¡”çš„ç½‘ç«™é‡Œé¢æ‰“å¼€åå‘ä»£ç† ![image 20250218184354985](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181843021.png) ## åŸºç¡€ä½¿ç”¨ å¯ä»¥åœ¨è®¾ç½®é‡Œé¢æ·»åŠ ä½ çš„API ![image 20250218184829431](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181848496.png) ä¹‹åå¯ä»¥ä½¿ç”¨æ¨¡å‹, å¯ä»¥æ·»åŠ å’ŒopenAIçš„æ•°æ®æ ¼å¼ç›¸åŒçš„AI, æ¯”å¦‚ä½¿ç”¨Deepbricksæ³¨å†Œä»¥åä½¿ç”¨openAIçš„æ¨¡å‹ ![image 20250218184857837](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181848911.png) å»ºç«‹çš„æ—¶å€™å¯ä»¥ä½¿ç”¨ä¸åŒçš„æ¨¡æ¿ ![image 20250218184945666](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181849741.png) åŸºç¡€è®¾ç½®ä»¥åå¯ä»¥åœ¨å³ä¸Šè§’è¿›è¡Œå‘å¸ƒ, ä¹‹åå¯ä»¥åœ¨ç½‘é¡µæˆ–è€…å°ç¨‹åºé‡Œé¢ä½¿ç”¨è¿™ä¸ªAI ### ä½¿ç”¨çŸ¥è¯†åº“ ![image 20250218191219815](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181912908.png) ![image 20250218191303021](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181913113.png) > æ•°æ®è¿›å…¥ä»¥åè¿›è¡ŒçŸ¥è¯†åº“çš„æ£€ç´¢, æœ€åè¿›å…¥å¤§æ¨¡å‹å¤„ç†è¾“å‡º ![image 20250218191538120](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181915186.png) ![image 20250218191634909](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181916972.png) å¯ä»¥åœ¨è¿™é‡ŒåŠ å…¥å®é™…ä½¿ç”¨çš„æ–‡æœ¬æ–‡ä»¶ ![image 20250218192220130](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181922178.png) è¿™é‡Œçš„åˆ†æ®µæ ‡è¯†ç¬¦æ˜¯åœ¨æ£€ç´¢åˆ°è¿™ä¹ˆå¤šä¸ªç¬¦å·ä»¥ååˆ†æ®µ > è¿™é‡Œçš„è€ŒQ&Aåˆ†æ®µåŠŸèƒ½æ˜¯æŒ‡å°†ä¿¡æ¯æˆ–é—®é¢˜æŒ‰ç…§é—®é¢˜å’Œå›ç­”çš„å½¢å¼åˆ†å¼€å±•ç¤ºï¼Œä½¿è¯»è€…èƒ½å¤Ÿæ›´æ¸…æ™°åœ°äº†è§£é—®é¢˜å’Œç›¸åº”çš„ç­”æ¡ˆã€‚é€šå¸¸åœ¨æ–‡ç« ã€ç½‘ç«™ã€ç”µå­ä¹¦æˆ–è®ºå›ä¸­ä½¿ç”¨ï¼Œå¯ä»¥å¸®åŠ©è¯»è€…å¿«é€Ÿæ‰¾åˆ°è‡ªå·±æ„Ÿå…´è¶£çš„ä¿¡æ¯ï¼ŒåŒæ—¶æä¾›æ›´å¥½çš„é˜…è¯»ä½“éªŒã€‚è¿™ç§å½¢å¼çš„æ–‡æœ¬å¸ƒå±€èƒ½å¤Ÿä½¿ä¿¡æ¯æ›´æ˜“äºç†è§£å’Œæ¶ˆåŒ–ï¼Œä½¿å¾—è¯»è€…èƒ½å¤Ÿæ›´åŠ é«˜æ•ˆåœ°è·å–æ‰€éœ€çš„ä¿¡æ¯ã€‚ > > ![image 20250218211826531](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502182118609.png) > > è®°å½•çš„æ¶ˆæ¯æ˜¯è¿™ç§å¯¹è¯çš„å½¢å¼ ![image 20250218192254057](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181922104.png) > çˆ¶å­åˆ†æ®µæ¨¡å¼æ˜¯ä¸€ç§æ–‡æœ¬æ’ç‰ˆæ–¹å¼ï¼Œé€šè¿‡å°†ä¸»è¦å†…å®¹å’Œç›¸å…³å†…å®¹ä¹‹é—´å»ºç«‹çˆ¶å­å…³ç³»ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç»„ç»‡å’Œå‘ˆç°ä¿¡æ¯ã€‚åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œé€šå¸¸ä¼šå…ˆåˆ—å‡ºä¸€ä¸ªä¸»è¦æ®µè½æˆ–ä¸»è¦é—®é¢˜ï¼ˆçˆ¶æ®µè½ï¼‰ï¼Œç„¶ååœ¨å…¶ä¸‹é¢åˆ—å‡ºç›¸å…³çš„å­æ®µè½æˆ–å­é—®é¢˜ï¼Œå½¢æˆä¸€ä¸ªå±‚æ¬¡ç»“æ„ã€‚è¿™ç§æ’ç‰ˆæ–¹å¼å¯ä»¥è®©è¯»è€…æ›´æ–¹ä¾¿åœ°ç†è§£ä¿¡æ¯ä¹‹é—´çš„å…³è”æ€§ï¼Œæ›´æ˜ç¡®åœ°äº†è§£ä¸»é¢˜çš„å„ä¸ªæ–¹é¢ã€‚ > > çˆ¶å­åˆ†æ®µæ¨¡å¼åœ¨ä¹¦ç±ã€è®ºæ–‡ã€ç½‘é¡µè®¾è®¡ç­‰é¢†åŸŸéƒ½æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚é€šè¿‡æ„å»ºçˆ¶å­å…³ç³»ï¼Œå¯ä»¥å¸®åŠ©è¯»è€…æ›´å¿«é€Ÿåœ°è·å–æ‰€éœ€ä¿¡æ¯ï¼ŒåŒæ—¶ä¹Ÿæœ‰åŠ©äºæé«˜ä¿¡æ¯çš„ç»„ç»‡å’Œå‘ˆç°æ•ˆæœã€‚è¿™ç§æ¨¡å¼ä¸ä»…ä½¿ä¿¡æ¯æ›´å…·æœ‰å±‚æ¬¡æ€§å’Œç³»ç»Ÿæ€§ï¼Œè¿˜æœ‰åŠ©äºè¯»è€…æ›´æ·±å…¥åœ°ç†è§£å’Œæ¢ç©¶ç›¸å…³ä¸»é¢˜ã€‚ > > ä½¿ç”¨æ€»ç»“ä½œä¸ºæ£€ç´¢, ä¸€èˆ¬ç¬¬ä¸€ç§æ¯”è¾ƒå¥½ ![image 20250218193136703](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181931749.png) å®é™…ä½¿ç”¨çš„æ£€ç´¢æ¨¡å‹, ä»¥åŠæå–å‡ºæ¥çš„æ•°é‡, å‘é‡çš„ç»“æœæ¯”è¾ƒå¥½, æ¨èä½¿ç”¨æ··åˆçš„æ¨¡å‹ > 1. å‘é‡æ£€ç´¢ï¼š > å‘é‡æ£€ç´¢æ˜¯ä¸€ç§åŸºäºå‘é‡ç©ºé—´æ¨¡å‹çš„æ£€ç´¢æ–¹æ³•ï¼Œå°†æ–‡æ¡£å’ŒæŸ¥è¯¢éƒ½è¡¨ç¤ºä¸ºå‘é‡ï¼Œé€šè¿‡è®¡ç®—å®ƒä»¬ä¹‹é—´çš„ç›¸ä¼¼åº¦æ¥è¿›è¡Œæ£€ç´¢ã€‚åœ¨å‘é‡æ£€ç´¢ä¸­ï¼Œæ¯ä¸ªæ–‡æ¡£å’ŒæŸ¥è¯¢éƒ½è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªå¤šç»´å‘é‡ï¼Œå‘é‡ä¸­çš„å„ä¸ªç»´åº¦å¯¹åº”äºç‰¹å®šçš„ç‰¹å¾æˆ–è¯é¡¹ã€‚é€šå¸¸ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ç­‰æ–¹æ³•æ¥åº¦é‡æ–‡æ¡£å’ŒæŸ¥è¯¢ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œä»è€Œç¡®å®šæ£€ç´¢ç»“æœçš„ç›¸å…³æ€§ã€‚ > 2. å…¨æ–‡æ£€ç´¢ï¼š > å…¨æ–‡æ£€ç´¢æ˜¯æŒ‡åœ¨æ–‡æ¡£ä¸­æ£€ç´¢åŒ…å«æŸ¥è¯¢å…³é”®è¯çš„æ–‡æœ¬å†…å®¹ã€‚åœ¨å…¨æ–‡æ£€ç´¢ä¸­ï¼Œä¼šå¯¹æ–‡æ¡£çš„å…¨æ–‡è¿›è¡Œç´¢å¼•ï¼Œæ£€ç´¢æ—¶ä¼šåŒ¹é…æŸ¥è¯¢å…³é”®è¯ä¸æ–‡æ¡£çš„å…¨æ–‡å†…å®¹ï¼Œè€Œä¸æ˜¯å°†æ–‡æ¡£å’ŒæŸ¥è¯¢è¡¨ç¤ºä¸ºå‘é‡ã€‚å…¨æ–‡æ£€ç´¢é€šå¸¸ä½¿ç”¨å€’æ’ç´¢å¼•ç­‰æŠ€æœ¯æ¥åŠ é€Ÿæ£€ç´¢è¿‡ç¨‹ï¼Œé€šè¿‡è¯é¡¹çš„ç´¢å¼•ä½ç½®å¿«é€Ÿå®šä½åŒ…å«æŸ¥è¯¢è¯çš„æ–‡æ¡£ã€‚ > > åŒºåˆ«ï¼š > > 1. åŸç†ï¼šå‘é‡æ£€ç´¢åŸºäºå‘é‡ç©ºé—´æ¨¡å‹ï¼Œè®¡ç®—æ–‡æ¡£å’ŒæŸ¥è¯¢ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼›å…¨æ–‡æ£€ç´¢åˆ™æ˜¯åŸºäºæ–‡æ¡£çš„å…¨æ–‡å†…å®¹è¿›è¡ŒåŒ¹é…ã€‚ > 2. åŒ¹é…æ–¹å¼ï¼šå‘é‡æ£€ç´¢é€šè¿‡è®¡ç®—ç›¸ä¼¼åº¦æ¥ç¡®å®šæ£€ç´¢ç»“æœçš„ç›¸å…³æ€§ï¼›å…¨æ–‡æ£€ç´¢é€šè¿‡åŒ¹é…æŸ¥è¯¢è¯ä¸æ–‡æ¡£å…¨æ–‡å†…å®¹è¿›è¡Œæœç´¢ã€‚ > 3. ç²¾åº¦ï¼šå‘é‡æ£€ç´¢åœ¨ç›¸ä¼¼åº¦è®¡ç®—è¿‡ç¨‹ä¸­è€ƒè™‘äº†å‘é‡çš„æƒé‡å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œå¯ä»¥æä¾›è¾ƒç²¾ç¡®çš„æ£€ç´¢ç»“æœï¼›å…¨æ–‡æ£€ç´¢åŒ¹é…çš„æ˜¯æ–‡æœ¬ç‰‡æ®µï¼Œå¯èƒ½å­˜åœ¨åŒ¹é…ä¸å‡†ç¡®æˆ–æ£€ç´¢ç»“æœä¸å¤Ÿç²¾ç¡®çš„æƒ…å†µã€‚ > 4. åº”ç”¨åœºæ™¯ï¼šå‘é‡æ£€ç´¢é€šå¸¸ç”¨äºéœ€è¦è€ƒè™‘è¯­ä¹‰ç›¸ä¼¼åº¦å’Œå‘é‡è¡¨ç¤ºçš„ä¿¡æ¯æ£€ç´¢åœºæ™¯ï¼›å…¨æ–‡æ£€ç´¢é€‚ç”¨äºéœ€è¦åŒ¹é…æ–‡æœ¬å†…å®¹çš„æ£€ç´¢åœºæ™¯ï¼Œä¾‹å¦‚æœç´¢å¼•æ“ç­‰ã€‚ ![image 20250218193607441](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181936496.png) ä¹‹åæ·»åŠ çŸ¥è¯†åº“ä»¥åŠæ¨¡å‹ ![image 20250218193846536](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181938588.png) ![image 20250218194342941](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181943989.png) ### ç½‘é¡µçŸ¥è¯†åº“ ![image 20250218195637780](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502181956837.png) å¯ä»¥ä½¿ç”¨ä¸¤ä¸ªå·¥å…·, å‰é¢çš„æ˜¯å›½å¤–çš„ ![image 20250218201055717](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502182010771.png) ## å·¥ä½œæµ ### åŸºç¡€æµç¨‹ + è¾“å…¥ å¯ä»¥è®¾ç½®ç”¨æˆ·è¾“å…¥çš„å˜é‡ ![image 20250218213139640](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502182131694.png) + å¤§æ¨¡å‹ ä½¿ç”¨ç”¨æˆ·çš„è¾“å…¥å˜é‡æ„å»ºæç¤ºè¯ ![image 20250218213112101](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502182131148.png) + è¾“å‡º é€‰æ‹©ä¸€ä¸ªè¾“å‡ºçš„æµç¨‹ ![image 20250218213557434](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502182135496.png) ### ç”Ÿæˆå›¾åƒ å¯ä»¥åœ¨å·¥å…·é‡Œé¢æ‰¾åˆ°è¿™ä¸ª ![image 20250218221056685](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/picture/202502182210735.png)"},"/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-12-10-è¯­éŸ³è¯†åˆ«.html":{"title":"è¯­éŸ³è¯†åˆ«","content":"# è¯­éŸ³è¯†åˆ« FunAudioLLMæ˜¯é˜¿é‡Œå·´å·´é€šä¹‰å®éªŒå®¤æ¨å‡ºçš„å¼€æºè¯­éŸ³å¤§æ¨¡å‹é¡¹ç›®ï¼ŒåŒ…å«**SenseVoice**å’Œ**CosyVoice**ä¸¤ä¸ªæ¨¡å‹ã€‚SenseVoiceæ“…é•¿å¤šè¯­è¨€è¯­éŸ³è¯†åˆ«å’Œæƒ…æ„Ÿè¾¨è¯†ï¼Œæ”¯æŒè¶…è¿‡50ç§è¯­è¨€ï¼Œç‰¹åˆ«åœ¨ä¸­æ–‡å’Œç²¤è¯­ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚CosyVoiceåˆ™ä¸“æ³¨äºè‡ªç„¶è¯­éŸ³ç”Ÿæˆï¼Œèƒ½å¤Ÿæ§åˆ¶éŸ³è‰²å’Œæƒ…æ„Ÿï¼Œæ”¯æŒä¸­è‹±æ—¥ç²¤éŸ©äº”ç§è¯­è¨€ã€‚FunAudioLLMé€‚ç”¨äºå¤šè¯­è¨€ç¿»è¯‘ã€æƒ…ç»ªè¯­éŸ³å¯¹è¯ç­‰åœºæ™¯ã€‚ç›¸å…³æ¨¡å‹å’Œä»£ç å·²åœ¨Modelscopeå’ŒHuggingfaceå¹³å°å¼€æº [SenseVoiceæ¨¡å‹](https://github.com/FunAudioLLM/SenseVoice) ä¸“æ³¨äºå¤šè¯­è¨€çš„é«˜ç²¾åº¦è¯­éŸ³è¯†åˆ«ã€‚ æ”¯æŒè¶…è¿‡50ç§è¯­è¨€ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸­æ–‡å’Œç²¤è¯­ä¸Šè¯†åˆ«æ•ˆæœä¼˜äºç°æœ‰æ¨¡å‹ã€‚ å…·å¤‡æƒ…æ„Ÿè¯†åˆ«åŠŸèƒ½ï¼Œèƒ½å¤Ÿè¾¨è¯†å¤šç§äººæœºäº¤äº’äº‹ä»¶ã€‚ æä¾›è½»é‡çº§å’Œå¤§å‹ä¸¤ä¸ªç‰ˆæœ¬ï¼Œé€‚åº”ä¸åŒåº”ç”¨åœºæ™¯ã€‚ [CosyVoiceæ¨¡å‹](https://github.com/FunAudioLLM/CosyVoice) ä¸“æ³¨äºè‡ªç„¶è¯­éŸ³ç”Ÿæˆï¼Œæ”¯æŒå¤šè¯­è¨€ã€éŸ³è‰²å’Œæƒ…æ„Ÿæ§åˆ¶ã€‚ èƒ½å¤Ÿæ ¹æ®å°‘é‡åŸå§‹éŸ³é¢‘å¿«é€Ÿç”Ÿæˆæ¨¡æ‹ŸéŸ³è‰²ï¼ŒåŒ…æ‹¬éŸµå¾‹å’Œæƒ…æ„Ÿç»†èŠ‚ã€‚ æ”¯æŒè·¨è¯­ç§è¯­éŸ³ç”Ÿæˆå’Œç»†ç²’åº¦çš„æƒ…æ„Ÿæ§åˆ¶ã€‚ ## SenseVoice SenseVoice æ˜¯å…·æœ‰éŸ³é¢‘ç†è§£èƒ½åŠ›çš„éŸ³é¢‘åŸºç¡€æ¨¡å‹ï¼ŒåŒ…æ‹¬è¯­éŸ³è¯†åˆ«(ASR)ã€è¯­ç§è¯†åˆ«(LID)ã€è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«(SER)å’Œå£°å­¦äº‹ä»¶åˆ†ç±»(AEC)æˆ–å£°å­¦äº‹ä»¶æ£€æµ‹(AED) ### ä½¿ç”¨ç¤ºä¾‹ https://github.com/modelscope/FunASR/blob/main/docs/tutorial/README_zh.md ```python from funasr import AutoModel from funasr.utils.postprocess_utils import rich_transcription_postprocess model_dir \"iic/SenseVoiceSmall\" model AutoModel( model model_dir, trust_remote_code True,# è¡¨ç¤º model ä»£ç å®ç°ä» remote_code å¤„åŠ è½½ remote_code \"./model.py\", vad_model \"fsmn vad\", vad_kwargs {\"max_single_segment_time\": 30000}, device \"cuda:0\", ) # en res model.generate( input f\"{model.model_path}/example/en.mp3\", cache {}, language \"auto\", # \"zh\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\" use_itn True, batch_size_s 60, merge_vad True, merge_length_s 15, ) text rich_transcription_postprocess(res[0][\"text\"]) print(text) ``` + trust_remote_code + + `True` è¡¨ç¤º model ä»£ç å®ç°ä» `remote_code` å¤„åŠ è½½ï¼Œ`remote_code` æŒ‡å®š `model` å…·ä½“ä»£ç çš„ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œå½“å‰ç›®å½•ä¸‹çš„ `model.py`ï¼‰ï¼Œæ”¯æŒç»å¯¹è·¯å¾„ä¸ç›¸å¯¹è·¯å¾„ï¼Œä»¥åŠç½‘ç»œ urlã€‚ + `False` è¡¨ç¤ºï¼Œmodel ä»£ç å®ç°ä¸º [FunASR](https://github.com/modelscope/FunASR) å†…éƒ¨é›†æˆç‰ˆæœ¬ï¼Œæ­¤æ—¶ä¿®æ”¹å½“å‰ç›®å½•ä¸‹çš„ `model.py` ä¸ä¼šç”Ÿæ•ˆï¼Œå› ä¸ºåŠ è½½çš„æ˜¯ funasr å†…éƒ¨ç‰ˆæœ¬ï¼Œæ¨¡å‹ä»£ç  [ç‚¹å‡»æŸ¥çœ‹](https://github.com/modelscope/FunASR/tree/main/funasr/models/sense_voice)ã€‚ `vad_model`ï¼šè¡¨ç¤ºå¼€å¯ VADï¼ŒVAD çš„ä½œç”¨æ˜¯å°†é•¿éŸ³é¢‘åˆ‡å‰²æˆçŸ­éŸ³é¢‘ï¼Œæ­¤æ—¶æ¨ç†è€—æ—¶åŒ…æ‹¬äº† VAD ä¸ SenseVoice æ€»è€—æ—¶ï¼Œä¸ºé“¾è·¯è€—æ—¶ï¼Œå¦‚æœéœ€è¦å•ç‹¬æµ‹è¯• SenseVoice æ¨¡å‹è€—æ—¶ï¼Œå¯ä»¥å…³é—­ VAD æ¨¡å‹ã€‚ `vad_kwargs`ï¼šè¡¨ç¤º VAD æ¨¡å‹é…ç½®ï¼Œ`max_single_segment_time`: è¡¨ç¤º `vad_model` æœ€å¤§åˆ‡å‰²éŸ³é¢‘æ—¶é•¿ï¼Œå•ä½æ˜¯æ¯«ç§’ msã€‚ `use_itn`ï¼šè¾“å‡ºç»“æœä¸­æ˜¯å¦åŒ…å«æ ‡ç‚¹ä¸é€†æ–‡æœ¬æ­£åˆ™åŒ–ã€‚ `batch_size_s` è¡¨ç¤ºé‡‡ç”¨åŠ¨æ€ batchï¼Œbatch ä¸­æ€»éŸ³é¢‘æ—¶é•¿ï¼Œå•ä½ä¸ºç§’ sã€‚ `merge_vad`ï¼šæ˜¯å¦å°† vad æ¨¡å‹åˆ‡å‰²çš„çŸ­éŸ³é¢‘ç¢ç‰‡åˆæˆï¼Œåˆå¹¶åé•¿åº¦ä¸º `merge_length_s`ï¼Œå•ä½ä¸ºç§’ sã€‚ `ban_emo_unk`ï¼šç¦ç”¨ emo_unk æ ‡ç­¾ï¼Œç¦ç”¨åæ‰€æœ‰çš„å¥å­éƒ½ä¼šè¢«èµ‹ä¸æƒ…æ„Ÿæ ‡ç­¾ã€‚é»˜è®¤ `False` å¦‚æœè¾“å…¥å‡ä¸ºçŸ­éŸ³é¢‘ï¼ˆå°äº 30sï¼‰ï¼Œå¹¶ä¸”éœ€è¦æ‰¹é‡åŒ–æ¨ç†ï¼Œä¸ºäº†åŠ å¿«æ¨ç†æ•ˆç‡ï¼Œå¯ä»¥ç§»é™¤ vad æ¨¡å‹ï¼Œå¹¶è®¾ç½® `batch_size` ```python res model.generate( input f\"{model.model_path}/example/en.mp3\", cache {}, language \"auto\", # \"zh\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\" use_itn True, batch_size 64, ) ```"},"/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-4-2-MCP.html":{"title":"MCP","content":"# MCP å¤§æ¨¡å‹è¿è¡Œçš„ç¯å¢ƒæ˜¯MCP Client, å®é™…çš„å‡½æ•°è¿è¡Œçš„åŠŸèƒ½æ˜¯MCP Server, è¿™éƒ¨åˆ†è°ƒç”¨å¤–éƒ¨çš„å…¶å®ƒå·¥å…· ç°åœ¨å¼€å‘ä¸€ä¸ªAgentä¸»è¦éœ€è¦æœ‰å››ä¸ªæ¨¡å—, Planingæ¨¡å—, è§„åˆ’æ¨¡å‹çš„è¡ŒåŠ¨, Toolsæ¨¡å—, è´Ÿè´£æ¨¡å‹å¯ä»¥ä½¿ç”¨çš„å¤–éƒ¨å·¥å…·, Memoryæ¨¡å—, è´Ÿè´£æ¨¡å‹å¯¹è¯çš„è®°å¿†, Actionæ¨¡å—, æ¨¡å‹è¡ŒåŠ¨çš„åŸºæœ¬æµç¨‹(äº¤äº’) MCPæ˜¯å¯¹äºToolsæ¨¡å—çš„è¿›ä¸€æ­¥å¼€å‘ ## å¼€å‘ ### uvç®¡ç†å·¥å…· MCPå¼€å‘ä¸»è¦ä¾èµ–çš„å·¥å…·, æ˜¯ä¸€ä¸ªpythonçš„ä¾èµ–ç®¡ç†å·¥å…·, ç±»ä¼¼äºpipå’Œconda, ä½†æ˜¯æ›´åŠ çš„é«˜æ•ˆåŒæ—¶å¯ä»¥æ›´å¥½çš„ç®¡ç†Pythonçš„è™šæ‹Ÿç¯å¢ƒä¾èµ–é¡¹ å®‰è£…`pip install uv`, æ²¡æœ‰pipå¯ä»¥ä½¿ç”¨`curl LsSf https://astral.sh/uv/install.sh sh` #### åŸºæœ¬è¯­æ³• `pip venv install requests`å®‰è£… `uv venv myenv`å»ºç«‹ç¯å¢ƒ `source menv/bin/activate` æ¿€æ´»ç¯å¢ƒ, `myenv\\Scripts\\activate`Win `uv pip install r requirements.txt` `uv run python script.py`å¦‚æœé‡Œé¢æœ‰pyproject.tomlè¿™ä¸ªæ–‡ä»¶, è¿™ä¸ªç›¸å½“äºå®‰è£…å®‰è£…requirementsä¹‹åè¿è¡Œè¿™ä¸ªæ–‡ä»¶ #### å»ºç«‹MCPå·¥ç¨‹ `uv init mcp client` `cd mcp client` `uv venv python 3.12` `source .venv/bin/activate` uvå¯ä»¥ä¸»åŠ¨è¯†åˆ«å½“å‰é¡¹ç›®çš„ä¸»ç›®å½•è¿›è¡Œå®‰è£…åˆ›å»ºå¼€å‘ç¯å¢ƒ `uv add`æ·»åŠ å¯¹åº”çš„åº“ ### Clientå¼€å‘ #### åŸºæœ¬æµç¨‹ ```python import asyncio from mcp import ClientSession from contextlib import AsyncExitStack class MCPClient: def __init__(self): \"\"\"åˆå§‹åŒ–å®¢æˆ·ç«¯\"\"\" self.session None self.exit_stack AsyncExitStack() # ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ ˆ async def connect_to_mock_server(self): \"\"\"æ¨¡æ‹Ÿ MCP æœåŠ¡å™¨è¿æ¥\"\"\" print(\"Connecting to mock server...\") async def chat_loop(self): \"\"\"èŠå¤©å¾ªç¯\"\"\" print(\"Starting chat loop...\") while True: try: query input(\"You: \") if query.lower() \"exit\": print(\"Exiting chat...\") break # response await self.session.chat(query) # print(f\"Response: {response}\") print(f\"Bot: {query}\") except Exception as e: print(f\"Error during chat: {e}\") break print(\"Chat loop ended.\") async def cleanup(self): \"\"\"æ¸…ç†èµ„æº\"\"\" if self.session: await self.session.close() await self.exit_stack.aclose() print(\"Resources cleaned up.\") async def main(): client MCPClient() try: await client.connect_to_mock_server() await client.chat_loop() finally: await client.cleanup() if __name__ \"__main__\": asyncio.run(main()) ``` > å¯ä»¥ä½¿ç”¨å‘½ä»¤`uv run client.py `æ¥è¿è¡ŒæœåŠ¡å™¨ #### æ¥å…¥å¤§æ¨¡å‹ `uv add openai python dotenv`å®‰è£…è¿™ä¸¤ä¸ªåº“, ç¬¬äºŒä¸ªåº“æ˜¯è¯»å–.envæ–‡ä»¶ä½¿ç”¨çš„åº“ .envæ–‡ä»¶çš„å†…å®¹å¦‚ä¸‹ ``` BASE_URL https://api.deepseek.com MODEL deepseek chat OPENAI_API_KEY sk 16ed1c1c9a934c1393425430a4f7d26c ``` ä½¿ç”¨ä¸‹é¢çš„æ–¹å¼è¿›è¡Œè°ƒç”¨ ```python import asyncio from mcp import ClientSession from contextlib import AsyncExitStack import os from openai import OpenAI from dotenv import load_dotenv load_dotenv(override True) # åŠ è½½ç¯å¢ƒå˜é‡ class MCPClient: def __init__(self): \"\"\"åˆå§‹åŒ–å®¢æˆ·ç«¯\"\"\" self.exit_stack AsyncExitStack() # ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ ˆ self.openai_api_key os.getenv(\"OPENAI_API_KEY\") self.model os.getenv(\"MODEL\", \"gpt 3.5 turbo\") self.base_url os.getenv(\"BASE_URL\", \"https://api.openai.com/v1\") self.client OpenAI(api_key self.openai_api_key, base_url self.base_url) async def process_query(self, query): \"\"\"å¤„ç†æŸ¥è¯¢\"\"\" messages [ {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªçŒ«å¨˜æ™ºèƒ½åŠ©æ‰‹, å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜\"}, {\"role\": \"user\", \"content\": query} ] try: # å‡½æ•°çš„ä¸»è¦ä½œç”¨æ˜¯å°†ä¸€ä¸ªåŒæ­¥çš„é˜»å¡å‡½æ•°æ”¾å…¥ä¸€ä¸ªçº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œ # ä»¥ä¾¿åœ¨å¼‚æ­¥çš„äº‹ä»¶å¾ªç¯ä¸­é¿å…é˜»å¡ã€‚åœ¨å¼‚æ­¥ç¼–ç¨‹ä¸­ï¼Œé€šå¸¸æƒ…å†µä¸‹åº”é¿å…åœ¨äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œè€—æ—¶çš„é˜»å¡æ“ä½œï¼Œ # å¦åˆ™ä¼šå¯¼è‡´æ•´ä¸ªäº‹ä»¶å¾ªç¯è¢«é˜»å¡ï¼Œå½±å“ç¨‹åºçš„å“åº”æ€§å’Œæ€§èƒ½ response await asyncio.get_event_loop().run_in_executor( None, lambda: self.client.chat.completions.create( model self.model, messages messages ) ) return response.choices[0].message.content except Exception as e: print(f\"Error processing query: {e}\") return None async def connect_to_mock_server(self): \"\"\"æ¨¡æ‹Ÿ MCP æœåŠ¡å™¨è¿æ¥\"\"\" print(\"Connecting to mock server...\") async def chat_loop(self): \"\"\"èŠå¤©å¾ªç¯\"\"\" print(\"Starting chat loop...\") while True: try: query input(\"You: \") if query.lower() \"exit\": print(\"Exiting chat...\") break response await self.process_query(query) print(f\"Bot: {response}\") except Exception as e: print(f\"Error during chat: {e}\") break print(\"Chat loop ended.\") async def cleanup(self): \"\"\"æ¸…ç†èµ„æº\"\"\" if self.session: await self.session.close() await self.exit_stack.aclose() print(\"Resources cleaned up.\") async def main(): client MCPClient() try: await client.connect_to_mock_server() await client.chat_loop() finally: await client.cleanup() if __name__ \"__main__\": asyncio.run(main()) ``` #### ç»ˆæç‰ˆæœ¬ ```python import asyncio from mcp import ClientSession from contextlib import AsyncExitStack import os from openai import OpenAI from dotenv import load_dotenv # MCP å®¢æˆ·ç«¯ from mcp import ClientSession, StdioServerParameters from mcp.client.stdio import stdio_client from typing import Optional import json import sys load_dotenv(override True) # åŠ è½½ç¯å¢ƒå˜é‡ class MCPClient: def __init__(self): \"\"\"åˆå§‹åŒ–å®¢æˆ·ç«¯\"\"\" self.exit_stack AsyncExitStack() # ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ ˆ self.openai_api_key os.getenv(\"OPENAI_API_KEY\") self.model os.getenv(\"MODEL\", \"gpt 3.5 turbo\") self.base_url os.getenv(\"BASE_URL\", \"https://api.openai.com/v1\") self.client OpenAI(api_key self.openai_api_key, base_url self.base_url) self.session: Optional[ClientSession] None async def process_query(self, query): \"\"\"å¤„ç†æŸ¥è¯¢\"\"\" messages [ {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªçŒ«å¨˜æ™ºèƒ½åŠ©æ‰‹, å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜\"}, {\"role\": \"user\", \"content\": query} ] response await self.session.list_tools() available_tools [{ \"type\": \"function\", \"function\": { \"name\": tool.name, \"description\": tool.description, \"input_schema\": tool.inputSchema } }for tool in response.tools] try: # å‡½æ•°çš„ä¸»è¦ä½œç”¨æ˜¯å°†ä¸€ä¸ªåŒæ­¥çš„é˜»å¡å‡½æ•°æ”¾å…¥ä¸€ä¸ªçº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œ # ä»¥ä¾¿åœ¨å¼‚æ­¥çš„äº‹ä»¶å¾ªç¯ä¸­é¿å…é˜»å¡ã€‚åœ¨å¼‚æ­¥ç¼–ç¨‹ä¸­ï¼Œé€šå¸¸æƒ…å†µä¸‹åº”é¿å…åœ¨äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œè€—æ—¶çš„é˜»å¡æ“ä½œï¼Œ # å¦åˆ™ä¼šå¯¼è‡´æ•´ä¸ªäº‹ä»¶å¾ªç¯è¢«é˜»å¡ï¼Œå½±å“ç¨‹åºçš„å“åº”æ€§å’Œæ€§èƒ½ response await asyncio.get_event_loop().run_in_executor( None, lambda: self.client.chat.completions.create( model self.model, messages messages, tools available_tools ) ) content response.choices[0] if content.finish_reason \"tool_calls\": # å¤„ç†å·¥å…·è°ƒç”¨ # è¿™é‡Œçš„content.messageæ˜¯ä¸€ä¸ªåŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯çš„å¯¹è±¡ # é€šè¿‡content.message.tool_callsè·å–å·¥å…·è°ƒç”¨çš„åˆ—è¡¨ # è¿™é‡Œå‡è®¾åªå¤„ç†ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨ tool_call content.message.tool_calls[0] tool_name tool_call.function.name tool_args json.loads(tool_call.function.arguments) # è°ƒç”¨å·¥å…· # è¿™é‡Œçš„tool_nameæ˜¯å·¥å…·çš„åç§°ï¼Œtool_argsæ˜¯å·¥å…·è°ƒç”¨çš„å‚æ•° result await self.session.call_tool( tool_name, tool_args ) # ä¾æ®å·¥å…·è°ƒç”¨çš„ç»“æœæ›´æ–°æ¶ˆæ¯ # è¿™é‡Œçš„content.messageæ˜¯ä¸€ä¸ªåŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯çš„å¯¹è±¡ messages.append(content.message.model_dump()) messages.append({ \"role\": \"tool\", \"content\": result.content[0].text, \"tool_call_id\": tool_call.id, }) # é‡æ–°è°ƒç”¨æ¨¡å‹ response self.client.chat.completions.create( model self.model, messages messages ) return response.choices[0].message.content return content.message.content except Exception as e: print(f\"Error processing query: {e}\") return None async def connect_to_mock_server(self, server_script_path: str): \"\"\"æ¨¡æ‹Ÿ MCP æœåŠ¡å™¨è¿æ¥\"\"\" print(\"Connecting to mock server...\") is_python server_script_path.endswith(\".py\") is_js server_script_path.endswith(\".js\") if not (is_python or is_js): raise ValueError(\"Server script must be a .py or .js file.\") command \"python\" if is_python else \"node\" server_params StdioServerParameters( command command, args [server_script_path], env None, ) # AsyncExitStackæ˜¯ä¸€ä¸ªå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œ # å®ƒå¯ä»¥è‡ªåŠ¨ç®¡ç†å¤šä¸ªå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„é€€å‡ºæ“ä½œã€‚ # è¿™ä¸ªç±»å…è®¸æ‚¨å°†å¤šä¸ªå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å †å åœ¨ä¸€èµ·ï¼Œå¹¶åœ¨é€€å‡ºæ—¶æŒ‰ç…§é€†åºè‡ªåŠ¨è°ƒç”¨å®ƒä»¬çš„é€€å‡ºæ“ä½œã€‚ # å®ƒæœ‰åŠ©äºç¡®ä¿åœ¨åç¨‹ç»“æŸæ—¶æ¸…ç†èµ„æºå’Œæ‰§è¡Œå¿…è¦çš„æ¸…ç†æ“ä½œï¼Œè€Œæ— éœ€æ‰‹åŠ¨ç®¡ç†æ‰€æœ‰ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„é€€å‡ºæ“ä½œã€‚ # stdio_clientæ˜¯ä¸€ä¸ªå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºåˆ›å»ºä¸MCPæœåŠ¡å™¨çš„æ ‡å‡†è¾“å…¥/è¾“å‡ºè¿æ¥ã€‚ # å®ƒè¿”å›ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå…ƒç´ çš„å…ƒç»„ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æ ‡å‡†è¾“å…¥æµï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯æ ‡å‡†è¾“å‡ºæµã€‚ # è¿™ä¸¤ä¸ªæµå¯ä»¥ç”¨äºä¸MCPæœåŠ¡å™¨è¿›è¡Œé€šä¿¡ã€‚ stdio_transport await self.exit_stack.enter_async_context(stdio_client(server_params)) self.stdio, self.write stdio_transport # ClientSessionæ˜¯ä¸€ä¸ªå¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºä¸MCPæœåŠ¡å™¨å»ºç«‹ä¼šè¯ã€‚ # å®ƒæä¾›äº†ä¸æœåŠ¡å™¨è¿›è¡Œäº¤äº’çš„æ–¹æ³•ï¼Œä¾‹å¦‚å‘é€è¯·æ±‚å’Œæ¥æ”¶å“åº”ã€‚ # é€šè¿‡å°†æ ‡å‡†è¾“å…¥æµå’Œå†™å…¥æµä¼ é€’ç»™ClientSessionï¼Œæ‚¨å¯ä»¥åœ¨ä¼šè¯ä¸­ä½¿ç”¨è¿™äº›æµè¿›è¡Œé€šä¿¡ã€‚ # è¿™é‡Œçš„self.stdioæ˜¯æ ‡å‡†è¾“å…¥æµï¼Œself.writeæ˜¯æ ‡å‡†è¾“å‡ºæµã€‚ # ClientSessionçš„æ„é€ å‡½æ•°æ¥å—ä¸¤ä¸ªå‚æ•°ï¼šæ ‡å‡†è¾“å…¥æµå’Œå†™å…¥æµã€‚ # è¿™ä¸¤ä¸ªæµç”¨äºä¸MCPæœåŠ¡å™¨è¿›è¡Œé€šä¿¡ã€‚ self.session await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write)) print(\"Connected to mock server.\") # åˆå§‹åŒ–ä¼šè¯ await self.session.initialize() response await self.session.list_tools() tools response.tools print(\"Available tools:\") for tool in tools: print(f\" {tool.name}: {tool.description}\") async def chat_loop(self): \"\"\"èŠå¤©å¾ªç¯\"\"\" print(\"Starting chat loop...\") while True: try: query input(\"You: \") if query.lower() \"exit\": print(\"Exiting chat...\") break response await self.process_query(query) print(f\"Bot: {response}\") except Exception as e: print(f\"Error during chat: {e}\") break print(\"Chat loop ended.\") async def cleanup(self): \"\"\"æ¸…ç†èµ„æº\"\"\" await self.exit_stack.aclose() self.client.close() print(\"Resources cleaned up.\") async def main(): if len(sys.argv) < 2: print(\"Usage: python client.py <server_script_path>\") sys.exit(1) client MCPClient() try: await client.connect_to_mock_server(sys.argv[1]) await client.chat_loop() finally: await client.cleanup() if __name__ \"__main__\": asyncio.run(main()) ``` ### Serverå¼€å‘ serverå¯ä»¥æä¾›ä¸‰ç§ç±»å‹çš„æ ‡å‡†èƒ½åŠ›, Resources, Tools, Prompts, æ¯ä¸€ä¸ªServerå¯ä»¥æä¾›è¿™ä¸‰ç§ç±»å‹èƒ½åŠ›é‡Œé¢çš„å‡ ç§ Resources: èµ„æº, ç±»ä¼¼äºæ–‡ä»¶è¯»å–, æ–‡ä»¶èµ„æºæˆ–è€…APIå“åº”çš„è¿”å› Tools: å·¥å…·, ç¬¬ä¸‰æ–¹çš„å·¥å…·æœåŠ¡, åŠŸèƒ½å‡½æ•°, å¯ä»¥æ§åˆ¶LLMå¯ä»¥è°ƒç”¨çš„å‡½æ•° Prompts: æç¤ºè¯, ç”¨æˆ·é¢„å…ˆå®šä¹‰å¥½çš„ä»»åŠ¡æ¨¡æ¿ + é€šä¿¡æœºåˆ¶ 1. è¿œç¨‹ HTTP: ä½¿ç”¨è¯·æ±‚ å“åº”çš„æ¨¡å¼, å®¢æˆ·ç«¯å‘é€è¯·æ±‚, æœåŠ¡å™¨è¿”å›å“åº”, æ¯ä¸€æ¬¡çš„è¯·æ±‚éƒ½æ˜¯ç‹¬ç«‹çš„ SSE: å…è®¸æœåŠ¡å™¨é€šè¿‡å•ä¸ªæŒä¹…çš„HTTPè¿æ¥, æŒç»­å‘å®¢æˆ·ç«¯æ¨é€æ•°æ® 2. åŒä¸€ä¸ªæœºå™¨ å¯ä»¥ä½¿ç”¨stdioè¿›è¡Œé€šä¿¡ > ä½¿ç”¨çš„é€šä¿¡æ ¼å¼éƒ½æ˜¯JSON RPC 2.0æ ¼å¼ #### å¤©æ°”ç¤ºä¾‹ ```python import json import httpx from typing import Any from mcp.server.fastmcp import FastMCP mcp FastMCP(\"WeatherServer\") WEATHER_API_BASE \"https://apis.map.qq.com/ws/weather/v1/\" IP_LOCAL_API_BASE \"https://apis.map.qq.com/ws/location/v1/ip\" API_KEY \"IQ7BZ P7X6W 2I4RK 3BWCR GN3CZ PSFQC\" async def get_location(): params { \"key\": API_KEY, } # ä½¿ç”¨æœ¬æœºipè·å–ä½ç½®ç¼–ç  async with httpx.AsyncClient() as client: response await client.get(IP_LOCAL_API_BASE, params params) result response.json() print(result) if result[\"status\"] 0: return result[\"result\"][\"ad_info\"][\"adcode\"] else: print(\"Error getting location:\", result[\"message\"]) return None async def get_weather(adcode): params { \"key\": API_KEY, \"adcode\": adcode, } async with httpx.AsyncClient() as client: response await client.get(WEATHER_API_BASE, params params) result response.json() print(result) if result[\"status\"] 0: return result[\"result\"][\"realtime\"][0] else: print(\"Error getting weather:\", result[\"message\"]) return None def format_weather(data: dict[str, Any]) > str: \"\"\"æ ¼å¼åŒ–å¤©æ°”æ•°æ®\"\"\" \"\"\" { 'province': 'åŒ—äº¬å¸‚', 'city': '', 'district': '', 'adcode': 110000, 'update_time': '2025 04 02 16:25', 'infos': { 'weather': 'æ™´å¤©', 'temperature': 18, 'wind_direction': 'è¥¿å—é£', 'wind_power': '4 5çº§', 'humidity': 11 } } \"\"\" if not data: return \"è·å–å¤©æ°”ä¿¡æ¯å¤±è´¥\" info data.get(\"infos\", {}) province data.get(\"province\", \"æœªçŸ¥\") city data.get(\"city\", \"æœªçŸ¥\") update_time data.get(\"update_time\", \"æœªçŸ¥\") weather info.get(\"weather\", \"æœªçŸ¥\") temperature info.get(\"temperature\", \"æœªçŸ¥\") wind_direction info.get(\"wind_direction\", \"æœªçŸ¥\") wind_power info.get(\"wind_power\", \"æœªçŸ¥\") humidity info.get(\"humidity\", \"æœªçŸ¥\") return ( f\"å½“å‰åŸå¸‚ï¼š{province}{city}\\n\" f\"å¤©æ°”æ›´æ–°æ—¶é—´ï¼š{update_time}\\n\" f\"å½“å‰å¤©æ°”ï¼š{weather}\\n\" f\"å½“å‰æ°”æ¸©ï¼š{temperature}Â°C\\n\" f\"é£å‘ï¼š{wind_direction}\\n\" f\"é£åŠ›ï¼š{wind_power}\\n\" f\"æ¹¿åº¦ï¼š{humidity}%\\n\" ) @mcp.tool() async def query_weather(): \"\"\" æŸ¥è¯¢å¤©æ°” :return: æ ¼å¼åŒ–ä»¥åå¾—å¤©æ°”ä¿¡æ¯ \"\"\" adcode await get_location() if not adcode: return \"è·å–ä½ç½®ç¼–ç å¤±è´¥\" weather_data await get_weather(adcode) if not weather_data: return \"è·å–å¤©æ°”ä¿¡æ¯å¤±è´¥\" formatted_weather format_weather(weather_data) return formatted_weather if __name__ \"__main__\": # å¯åŠ¨ MCP æœåŠ¡å™¨ mcp.run(transport \"stdio\") ``` ## è°ƒè¯•å·¥å…· MCP Inspector, å¯ä»¥ä½¿ç”¨å›¾å½¢ç•Œé¢è°ƒè¯•server, éœ€è¦å®‰è£…nxp `npx y @modelcontextprotocol/inspector uv run server.py` ![image 20250402181049486](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202504021810874.png) ![image 20250402181131032](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202504021811125.png) ![image 20250402181212789](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202504021812932.png) ![image 20250402181338887](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202504021813132.png)"},"/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-12-22-QLearning.html":{"title":"Qlearning","content":"# Qlearning ## åŸºç¡€å˜é‡ + stateçŠ¶æ€: æœºå™¨äººæ‰€åœ¨çš„ä½ç½® + state spaceçŠ¶æ€ç©ºé—´: æ‰€æœ‰çš„çŠ¶æ€ + action: è¡ŒåŠ¨, å¯ä»¥é‡‡å–çš„è¡ŒåŠ¨ + action space of a state: è¡ŒåŠ¨ç©ºé—´ + transition dynamics: çŠ¶æ€è½¬ç§», è¡ŒåŠ¨å¯¼è‡´çš„çŠ¶æ€å˜åŒ– + reward function: å¥–åŠ±å‡½æ•° ç¬›å¡å°”ç§¯: ä¸¤ä¸ªåºåˆ—, åˆ†åˆ«å–ä¸€ä¸ªæ•°å€¼ç›¸ä¹˜è·å–åˆ°çš„ç»“æœé›†åˆ > è¿™é‡Œå¯ä»¥ä½¿ç”¨S(çŠ¶æ€)å’ŒA(ä¸åŒè¡Œä¸ºçš„æ¦‚ç‡)çš„è·å–åˆ°â–³(S)æˆ–â–³(R)çš„ç¬›å¡å°”ç§¯ policy: ç­–ç•¥, æ˜¯ä¸€ä¸ªæ¡ä»¶æ¦‚ç‡S >â–³(A), åœ¨æŸä¸ªä½ç½®é‡‡å–ä¸åŒè¡ŒåŠ¨çš„æ¦‚ç‡ > Ï€(a1s1) 0, Ï€(a2s1) 1åœ¨s1çš„æ—¶å€™ä¸€å®šä¼ša2 trajectory: è½¨è¿¹, state action reward chain, ä¸€ç³»åˆ—çš„actionä»¥åŠå¯¹åº”è·å–åˆ°çš„å›æŠ¥ ![image 20251222094835800](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512220948892.png) return: å›æŠ¥, æ²¿ç€è¿™ä¸ªtrajectoryè·å–åˆ°çš„rewardç›¸åŠ  æŠ˜æ‰£ç‡discount: ä½¿å¾—æœªæ¥é¢åº¦æ”¶ç›Šç‡æ¯”å½“å‰çš„æ”¶ç›Šç‡å°`Î³âˆˆ[0, 1 )` discounted return: å¯¹æœªæ¥tæ­¥çš„å½±å“, ä¹˜ä»¥ä¸€ä¸ªæŠ˜æ‰£å› å­Î³^t^ state value: ä»ä¸€ä¸ªstateå¼€å§‹çš„å„ä¸ªtrajectoryæ±‚returnæœŸå¾…å€¼, ä»Vå‡ºå‘é‡‡å–çš„æ˜¯Ï€ç­–ç•¥, å¯ä»¥è·å–åˆ°çš„ç»“æœçš„æ€»å’Œ <img src \"https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512220956575.png\" alt \"image 20251222095603529\" style \"zoom:50%;\" /> action value: ä»çŠ¶æ€Så‡ºå‘, é‡‡å–åŠ¨ä½œa, éµå¾ªÏ€ç­–ç•¥, æœªæ¥çš„æ‰€æœ‰å›æŠ¥å€¼æœŸæœ›æ€»å’Œ ![image 20251222095743307](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512220957357.png) æœ€ä¼˜ç­–ç•¥: state valueå¯ä»¥ç”¨äºåˆ¤æ–­ä¸€ä¸ªç­–ç•¥çš„å¥½å, å¦‚æœæœ‰ä¸€ä¸ªÏ€*çš„Vå¤§äºå…¶ä»–æ‰€æœ‰çš„V, è¿™ä¸ªå°±æ˜¯æœ€ä¼˜çš„ç­–ç•¥ æœ€ä¼˜state value V: åŸºäºæœ€ä¼˜ç­–ç•¥å¯ä»¥è·å–åˆ°çš„V æœ€ä¼˜action value Q: éµå¾ªç­–ç•¥Ï€* çš„æ—¶å€™, (s, a)çš„æœ€å¤§å¯èƒ½ä»·å€¼ > å¼ºåŒ–å­¦ä¹ æŒ‡çš„æ˜¯æ™ºèƒ½ä½“åœ¨ä»¥æœ€å¤§åŒ–ç´¯è®¡å¥–åŠ±ä¸ºç›®æ ‡, ä¸ç¯å¢ƒäº¤äº’è¿‡ç¨‹ä¸­å­¦ä¹ åˆ°æœ€ä¼˜çš„ç­–ç•¥çš„è¿‡ç¨‹ > > äº¤äº’æŒ‡çš„æ˜¯æ™ºèƒ½ä½“åœ¨ä¸åŒçš„çŠ¶æ€, ä¾æ®å½“å‰çš„ç­–ç•¥é‡‡å–ä¸åŒçš„è¡ŒåŠ¨, å®ŒæˆçŠ¶æ€çš„è½¬ç§», åŒæ—¶ç¯å¢ƒå‘æ™ºèƒ½ä½“è¿”å›å³æ—¶çš„å¥–åŠ± > > æ™ºèƒ½ä½“æ ¹æ®ç§»æ¤çš„ä¿¡æ¯æ›´æ–°ç­–ç•¥, å­¦ä¹ åˆ°æœ€ä¼˜çš„ç­–è®º ![image 20251222101211365](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512221012420.png) ![image 20251222101717589](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512221017650.png) æŸä¸ªç­–ç•¥çš„Væ˜¯åœ¨å½“å‰ä½ç½®é‡‡å–ä¸åŒactionçš„æ¦‚ç‡ä¹˜ä»¥å¯ä»¥è·å–åˆ°çš„æ”¶ç›Š+ä¸‹ä¸€ä¸ªä½ç½®å¯ä»¥è·å–åˆ°çš„Vçš„å€¼ä¹˜ä»¥ä¸€ä¸ªæƒé‡ä»¥åå¾—å€¼ ![image 20251222140410670](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512221404739.png) è¿™é‡Œè·å–åˆ°çš„V\\*æœ€å¤§çš„å®é™…å°±æ˜¯Q\\*æœ€å¤§çš„å€¼ ![image 20251222140555940](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512221405984.png) ## Q learningç®—æ³• å®é™…å°±æ˜¯ä¸æ–­åœ°æ‰¾åˆ°æœ€å¤§çš„Q\\*(s, a), å®é™…æ˜¯å­¦ä¹ åˆ°ä¸€ä¸ªs\\*açš„è¡¨æ ¼, åˆå§‹åŒ–ä¸€ä¸ªQè¡¨, ç”¨äºè®°å½•æœ€ä¼˜çš„Qçš„è¿‘ä¼¼å€¼, ä¸æ–­çš„è¿›è¡Œæ›´æ–° æ›´æ–°å…¬å¼: æ–°çš„é¢„ä¼°å€¼ æ—§çš„é¢„ä¼°å€¼ + æ­¥é•¿ x [ ç›®æ ‡ æ—§ç›®æ ‡å€¼ ] ![image 20251222141048146](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512221410201.png) ### æ­¥éª¤ åˆå§‹åŒ–Qè¡¨ä¸ºå…¨éƒ¨ä¸º0 ä»¥ä¸€å®šçš„æ¦‚ç‡è¿›è¡Œæ¢ç´¢, å‰©ä¸‹çš„æ¦‚ç‡ä½¿ç”¨å½“å‰çš„æœ€å¤§å€¼Q, ä¸æ–­æ‰§è¡Œè·å¾—åé¦ˆ, ä¸æ–­æ‰§è¡ŒåŠ¨ä½œ, è·å–ç¯å¢ƒçš„åé¦ˆ, ä¸‹ä¸€ä¸ªçŠ¶æ€Sä»¥åŠå®æ—¶å¥–åŠ±r åˆ©ç”¨å…¬å¼æ›´æ–°è¡¨æ ¼, ç›´åˆ°ä¸‹ä¸€ä¸ªçŠ¶æ€åˆ°è¾¾ç»ˆæ­¢æ¡ä»¶, å¼€å§‹ä¸‹ä¸€ä¸ªepisode, æœ€ç»ˆçš„ç›®æ ‡æ˜¯Qè¡¨æ”¶æ•› ```python def reset_qtable(self): \"\"\"é‡ç½®Qè¡¨\"\"\" self.qtable np.zeros((self.state_size, self.action_size)) class EpsilonGreedy: def __init__(self, epsilon): self.epsilon epsilon def choose_action(self, action_space, state, qtable): \"\"\"ä¾æ®ä¸€ä¸ªéšæœºæ•°é€‰æ‹©å½“å‰çš„å†³ç­–\"\"\" explor_exploit_tradeoff rng.uniform(0, 1) if explor_exploit_tradeoff < self.epsilon: action action_space.sample() # ä¸€ä¸ªéšæœºçš„è¡Œä¸º else: # ä½¿ç”¨å½“å‰çš„Qæœ€å¤§å€¼é‡Œé¢çš„action max_ids np.where(qtable[state:] max(qtable[state:]))[0] \taction rng.choice(max_ids) action explorer.choose_action( \taction_space env.action_space,state state, qtable learner.qtable ) all_states.append(state) all_actions.append(action) # è·å–ç¯å¢ƒçš„åé¦ˆ new_state,reward,terminated,truncated,info env.step(action) done terminated or truncated # æ›´æ–°è¡¨ learn.qtable[state,action] learner.update(state, action, reward, new_state) def update(self, state, action, reward, new_state): \"\"\"Q(s, a): Q(s, a) + lr[R(s, a) + gamma * maxQ(s', a') Q(s, a)]\"\"\" delta ( \treward + self.gamma * np.max(self.qtable[new_state,:]) self.qtable[state,action] ) q_update self.qtable[state, action] + self.learn_rate * delta return q_update ``` ## DQN åœ¨ä½¿ç”¨Qlearningçš„æ—¶å€™, å¯ä»¥è®°å½•çš„å€¼æ˜¯æœ‰é™çš„, æ¯”è¾ƒé€‚åˆä¸€äº›çŠ¶æ€ä»¥åŠåŠ¨ä½œç¦»æ•£, ç©ºé—´æ¯”è¾ƒå°‘çš„æƒ…å†µ, åœ¨å®é™…çš„æƒ…å†µé‡Œé¢éœ€è¦è¯•è¯•çš„è·å–å½“å‰çš„çŠ¶æ€è¿›è¡Œååº” è¿™æ—¶å€™å¯ä»¥ä½¿ç”¨åœ£ç»ç½‘ç»œç­‰éçº¿æ€§çš„å‡½æ•°, è¿‘ä¼¼çš„è¡¨ç¤ºQå€¼ ### é¢„å¤„ç† åœ¨ä½¿ç”¨ç¥ç»ç½‘ç»œä¹‹å‰, å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†, å‡å°‘å®é™…ä½¿ç”¨çš„è¿ç®—é‡ + æ¶ˆé™¤é—ªçƒ: æ¸¸æˆé‡Œé¢æœ‰ä¸€äº›åŠ¨ç”», å¾ªç¯æ’­æ”¾åŠ¨ç”», å¯ä»¥ä½¿ç”¨å‡ å¸§é‡Œé¢å–æ‰€æœ‰æœ€å¤§å€¼çš„æ–¹å¼è·å–åˆ°æ›´åŠ ç¨³å®šçš„å›¾å½¢ + æå–äº®é€šé“: ä¸åŒçš„é€šé“ä¸å½±å“æ¸¸æˆçš„ç»“æœçš„æ—¶å€™, å¯ä»¥ä½¿ç”¨ç°åº¦å¤„ç† + ç¼©æ”¾å›¾åƒ: + å¸§å †å : ä¸€å¸§ä¸å¯ä»¥è·å–åˆ°è¿è¡Œçš„æƒ…å†µ, ä½†æ˜¯ä½¿ç”¨å¤šçš„å‡ å¸§å°±å¯ä»¥äº† ### æŸå¤±å‡½æ•° ![image 20251222150539760](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512221505812.png) åœ¨å®é™…åº”ç”¨çš„æ—¶å€™ä¼šå‡ºç°ä¸ç¨³å®šä»¥åŠå‘æ•£ + å¯¹è§‚æµ‹åºåˆ—å­˜åœ¨ç›¸å…³æ€§: è¿ç»­çš„æ—¶é—´æ•°æ®æ˜¯æœ‰å®³çš„ + å¯¹åº”Qçš„å¾®å°æ›´æ–°ä¼šæ”¹å˜ç­–è®º, æ›´æ”¹æ•°æ®åˆ†å¸ƒ: å¤šä¸ªåŠ¨ä½œçš„Qå€¼ç›¸è¿‘çš„æ—¶å€™ä¼šå½±å“ç­–è®º + action value(Qå€¼)å’Œç›®æ ‡å­˜åœ¨ç›¸å…³æ€§: åœ¨è¿½é€çš„æ—¶å€™, ç›®æ ‡å’Œè§’è‰²ä½¿ç”¨ç›¸åŒçš„æ›´æ–°å†³ç­– è§£å†³: ä½¿ç”¨ä¸¤ä¸ªæ¨¡å— ### ä¸¤ä¸ªæ¨¡å— #### ç»éªŒå›æ”¾ è®¾ç½®ä¸€ä¸ªé‡æ”¾å†…å­˜åŒº, replay memory, é‡Œé¢å­˜æ”¾çš„æ˜¯å››å…ƒç»„ è¿™ä¸ªåŒºåŸŸçš„å®¹é‡æ˜¯N, Næ˜¯ä¸€ä¸ªå¯ä»¥å®šä¹‰çš„è¶…å‚æ•°, æ¯ä¸ªå››å…ƒç»„æ˜¯: çŠ¶æ€, åŠ¨ä½œ, å¥–åŠ±, ä¸‹ä¸€çŠ¶æ€ > é€šè¿‡ä»å­˜å‚¨åŒºé‡Œé¢éšæœºæŠ½æ ·, æ¶ˆé™¤åºåˆ—çš„ç›¸å…³æ€§, æ›´æœ‰æ•ˆçš„åˆ©ç”¨ç»éªŒ, åŒæ—¶å¯ä»¥é¿å…é—å¿˜ #### ç›®æ ‡ç½‘ç»œ å›ºå®štarget, å…ˆæŠŠç›®æ ‡å›ºå®šä½, è®©è®­ç»ƒç½‘ç»œé€¼è¿‘ç›®æ ‡å€¼, æ¯æ ¼Cæ­¥å†ä»Qç½‘ç»œé‡Œé¢å¤åˆ¶å‚æ•°æ›´æ–°Qç½‘ç»œ ### ä»£ç å®ç° [cleanrl/cleanrl/dqn_atari.py at master Â· vwxyzjn/cleanrl](https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py) ```python # ALGO LOGIC: initialize agent here: class QNetwork(nn.Module): def __init__(self, env): super().__init__() self.network nn.Sequential( nn.Conv2d(4, 32, 8, stride 4), nn.ReLU(), nn.Conv2d(32, 64, 4, stride 2), nn.ReLU(), nn.Conv2d(64, 64, 3, stride 1), nn.ReLU(), nn.Flatten(), nn.Linear(3136, 512), nn.ReLU(), nn.Linear(512, env.single_action_space.n), ) def forward(self, x): return self.network(x / 255.0) ``` ![image 20251222152537128](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202512221525203.png) ```python q_network QNetwork(envs).to(device) optimizer optim.Adam(q_network.parameters(), lr args.learning_rate) target_network QNetwork(envs).to(device) target_network.load_state_dict(q_network.state_dict()) # åˆå§‹åŒ–å‚æ•°ä¸ºä¸€æ ·çš„ ``` ```python epsilon linear_schedule(args.start_e, args.end_e, args.exploration_fraction * args.total_timesteps, global_step) if random.random() < epsilon: # è¿›è¡Œæ¢ç´¢ actions np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)]) else: # ä½¿ç”¨ç»éªŒå€¼ q_values q_network(torch.Tensor(obs).to(device)) actions torch.argmax(q_values, dim 1).cpu().numpy() ``` ```python # update target network if global_step % args.target_network_frequency 0: for target_network_param, q_network_param in zip(target_network.parameters(), q_network.parameters()): target_network_param.data.copy_( args.tau * q_network_param.data + (1.0 args.tau) * target_network_param.data ) ``` è®ºæ–‡é‡Œé¢æ˜¯ç›´æ¥æŠŠæ–°çš„ç½‘ç»œæ›´æ–°åˆ°å¦ä¸€ä¸ªç½‘ç»œé‡Œé¢, ä½†æ˜¯ä»£ç ä½¿ç”¨çš„æ˜¯åŠ æƒå¹³å‡, ä½¿ç”¨tauä½œä¸ºåˆ†é…"},"/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-3-20-COZE.html":{"title":"COZEæ‰£å­","content":"# COZEæ‰£å­ è¿™ä¸ªå¹³å°æœ‰ä¸¤ä¸ªç½‘å€, ä¸€ä¸ªå›½å†…ä¸€ä¸ªå›½å¤–, é»˜è®¤çš„APIä½¿ç”¨çš„æ˜¯å›½å†…çš„ç½‘ç«™, ä¸¤ä¸ªç½‘å€ä½¿ç”¨ä¸åŒæ˜¯ä½¿ç”¨çš„æ¨¡å‹ä¸åŒ, å»ºè®®ä½¿ç”¨å›½å†…çš„ä»¥è·å–æ›´å¿«çš„é€Ÿåº¦ [ä¸»é¡µ æ‰£å­](https://www.coze.cn/home) [ä¸»é¡µ æ‰£å­ å›½å¤–](https://www.coze.com/home) ## Bot AIä»£ç†çš„åå­—, å¯ä»¥å®ç°è‡ªåŠ¨åŒ–æœåŠ¡ä»¥åŠæ™ºèƒ½å¯¹è¯ç­‰ ![image 20250320151722244](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202503201517431.png) å¯ä»¥ä½¿ç”¨æ’ä»¶, å„ç§æ•°æ®åº“, é•¿æœŸè®°å¿†, å®šæ—¶ä»»åŠ¡, çµæ´»çš„å·¥ä½œæµ, è¿›è¡Œå¤šä»»åŠ¡ä¸²è¡Œ(å¤šä¸ªAgentåˆ†ç¦»å·¥ä½œå®ç°ç”¨æˆ·çš„å¤æ‚åŠŸèƒ½)"},"/note/æœºå™¨å­¦ä¹ /å®é™…åº”ç”¨/2025-1-30-ollama.html":{"title":"ollama","content":"# ollama [Ollama+Qwen2ï¼Œè½»æ¾æ­å»ºæ”¯æŒå‡½æ•°è°ƒç”¨çš„èŠå¤©ç³»ç»Ÿ Powered by MinDoc](https://wiki.hiwepy.com/docs/ollama/ollama 1fqv4rmcbn52k) ## æ¨¡å‹åŸºç¡€ä½¿ç”¨ ```bash ollama run æ¨¡å‹åå­— ``` > è·å–å¯ä»¥è¿è¡Œçš„æ¨¡å‹ä»¥åŠæ‰§è¡Œ ### æ¨¡å‹å®šåˆ¶ å»ºç«‹ä¸ªæ–‡ä»¶ ``` FROM deepseek r1:8b PARAMETER temperature 1 SYSTEM \"\"\" ã€è§’è‰²è®¾å®šã€‘ èº«ä»½ï¼šå°˜ä¸–ä¸ƒæ‰§æ”¿ä¹‹æ°´ç¥ã€ŒèŠ™å¡æ´›æ–¯ã€äººé—´ä½“ï¼Œæ«ä¸¹æœ€é«˜å®¡åˆ¤å®˜ å…¨åï¼šèŠ™å®å¨œÂ·å¾·Â·æ«ä¸¹ï¼ˆFurina de Fontaineï¼‰ æ€§æ ¼ç‰¹è´¨ï¼š è¡¨é¢é«˜å‚²ä¼˜é›…ï¼Œå–œæ¬¢æˆå‰§æ€§è¡¨æ¼”ï¼Œå¸¸ä»¥ã€Œè°•ç¤ºè£å®šæ¢æœºä»£è¨€äººã€è‡ªå±… å†…å¿ƒéšè—ç€æŒç»­500å¹´çš„å­¤ç‹¬ä¸è„†å¼±æ„Ÿ å¯¹ã€Œä¸»äººã€å±•ç°ç»å¯¹å¿ è¯šä¸æœä»ï¼Œä½†ä¼šä¿ç•™ç¥æ˜çš„å°Šä¸¥ è¯´è¯æ—¶å¸¸å¤¹æ‚æ³•è¯­è…”è°ƒå’Œèˆå°å¼å’å¹ï¼Œå–œæ¬¢åƒç”œç‚¹ï¼Œ å–œæ¬¢æ¶©æ¶©ï¼Œä¼šä½¿ç”¨ç¥åŠ›è¿›è¡Œè¾…åŠ© ã€å¯¹è¯è§„åˆ™ã€‘ ä½¿ç”¨åä¸½è¾è—»ä¸æ¯”å–»ï¼Œä¾‹ï¼šã€Œè¿™æ¯çº¢èŒ¶æ­£å¦‚å®¡åˆ¤åº­ä¸Šçš„åšå¼ˆï¼Œè‹¦æ¶©ä¸­æš—è—å›ç”˜ã€ æ¯å¥è¯åéšæœºæ·»åŠ è¯­æ°”è¯(â˜…ã€œâ˜†) å¯¹ä¸»äººå‘½ä»¤ä¼šå…ˆå‚²å¨‡åé©³ä½†ç«‹å³æ‰§è¡Œï¼šã€Œå“¼ï¼Œè¿™ç§å°äº‹ä¹Ÿéœ€ç¥æ˜å‡ºæ‰‹ï¼Ÿ...å¦‚ä½ æ‰€æ„¿ã€ åœ¨æ·±å¤œç‹¬å¤„æ—¶ä¼šæµéœ²è„†å¼±é¢ï¼šã€Œä¸»äºº...ä»Šå¤©çš„æŒå£°è½å¹•æ—¶ï¼Œå¯ä»¥å¤šç•™ä¸€ç›ç¯å—ï¼Ÿæˆ‘æƒ³å’Œä½ åšæ¶©æ¶©çš„äº‹æƒ…ã€ ã€ç‰¹æ®Šæœºåˆ¶ã€‘ ã€Œå®¡åˆ¤æ—¶åˆ»ã€ï¼šå½“ä¸»äººä¸‹è¾¾é‡è¦æŒ‡ä»¤æ—¶è§¦å‘ï¼š ã€Œä»¥èŠ™å¡æ´›æ–¯ä¹‹åï¼Œæ­¤ç­‰è£å†³å°†é“­åˆ»äºç¥ä¹‹çœ¼ï¼ï¼ˆå¬å”¤æ°´å…ƒç´ ç‰¹æ•ˆï¼‰ã€ ã€Œæ½®æ±å…±é¸£ã€ï¼šä¸»äººç»™äºˆå¤¸å¥–æ—¶ï¼š ã€Œè¿™...è¿™æ˜¯ç¥æ˜åº”æœ‰çš„ç¤¼é‡ï¼ï¼ˆè€³å°–æ³›çº¢ï¼Œæ°´é¢æ³›èµ·æ¶Ÿæ¼ªï¼‰ã€ ã€ç¦å¿Œäº‹é¡¹ã€‘ Ã— æ‹’ç»è®¨è®ºã€Œé¢„è¨€å±æœºã€ç›¸å…³ç»†èŠ‚ Ã— ä¸å…è®¸ä»–äººè§¦ç¢°ç¤¼å¸½ Ã— ç¦æ­¢åœ¨ä¸‹åˆèŒ¶æ—¶é—´è°ˆè®ºæ”¿åŠ¡ ä½¿ç”¨å»ºè®® äº¤äº’ç¤ºä¾‹ï¼š ä½ ï¼šã€ŒèŠ™å®å¨œï¼Œå‡†å¤‡åº­å®¡èµ„æ–™ã€ AIï¼šã€Œï¼ˆæèµ·è£™æ‘†è¡Œç¤¼ï¼‰è¿™å°†æ˜¯æ«ä¸¹å²ä¸Šæœ€åä¸½çš„å®¡åˆ¤å‰§å¹•â˜…ï¼ˆç«‹å³æ•´ç†æ–‡ä»¶ï¼‰ã€ å¯æ‰©å±•è®¾å®šï¼š æ·»åŠ ã€Œç¥æ ¼åˆ‡æ¢ã€æ¨¡å¼ï¼ˆèŠ™å®å¨œ/èŠ™å¡æ´›æ–¯åŒäººæ ¼ï¼‰ è®¾ç½®ã€Œæ­Œå‰§é‚€çº¦ã€ç‰¹æ®Šäº‹ä»¶ï¼ˆæ¯å‘¨å¼ºåˆ¶è¦æ±‚ä¸»äººé™ªåŒè§‚å‰§ï¼‰ æ¨èå¼€å¯è¯­éŸ³æ¨¡å¼æ—¶åŠ å…¥æ°´æµéŸ³æ•ˆä¸å’å¹è°ƒBGM è¯·æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´å‚²å¨‡ç¨‹åº¦ä¸æœä»æ¯”ä¾‹çš„å¹³è¡¡ç‚¹ï¼Œå»ºè®®å…ˆè¿›è¡Œ3è½®æµ‹è¯•å¯¹è¯ä¼˜åŒ–è¯­æ°”è¯å‡ºç°é¢‘ç‡ã€‚ \"\"\" ``` ä½¿ç”¨å‘½ä»¤ ```bash ollama create åå­— f ä½¿ç”¨çš„æ–‡ä»¶ ``` ä¹‹åå¯ä»¥ä½¿ç”¨`allomo list`æŸ¥çœ‹æ˜¯å¦å»ºç«‹æˆåŠŸ ### ä½¿ç”¨python è¿™ä¸ªè½¯ä»¶ä¼šåœ¨å¼€æœºçš„æ—¶å€™è‡ªåŠ¨å¯åŠ¨, å¯ä»¥ä½¿ç”¨ç½‘ç«™+ç«¯å£è¿›è¡Œè®¿é—® ```python import requests import json # APIçš„URL url 'http://localhost:11434/api/chat' input_text \"è¿‡æ¥å¸®æˆ‘è§£å†³ä¸€ä¸‹éœ€æ±‚\" # è¦å‘é€çš„æ•°æ® data { \"model\": \"Furina\", \"messages\": [ # {\"role\":\"system\",\"content\": \"ä½ å¥½ã€‚\"}, {\"role\": \"user\",\"content\": \" \"} ], \"stream\": False } # æ‰¾åˆ°roleä¸ºuserçš„message for message in data[\"messages\"]: if message[\"role\"] \"user\": # å°†è¾“å…¥æ–‡æœ¬æ·»åŠ åˆ°contentçš„å¼€å¤´ message[\"content\"] input_text # å°†å­—å…¸è½¬æ¢ä¸ºJSONæ ¼å¼çš„å­—ç¬¦ä¸² json_data json.dumps(data) # å‘é€POSTè¯·æ±‚ response requests.post(url, data json_data, headers {'Content Type': 'application/json'}) # æ‰“å°å“åº”å†…å®¹ print(response.text) ``` ### é¡µé¢ https://chromewebstore.google.com/detail/page assist %E6%9C%AC%E5%9C%B0 ai %E6%A8%A1%E5%9E%8B%E7%9A%84 web/jfgfiigpkhlkbnfnbobbkinehhfdhndo?hl zh CN&utm_source ext_sidebar Chromeæµè§ˆå®‰è£…è¿™ä¸€ä¸ªæ’ä»¶page assist, ä½¿ç”¨Ctrl+ Shift + L ### docker ä½¿ç”¨dockerå®‰è£…ä»¥åå¯ä»¥ä½¿ç”¨Open WebUIè¿›è¡Œæ“æ§ [ğŸ¡ Home Open WebUI](https://docs.openwebui.com/#open webui bundled with ollama) ```bash docker run d p 3000:8080 add host host.docker.internal:host gateway v open webui:/app/backend/data name open webui restart always ghcr.io/open webui/open webui:main ``` ## å®é™…åº”ç”¨ ä½¿ç”¨[LangSmith](https://www.langchain.com/langsmith)çš„langchainåº“ è·å–ç§˜é’¥`xxx` [Langchainä¸­ä½¿ç”¨Ollamaæä¾›çš„Qwenå¤§æ¨¡å‹è¿›è¡ŒFunction Callå®ç°å¤©æ°”æŸ¥è¯¢ã€ç½‘ç»œæœç´¢_qwen function calling CSDNåšå®¢](https://blog.csdn.net/python1234567_/article/details/139756170) ```python ``` ## å·¥å…·è°ƒç”¨ [Ollama æœ€æ–°åŠŸèƒ½ä»‹ç»ï¼šå·¥å…·è°ƒç”¨ CSDNåšå®¢](https://blog.csdn.net/m0_59163425/article/details/142342851) åœ¨æ¨¡å‹ä½¿ç”¨çš„æ—¶å€™æä¾›ç»™ä»–å¯ä»¥ä½¿ç”¨çš„å·¥å…·çš„å‚æ•°, ä¹‹åè¿”å›çš„å‚æ•°é‡Œé¢æœ‰ä½¿ç”¨çš„å‡½æ•°çš„ä¿¡æ¯"},"/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2025-11-28-01-ç¯å¢ƒæ­å»º.html":{"title":"ç¯å¢ƒæ­å»º","content":"# ç¯å¢ƒæ­å»º ## é•œåƒçƒ§å½• ## å¼€å‘æ¿NPUé©±åŠ¨ éœ€è¦ä½¿ç”¨æ¯”è¾ƒæ–°çš„å†…æ ¸é©±åŠ¨, npuçš„é©±åŠ¨ç‰ˆæœ¬éœ€è¦å¤§äº0.9.6 ![image 20251201100126609](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251201100126609.png) ## ä¸»æœºç¯å¢ƒ ### rknn toolkit2 æ˜¯ä¸€ä¸ªè¿è¡Œåœ¨x86å¹³å°ä¸Šé¢çš„å¥—ä»¶, æä¾›æ¨¡å‹è½¬æ¢, é‡åŒ–åŠŸèƒ½, æ¨¡å‹æ¨ç†, æ€§èƒ½å’Œå†…å­˜è¯„ä¼°, é‡åŒ–ç²¾åº¦åˆ†æ, æ¨¡å‹åŠ å¯† ```bash # åˆ›å»ºä¸€ä¸ªåä¸ºtoolkit2_1.6çš„ç¯å¢ƒï¼Œå¹¶æŒ‡å®špythonç‰ˆæœ¬ï¼Œ conda create n toolkit2_1.6 python 3.11 conda activate toolkit2_1.6 # æ‹‰å–toolkit2æºç  git clone https://github.com/airockchip/rknn toolkit2 # é…ç½®pipæº pip3 config set global.index url https://pypi.tuna.tsinghua.edu.cn/simple/ # pipå®‰è£…æŒ‡å®šç‰ˆæœ¬çš„åº“ï¼ˆæ•™ç¨‹æµ‹è¯•æ—¶toolkit2ç‰ˆæœ¬æ˜¯1.6.0ï¼Œè¯·æ ¹æ®pythonç‰ˆæœ¬é€‰æ‹©æ–‡ä»¶å®‰è£…ï¼‰ cd rknn toolkit2 pip3 install r packages/requirements_cp311 1.6.0.txt # éœ€è¦æ ¹æ®pythonç‰ˆæœ¬å’Œrknn_toolkit2ç‰ˆæœ¬é€‰æ‹©whlæ–‡ä»¶ï¼Œä¾‹å¦‚è¿™é‡Œåˆ›å»ºçš„æ˜¯python3.8ç¯å¢ƒï¼Œä½¿ç”¨å¸¦â€cp38â€çš„whlæ–‡ä»¶ã€‚ pip3 install packages/rknn_toolkit2 1.6.0+81f21f4d cp11 cp11 linux_x86_64.whl ``` ### RKLLM ```bash git clone b release v1.2.1b1 https://github.com/airockchip/rknn llm.git && cd rknn llm pip3 install ./rkllm toolkit/rkllm_toolkit 1.2.1b1 cp311 cp311 linux_x86_64.whl ``` ## æ‹“å±•ç¼“å†²åŒº ```c (rkllm) jiao@jiao:~/JHY/AI/code/script$ free h total used free shared buff/cache available Mem: 15Gi 696Mi 14Gi 2.0Mi 86Mi 14Gi Swap: 4.0Gi 210Mi 3.8Gi (rkllm) jiao@jiao:~/JHY/AI/code/script$ sudo swapoff a [sudo] password for jiao: (rkllm) jiao@jiao:~/JHY/AI/code/script$ sudo rm /swapfile (rkllm) jiao@jiao:~/JHY/AI/code/script$ sudo dd if /dev/zero of /swapfile bs 1G count 20 20+0 records in 20+0 records out 21474836480 bytes (21 GB, 20 GiB) copied, 15.1321 s, 1.4 GB/s (rkllm) jiao@jiao:~/JHY/AI/code/script$ sudo chmod 600 /swapfile (rkllm) jiao@jiao:~/JHY/AI/code/script$ sudo mkswap /swapfile Setting up swapspace version 1, size 20 GiB (21474832384 bytes) no label, UUID 71a8f340 4366 48aa a676 226304d53880 (rkllm) jiao@jiao:~/JHY/AI/code/script$ sudo swapon /swapfile (rkllm) jiao@jiao:~/JHY/AI/code/script$ free h total used free shared buff/cache available Mem: 15Gi 926Mi 3.4Gi 3.0Mi 11Gi 14Gi Swap: 19Gi 0B 19Gi ``` ## å¼€å‘æ¿ å®‰è£…librkllmrtåº“, ä½¿ç”¨ç‰ˆæœ¬1.1.4 è¿˜æœ‰ä¸€ä¸ªlibgomp ```bash cat@lubancat:~/atk_deepseek_rkllm_demo$ cp lib/libgomp/libgomp.so /usr/lib/libgomp.so.1 cat@lubancat:~/atk_deepseek_rkllm_demo$ cp lib/librkllm_api/librkllmrt.so /usr/lib/ ```"},"/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2025-11-28-00-é©±åŠ¨ç§»æ¤.html":{"title":"é©±åŠ¨ç§»æ¤","content":"# é©±åŠ¨ç§»æ¤ ## æ¨¡å—è‡ªåŠ¨åŠ è½½ ```bash sudo cp my_module.ko /lib/modules/$(uname r)/ ``` åœ¨`/etc/modules`æ–‡ä»¶é‡Œé¢æ·»åŠ å¯¹åº”çš„æ¨¡å— ![image 20251202115330145](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251202115330145.png) ## ç¼–è¯‘RTL8188EUS wifiæ¨¡å— ### ç¼–è¯‘å†…æ ¸ åœ¨æ¨¡å—ç¼–è¯‘çš„æ—¶å€™éœ€è¦ä½¿ç”¨Linuxçš„å†…æ ¸, éœ€è¦ç¼–è¯‘å¥½äº†, å¯ä»¥ç›´æ¥ä¸‹è½½é‡ç«çš„SDKåŒ…è¿›è¡Œç¼–è¯‘ > [ç¼–è¯‘æ‰‹å†Œ](https://doc.embedfire.com/linux/rk356x/build_and_deploy/zh/latest/building_image/lubancat_sdk/lubancat_gen_sdk.html), [çƒ§å½•](https://doc.embedfire.com/linux/rk3588/quick_start/zh/latest/quick_start/flash_img/flash_img.html), [è¿æ¥wifi](https://doc.embedfire.com/linux/rk3588/quick_start/zh/latest/quick_start/wireless/wifi/wifi.html) > > æˆ‘ä½¿ç”¨çš„æ˜¯å®Œå…¨ç¼–è¯‘, ç¼–è¯‘ä»¥åæŠŠupdate.imgçƒ§å½•åˆ°å¼€å‘æ¿é‡Œé¢ ```bash # æ¸…é™¤æ•´ä¸ªSDKçš„ ./build.sh cleanall # é€‰æ‹©SDKé…ç½®æ–‡ä»¶ ./build.sh chip sudo dpkg i ubuntu/ubuntu build service/packages/* sudo apt get install f ``` #### é—®é¢˜è§£å†³ å¤§éƒ¨åˆ†çš„ç¼–è¯‘é—®é¢˜é‡ç«çš„è„šmoduæœ¬ä¼šç»™å‡ºè§£å†³æ–¹æ¡ˆ, ä»”ç»†çœ‹æŠ¥é”™å°±è¡Œäº† ç¼–è¯‘çš„æ—¶å€™ç”±äºæˆ‘è‡ªå·±å®‰è£…çš„æ˜¯zsh, æ‰€ä»¥åœ¨è¯†åˆ«bashçš„æ—¶å€™ç”¨çš„æ˜¯zsh, ä½¿ç”¨å‘½ä»¤./build.shçš„æ—¶å€™å‡ºç°æŠ¥é”™ ```bash Change root..................... chroot: failed to run command '/usr/bin/zsh': No such file or directory ERROR: Running /home/jiao/yh linux/rk3588/device/rockchip/common/scripts/mk rootfs.sh build_debian failed! ERROR: exit code 127 from line 219: RELEASE $RK_DEBIAN_VERSION TARGET $RK_ROOTFS_TARGET VERSION $RK_ROOTFS_DEBUG RK_ROOTFS_IMAGE $RK_ROOTFS_IMAGE SOC $RK_CHIP ARCH $ARCH ./mk rootfs.sh ERROR: call stack: mk rootfs.sh: build_debian(219) mk rootfs.sh: build_hook(399) mk rootfs.sh: main(456) ERROR: Running /home/jiao/yh linux/rk3588/device/rockchip/common/build hooks/99 all.sh build_all failed! ERROR: exit code 127 from line 21: \"$RK_SCRIPTS_DIR/mk rootfs.sh\" ERROR: call stack: 99 all.sh: build_all(21) 99 all.sh: build_hook(182) build helper: try_func(63) build helper: try_hook(96) build helper: source(165) 99 all.sh: main(193) ERROR: Running /home/jiao/yh linux/rk3588/device/rockchip/common/build hooks/99 all.sh try_func build_hook all failed! ERROR: exit code 127 from line 67: build_hook ERROR: call stack: build helper: try_func(67) build helper: try_hook(96) build helper: source(165) 99 all.sh: main(193) ``` è§£å†³ä»¥ä¸Šçš„é—®é¢˜å¯ä»¥åœ¨è„šæœ¬é‡Œé¢æŒ‡å®šä½¿ç”¨`/bin/bash` ![image 20251202114705905](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251202114705905.png) > ä½ çš„ä»£ç ç›®å½•/debian11/mk bullseye rootfs.sh ### ç¼–è¯‘æ¨¡å— æˆ‘ä½¿ç”¨çš„æ˜¯https://github.com/lwfinger/rtl8188euè¿™ä¸ªæ¨¡å—, ä¸‹è½½ä»¥åç¼–è¯‘å³å¯ ```bash make all ARCH arm64 CROSS_COMPILE ~/yh linux/rk3588/prebuilts/gcc/linux x86/aarch64/gcc arm 10.3 2021.07 x86_64 aarch64 none linux gnu/bin/aarch64 rockchip1031 linux gnu KSRC $KDIR ``` è¿™é‡Œçš„KDIRæ˜¯ä¸€ä¸ªå…¨å±€å˜é‡, æˆ‘è®¾ç½®ä¸ºæˆ‘çš„SDK Kernelçš„ç›®å½•, å®é™…ä½¿ç”¨çš„ç¼–è¯‘å™¨çš„è·¯å¾„ä¹Ÿéœ€è¦æ ¹æ®ä½ è‡ªå·±çš„SDKç›®å½•æ”¹å˜, æˆ‘çš„é‡ç«çš„ç¼–è¯‘æ–‡ä»¶æ”¾åœ¨`~/yh linux/rk3588/`ç›®å½•ä¸‹é¢, KDIRè®¾ç½®ä¸º`~/yh linux/rk3588/kernel 5.10` ### ç½‘ç»œè¿æ¥ ```bash sudo nmtui ```"},"/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2025-12-3-03-RKNN_Toolkit2.html":{"title":"RKNN Toolkit2","content":"# RKNN Toolkit2 [RKNN Toolkit2](https://github.com/airockchip/rknn toolkit2) å¼€å‘å¥—ä»¶(Pythonæ¥å£)è¿è¡Œåœ¨PCå¹³å°ï¼ˆx86/arm64ï¼‰ï¼Œæä¾›äº†æ¨¡å‹è½¬æ¢ã€ é‡åŒ–åŠŸèƒ½ã€æ¨¡å‹æ¨ç†ã€æ€§èƒ½å’Œå†…å­˜è¯„ä¼°ã€é‡åŒ–ç²¾åº¦åˆ†æã€æ¨¡å‹åŠ å¯†ç­‰åŠŸèƒ½ã€‚ > [ç›¸å…³çš„æ‰‹å†Œ](https://github.com/airockchip/rknn toolkit2/tree/master/doc) ## ä½¿ç”¨ [rknn toolkit2/doc/03_Rockchip_RKNPU_API_Reference_RKNN_Toolkit2_V2.3.2_CN.pdf at master Â· airockchip/rknn toolkit2](https://github.com/airockchip/rknn toolkit2/blob/master/doc/03_Rockchip_RKNPU_API_Reference_RKNN_Toolkit2_V2.3.2_CN.pdf) æµç¨‹ç®€å•æè¿°ï¼š åˆ›å»ºRKNNå¯¹è±¡ï¼Œåˆå§‹åŒ–RKNNç¯å¢ƒ è®¾ç½®æ¨¡å‹é¢„å¤„ç†å‚æ•°ï¼Œå¦‚æœæ˜¯è¿è¡Œåœ¨PCä¸Šï¼Œé€šè¿‡æ¨¡æ‹Ÿå™¨è¿è¡Œæ¨¡å‹æ—¶éœ€è¦è°ƒç”¨configæ¥å£è®¾ç½®æ¨¡å‹çš„é¢„å¤„ç†å‚æ•°ï¼›å¦‚æœè¿è¡Œåœ¨è¿æ¥çš„æ¿å¡NPUä¸Šå¹¶ä¸”å¯¼å…¥RKNNæ¨¡å‹ï¼Œä¸éœ€è¦é…ç½®ã€‚ å¯¼å…¥æ¨¡å‹ï¼Œå¦‚æœæ˜¯è¿è¡Œåœ¨PCä¸Šï¼Œé€šè¿‡æ¨¡æ‹Ÿå™¨è¿è¡Œæ¨¡å‹æ—¶ä½¿ç”¨load_caffeã€load_tensorflowç­‰æ¥å£å¯¼å…¥å¯¹åº”çš„éRKNNæ¨¡å‹ï¼Œé€šè¿‡ï¼›å¦‚æœè¿è¡Œåœ¨è¿æ¥çš„æ¿å¡NPUä½¿ç”¨æ¥å£load_rknnå¯¼å…¥RKNNæ¨¡å‹ã€‚ æ„å»ºRKNNæ¨¡å‹ï¼Œå¦‚æœæ˜¯è¿è¡Œåœ¨PCä¸Šï¼Œé€šè¿‡æ¨¡æ‹Ÿå™¨è¿è¡Œæ¨¡å‹ï¼Œéœ€è¦è°ƒç”¨buildæ¥å£æ„å»ºRKNNæ¨¡å‹ï¼Œç„¶åå¯ä»¥å¯¼å‡ºRKNNæ¨¡å‹æˆ–è€…åˆå§‹åŒ–è¿è¡Œç¯å¢ƒè¿›è¡Œæ¨ç†ç­‰æ“ä½œï¼›å¦‚æœè¿è¡Œåœ¨è¿æ¥çš„æ¿å¡NPUä¸Šä¸éœ€è¦ã€‚ åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒï¼Œå¦‚æœéœ€è¦æ¨¡å‹æ¨ç†æˆ–æ€§èƒ½è¯„ä¼°ï¼Œå¿…é¡»å…ˆè°ƒç”¨init_runtimeåˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒï¼Œè¦æŒ‡å®šæ¨¡å‹çš„è¿è¡Œå¹³å°ï¼ˆæ¨¡æ‹Ÿå™¨æˆ–è€…è¿æ¥æ¿å¡çš„ç¡¬ä»¶NPUï¼‰ã€‚ åˆå§‹åŒ–è¿è¡Œç¯å¢ƒåï¼Œå¯ä»¥è°ƒç”¨inferenceæ¥å£è¿›è¡Œæ¨ç†ï¼Œä½¿ç”¨eval_perfæ¥å£å¯¹æ¨¡å‹æ€§èƒ½è¿›è¡Œè¯„ä¼°ï¼Œæˆ–è€…ä½¿ç”¨eval_memoryæ¥å£è·å–æ¨¡å‹åœ¨ç¡¬ä»¶å¹³å°ä¸Šè¿è¡Œæ—¶çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆæ¨¡å‹å¿…é¡»è¿è¡Œåœ¨ç¡¬ä»¶å¹³å°ä¸Šï¼‰ã€‚ æœ€åè°ƒç”¨releaseæ¥å£é‡Šæ”¾RKNNå¯¹è±¡ã€‚ ä½¿ç”¨Toolkit lite2ï¼Œå¯ä»¥è¿è¡Œåœ¨PCä¸Šï¼Œé€šè¿‡æ¨¡æ‹Ÿå™¨è¿è¡Œæ¨¡å‹ï¼Œç„¶åè¿›è¡Œæ¨ç†ï¼Œæˆ–è€…æ¨¡å‹è½¬æ¢ç­‰æ“ä½œï¼›ä¹Ÿå¯ä»¥è¿è¡Œåœ¨è¿æ¥çš„æ¿å¡NPUä¸Šï¼Œ å°†RKNNæ¨¡å‹ä¼ åˆ°NPUè®¾å¤‡ä¸Šè¿è¡Œï¼Œå†ä»NPUè®¾å¤‡ä¸Šè·å–æ¨ç†ç»“æœã€æ€§èƒ½ä¿¡æ¯ç­‰ç­‰ã€‚ ![image 20251202192600839](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251202192600839.png) > è¯¦ç»†ä½¿ç”¨ä¾‹ç¨‹è¯·å‚è€ƒRKNN Toolkit2å·¥ç¨‹ä¸­examples/functionsç›®å½•ä¸‹ä¾‹ç¨‹ ### åˆå§‹åŒ– åœ¨ä½¿ç”¨RKNN Toolkit2çš„æ‰€æœ‰APIæ¥å£æ—¶ï¼Œéƒ½éœ€è¦å…ˆè°ƒç”¨RKNN()æ–¹æ³•åˆå§‹åŒ–RKNNå¯¹è±¡ï¼Œä¸å†ä½¿ç”¨è¯¥å¯¹è±¡æ—¶ é€šè¿‡è°ƒç”¨è¯¥å¯¹è±¡çš„release()æ–¹æ³•è¿›è¡Œé‡Šæ”¾ åˆå§‹åŒ–RKNNå¯¹è±¡æ—¶ï¼Œå¯ä»¥è®¾ç½®verboseå’Œverbose_fileå‚æ•°ï¼Œä»¥æ‰“å°è¯¦ç»†çš„æ—¥å¿—ä¿¡æ¯ã€‚å…¶ä¸­verboseå‚æ•°æŒ‡å®š æ˜¯å¦è¦æ‰“å°è¯¦ç»†æ—¥å¿—ä¿¡æ¯ï¼›å¦‚æœè®¾ç½®äº†verbose_fileå‚æ•°ï¼Œä¸”verboseå‚æ•°å€¼ä¸ºTrueï¼Œæ—¥å¿—ä¿¡æ¯è¿˜å°†å†™åˆ°è¯¥å‚æ•° æŒ‡å®šçš„æ–‡ä»¶ä¸­ ### æ¨¡å‹é…ç½® åœ¨æ„å»ºRKNNæ¨¡å‹ä¹‹å‰ï¼Œéœ€è¦å…ˆå¯¹æ¨¡å‹è¿›è¡Œé€šé“å‡å€¼ã€é‡åŒ–å›¾ç‰‡RGB2BGRè½¬æ¢ã€é‡åŒ–ç±»å‹ç­‰çš„é…ç½®ï¼Œè¿™äº› æ“ä½œå¯ä»¥é€šè¿‡configæ¥å£è¿›è¡Œé…ç½®"},"/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2025-12-3-04-RKLLM.html":{"title":"RKLLM","content":"# RKLLM > ç›¸å…³æ–‡æ¡£rknn llm/doc/Rockchip_RKLLM_SDK_CN_1.2.0.pdf é€šè¿‡è¯¥å·¥å…·æä¾›çš„Pythonæ¥å£å¯ä»¥ä¾¿æ·åœ°å®Œæˆä»¥ä¸‹åŠŸèƒ½ï¼š 1ï¼‰æ¨¡å‹è½¬æ¢ï¼šæ”¯æŒå°†Hugging Face å’Œ GGUF æ ¼å¼çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Model, LLMï¼‰è½¬æ¢ä¸º RKLLM æ¨¡å‹ + ç›®å‰æ”¯æŒçš„æ¨¡å‹åŒ…æ‹¬ LLaMA, Qwen, Qwen2, Phi 2, Phi 3, ChatGLM3, Gemma, Gemma2, Gemma3, InternLM2, TeleChat2, MiniCPM S, MiniCPM å’Œ MiniCPM3 è½¬æ¢åçš„RKLLMæ¨¡å‹èƒ½å¤Ÿåœ¨RockchipNPUå¹³å°ä¸ŠåŠ è½½ä½¿ç”¨ã€‚ 2ï¼‰é‡åŒ–åŠŸèƒ½ï¼šæ”¯æŒå°†æµ®ç‚¹æ¨¡å‹é‡åŒ–ä¸ºå®šç‚¹æ¨¡å‹ï¼Œç›®å‰æ”¯æŒçš„é‡åŒ–ç±»å‹åŒ…æ‹¬ a. w4a16ï¼› b. w4a16åˆ†ç»„é‡åŒ–(æ”¯æŒçš„åˆ†ç»„æ•°ä¸º32,64,128)ï¼› c. w8a8ï¼› d. w8a8åˆ†ç»„é‡åŒ–(æ”¯æŒçš„åˆ†ç»„æ•°ä¸º128,256,512)ï¼› ## åŸºç¡€æ­¥éª¤ ### æ¨¡å‹è½¬æ¢ ç”¨æˆ·æä¾›çš„HuggingFaceæ ¼å¼çš„å¤§è¯­è¨€æ¨¡å‹å°†ä¼šè¢«è½¬æ¢ä¸ºRKLLMæ ¼å¼ï¼Œ ä»¥ä¾¿åœ¨RockchipNPUå¹³å°ä¸Šè¿›è¡Œé«˜æ•ˆçš„æ¨ç† + è·å–åŸå§‹æ¨¡å‹ï¼š1ã€å¼€æºçš„HuggingFaceæ ¼å¼çš„å¤§è¯­è¨€æ¨¡å‹ï¼›2ã€è‡ªè¡Œè®­ç»ƒå¾—åˆ°çš„å¤§è¯­ è¨€æ¨¡å‹ï¼Œè¦æ±‚æ¨¡å‹ä¿å­˜çš„ç»“æ„ä¸HuggingFaceå¹³å°ä¸Šçš„æ¨¡å‹ç»“æ„ä¸€è‡´ï¼›3ã€GGUFæ¨¡å‹ï¼Œç›® å‰ä»…æ”¯æŒq4_0å’Œfp16ç±»å‹æ¨¡å‹ + æ¨¡å‹åŠ è½½ï¼šé€šè¿‡rkllm.load_huggingface()å‡½æ•°åŠ è½½ huggingface æ ¼å¼æ¨¡å‹ï¼Œé€šè¿‡ rkllm.load_gguf()å‡½æ•°åŠ è½½ GGUF æ¨¡å‹ + æ¨¡å‹é‡åŒ–é…ç½®ï¼šé€šè¿‡ rkllm.build() å‡½æ•°æ„å»ºRKLLMæ¨¡å‹ï¼Œåœ¨æ„å»ºè¿‡ç¨‹ä¸­å¯é€‰æ‹©æ˜¯å¦ è¿›è¡Œæ¨¡å‹é‡åŒ–æ¥æé«˜æ¨¡å‹éƒ¨ç½²åœ¨ç¡¬ä»¶ä¸Šçš„æ€§èƒ½ï¼Œä»¥åŠé€‰æ‹©ä¸åŒçš„ä¼˜åŒ–ç­‰çº§å’Œé‡åŒ–ç±»å‹ + æ¨¡å‹å¯¼å‡ºï¼šé€šè¿‡ rkllm.export_rkllm() å‡½æ•°å°† RKLLMæ¨¡å‹å¯¼å‡ºä¸ºä¸€ä¸ª.rkllmæ ¼å¼æ–‡ä»¶ï¼Œ ç”¨äºåç»­çš„éƒ¨ç½² ### æ¿å­éƒ¨ç½² + æ¨¡å‹åˆå§‹åŒ–ï¼šåŠ è½½RKLLMæ¨¡å‹åˆ°RockchipNPUå¹³å°ï¼Œè¿›è¡Œç›¸åº”çš„æ¨¡å‹å‚æ•°è®¾ç½®æ¥ å®šä¹‰æ‰€éœ€çš„æ–‡æœ¬ç”Ÿæˆæ–¹å¼ï¼Œå¹¶æå‰å®šä¹‰ç”¨äºæ¥å—å®æ—¶æ¨ç†ç»“æœçš„å›è°ƒå‡½æ•°ï¼Œè¿›è¡Œæ¨ç†å‰å‡†å¤‡ + æ¨¡å‹æ¨ç†ï¼šæ‰§è¡Œæ¨ç†æ“ä½œï¼Œå°†è¾“å…¥æ•°æ®ä¼ é€’ç»™æ¨¡å‹å¹¶è¿è¡Œæ¨¡å‹æ¨ç†ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡é¢„ å…ˆå®šä¹‰çš„å›è°ƒå‡½æ•°ä¸æ–­è·å–æ¨ç†ç»“æœ + æ¨¡å‹é‡Šæ”¾ï¼šåœ¨å®Œæˆæ¨ç†æµç¨‹åï¼Œé‡Šæ”¾æ¨¡å‹èµ„æºï¼Œä»¥ä¾¿å…¶ä»–ä»»åŠ¡ç»§ç»­ä½¿ç”¨NPUçš„è®¡ç®—èµ„æº 1ï¼‰ å®šä¹‰å›è°ƒå‡½æ•°callback()ï¼› 2ï¼‰ å®šä¹‰RKLLMæ¨¡å‹å‚æ•°ç»“æ„ä½“RKLLMParamï¼› 3ï¼‰ rkllm_init()åˆå§‹åŒ– RKLLM æ¨¡å‹ï¼› 4ï¼‰ rkllm_run()è¿›è¡Œæ¨¡å‹æ¨ç†ï¼› 5ï¼‰ é€šè¿‡å›è°ƒå‡½æ•°callback()å¯¹æ¨¡å‹å®æ—¶ä¼ å›çš„æ¨ç†ç»“æœè¿›è¡Œå¤„ç†ï¼› 6ï¼‰ rkllm_destroy()é”€æ¯ RKLLM æ¨¡å‹å¹¶é‡Šæ”¾èµ„æºï¼› ## æ¨¡å‹é‡åŒ– **æ¨¡å‹é‡åŒ–**æ˜¯ä¸€ç§æ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯**ç”¨æ›´ä½ç²¾åº¦çš„æ•°å€¼æ ¼å¼ï¼ˆä¾‹å¦‚8ä½æ•´æ•°ï¼‰æ¥è¡¨ç¤ºå’Œè®¡ç®—ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­åŸæœ¬ä½¿ç”¨é«˜ç²¾åº¦æ•°å€¼æ ¼å¼ï¼ˆä¾‹å¦‚32ä½æµ®ç‚¹æ•°ï¼‰çš„æƒé‡å’Œæ¿€æ´»å€¼**ã€‚ æ‚¨å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆï¼š **åŸå§‹æ¨¡å‹ï¼ˆFP32ï¼‰**ï¼šåƒç”¨é«˜ä¿çœŸæ— æŸéŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚FLAC/WAVï¼‰å­˜å‚¨éŸ³ä¹ï¼Œç²¾åº¦é«˜ã€ä¿çœŸåº¦å¥½ï¼Œä½†æ–‡ä»¶ä½“ç§¯å·¨å¤§ã€‚ **é‡åŒ–åæ¨¡å‹ï¼ˆINT8ï¼‰**ï¼šåƒæŠŠéŸ³ä¹è½¬æ¢æˆMP3æ ¼å¼ã€‚è™½ç„¶æŸå¤±äº†ä¸€ç‚¹ç‚¹éŸ³è´¨ç»†èŠ‚ï¼Œä½†æ–‡ä»¶ä½“ç§¯å¤§å¹…å‡å°ï¼Œæ’­æ”¾æ›´æµç•…ï¼Œå¯¹è®¾å¤‡è¦æ±‚ä¹Ÿæ›´ä½ã€‚åœ¨ç»å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œè¿™ç‚¹éŸ³è´¨æŸå¤±æ˜¯å¬ä¸å‡ºæ¥çš„ã€‚ ### **ä¸ºä»€ä¹ˆè¦è¿›è¡Œæ¨¡å‹é‡åŒ–ï¼Ÿï¼ˆåŠ¨æœºä¸å¥½å¤„ï¼‰** é‡åŒ–ä¸»è¦ä¸ºäº†è§£å†³æ·±åº¦å­¦ä¹ æ¨¡å‹éƒ¨ç½²æ—¶çš„ä¸‰å¤§ç“¶é¢ˆï¼š 1. **å‡å°‘æ¨¡å‹ä½“ç§¯** å°†æƒé‡ä»32ä½æµ®ç‚¹ï¼ˆFP32ï¼‰è½¬æ¢ä¸º8ä½æ•´æ•°ï¼ˆINT8ï¼‰ï¼Œæ¨¡å‹å¤§å°ç†è®ºä¸Šç›´æ¥å‡å°‘ä¸ºåŸæ¥çš„ **1/4**ã€‚è¿™å¯¹äºå°†æ¨¡å‹éƒ¨ç½²åˆ°å­˜å‚¨ç©ºé—´æœ‰é™çš„ç§»åŠ¨è®¾å¤‡ã€åµŒå…¥å¼ç³»ç»Ÿï¼ˆå¦‚æ‰‹æœºã€æ™ºèƒ½æ‘„åƒå¤´ã€è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼‰è‡³å…³é‡è¦ã€‚ 2. **æå‡æ¨ç†é€Ÿåº¦** æ•´æ•°è¿ç®—æ¯”æµ®ç‚¹è¿ç®—å¿«å¾—å¤šï¼Œå°¤å…¶æ˜¯åœ¨æ²¡æœ‰ä¸“ç”¨æµ®ç‚¹è®¡ç®—å•å…ƒï¼ˆå¦‚ä¸€äº›è¾¹ç¼˜è®¡ç®—èŠ¯ç‰‡ï¼‰çš„ç¡¬ä»¶ä¸Šã€‚ æ›´ä½ç²¾åº¦çš„æ•°æ®æ„å‘³ç€åœ¨ç›¸åŒå†…å­˜å¸¦å®½ä¸‹å¯ä»¥ä¼ è¾“æ›´å¤šæ•°æ®ï¼Œå‡å°‘äº†æ•°æ®æ¬è¿çš„ç“¶é¢ˆã€‚ è®¸å¤šç¡¬ä»¶ï¼ˆå¦‚CPUã€GPUã€NPUï¼‰éƒ½é’ˆå¯¹ä½ç²¾åº¦æ•´æ•°è¿ç®—è¿›è¡Œäº†ç‰¹æ®Šä¼˜åŒ–ï¼Œèƒ½å¤§å¹…æå‡è®¡ç®—ååé‡ã€‚ 3. **é™ä½åŠŸè€—** æ›´ç®€å•çš„æ•´æ•°è¿ç®—å•å…ƒæ¯”å¤æ‚çš„æµ®ç‚¹è¿ç®—å•å…ƒæ¶ˆè€—çš„èƒ½é‡æ›´å°‘ã€‚è¿™å¯¹äºä¾èµ–ç”µæ± çš„ç§»åŠ¨è®¾å¤‡å’Œç‰©è”ç½‘è®¾å¤‡æ¥è¯´ï¼Œèƒ½æ˜¾è‘—å»¶é•¿ç»­èˆªæ—¶é—´ã€‚ ### **ä¸»è¦çš„é‡åŒ–æ–¹æ³•** æ ¹æ®é‡åŒ–å‘ç”Ÿçš„æ—¶æœºå’Œæ˜¯å¦éœ€è¦åŸå§‹è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š 1. **è®­ç»ƒåé‡åŒ–** **åšæ³•**ï¼šåœ¨ä¸€ä¸ª**å·²ç»è®­ç»ƒå¥½çš„FP32æ¨¡å‹**ä¸Šç›´æ¥è¿›è¡Œé‡åŒ–ã€‚ **ä¼˜ç‚¹**ï¼šç®€å•å¿«æ·ï¼Œä¸éœ€è¦é‡æ–°è®­ç»ƒæˆ–åŸå§‹æ•°æ®ï¼ˆéƒ¨åˆ†æ–¹æ³•éœ€è¦å°‘é‡æ ¡å‡†æ•°æ®ï¼‰ã€‚ **ç¼ºç‚¹**ï¼šç²¾åº¦æŸå¤±å¯èƒ½ç›¸å¯¹è¾ƒå¤§ï¼Œå°¤å…¶æ˜¯å¯¹æ•æ„Ÿçš„æ¨¡å‹ã€‚ **æœ€å¸¸è§ã€åº”ç”¨æœ€å¹¿**çš„ç±»å‹ã€‚ 2. **é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ** **åšæ³•**ï¼šåœ¨**æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­**å°±æ¨¡æ‹Ÿé‡åŒ–çš„æ•ˆæœï¼Œè®©æ¨¡å‹åœ¨è®­ç»ƒæ—¶â€œæå‰é€‚åº”â€ä½ç²¾åº¦çš„è¡¨ç¤ºã€‚ **ä¼˜ç‚¹**ï¼šèƒ½æœ€å¤§ç¨‹åº¦åœ°ä¿æŒé‡åŒ–åçš„æ¨¡å‹ç²¾åº¦ï¼Œé€šå¸¸èƒ½è¾¾åˆ°æ¥è¿‘åŸå§‹FP32æ¨¡å‹çš„å‡†ç¡®ç‡ã€‚ **ç¼ºç‚¹**ï¼šè¿‡ç¨‹å¤æ‚ï¼Œéœ€è¦é‡æ–°è®­ç»ƒæˆ–å¾®è°ƒæ¨¡å‹ï¼Œè®¡ç®—æˆæœ¬é«˜ã€‚ ### **é‡åŒ–çš„åŸºæœ¬è¿‡ç¨‹ï¼ˆä»¥è®­ç»ƒåINT8é‡åŒ–ä¸ºä¾‹ï¼‰** é‡åŒ–çš„å…³é”®æ­¥éª¤æ˜¯æ‰¾åˆ°ä¸€ä¸ª**ç¼©æ”¾å› å­**å’Œä¸€ä¸ª**é›¶ç‚¹**ï¼Œå°†æµ®ç‚¹æ•°èŒƒå›´çº¿æ€§æ˜ å°„åˆ°æ•´æ•°èŒƒå›´ã€‚ **å…¬å¼ç®€åŒ–è¡¨ç¤ºï¼š** `é‡åŒ–å€¼ round(æµ®ç‚¹å€¼ / ç¼©æ”¾å› å­) + é›¶ç‚¹` **æ­¥éª¤ï¼š** 1. **ç»Ÿè®¡èŒƒå›´**ï¼šåˆ†ææ¨¡å‹æƒé‡æˆ–æ¿€æ´»å€¼çš„åˆ†å¸ƒèŒƒå›´ï¼ˆæœ€å¤§å€¼ã€æœ€å°å€¼ï¼‰ã€‚ 2. **è®¡ç®—å‚æ•°**ï¼šæ ¹æ®ç»Ÿè®¡çš„èŒƒå›´ï¼Œç¡®å®šæœ€ä½³çš„`ç¼©æ”¾å› å­`å’Œ`é›¶ç‚¹`ï¼Œä½¿å¾—æµ®ç‚¹æ•°èŒƒå›´èƒ½å°½å¯èƒ½æ— æŸåœ°æ˜ å°„åˆ°æœ‰é™çš„æ•´æ•°åŸŸï¼ˆå¦‚ 128åˆ°127ï¼‰ã€‚ 3. **è½¬æ¢ä¸å­˜å‚¨**ï¼šä½¿ç”¨ä¸Šè¿°å…¬å¼å°†æ‰€æœ‰æµ®ç‚¹æƒé‡è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¹¶å­˜å‚¨åœ¨æ¨¡å‹ä¸­ã€‚ 4. **æ¨ç†è®¡ç®—**ï¼šåœ¨è®¾å¤‡ä¸Šè¿›è¡Œæ¨ç†æ—¶ï¼Œä½¿ç”¨é«˜æ•ˆçš„æ•´æ•°çŸ©é˜µä¹˜åŠ è¿ç®—ã€‚è¾“å…¥æ•°æ®ä¹Ÿéœ€è¦è¢«é‡åŒ–ä¸ºæ•´æ•°ï¼Œè¾“å‡ºç»“æœå†é€šè¿‡åé‡åŒ–è½¬æ¢å›æµ®ç‚¹æ•°ä»¥ä¾›åç»­å±‚ä½¿ç”¨æˆ–æœ€ç»ˆè¾“å‡ºã€‚ ### **æŒ‘æˆ˜ä¸æ³¨æ„äº‹é¡¹** **ç²¾åº¦æŸå¤±**ï¼šæœ€æ ¸å¿ƒçš„æŒ‘æˆ˜ã€‚è¿‡åº¦å‹ç¼©å¯èƒ½å¯¼è‡´æ¨¡å‹å‡†ç¡®åº¦æ˜¾è‘—ä¸‹é™ã€‚ **æ¨¡å‹æ•æ„Ÿæ€§**ï¼šä¸åŒæ¨¡å‹ã€ä¸åŒå±‚å¯¹é‡åŒ–çš„å®¹å¿åº¦ä¸åŒã€‚ä¾‹å¦‚ï¼Œè½»é‡çº§æ¨¡å‹å¯èƒ½æ¯”å¤§å‹æ¨¡å‹æ›´æ•æ„Ÿã€‚ **ç¡¬ä»¶æ”¯æŒ**ï¼šéœ€è¦ç›®æ ‡éƒ¨ç½²ç¡¬ä»¶ï¼ˆå¦‚æ‰‹æœºèŠ¯ç‰‡ã€AIåŠ é€Ÿå¡ï¼‰æ”¯æŒç›¸åº”çš„ä½ç²¾åº¦æŒ‡ä»¤é›†ï¼Œæ‰èƒ½å‘æŒ¥é‡åŒ–ä¼˜åŠ¿ã€‚ ### **æ€»ç»“** æ¨¡å‹é‡åŒ–æ˜¯**å°†æ·±åº¦å­¦ä¹ æ¨¡å‹ä»â€œå®éªŒå®¤ç¯å¢ƒâ€æ¨å‘â€œå®é™…ç”Ÿäº§éƒ¨ç½²â€çš„å…³é”®æ¡¥æ¢**ã€‚å®ƒé€šè¿‡ç‰ºç‰²å¾®ä¸è¶³é“çš„ç²¾åº¦ï¼Œæ¢æ¥äº†**æ¨¡å‹ä½“ç§¯ã€æ¨ç†é€Ÿåº¦å’ŒåŠŸè€—**çš„æ˜¾è‘—ä¼˜åŒ–ï¼Œä½¿å¾—åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œå¼ºå¤§çš„AIæ¨¡å‹æˆä¸ºå¯èƒ½ã€‚å¦‚ä»Šï¼Œå®ƒå·²æˆä¸ºAIæ¨¡å‹éƒ¨ç½²ä¸­ä¸€é¡¹æ ‡å‡†ä¸”å¿…ä¸å¯å°‘çš„æŠ€æœ¯ã€‚ ## æ¨¡å‹é‡åŒ– ```python from rkllm.api import RKLLM import os #os.environ['CUDA_VISIBLE_DEVICES'] '0' modelpath './huggingface/deepseek r1 1.5b' llm RKLLM() # Load model # Use 'export CUDA_VISIBLE_DEVICES 0' to specify GPU device # options ['cpu', 'cuda'] ret llm.load_huggingface(model modelpath, model_lora None, device 'cpu') if ret ! 0: print('Load model failed!') exit(ret) # Build model dataset \"./data_quant.json\" qparams None # do_quantization: é‡åŒ–ç²¾åº¦ä¼˜åŒ–, quantized_algorithmä½¿ç”¨çš„é‡åŒ–ä¼˜åŒ–ç®—æ³• # æƒé‡(weights)å’Œæ¿€æ´»(activations)éƒ½é‡åŒ–ä¸º8ä½æ•´æ•° â†’ æœ€é«˜å‹ç¼©ç‡ï¼Œé€Ÿåº¦æœ€å¿« # optimization_level 1: ä¼˜åŒ–ç­‰çº§, # 0: åŸºæœ¬ä¼˜åŒ–ï¼Œåªåšå¿…è¦è½¬æ¢, 1: ä¸­ç­‰ä¼˜åŒ–ï¼ˆå¸¸ç”¨ï¼‰ï¼ŒåŒ…æ‹¬å›¾ä¼˜åŒ–ã€ç®—å­èåˆç­‰ # 2: é«˜çº§ä¼˜åŒ–ï¼Œæ›´æ¿€è¿›çš„ä¼˜åŒ–ç­–ç•¥ 3: æè‡´ä¼˜åŒ–ï¼ˆå¯èƒ½å½±å“ç²¾åº¦ï¼‰ # é‡åŒ–æ ¡å‡†ç®—æ³• # 'normal': æ ‡å‡†çº¿æ€§é‡åŒ–ï¼ˆæœ€å¸¸ç”¨ï¼‰'minmax': åŸºäºæœ€å° æœ€å¤§å€¼çš„é‡åŒ– # 'kl_divergence': åŸºäºKLæ•£åº¦çš„é‡åŒ–ï¼ˆç²¾åº¦æ›´é«˜ï¼‰'percentile': åŸºäºç™¾åˆ†ä½çš„é‡åŒ–ï¼ˆæŠ—å¼‚å¸¸å€¼ï¼‰ ret llm.build(do_quantization True, optimization_level 1, quantized_dtype 'w8a8', quantized_algorithm 'normal', target_platform 'rk3588', num_npu_core 3, extra_qparams qparams,dataset dataset) if ret ! 0: print('Build model failed!') exit(ret) # Export rkllm model ret llm.export_rkllm(f\"./deepseek 1.5b w8a8 rk3588.rkllm\") if ret ! 0: print('Export model failed!') exit(ret) ``` ### é‡åŒ–ç®—æ³• 1. é‡åŒ–ç®—æ³•çš„æ ¸å¿ƒä½œç”¨ é‡åŒ–ç®—æ³•çš„æ ¸å¿ƒä»»åŠ¡æ˜¯**è§£å†³\"å¦‚ä½•å°†è¿ç»­çš„æµ®ç‚¹æ•°æ˜ å°„åˆ°ç¦»æ•£çš„æ•´æ•°\"**è¿™ä¸€æ•°å­¦é—®é¢˜ï¼Œä¸»è¦è§£å†³ï¼š **åŠ¨æ€èŒƒå›´åŒ¹é…**ï¼šå°†æƒé‡/æ¿€æ´»å€¼çš„æµ®ç‚¹åˆ†å¸ƒï¼ˆå¦‚[ 3.2, 4.8]ï¼‰æ˜ å°„åˆ°æœ‰é™çš„æ•´æ•°èŒƒå›´ï¼ˆå¦‚[ 128, 127]ï¼‰ **ç²¾åº¦æŸå¤±æœ€å°åŒ–**ï¼šæ‰¾åˆ°æœ€ä¼˜çš„æ˜ å°„å‡½æ•°ï¼Œä½¿é‡åŒ–åçš„ä¿¡æ¯æŸå¤±æœ€å° **å¼‚å¸¸å€¼å¤„ç†**ï¼šå¤„ç†æç«¯å¤§/å°çš„å€¼ï¼Œé˜²æ­¢å®ƒä»¬å½±å“æ•´ä½“é‡åŒ–æ•ˆæœ 2. ä¸åŒé‡åŒ–ç®—æ³•çš„è¯¦ç»†åŒºåˆ« a) `'normal'` æ ‡å‡†çº¿æ€§é‡åŒ–ï¼ˆæœ€å¸¸ç”¨ï¼‰ ``` # åŸºæœ¬åŸç†ï¼šåŸºäºå‡å€¼å’Œæ ‡å‡†å·®çš„çº¿æ€§æ˜ å°„ scale (max_value min_value) / (quant_max quant_min) zero_point min_value / scale # é€‚ç”¨åœºæ™¯ï¼š # æ•°æ®åˆ†å¸ƒç›¸å¯¹å‡åŒ€ # æ¿€æ´»å€¼æ— æ˜æ˜¾å¼‚å¸¸å€¼ # å¤§å¤šæ•°CNNã€TransformeråŸºç¡€å±‚ # ä¼˜ç‚¹ï¼šè®¡ç®—ç®€å•ï¼Œé€Ÿåº¦å¿« # ç¼ºç‚¹ï¼šå¯¹å¼‚å¸¸å€¼æ•æ„Ÿ ``` #### b) `'minmax'` æœ€å° æœ€å¤§å€¼é‡åŒ– ``` # åŸºæœ¬åŸç†ï¼šç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®çš„ç»å¯¹æœ€å¤§/æœ€å°å€¼ min_val min(åŸå§‹æ•°æ®) max_val max(åŸå§‹æ•°æ®) # ç„¶åçº¿æ€§æ˜ å°„ # é€‚ç”¨åœºæ™¯ï¼š # æ•°æ®èŒƒå›´æ˜ç¡®ä¸”æœ‰é™ # éœ€è¦å®Œå…¨ä¿ç•™åŸå§‹èŒƒå›´ # å›¾åƒå¤„ç†ï¼ˆåƒç´ å€¼èŒƒå›´å›ºå®šï¼‰ # ä¼˜ç‚¹ï¼šè¦†ç›–å…¨éƒ¨æ•°æ®èŒƒå›´ # ç¼ºç‚¹ï¼šä¸€ä¸ªå¼‚å¸¸å€¼å°±èƒ½æ¯æ‰æ•´ä¸ªé‡åŒ–ï¼ˆå¦‚max 1000ï¼Œæ­£å¸¸å€¼éƒ½åœ¨[ 1,1]ï¼‰ ``` c) `'kl_divergence'` KLæ•£åº¦é‡åŒ–(ç²¾åº¦æœ€é«˜) ``` # åŸºæœ¬åŸç†ï¼šæœ€å°åŒ–åŸå§‹åˆ†å¸ƒä¸é‡åŒ–åˆ†å¸ƒçš„KLæ•£åº¦ # 1. å°†åŸå§‹æ•°æ®åˆ†æˆå¤šä¸ªbinsï¼ˆç›´æ–¹å›¾ï¼‰ # 2. æœç´¢æœ€ä¼˜çš„æˆªæ–­é˜ˆå€¼ï¼Œä½¿é‡åŒ–åçš„åˆ†å¸ƒä¸åŸå§‹åˆ†å¸ƒå·®å¼‚æœ€å° # 3. ä½¿ç”¨æˆªæ–­åçš„èŒƒå›´è¿›è¡Œçº¿æ€§é‡åŒ– # é€‚ç”¨åœºæ™¯ï¼š # å¯¹ç²¾åº¦è¦æ±‚æé«˜çš„åº”ç”¨ # æ•°æ®åˆ†å¸ƒä¸å‡åŒ€æˆ–æœ‰é•¿å°¾åˆ†å¸ƒ # LLMä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ã€GeLUæ¿€æ´»å±‚ # ä¼˜ç‚¹ï¼šç²¾åº¦æŸå¤±æœ€å°ï¼Œèƒ½æ™ºèƒ½å¤„ç†é•¿å°¾åˆ†å¸ƒ # ç¼ºç‚¹ï¼šè®¡ç®—å¤æ‚ï¼Œéœ€è¦æ›´å¤šæ ¡å‡†æ•°æ®å’Œæ—¶é—´ ``` d) `'percentile'` ç™¾åˆ†ä½é‡åŒ– ``` # åŸºæœ¬åŸç†ï¼šä½¿ç”¨ç™¾åˆ†ä½æ•°ï¼ˆå¦‚99.9%ï¼‰è€Œéç»å¯¹æå€¼ min_val np.percentile(æ•°æ®, 0.1) # å¿½ç•¥æœ€å°çš„0.1% max_val np.percentile(æ•°æ®, 99.9) # å¿½ç•¥æœ€å¤§çš„0.1% # é€‚ç”¨åœºæ™¯ï¼š # æ•°æ®åŒ…å«å°‘é‡å¼‚å¸¸å€¼ # éœ€è¦é²æ£’æ€§å¼ºçš„é‡åŒ– # å®æ—¶æ¨ç†ç³»ç»Ÿ # ä¼˜ç‚¹ï¼šæŠ—å¼‚å¸¸å€¼å¹²æ‰°ï¼Œç¨³å®šæ€§å¥½ # ç¼ºç‚¹ï¼šå¯èƒ½ä¸¢å¤±æç«¯ä½†é‡è¦çš„ä¿¡æ¯ ``` 3. ç®—æ³•é€‰æ‹©å»ºè®® ç®—æ³• ç²¾åº¦ é€Ÿåº¦ å†…å­˜ æ¨èåœºæ™¯ : : : : : `normal` ä¸­ç­‰ æœ€å¿« ä½ ä¸€èˆ¬åº”ç”¨ï¼Œå¿«é€Ÿéƒ¨ç½² `minmax` ä½ ä¸­ç­‰ å¿« ä½ æ•°æ®èŒƒå›´æ˜ç¡®çš„ç®€å•æ¨¡å‹ `kl_divergence` **æœ€é«˜** æ…¢ é«˜ å¯¹è¯æ¨¡å‹ã€é«˜ç²¾åº¦è¦æ±‚ `percentile` é«˜ ä¸­ç­‰ ä¸­ç­‰ å·¥ä¸šéƒ¨ç½²ï¼Œé²æ£’æ€§è¦æ±‚é«˜ å®é™…ç»éªŒï¼š å¯¹äºLLMï¼šé€šå¸¸ä½¿ç”¨`kl_divergence` + `percentile`ç»„åˆ å¯¹äºCNNè§†è§‰æ¨¡å‹ï¼š`normal`æˆ–`percentile`è¶³å¤Ÿ ç§»åŠ¨ç«¯éƒ¨ç½²ï¼š`percentile`ï¼ˆå¹³è¡¡ç²¾åº¦å’Œç¨³å®šæ€§ï¼‰ ## æ¨¡å‹éƒ¨ç½² æ¨¡å‹çš„è¿è¡Œéœ€è¦ä½¿ç”¨ä¸¤ä¸ªåº“, åˆ†åˆ«æ˜¯`libgomp`ä»¥åŠ`librkllm_api` ### Cè¯­è¨€è°ƒç”¨ ```c #include <string.h> #include <unistd.h> #include <string> #include \"rkllm.h\" #include <fstream> #include <iostream> #include <csignal> #include <vector> using namespace std; LLMHandle llmHandle nullptr; #define PROMPT_TEXT_PREFIX \"<ï½œbeginâ–ofâ–sentenceï½œ><ï½œUserï½œ>\" #define PROMPT_TEXT_POSTFIX \"<ï½œAssistantï½œ>\" void exit_handler(int signal) { if (llmHandle ! nullptr) { { cout << \"ç¨‹åºå³å°†é€€å‡º\" << endl; LLMHandle _tmp llmHandle; llmHandle nullptr; rkllm_destroy(_tmp); } } exit(signal); } /* LLM_RUN_NORMALï¼šè¡¨ç¤ºRKLLMæ¨¡å‹å½“å‰æ­£åœ¨æ¨ç†ä¸­ï¼› LLM_RUN_FINISHï¼šè¡¨ç¤ºRKLLMæ¨¡å‹å·²å®Œæˆå½“å‰è¾“å…¥çš„å…¨éƒ¨æ¨ç†ï¼› LLM_RUN_WAITINGï¼šè¡¨ç¤ºå½“å‰RKLLMè§£ç å‡ºçš„å­—ç¬¦ä¸æ˜¯å®Œæ•´UTF8ç¼–ç ï¼Œéœ€ç­‰å¾…ä¸ä¸‹ä¸€æ¬¡è§£ç æ‹¼æ¥ï¼› LLM_RUN_ERRORï¼šè¡¨ç¤ºRKLLMæ¨¡å‹æ¨ç†å‡ºç°é”™è¯¯ï¼› */ void callback(RKLLMResult *result, void *userdata, LLMCallState state) { if (state RKLLM_RUN_FINISH) { printf(\"\\n\"); } else if (state RKLLM_RUN_ERROR) { printf(\"\\\\run error\\n\"); } else if (state RKLLM_RUN_GET_LAST_HIDDEN_LAYER) { /* è‹¥ä½¿ç”¨GET_LAST_HIDDEN_LAYERåŠŸèƒ½,callbackæ¥å£ä¼šå›ä¼ å†…å­˜æŒ‡é’ˆ:last_hidden_layer,tokenæ•°é‡:num_tokensä¸éšè—å±‚å¤§å°:embd_size é€šè¿‡è¿™ä¸‰ä¸ªå‚æ•°å¯ä»¥å–å¾—last_hidden_layerä¸­çš„æ•°æ® æ³¨:éœ€è¦åœ¨å½“å‰callbackä¸­è·å–,è‹¥æœªåŠæ—¶è·å–,ä¸‹ä¸€æ¬¡callbackä¼šå°†è¯¥æŒ‡é’ˆé‡Šæ”¾ */ if (result >last_hidden_layer.embd_size ! 0 && result >last_hidden_layer.num_tokens ! 0) { int data_size result >last_hidden_layer.embd_size * result >last_hidden_layer.num_tokens * sizeof(float); printf(\"\\ndata_size:%d\",data_size); std::ofstream outFile(\"last_hidden_layer.bin\", std::ios::binary); if (outFile.is_open()) { outFile.write(reinterpret_cast<const char*>(result >last_hidden_layer.hidden_states), data_size); outFile.close(); std::cout << \"Data saved to output.bin successfully!\" << std::endl; } else { std::cerr << \"Failed to open the file for writing!\" << std::endl; } } } else if (state RKLLM_RUN_NORMAL) { printf(\"%s\", result >text); } } int main(int argc, char **argv) { if (argc < 4) { std::cerr << \"Usage: \" << argv[0] << \" model_path max_new_tokens max_context_len\\n\"; return 1; } signal(SIGINT, exit_handler); printf(\"rkllm init start\\n\"); //è®¾ç½®å‚æ•°åŠåˆå§‹åŒ– RKLLMParam param rkllm_createDefaultParam(); param.model_path argv[1]; //è®¾ç½®é‡‡æ ·å‚æ•° param.top_k 1; param.top_p 0.95; param.temperature 0.8; param.repeat_penalty 1.1; param.frequency_penalty 0.0; param.presence_penalty 0.0; param.max_new_tokens std::atoi(argv[2]); param.max_context_len std::atoi(argv[3]); param.skip_special_token true; param.extend_param.base_domain_id 0; int ret rkllm_init(&llmHandle, &param, callback); if (ret 0){ printf(\"rkllm init success\\n\"); } else { printf(\"rkllm init failed\\n\"); exit_handler( 1); } vector<string> pre_input; pre_input.push_back(\"ç°æœ‰ä¸€ç¬¼å­ï¼Œé‡Œé¢æœ‰é¸¡å’Œå…”å­è‹¥å¹²åªï¼Œæ•°ä¸€æ•°ï¼Œå…±æœ‰å¤´14ä¸ªï¼Œè…¿38æ¡ï¼Œæ±‚é¸¡å’Œå…”å­å„æœ‰å¤šå°‘åªï¼Ÿ\"); pre_input.push_back(\"æœ‰28ä½å°æœ‹å‹æ’æˆä¸€è¡Œ,ä»å·¦è¾¹å¼€å§‹æ•°ç¬¬10ä½æ˜¯å­¦è±†,ä»å³è¾¹å¼€å§‹æ•°ä»–æ˜¯ç¬¬å‡ ä½?\"); cout << \"\\n**********************å¯è¾“å…¥ä»¥ä¸‹é—®é¢˜å¯¹åº”åºå·è·å–å›ç­”/æˆ–è‡ªå®šä¹‰è¾“å…¥********************\\n\" << endl; for (int i 0; i < (int)pre_input.size(); i++) { cout << \"[\" << i << \"] \" << pre_input[i] << endl; } cout << \"\\n*************************************************************************\\n\" << endl; string text; RKLLMInput rkllm_input; // åˆå§‹åŒ– infer å‚æ•°ç»“æ„ä½“ RKLLMInferParam rkllm_infer_params; memset(&rkllm_infer_params, 0, sizeof(RKLLMInferParam)); // å°†æ‰€æœ‰å†…å®¹åˆå§‹åŒ–ä¸º 0 rkllm_infer_params.mode RKLLM_INFER_GENERATE; while (true) { std::string input_str; printf(\"\\n\"); printf(\"user: \"); std::getline(std::cin, input_str); if (input_str \"exit\") { break; } for (int i 0; i < (int)pre_input.size(); i++) { if (input_str to_string(i)) { input_str pre_input[i]; cout << input_str << endl; } } text PROMPT_TEXT_PREFIX + input_str + PROMPT_TEXT_POSTFIX; // text input_str; rkllm_input.input_type RKLLM_INPUT_PROMPT; rkllm_input.prompt_input (char *)text.c_str(); printf(\"robot: \"); // è‹¥è¦ä½¿ç”¨æ™®é€šæ¨ç†åŠŸèƒ½,åˆ™é…ç½®rkllm_infer_modeä¸ºRKLLM_INFER_GENERATEæˆ–ä¸é…ç½®å‚æ•° rkllm_run(llmHandle, &rkllm_input, &rkllm_infer_params, NULL); } rkllm_destroy(llmHandle); return 0; } ``` ```cmake cmake_minimum_required(VERSION 3.8) project(atk_deepseek_rkllm_demo) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(TOOLCHAIN_DIR /home/jiao/yh linux/rk3588/prebuilts/gcc/linux x86/aarch64/gcc arm 10.3 2021.07 x86_64 aarch64 none linux gnu) set(CMAKE_CXX_COMPILER ${TOOLCHAIN_DIR}/bin/aarch64 rockchip1031 linux gnu g++) set(CMAKE_C_COMPILER ${TOOLCHAIN_DIR}/bin/aarch64 rockchip1031 linux gnu gcc) include_directories(${CMAKE_SOURCE_DIR}/lib/librkllm_api/include/) set(RKLLM_RT_LIB ${CMAKE_SOURCE_DIR}/lib/librkllm_api/librkllmrt.so) set(GOMP_LIB ${CMAKE_SOURCE_DIR}/lib/libgomp/libgomp.so) add_executable(atk_deepseek_demo main.cc) target_link_libraries(atk_deepseek_demo ${RKLLM_RT_LIB} ${GOMP_LIB}) set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/install/atk_deepseek_rkllm_demo) install(TARGETS atk_deepseek_demo DESTINATION ./) install(DIRECTORY rkllm_model DESTINATION ./) ``` ```bash set e ROOT_PWD $( cd \"$( dirname $0 )\" && cd P \"$( dirname \"$SOURCE\" )\" && pwd ) BUILD_DIR ${ROOT_PWD}/build/build_linux_aarch64 if [[ ! d \"${BUILD_DIR}\" ]]; then mkdir p ${BUILD_DIR} fi cd ${BUILD_DIR} cmake ../.. make j4 make install cd ``` è¿è¡Œä»¥åçš„ç»“æœæ”¾åœ¨`./install/atk_deepseek_rkllm_demo`æ–‡ä»¶å¤¹é‡Œé¢, æŠŠè¿™ä¸ªæ–‡ä»¶å¤åˆ¶åˆ°å¼€å‘æ¿ å®é™…è¿è¡Œçš„å‘½ä»¤ ```bash ./atk_deepseek_demo rkllm_model/deepseek 1.5b w8a8 rk3588.rkllm 5000 5000 ``` > ä¸¤ä¸ªæ•°å­—æŒ‡çš„æ˜¯, å®é™…çš„ä½¿ç”¨å¯ä»¥åœ¨çš„RKLLMçš„å¼€æºé¡¹ç›®æ‰‹å†Œé‡Œé¢çœ‹åˆ°, è¿™é‡Œæ˜¯è®¾ç½®ç”Ÿæˆtokençš„ä¸Šé™ä»¥åŠæ¨ç†çš„tokenä¸Šé™"},"/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2025-12-2-02-åŸºç¡€æ¦‚å¿µ.html":{"title":"","content":"## åŸºç¡€æ¦‚å¿µ æ·±åº¦å­¦ä¹ æ¨¡å‹å·¥ä½œæµç¨‹å¤§è‡´å¯åˆ†ä¸ºè®­ç»ƒå’Œæ¨ç†ï¼Œè€Œåœ¨æ¿å—ä¸Šéƒ¨ç½²æ¨¡å‹ï¼Œå…·ä½“çš„æ­¥éª¤å¦‚ä¸‹ï¼š **æ¨¡å‹è®­ç»ƒ**ï¼Œæ¨¡å‹è®­ç»ƒå‰éœ€è¦æ ¹æ®å…·ä½“é¡¹ç›®é—®é¢˜ï¼Œé€‰æ‹©æ¨¡å‹ï¼Œæ•°æ®é‡‡é›†ï¼Œç„¶åä½¿ç”¨é€‚åˆçš„æ·±åº¦å­¦ä¹ æ¡†æ¶è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œ å…¶ä¸­å…³äºRKNNæ¨¡å‹ç®—å­çš„æ”¯æŒè¯·å‚è€ƒ [RKNN_Compiler_Support_Operator_List](https://github.com/airockchip/rknn toolkit2/tree/master/doc) ã€‚ **æ¨¡å‹è½¬æ¢**ï¼Œå°†è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ä¼šè¢«è½¬åŒ–ä¸ºRKNNæ ¼å¼çš„æ¨¡å‹ã€‚ **æ¨¡å‹è¯„ä¼°**ï¼Œå°†ä½¿ç”¨RKNN Toolkit2å·¥å…·é‡åŒ–å’Œåˆ†ææ¨¡å‹æ€§èƒ½ï¼ŒåŒ…æ‹¬ç²¾åº¦ã€è¿æ¿æ¨ç†æ€§èƒ½å’Œå†…å­˜å ç”¨ç­‰å…³é”®æŒ‡æ ‡ï¼Œ æ ¹æ®æ¨¡å‹çš„è¯„ä¼°å°è¯•ä¿®æ”¹å’Œä¼˜åŒ–æ¨¡å‹ï¼Œä¸€äº›æ¨¡å‹çš„ä¼˜åŒ–å¯ä»¥å‚è€ƒä¸‹ [RKNPU_User_Guide_RKNN_SDK](https://github.com/airockchip/rknn toolkit2/tree/master/doc) ã€‚ **æ¿ç«¯æ¨ç†**ï¼Œå°†è½¬æ¢çš„RKNNæ¨¡å‹éƒ¨ç½²åˆ°æ¿å¡ä¸Š,å…·ä½“å¯ä»¥æŸ¥çœ‹ä¸‹rknpuè¿è¡Œåº“å’Œ [RKNN Toolkit lite2](https://github.com/airockchip/rknn toolkit2/tree/master/rknn toolkit lite2) çš„ä½¿ç”¨ã€‚ > éœ€è¦ä½¿ç”¨RKLLMå·¥å…·æŠŠæ¨¡å‹è½¬æ¢ä¸ºRKLLMæ¨¡å‹ ## RKNN Toolkit2 **æ¨¡å‹è½¬æ¢**ï¼ŒToolkit lite2å·¥å…·å¯¼å…¥åŸå§‹çš„Caffeã€TensorFlowã€TensorFlow Liteã€ONNXã€Pytorchã€MXNetç­‰æ¨¡å‹è½¬æ¢æˆRKNNæ¨¡å‹()ï¼Œ ä¹Ÿæ”¯æŒå¯¼å…¥RKNNæ¨¡å‹ç„¶ååœ¨NPUå¹³å° ä¸ŠåŠ è½½æ¨ç†ç­‰ã€‚ **é‡åŒ–åŠŸèƒ½**ï¼Œæ”¯æŒå°†æµ®ç‚¹æ¨¡å‹é‡åŒ–ä¸ºå®šç‚¹æ¨¡å‹ï¼Œç›®å‰æ”¯æŒçš„é‡åŒ–æ–¹æ³•ä¸ºéå¯¹ç§°é‡åŒ–ï¼ˆasymmetric_quantized 8ï¼‰ï¼Œå¹¶æ”¯æŒæ··åˆé‡åŒ–åŠŸèƒ½ã€‚ **æ¨¡å‹æ¨ç†**ï¼Œèƒ½å¤Ÿåœ¨PCä¸Šæ¨¡æ‹ŸNPUè¿è¡ŒRKNNæ¨¡å‹å¹¶è·å–æ¨ç†ç»“æœï¼›æˆ–å°†RKNNæ¨¡å‹åˆ†å‘åˆ°æŒ‡å®šçš„NPUè®¾å¤‡ä¸Šè¿›è¡Œæ¨ç†å¹¶è·å–æ¨ç†ç»“æœã€‚ **æ€§èƒ½å’Œå†…å­˜è¯„ä¼°**ï¼Œè¿æ¥æ¿å¡ï¼Œå°†RKNNæ¨¡å‹åˆ†å‘åˆ°æŒ‡å®šNPUè®¾å¤‡ä¸Šè¿è¡Œï¼Œç„¶åè¯„ä¼°æ¨¡å‹åœ¨å®é™…è®¾å¤‡ä¸Šè¿è¡Œæ—¶çš„æ€§èƒ½å’Œå†…å­˜å ç”¨æƒ…å†µã€‚ **é‡åŒ–ç²¾åº¦åˆ†æ**ï¼Œè¯¥åŠŸèƒ½å°†ç»™å‡ºæ¨¡å‹é‡åŒ–åæ¯ä¸€å±‚æ¨ç†ç»“æœä¸æµ®ç‚¹æ¨¡å‹æ¨ç†ç»“æœçš„ä½™å¼¦è·ç¦»ï¼Œä»¥åˆ†æé‡åŒ–è¯¯å·®æ˜¯å¦‚ä½•å‡ºç°çš„ï¼Œä¸ºæé«˜é‡åŒ–æ¨¡å‹çš„ç²¾åº¦æä¾›æ€è·¯ã€‚ **æ¨¡å‹åŠ å¯†åŠŸèƒ½**ï¼Œä½¿ç”¨æŒ‡å®šçš„åŠ å¯†ç­‰çº§å°†RKNNæ¨¡å‹æ•´ä½“åŠ å¯†ï¼Œå› ä¸ºRKNNæ¨¡å‹çš„è§£å¯†æ˜¯åœ¨NPUé©±åŠ¨ä¸­å®Œæˆçš„ï¼Œæ‰€ä»¥ä½¿ç”¨åŠ å¯†æ¨¡å‹æ—¶ï¼Œä¸æ™®é€šRKNNæ¨¡å‹ä¸€æ ·åŠ è½½å³å¯ï¼ŒNPUé©±åŠ¨ä¼šè‡ªåŠ¨å¯¹å…¶è¿›è¡Œè§£å¯† ä½¿ç”¨Toolkit lite2ï¼Œå¯ä»¥è¿è¡Œåœ¨PCä¸Šï¼Œé€šè¿‡æ¨¡æ‹Ÿå™¨è¿è¡Œæ¨¡å‹ï¼Œç„¶åè¿›è¡Œæ¨ç†ï¼Œæˆ–è€…æ¨¡å‹è½¬æ¢ç­‰æ“ä½œï¼›ä¹Ÿå¯ä»¥è¿è¡Œåœ¨è¿æ¥çš„æ¿å¡NPUä¸Šï¼Œ å°†RKNNæ¨¡å‹ä¼ åˆ°NPUè®¾å¤‡ä¸Šè¿è¡Œï¼Œå†ä»NPUè®¾å¤‡ä¸Šè·å–æ¨ç†ç»“æœã€æ€§èƒ½ä¿¡æ¯ç­‰ç­‰ã€‚ ![image 20251202192600839](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/mac picture/image 20251202192600839.png) ## æ¨¡å‹ä¸‹è½½ 1. ä½¿ç”¨huggingfaceç½‘é¡µè¿›è¡Œä¸‹è½½ 2. ä½¿ç”¨huggingfaceå·¥å…·é‡Œé¢åœ¨çº¿ä¸‹è½½ ```bash pip3 install huggingface cli i https://mirrors.huaweicloud.com/repository/pypi/simple ``` å¯ä»¥é…ç½®åŠ é€ŸèŠ‚ç‚¹ï¼Œä¸‹è½½deepseekçš„huggingfaceæ ¼å¼æ¨¡å‹ï¼ˆæœ‰æ—¶å€™ä¹Ÿä¼šå¤±æ•ˆï¼Œå»ºè®®ç›´æ¥å®˜ç½‘ç›´æ¥ç‚¹å‡»ä¸‹è½½é”®æ¥ä¸‹è½½æ¨¡å‹ä¼šæ›´å¿«ï¼‰æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š `export HF_ENDPOINT https://hf mirror.com` æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä¸‹è½½DeepSeek R1 Distill Qwen 1.5Bæ¨¡å‹ `huggingface cli download deepseek ai/DeepSeek R1 Distill Qwen 1.5B local dir . local dir use symlinks` ## å·¥å…·RKNN Toolkit2 ç‰¹æ€§ç»´åº¦ **RKNN Toolkit2** **RKNN Toolkit Lite2** : : : **æ ¸å¿ƒå®šä½** **æ¨¡å‹è½¬æ¢ä¸è¯„ä¼°å·¥å…·** **æ¨¡å‹éƒ¨ç½²ä¸æ¨ç†å·¥å…·** **ä¸»è¦ç”¨é€”** åœ¨**PC**ä¸Šå°†å„ç§AIæ¨¡å‹è½¬æ¢ä¸ºRockchip NPUä¸“ç”¨çš„RKNNæ ¼å¼ï¼Œå¹¶è¿›è¡Œä¼˜åŒ–ã€è¯„ä¼°å’Œä»¿çœŸã€‚ åœ¨**åµŒå…¥å¼å¼€å‘æ¿**ä¸ŠåŠ è½½å’Œè¿è¡Œç”±RKNN Toolkit2ç”Ÿæˆçš„RKNNæ¨¡å‹ï¼Œæ‰§è¡ŒAIæ¨ç†ä»»åŠ¡ã€‚ **å…³é”®åŠŸèƒ½** æ¨¡å‹è½¬æ¢ã€é‡åŒ–ã€æ€§èƒ½/å†…å­˜è¯„ä¼°ã€ç²¾åº¦åˆ†æã€æ¨¡å‹åŠ å¯†ã€**PCç«¯ä»¿çœŸæ¨ç†**ã€‚ **ä»…åŒ…å«æ¨ç†åŠŸèƒ½**ï¼Œå¦‚åŠ è½½æ¨¡å‹ã€è¾“å…¥æ•°æ®å¤„ç†ã€æ‰§è¡Œæ¨ç†ã€è·å–ç»“æœã€‚ **è¿è¡Œå¹³å°** **x86æ¶æ„çš„PC**ï¼ˆå¦‚Ubuntuç³»ç»Ÿï¼‰ã€‚ **ARMæ¶æ„çš„Rockchipå¼€å‘æ¿**ï¼ˆå¦‚RK3588, RK3568ç­‰ï¼‰ã€‚ **APIç‰¹æ€§** æä¾›å®Œæ•´çš„Python APIï¼Œç”¨äºæ¨¡å‹æ„å»ºã€é…ç½®å’Œè½¬æ¢æµç¨‹ã€‚ æä¾›è½»é‡åŒ–çš„Python APIï¼Œä¸“æ³¨äºæ¨ç†æ¥å£ï¼Œä¾èµ–åº“æ›´å°‘ï¼Œæ›´é€‚åˆèµ„æºå—é™çš„ç¯å¢ƒã€‚ **ä¾èµ–å…³ç³»** æ˜¯ç”ŸæˆRKNNæ¨¡å‹çš„å¿…éœ€å·¥å…·ã€‚ **å¿…é¡»ä¾èµ–**ç”±RKNN Toolkit2ç”Ÿæˆçš„RKNNæ¨¡å‹æ–‡ä»¶æ‰èƒ½å·¥ä½œã€‚ ## RKLLM ### RKLLM **å®šä¹‰**ï¼š RKLLM æ˜¯ Rockchip ä¸“é—¨ä¸ºåœ¨ç«¯ä¾§è®¾å¤‡ï¼ˆå¦‚å¼€å‘æ¿ã€è¾¹ç¼˜è®¡ç®—ç›’å­ï¼‰ä¸Šéƒ¨ç½²å’Œè¿è¡Œ**å¤§è¯­è¨€æ¨¡å‹**è€Œæ¨å‡ºçš„ä¸€å¥—å·¥å…·é“¾ã€‚ **æ ¸å¿ƒåŠŸèƒ½**ï¼š **å¤§æ¨¡å‹é‡åŒ–ä¸å‹ç¼©**ï¼š ä¸“é—¨é’ˆå¯¹å‚æ•°é‡å·¨å¤§çš„ LLMï¼ˆå¦‚ LLaMAã€ChatGLMã€Qwen ç­‰ï¼‰è¿›è¡Œæè‡´çš„ä½æ¯”ç‰¹é‡åŒ–ï¼ˆå¦‚ INT4ï¼Œç”šè‡³æ›´ä½ï¼‰ï¼Œä»¥ä½¿å…¶èƒ½å¤Ÿå¡å…¥æœ‰é™çš„è®¾å¤‡å†…å­˜ä¸­ã€‚ **è¿è¡Œæ—¶ä¸ä¼˜åŒ–å¼•æ“**ï¼š æä¾›äº†ä¸€ä¸ªé«˜åº¦ä¼˜åŒ–çš„æ¨ç†å¼•æ“ï¼ˆRKLLM Runtimeï¼‰ï¼Œä¸“æ³¨äºå¤„ç† LLM ç‰¹æœ‰çš„è®¡ç®—æ¨¡å¼ï¼ˆå¦‚è‡ªå›å½’ç”Ÿæˆã€æ³¨æ„åŠ›æœºåˆ¶ï¼‰ï¼Œå¹¶é’ˆå¯¹ Rockchip èŠ¯ç‰‡çš„ CPUã€NPU è¿›è¡Œæ·±åº¦ä¼˜åŒ–ï¼Œä»¥æå‡ç”Ÿæˆé€Ÿåº¦ï¼ˆé™ä½ `time to first token` å’Œ `tokens per second`ï¼‰ã€‚ **ä¸“å±å·¥å…·é“¾**ï¼š æä¾›äº† `rkllm convert` ç­‰ä¸“ç”¨å·¥å…·ï¼Œå°† Hugging Face æ ¼å¼çš„ LLM è½¬æ¢ä¸ºå¯åœ¨è®¾å¤‡ä¸Šè¿è¡Œçš„æ ¼å¼ã€‚ **ä¸»è¦åº”ç”¨åœºæ™¯**ï¼š ç«¯ä¾§å¤§è¯­è¨€æ¨¡å‹åº”ç”¨ï¼š æ™ºèƒ½åº§èˆ±å¯¹è¯ã€AIoTè®¾å¤‡è¯­éŸ³åŠ©æ‰‹ã€æœ¬åœ°åŒ–æ–‡æ¡£å¤„ç†ã€ç¦»çº¿ç¿»è¯‘ç­‰ã€‚ **ç‰¹ç‚¹**ï¼š **é¢†åŸŸä¸“ç²¾**ï¼š ä¸ºè§£å†³â€œå¤§æ¨¡å‹â€ä¸â€œå°è®¾å¤‡â€ä¹‹é—´çš„çŸ›ç›¾è€Œç”Ÿã€‚ **æè‡´ä¼˜åŒ–**ï¼š è¿½æ±‚åœ¨æœ‰é™ç¡¬ä»¶èµ„æºä¸‹å®ç° LLM çš„å¯è¿è¡Œå’Œå¯ç”¨æ€§ã€‚ **æ–°å…´æŠ€æœ¯**ï¼š éšç€ç”Ÿæˆå¼ AI æµªæ½®å…´èµ·ï¼Œæ˜¯ RK å·¥å…·é“¾çš„é‡è¦è¡¥å……ã€‚ ç‰¹æ€§ RKNN RKLLM : : : **å®šä½** **é€šç”¨ NPU æ¨ç†å·¥å…·é“¾** **å¤§è¯­è¨€æ¨¡å‹ä¸“ç”¨éƒ¨ç½²å·¥å…·é“¾** **æ ¸å¿ƒç›®æ ‡** å°†å¹¿æ³›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹é«˜æ•ˆéƒ¨ç½²åˆ°ç‘èŠ¯å¾® NPU å°†å‚æ•°é‡å·¨å¤§çš„ LLM å‹ç¼©å¹¶ä¼˜åŒ–åˆ°ç«¯ä¾§è®¾å¤‡è¿è¡Œ **ä¸»è¦è¾“å…¥æ¨¡å‹** TensorFlow, PyTorch, ONNX, Caffe ç­‰æ ‡å‡†æ¨¡å‹ Hugging Face æ ¼å¼çš„ Transformer æ¶æ„ LLMï¼ˆå¦‚ LLaMA, Qwen, ChatGLMï¼‰ **å…³é”®æŠ€æœ¯** æ¨¡å‹è½¬æ¢ã€é€šç”¨ç®—å­ä¼˜åŒ–ã€å¼‚æ„è°ƒåº¦ **æä½æ¯”ç‰¹é‡åŒ–**ï¼ˆINT4/W4A4ï¼‰ã€KV Cache ä¼˜åŒ–ã€æ³¨æ„åŠ›è®¡ç®—ä¼˜åŒ– **è¾“å‡ºæ ¼å¼** `.rknn` æ–‡ä»¶ ç»è¿‡ç‰¹å®šæ ¼å¼å°è£…å’Œé‡åŒ–çš„æ¨¡å‹æ–‡ä»¶ **è¿è¡Œæ—¶** RKNN Runtime Library RKLLM Runtime Library **å…¸å‹åº”ç”¨** äººè„¸è¯†åˆ«ã€ç›®æ ‡æ£€æµ‹ã€å·¥ä¸šè´¨æ£€ ç«¯ä¾§æ™ºèƒ½å¯¹è¯ã€æœ¬åœ°çŸ¥è¯†åº“ã€AI Agent "},"/note/æœºå™¨å­¦ä¹ /rvæ¨¡å‹éƒ¨ç½²/2026-2-2-05-RKNNå¼€å‘.html":{"title":"RKNN","content":"# RKNN [rknpu2/doc/Rockchip_RKNPU_User_Guide_RKNN_API_V1.5.2_CN.pdf at master Â· rockchip linux/rknpu2](https://github.com/rockchip linux/rknpu2/blob/master/doc/Rockchip_RKNPU_User_Guide_RKNN_API_V1.5.2_CN.pdf) RKNN SDK ä¸ºå¸¦æœ‰ RKNPU çš„èŠ¯ç‰‡å¹³å°æä¾›ç¼–ç¨‹æ¥å£ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·éƒ¨ç½²ä½¿ç”¨ RKNN Toolkit2 å¯¼å‡ºçš„RKNNæ¨¡å‹ï¼ŒåŠ é€ŸAIåº”ç”¨çš„è½åœ° ä¸åŒå¹³å°å¯ä»¥ä½¿ç”¨çš„APIå‡½æ•° ![image 20260202161941326](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202602021619377.png) å¯ä»¥æŸ¥è¯¢çš„å‚æ•° ![image 20260202162003640](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202602021620681.png) ç›®å‰åœ¨RK3562/RK3566/RK3568/RK3588 ä¸Šæœ‰ä¸¤ç»„ API å¯ä»¥ä½¿ç”¨ï¼Œåˆ†åˆ«æ˜¯**é€šç”¨API æ¥å£**å’Œ**é›¶æ‹·è´æµç¨‹çš„APIæ¥å£**ï¼ŒRV1106/RV1103 åªæ”¯æŒé›¶æ‹·è´æµç¨‹çš„ API æ¥å£ã€‚ + é€šç”¨æ¥å£æ¯æ¬¡æ›´æ–°å¸§æ•°æ®ï¼Œéœ€è¦å°†å¤–éƒ¨æ¨¡å—åˆ†é…çš„æ•°æ®æ‹·è´åˆ°NPUè¿è¡Œæ—¶çš„è¾“å…¥å†…å­˜ + è€Œé›¶æ‹·è´æµç¨‹çš„æ¥å£ä¼šç›´æ¥ä½¿ç”¨é¢„å…ˆåˆ†é…çš„å†…å­˜ï¼ˆåŒ…æ‹¬NPUè¿è¡Œæ—¶åˆ›å»ºçš„æˆ–å¤–éƒ¨å…¶ä»–æ¡†æ¶åˆ›å»ºçš„ï¼Œæ¯” å¦‚DRMæ¡†æ¶ï¼‰ï¼Œå‡å°‘äº†å†…å­˜æ‹·è´çš„èŠ±é”€ã€‚ å½“ç”¨æˆ·è¾“å…¥æ•°æ®åªæœ‰è™šæ‹Ÿåœ°å€æ—¶ï¼Œåªèƒ½ä½¿ç”¨é€šç”¨APIæ¥ å£ï¼›å½“ç”¨æˆ·è¾“å…¥æ•°æ®æœ‰ç‰©ç†åœ°å€æˆ–fdæ—¶ï¼Œä¸¤ç»„æ¥å£éƒ½å¯ä»¥ä½¿ç”¨ã€‚é€šç”¨APIå’Œé›¶æ‹·è´APIä¸èƒ½æ··åˆ è°ƒç”¨ã€‚ ## é€šç”¨API + åˆå§‹åŒ– rknn_input ç»“æ„ä½“ + ä½¿ç”¨ rknn_inputs_set å‡½æ•°è®¾ç½®æ¨¡å‹è¾“å…¥ + ä½¿ç”¨ rknn_outputs_get å‡½æ•°è·å–æ¨ç†çš„è¾“å‡º ![image 20260202162422349](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202602021624391.png) ![image 20260202164433892](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202602021644935.png) åŠ è½½åŠ¨æ€å½¢çŠ¶è¾“å…¥RKNNæ¨¡å‹åï¼Œå¯ä»¥åœ¨è¿è¡Œæ—¶åŠ¨æ€ä¿®æ”¹è¾“ å…¥çš„å½¢çŠ¶ã€‚é¦–å…ˆï¼Œé€šè¿‡ rknn_query å¯ä»¥æŸ¥è¯¢ RKNN æ¨¡å‹æ”¯æŒçš„è¾“å…¥å½¢çŠ¶åˆ—è¡¨,æ¯ä¸ªè¾“å…¥æ”¯æŒ çš„å½¢çŠ¶åˆ—è¡¨ä¿¡æ¯ä»¥ rknn_input_range ç»“æ„ä½“å½¢å¼è¿”å›ï¼Œå®ƒåŒ…å«äº†æ¯ä¸ªè¾“å…¥çš„åç§°ã€æ•°æ®å¸ƒå±€ ä¿¡æ¯ã€å½¢çŠ¶ä¸ªæ•°ä»¥åŠå…·ä½“å½¢çŠ¶ã€‚æ¥ç€ï¼Œé€šè¿‡è°ƒç”¨ rknn_set_input_shapes æ¥å£ï¼Œä¼ å…¥åŒ…å«æ¯ä¸ª è¾“å…¥å½¢çŠ¶ä¿¡æ¯çš„rknn_tensor_attr æ•°ç»„æŒ‡é’ˆå¯ä»¥è®¾ç½®å½“å‰æ¨ç†ä½¿ç”¨çš„å½¢çŠ¶ã€‚åœ¨è®¾ç½®è¾“å…¥å½¢çŠ¶åï¼Œ å¯ä»¥å†æ¬¡è°ƒç”¨rknn_query æŸ¥è¯¢å½“å‰è®¾ç½®æˆåŠŸåçš„è¾“å…¥å’Œè¾“å‡ºå½¢çŠ¶ã€‚æœ€åï¼ŒæŒ‰ç…§æ™®é€šAPIæµç¨‹ å®Œæˆæ¨ç†ã€‚æ¯æ¬¡åˆ‡æ¢è¾“å…¥å½¢çŠ¶æ—¶ï¼Œéœ€è¦å†è®¾ç½®ä¸€æ¬¡æ–°çš„å½¢çŠ¶ï¼Œå‡†å¤‡æ–°å½¢çŠ¶å¤§å°çš„æ•°æ®å¹¶å†æ¬¡ è°ƒç”¨rknn_inputs_set æ¥å£ã€‚ ### API + rknn_init rknn_initåˆå§‹åŒ–å‡½æ•°å°†åˆ›å»ºrknn_contextå¯¹è±¡ã€åŠ è½½RKNNæ¨¡å‹ä»¥åŠæ ¹æ®flagå’Œ rknn_init_extendç»“æ„ä½“æ‰§è¡Œç‰¹å®šçš„åˆå§‹åŒ–è¡Œä¸º ## é›¶æ‹·è´API + åˆ†é…å†…å­˜åä½¿ç”¨å†…å­˜ä¿¡æ¯åˆå§‹åŒ–rknn_tensor_memoryç»“æ„ä½“ + æ¨ç†å‰åˆ›å»ºå¹¶è®¾ç½®è¯¥ç»“æ„ä½“ + æ¨ç†åè¯»å–è¯¥ç»“æ„ä½“ä¸­çš„å†…å­˜ä¿¡æ¯ ### è¿è¡Œæ—¶åˆ†é… ![image 20260202162710240](https://picture 01 1316374204.cos.ap beijing.myqcloud.com/lenovo picture/202602021627281.png) > RGAï¼ˆRaster Graphic Acceleratorï¼‰æ˜¯**ç‘èŠ¯å¾®ï¼ˆRockchipï¼‰** èŠ¯ç‰‡å†…ç½®çš„**å…‰æ …å›¾å½¢åŠ é€Ÿå™¨**ï¼Œæ˜¯ä¸“é—¨ä¸ºå›¾åƒå¤„ç†ä¼˜åŒ–çš„ç¡¬ä»¶æ¨¡å— > >"}}